From 74f5ec1d37a8da48b9f4ea093348f065b6ed5f7e Mon Sep 17 00:00:00 2001
From: Yuantian Tang <andy.tang@nxp.com>
Date: Wed, 28 Sep 2022 13:44:06 +0800
Subject: [PATCH 065/274] LF-6249-2 gpu: imx: lcdifv3: Add i.MX93 LCDIFv3
 display controller support

This patch adds i.MX93 LCDIFv3 display controller support.
A compatible string for i.MX93 LCDIFv3 is added in the driver.
Also, check of_id->data before dereferencing it because it is
NULL for i.MX93 LCDIFv3.

Cc: Sandor Yu <Sandor.yu@nxp.com>
Reviewed-by: Sandor Yu <Sandor.yu@nxp.com>
Signed-off-by: Liu Ying <victor.liu@nxp.com>
---
 drivers/gpu/imx/Kconfig                       |   19 +
 drivers/gpu/imx/Makefile                      |    8 +
 drivers/gpu/imx/dpu-blit/Kconfig              |    5 +
 drivers/gpu/imx/dpu-blit/Makefile             |    5 +
 drivers/gpu/imx/dpu-blit/dpu-blit-registers.h |  283 ++
 drivers/gpu/imx/dpu-blit/dpu-blit.c           |  430 +++
 drivers/gpu/imx/dpu-blit/dpu-blit.h           |   47 +
 drivers/gpu/imx/dpu/Kconfig                   |    8 +
 drivers/gpu/imx/dpu/Makefile                  |    8 +
 drivers/gpu/imx/dpu/dpu-common.c              | 1333 +++++++++
 drivers/gpu/imx/dpu/dpu-constframe.c          |  253 ++
 drivers/gpu/imx/dpu/dpu-disengcfg.c           |  158 ++
 drivers/gpu/imx/dpu/dpu-extdst.c              |  521 ++++
 drivers/gpu/imx/dpu/dpu-fetchdecode.c         |  673 +++++
 drivers/gpu/imx/dpu/dpu-fetcheco.c            |  407 +++
 drivers/gpu/imx/dpu/dpu-fetchlayer.c          |  294 ++
 drivers/gpu/imx/dpu/dpu-fetchunit.c           |  346 +++
 drivers/gpu/imx/dpu/dpu-fetchwarp.c           |  305 ++
 drivers/gpu/imx/dpu/dpu-framegen.c            |  601 ++++
 drivers/gpu/imx/dpu/dpu-hscaler.c             |  386 +++
 drivers/gpu/imx/dpu/dpu-layerblend.c          |  346 +++
 drivers/gpu/imx/dpu/dpu-prv.h                 |  467 +++
 drivers/gpu/imx/dpu/dpu-sc-misc.c             |   93 +
 drivers/gpu/imx/dpu/dpu-signature.c           |  392 +++
 drivers/gpu/imx/dpu/dpu-store.c               |  157 ++
 drivers/gpu/imx/dpu/dpu-tcon.c                |  330 +++
 drivers/gpu/imx/dpu/dpu-vscaler.c             |  438 +++
 drivers/gpu/imx/imx8_dprc.c                   |  893 ++++++
 drivers/gpu/imx/imx8_pc.c                     |  218 ++
 drivers/gpu/imx/imx8_prg.c                    |  452 +++
 drivers/gpu/imx/ipu-v3/Kconfig                |   11 +
 drivers/gpu/imx/ipu-v3/Makefile               |   10 +
 drivers/gpu/imx/ipu-v3/ipu-common.c           | 1497 ++++++++++
 drivers/gpu/imx/ipu-v3/ipu-cpmem.c            |  976 +++++++
 drivers/gpu/imx/ipu-v3/ipu-csi.c              |  821 ++++++
 drivers/gpu/imx/ipu-v3/ipu-dc.c               |  425 +++
 drivers/gpu/imx/ipu-v3/ipu-di.c               |  748 +++++
 drivers/gpu/imx/ipu-v3/ipu-dmfc.c             |  214 ++
 drivers/gpu/imx/ipu-v3/ipu-dp.c               |  376 +++
 drivers/gpu/imx/ipu-v3/ipu-ic-csc.c           |  409 +++
 drivers/gpu/imx/ipu-v3/ipu-ic.c               |  761 +++++
 drivers/gpu/imx/ipu-v3/ipu-image-convert.c    | 2512 +++++++++++++++++
 drivers/gpu/imx/ipu-v3/ipu-pre.c              |  346 +++
 drivers/gpu/imx/ipu-v3/ipu-prg.c              |  483 ++++
 drivers/gpu/imx/ipu-v3/ipu-prv.h              |  274 ++
 drivers/gpu/imx/ipu-v3/ipu-smfc.c             |  202 ++
 drivers/gpu/imx/ipu-v3/ipu-vdi.c              |  234 ++
 drivers/gpu/imx/lcdif/Kconfig                 |    9 +
 drivers/gpu/imx/lcdif/Makefile                |    3 +
 drivers/gpu/imx/lcdif/lcdif-common.c          |  854 ++++++
 drivers/gpu/imx/lcdif/lcdif-regs.h            |  153 +
 drivers/gpu/imx/lcdifv3/Kconfig               |   10 +
 drivers/gpu/imx/lcdifv3/Makefile              |    3 +
 drivers/gpu/imx/lcdifv3/lcdifv3-common.c      |  866 ++++++
 drivers/gpu/imx/lcdifv3/lcdifv3-regs.h        |  150 +
 55 files changed, 22223 insertions(+)
 create mode 100644 drivers/gpu/imx/Kconfig
 create mode 100644 drivers/gpu/imx/Makefile
 create mode 100644 drivers/gpu/imx/dpu-blit/Kconfig
 create mode 100644 drivers/gpu/imx/dpu-blit/Makefile
 create mode 100644 drivers/gpu/imx/dpu-blit/dpu-blit-registers.h
 create mode 100644 drivers/gpu/imx/dpu-blit/dpu-blit.c
 create mode 100644 drivers/gpu/imx/dpu-blit/dpu-blit.h
 create mode 100644 drivers/gpu/imx/dpu/Kconfig
 create mode 100644 drivers/gpu/imx/dpu/Makefile
 create mode 100644 drivers/gpu/imx/dpu/dpu-common.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-constframe.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-disengcfg.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-extdst.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-fetchdecode.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-fetcheco.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-fetchlayer.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-fetchunit.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-fetchwarp.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-framegen.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-hscaler.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-layerblend.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-prv.h
 create mode 100644 drivers/gpu/imx/dpu/dpu-sc-misc.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-signature.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-store.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-tcon.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-vscaler.c
 create mode 100644 drivers/gpu/imx/imx8_dprc.c
 create mode 100644 drivers/gpu/imx/imx8_pc.c
 create mode 100644 drivers/gpu/imx/imx8_prg.c
 create mode 100644 drivers/gpu/imx/ipu-v3/Kconfig
 create mode 100644 drivers/gpu/imx/ipu-v3/Makefile
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-common.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-cpmem.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-csi.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-dc.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-di.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-dmfc.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-dp.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-ic-csc.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-ic.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-image-convert.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-pre.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-prg.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-prv.h
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-smfc.c
 create mode 100644 drivers/gpu/imx/ipu-v3/ipu-vdi.c
 create mode 100644 drivers/gpu/imx/lcdif/Kconfig
 create mode 100644 drivers/gpu/imx/lcdif/Makefile
 create mode 100644 drivers/gpu/imx/lcdif/lcdif-common.c
 create mode 100644 drivers/gpu/imx/lcdif/lcdif-regs.h
 create mode 100644 drivers/gpu/imx/lcdifv3/Kconfig
 create mode 100644 drivers/gpu/imx/lcdifv3/Makefile
 create mode 100644 drivers/gpu/imx/lcdifv3/lcdifv3-common.c
 create mode 100644 drivers/gpu/imx/lcdifv3/lcdifv3-regs.h

diff --git a/drivers/gpu/imx/Kconfig b/drivers/gpu/imx/Kconfig
new file mode 100644
index 000000000..0c9f14f02
--- /dev/null
+++ b/drivers/gpu/imx/Kconfig
@@ -0,0 +1,19 @@
+source "drivers/gpu/imx/ipu-v3/Kconfig"
+source "drivers/gpu/imx/dpu/Kconfig"
+source "drivers/gpu/imx/dpu-blit/Kconfig"
+source "drivers/gpu/imx/lcdif/Kconfig"
+source "drivers/gpu/imx/lcdifv3/Kconfig"
+config IMX8_PC
+	tristate
+	default y if IMX_DPU_CORE=y
+	default m if IMX_DPU_CORE=m
+
+config IMX8_PRG
+	tristate
+	default y if IMX_DPU_CORE=y
+	default m if IMX_DPU_CORE=m
+
+config IMX8_DPRC
+	tristate
+	default y if IMX_DPU_CORE=y
+	default m if IMX_DPU_CORE=m
diff --git a/drivers/gpu/imx/Makefile b/drivers/gpu/imx/Makefile
new file mode 100644
index 000000000..3c08def34
--- /dev/null
+++ b/drivers/gpu/imx/Makefile
@@ -0,0 +1,8 @@
+obj-$(CONFIG_IMX_IPUV3_CORE)	+= ipu-v3/
+obj-$(CONFIG_IMX_DPU_CORE)	+= dpu/
+obj-$(CONFIG_IMX_DPU_BLIT)      += dpu-blit/
+obj-$(CONFIG_IMX_LCDIF_CORE)    += lcdif/
+obj-$(CONFIG_IMX_LCDIFV3_CORE)  += lcdifv3/
+obj-$(CONFIG_IMX8_PC)	+= imx8_pc.o
+obj-$(CONFIG_IMX8_PRG)	+= imx8_prg.o
+obj-$(CONFIG_IMX8_DPRC)	+= imx8_dprc.o
diff --git a/drivers/gpu/imx/dpu-blit/Kconfig b/drivers/gpu/imx/dpu-blit/Kconfig
new file mode 100644
index 000000000..d71d9a7f9
--- /dev/null
+++ b/drivers/gpu/imx/dpu-blit/Kconfig
@@ -0,0 +1,5 @@
+config IMX_DPU_BLIT
+	tristate
+	depends on IMX_DPU_CORE
+	default y if IMX_DPU_CORE=y
+	default m if IMX_DPU_CORE=m
diff --git a/drivers/gpu/imx/dpu-blit/Makefile b/drivers/gpu/imx/dpu-blit/Makefile
new file mode 100644
index 000000000..6d06b88b9
--- /dev/null
+++ b/drivers/gpu/imx/dpu-blit/Makefile
@@ -0,0 +1,5 @@
+ccflags-y += -I $(srctree)/$(src)/../dpu/
+
+imx-dpu-blit-objs := dpu-blit.o
+
+obj-$(CONFIG_IMX_DPU_BLIT) += imx-dpu-blit.o
diff --git a/drivers/gpu/imx/dpu-blit/dpu-blit-registers.h b/drivers/gpu/imx/dpu-blit/dpu-blit-registers.h
new file mode 100644
index 000000000..3d86b272e
--- /dev/null
+++ b/drivers/gpu/imx/dpu-blit/dpu-blit-registers.h
@@ -0,0 +1,283 @@
+/*
+ * Copyright 2017 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#ifndef __DPU_BLIT_REGISTERS_H__
+#define __DPU_BLIT_REGISTERS_H__
+
+/* Registers Defination */
+#define COMCTRL_IPIDENTIFIER                       ((uint32_t)(0))
+
+#define PIXENGCFG_STORE9_TRIGGER                    ((uint32_t)(0x954))
+
+#define COMCTRL_USERINTERRUPTMASK0                  ((uint32_t)(0x48))
+#define COMCTRL_USERINTERRUPTMASK0_USERINTERRUPTMASK0_MASK 0xFFFFFFFFU
+#define COMCTRL_USERINTERRUPTENABLE0                ((uint32_t)(0x80))
+
+#define COMCTRL_INTERRUPTENABLE0                    ((uint32_t)(0x50))
+
+#define COMCTRL_INTERRUPTSTATUS0                    ((uint32_t)(0x68))
+#define COMCTRL_USERINTERRUPTSTATUS0                ((uint32_t)(0x98))
+
+#define COMCTRL_USERINTERRUPTCLEAR0                 ((uint32_t)(0x90))
+#define COMCTRL_USERINTERRUPTCLEAR0_USERINTERRUPTCLEAR0_MASK 0xFFFFFFFFU
+
+#define COMCTRL_INTERRUPTCLEAR0                     ((uint32_t)(0x60))
+#define COMCTRL_INTERRUPTCLEAR0_INTERRUPTCLEAR0_MASK 0xFFFFFFFFU
+
+
+#define PIXENGCFG_FETCHDECODE9_DYNAMIC              ((uint32_t)(0x828))
+#define PIXENGCFG_FETCHDECODE9_DYNAMIC_RESET_VALUE  0U
+
+#define PIXENGCFG_FETCHWARP9_DYNAMIC                ((uint32_t)(0x848))
+#define PIXENGCFG_FETCHWARP9_DYNAMIC_RESET_VALUE    0U
+
+#define PIXENGCFG_ROP9_DYNAMIC                      ((uint32_t)(0x868))
+#define PIXENGCFG_ROP9_DYNAMIC_RESET_VALUE          0x1000000U
+
+#define PIXENGCFG_MATRIX9_DYNAMIC                   ((uint32_t)(0x8A8))
+#define PIXENGCFG_MATRIX9_DYNAMIC_RESET_VALUE       0x1000000U
+
+#define PIXENGCFG_HSCALER9_DYNAMIC                  ((uint32_t)(0x8C8))
+#define PIXENGCFG_HSCALER9_DYNAMIC_RESET_VALUE      0x1000000U
+
+#define PIXENGCFG_VSCALER9_DYNAMIC                  ((uint32_t)(0x8E8))
+#define PIXENGCFG_VSCALER9_DYNAMIC_RESET_VALUE      0x1000000U
+
+#define PIXENGCFG_BLITBLEND9_DYNAMIC                ((uint32_t)(0x928))
+#define PIXENGCFG_BLITBLEND9_DYNAMIC_RESET_VALUE    0x1000000U
+
+#define PIXENGCFG_STORE9_STATIC                     ((uint32_t)(0x948))
+#define PIXENGCFG_STORE9_STATIC_RESET_VALUE         0x800010U
+#define PIXENGCFG_STORE9_STATIC_RESET_MASK          0xFFFFFFFFU
+#define PIXENGCFG_STORE9_STATIC_STORE9_SHDEN_MASK   0x1U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SHDEN_SHIFT  0U
+#define PIXENGCFG_STORE9_STATIC_STORE9_POWERDOWN_MASK 0x10U
+#define PIXENGCFG_STORE9_STATIC_STORE9_POWERDOWN_SHIFT 4U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SYNC_MODE_MASK 0x100U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SYNC_MODE_SHIFT 8U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SYNC_MODE__SINGLE 0U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SYNC_MODE__AUTO 0x1U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SW_RESET_MASK 0x800U
+#define PIXENGCFG_STORE9_STATIC_STORE9_SW_RESET_SHIFT 11U
+/* Field Value: STORE9_SW_RESET__OPERATION, Normal Operation  */
+#define PIXENGCFG_STORE9_STATIC_STORE9_SW_RESET__OPERATION 0U
+/* Field Value: STORE9_SW_RESET__SWRESET, Software Reset  */
+#define PIXENGCFG_STORE9_STATIC_STORE9_SW_RESET__SWRESET 0x1U
+#define PIXENGCFG_STORE9_STATIC_STORE9_DIV_MASK     0xFF0000U
+#define PIXENGCFG_STORE9_STATIC_STORE9_DIV_SHIFT    16U
+
+#define PIXENGCFG_STORE9_DYNAMIC                    ((uint32_t)(0x94C))
+
+#define FETCHDECODE9_STATICCONTROL                  ((uint32_t)(0x1008))
+#define FETCHDECODE9_STATICCONTROL_OFFSET           ((uint32_t)(0x8))
+#define FETCHDECODE9_STATICCONTROL_RESET_VALUE      0U
+#define FETCHDECODE9_STATICCONTROL_SHDEN_MASK       0x1U
+#define FETCHDECODE9_STATICCONTROL_SHDEN_SHIFT      0U
+#define FETCHDECODE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_MASK 0xFF0000U
+#define FETCHDECODE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT 16U
+
+#define FETCHDECODE9_BURSTBUFFERMANAGEMENT          ((uint32_t)(0x100C))
+#define FETCHDECODE9_BASEADDRESS0                   ((uint32_t)(0x101C))
+#define FETCHDECODE9_SOURCEBUFFERATTRIBUTES0        ((uint32_t)(0x1020))
+#define FETCHDECODE9_SOURCEBUFFERDIMENSION0         ((uint32_t)(0x1024))
+#define FETCHDECODE9_COLORCOMPONENTBITS0            ((uint32_t)(0x1028))
+#define FETCHDECODE9_COLORCOMPONENTSHIFT0           ((uint32_t)(0x102C))
+#define FETCHDECODE9_LAYEROFFSET0                   ((uint32_t)(0x1030))
+#define FETCHDECODE9_CLIPWINDOWOFFSET0              ((uint32_t)(0x1034))
+#define FETCHDECODE9_CLIPWINDOWDIMENSIONS0          ((uint32_t)(0x1038))
+#define FETCHDECODE9_CONSTANTCOLOR0                 ((uint32_t)(0x103C))
+#define FETCHDECODE9_LAYERPROPERTY0                 ((uint32_t)(0x1040))
+#define FETCHDECODE9_FRAMEDIMENSIONS                ((uint32_t)(0x1044))
+#define FETCHDECODE9_FRAMERESAMPLING                ((uint32_t)(0x1048))
+#define FETCHDECODE9_CONTROL			    ((uint32_t)(0x1054))
+
+#define FETCHWARP9_STATICCONTROL                    ((uint32_t)(0x1808))
+#define FETCHWARP9_STATICCONTROL_OFFSET             ((uint32_t)(0x8))
+#define FETCHWARP9_STATICCONTROL_RESET_VALUE        0xFF000000U
+#define FETCHWARP9_STATICCONTROL_RESET_MASK         0xFFFFFFFFU
+#define FETCHWARP9_STATICCONTROL_SHDEN_MASK         0x1U
+#define FETCHWARP9_STATICCONTROL_SHDEN_SHIFT        0U
+#define FETCHWARP9_STATICCONTROL_BASEADDRESSAUTOUPDATE_MASK 0xFF0000U
+#define FETCHWARP9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT 16U
+#define FETCHWARP9_STATICCONTROL_SHDLDREQSTICKY_MASK 0xFF000000U
+#define FETCHWARP9_STATICCONTROL_SHDLDREQSTICKY_SHIFT 24U
+
+#define FETCHWARP9_BURSTBUFFERMANAGEMENT            ((uint32_t)(0x180C))
+#define FETCHWARP9_BASEADDRESS0                     ((uint32_t)(0x1810))
+#define FETCHWARP9_SOURCEBUFFERATTRIBUTES0          ((uint32_t)(0x1814))
+#define FETCHWARP9_SOURCEBUFFERDIMENSION0           ((uint32_t)(0x1818))
+#define FETCHWARP9_COLORCOMPONENTBITS0              ((uint32_t)(0x181C))
+#define FETCHWARP9_COLORCOMPONENTSHIFT0             ((uint32_t)(0x1820))
+#define FETCHWARP9_LAYEROFFSET0                     ((uint32_t)(0x1824))
+#define FETCHWARP9_CLIPWINDOWOFFSET0                ((uint32_t)(0x1828))
+#define FETCHWARP9_CLIPWINDOWDIMENSIONS0            ((uint32_t)(0x182C))
+#define FETCHWARP9_CONSTANTCOLOR0                   ((uint32_t)(0x1830))
+#define FETCHWARP9_LAYERPROPERTY0                   ((uint32_t)(0x1834))
+#define FETCHWARP9_FRAMEDIMENSIONS                  ((uint32_t)(0x1950))
+#define FETCHWARP9_FRAMERESAMPLING                  ((uint32_t)(0x1954))
+#define FETCHWARP9_CONTROL                          ((uint32_t)(0x1970))
+
+
+#define FETCHECO9_STATICCONTROL                     ((uint32_t)(0x1C08))
+#define FETCHECO9_STATICCONTROL_OFFSET              ((uint32_t)(0x8))
+#define FETCHECO9_STATICCONTROL_RESET_VALUE         0U
+#define FETCHECO9_STATICCONTROL_RESET_MASK          0xFFFFFFFFU
+#define FETCHECO9_STATICCONTROL_SHDEN_MASK          0x1U
+#define FETCHECO9_STATICCONTROL_SHDEN_SHIFT         0U
+#define FETCHECO9_STATICCONTROL_BASEADDRESSAUTOUPDATE_MASK 0xFF0000U
+#define FETCHECO9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT 16U
+
+#define FETCHECO9_BURSTBUFFERMANAGEMENT             ((uint32_t)(0x1C0C))
+#define FETCHECO9_BASEADDRESS0                      ((uint32_t)(0x1C10))
+#define FETCHECO9_SOURCEBUFFERATTRIBUTES0           ((uint32_t)(0x1C14))
+#define FETCHECO9_SOURCEBUFFERDIMENSION0            ((uint32_t)(0x1C18))
+#define FETCHECO9_COLORCOMPONENTBITS0               ((uint32_t)(0x1C1C))
+#define FETCHECO9_COLORCOMPONENTSHIFT0              ((uint32_t)(0x1C20))
+#define FETCHECO9_LAYEROFFSET0                      ((uint32_t)(0x1C24))
+#define FETCHECO9_CLIPWINDOWOFFSET0                 ((uint32_t)(0x1C28))
+#define FETCHECO9_CLIPWINDOWDIMENSIONS0             ((uint32_t)(0x1C2C))
+#define FETCHECO9_CONSTANTCOLOR0                    ((uint32_t)(0x1C30))
+#define FETCHECO9_LAYERPROPERTY0                    ((uint32_t)(0x1C34))
+#define FETCHECO9_FRAMEDIMENSIONS                   ((uint32_t)(0x1C38))
+#define FETCHECO9_FRAMERESAMPLING                   ((uint32_t)(0x1C3C))
+#define FETCHECO9_CONTROL                           ((uint32_t)(0x1C40))
+
+
+#define ROP9_STATICCONTROL                          ((uint32_t)(0x2008))
+#define ROP9_STATICCONTROL_OFFSET                   ((uint32_t)(0x8))
+#define ROP9_STATICCONTROL_RESET_VALUE              0U
+#define ROP9_STATICCONTROL_RESET_MASK               0xFFFFFFFFU
+#define ROP9_STATICCONTROL_SHDEN_MASK               0x1U
+#define ROP9_STATICCONTROL_SHDEN_SHIFT              0U
+
+#define ROP9_CONTROL                                ((uint32_t)(0x200C))
+
+#define MATRIX9_STATICCONTROL                       ((uint32_t)(0x2C08))
+#define MATRIX9_STATICCONTROL_OFFSET                ((uint32_t)(0x8))
+#define MATRIX9_STATICCONTROL_RESET_VALUE           0U
+#define MATRIX9_STATICCONTROL_RESET_MASK            0xFFFFFFFFU
+#define MATRIX9_STATICCONTROL_SHDEN_MASK            0x1U
+#define MATRIX9_STATICCONTROL_SHDEN_SHIFT           0U
+
+#define MATRIX9_CONTROL                             ((uint32_t)(0x2C0C))
+
+#define HSCALER9_SETUP1                             ((uint32_t)(0x300C))
+#define HSCALER9_SETUP2                             ((uint32_t)(0x3010))
+#define HSCALER9_CONTROL                            ((uint32_t)(0x3014))
+
+#define VSCALER9_STATICCONTROL                      ((uint32_t)(0x3408))
+#define VSCALER9_STATICCONTROL_OFFSET               ((uint32_t)(0x8))
+#define VSCALER9_STATICCONTROL_RESET_VALUE          0U
+#define VSCALER9_STATICCONTROL_RESET_MASK           0xFFFFFFFFU
+#define VSCALER9_STATICCONTROL_SHDEN_MASK           0x1U
+#define VSCALER9_STATICCONTROL_SHDEN_SHIFT          0U
+
+#define VSCALER9_SETUP1                             ((uint32_t)(0x340C))
+#define VSCALER9_SETUP2                             ((uint32_t)(0x3410))
+#define VSCALER9_SETUP3                             ((uint32_t)(0x3414))
+#define VSCALER9_SETUP4                             ((uint32_t)(0x3418))
+#define VSCALER9_SETUP5                             ((uint32_t)(0x341C))
+#define VSCALER9_CONTROL                            ((uint32_t)(0x3420))
+
+#define HSCALER9_STATICCONTROL                      ((uint32_t)(0x3008))
+#define HSCALER9_STATICCONTROL_OFFSET               ((uint32_t)(0x8))
+#define HSCALER9_STATICCONTROL_RESET_VALUE          0U
+#define HSCALER9_STATICCONTROL_RESET_MASK           0xFFFFFFFFU
+#define HSCALER9_STATICCONTROL_SHDEN_MASK           0x1U
+#define HSCALER9_STATICCONTROL_SHDEN_SHIFT          0U
+
+#define BLITBLEND9_STATICCONTROL                    ((uint32_t)(0x3C08))
+#define BLITBLEND9_STATICCONTROL_OFFSET             ((uint32_t)(0x8))
+#define BLITBLEND9_STATICCONTROL_RESET_VALUE        0U
+#define BLITBLEND9_STATICCONTROL_RESET_MASK         0xFFFFFFFFU
+#define BLITBLEND9_STATICCONTROL_SHDEN_MASK         0x1U
+#define BLITBLEND9_STATICCONTROL_SHDEN_SHIFT        0U
+
+#define BLITBLEND9_CONTROL                          ((uint32_t)(0x3C0C))
+#define BLITBLEND9_CONSTANTCOLOR                    ((uint32_t)(0x3C14))
+#define BLITBLEND9_COLORREDBLENDFUNCTION            ((uint32_t)(0x3C18))
+#define BLITBLEND9_COLORGREENBLENDFUNCTION          ((uint32_t)(0x3C1C))
+#define BLITBLEND9_COLORBLUEBLENDFUNCTION           ((uint32_t)(0x3C20))
+#define BLITBLEND9_ALPHABLENDFUNCTION               ((uint32_t)(0x3C24))
+#define BLITBLEND9_BLENDMODE1                       ((uint32_t)(0x3C28))
+#define BLITBLEND9_BLENDMODE2                       ((uint32_t)(0x3C2C))
+
+
+#define STORE9_STATICCONTROL                        ((uint32_t)(0x4008))
+#define STORE9_STATICCONTROL_OFFSET                 ((uint32_t)(0x8))
+#define STORE9_STATICCONTROL_RESET_VALUE            0U
+#define STORE9_STATICCONTROL_RESET_MASK             0xFFFFFFFFU
+#define STORE9_STATICCONTROL_SHDEN_MASK             0x1U
+#define STORE9_STATICCONTROL_SHDEN_SHIFT            0U
+#define STORE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_MASK 0x100U
+#define STORE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT 8U
+
+#define STORE9_BURSTBUFFERMANAGEMENT                ((uint32_t)(0x400C))
+#define STORE9_BASEADDRESS                          ((uint32_t)(0x4018))
+#define STORE9_DESTINATIONBUFFERATTRIBUTES          ((uint32_t)(0x401C))
+#define STORE9_DESTINATIONBUFFERDIMENSION           ((uint32_t)(0x4020))
+#define STORE9_FRAMEOFFSET                          ((uint32_t)(0x4024))
+#define STORE9_COLORCOMPONENTBITS                   ((uint32_t)(0x4028))
+#define STORE9_COLORCOMPONENTSHIFT                  ((uint32_t)(0x402C))
+#define STORE9_CONTROL                              ((uint32_t)(0x4030))
+
+#define STORE9_START                                ((uint32_t)(0x403C))
+
+/* pixengcfg */
+#define PIXENGCFG_CLKEN_MASK 0x3000000U
+#define PIXENGCFG_CLKEN_SHIFT 24U
+/* Field Value: _CLKEN__DISABLE, Clock for block is disabled  */
+#define PIXENGCFG_CLKEN__DISABLE 0U
+#define PIXENGCFG_CLKEN__AUTOMATIC 0x1U
+/* Field Value: _CLKEN__FULL, Clock for block is without gating  */
+#define PIXENGCFG_CLKEN__FULL 0x3U
+
+#define PIXENGCFG_DIVIDER_RESET 0x80
+
+
+/* command sequencer */
+#define CMDSEQ_HIF                                  ((uint32_t)(0x400))
+
+#define CMDSEQ_LOCKUNLOCKHIF                        ((uint32_t)(0x500))
+#define CMDSEQ_LOCKUNLOCKHIF_LOCKUNLOCKHIF__LOCK_KEY 0x5651F763U
+#define CMDSEQ_LOCKUNLOCKHIF_LOCKUNLOCKHIF__UNLOCK_KEY 0x691DB936U
+
+#define CMDSEQ_LOCKUNLOCK                           ((uint32_t)(0x580))
+#define CMDSEQ_LOCKUNLOCK_LOCKUNLOCK__LOCK_KEY      0x5651F763U
+#define CMDSEQ_LOCKUNLOCK_LOCKUNLOCK__UNLOCK_KEY    0x691DB936U
+
+#define CMDSEQ_BUFFERADDRESS                        ((uint32_t)(0x588))
+#define CMDSEQ_BUFFERSIZE                           ((uint32_t)(0x58C))
+
+#define CMDSEQ_CONTROL                              ((uint32_t)(0x594))
+#define CMDSEQ_CONTROL_OFFSET                       ((uint32_t)(0x194))
+#define CMDSEQ_CONTROL_RESET_VALUE                  0U
+#define CMDSEQ_CONTROL_RESET_MASK                   0xFFFFFFFFU
+#define CMDSEQ_CONTROL_CLRAXIW_MASK                 0x1U
+#define CMDSEQ_CONTROL_CLRAXIW_SHIFT                0U
+#define CMDSEQ_CONTROL_CLRRBUF_MASK                 0x4U
+#define CMDSEQ_CONTROL_CLRRBUF_SHIFT                2U
+#define CMDSEQ_CONTROL_CLRCMDBUF_MASK               0x8U
+#define CMDSEQ_CONTROL_CLRCMDBUF_SHIFT              3U
+#define CMDSEQ_CONTROL_CLEAR_MASK                   0x80000000U
+#define CMDSEQ_CONTROL_CLEAR_SHIFT                  31U
+
+#define CMDSEQ_STATUS                               ((uint32_t)(0x598))
+#define CMDSEQ_STATUS_OFFSET                        ((uint32_t)(0x198))
+#define CMDSEQ_STATUS_RESET_VALUE                   0x41000080U
+#define CMDSEQ_STATUS_RESET_MASK                    0xFFFFFFFFU
+#define CMDSEQ_STATUS_FIFOSPACE_MASK                0x1FFFFU
+#define CMDSEQ_STATUS_IDLE_MASK                     0x40000000U
+
+#endif
diff --git a/drivers/gpu/imx/dpu-blit/dpu-blit.c b/drivers/gpu/imx/dpu-blit/dpu-blit.c
new file mode 100644
index 000000000..03c63d000
--- /dev/null
+++ b/drivers/gpu/imx/dpu-blit/dpu-blit.c
@@ -0,0 +1,430 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include <video/imx8-prefetch.h>
+
+#include "dpu-blit.h"
+#include "dpu-blit-registers.h"
+#include "dpu-prv.h"
+
+void dpu_be_wait(struct dpu_bliteng *dpu_be);
+
+static inline u32 dpu_be_read(struct dpu_bliteng *dpu_be, unsigned int offset)
+{
+	return readl(dpu_be->base + offset);
+}
+
+static inline void dpu_be_write(struct dpu_bliteng *dpu_be, u32 value,
+	unsigned int offset)
+{
+	writel(value, dpu_be->base + offset);
+}
+
+static void dpu_cs_wait_fifo_space(struct dpu_bliteng *dpu_be)
+{
+	while ((dpu_be_read(dpu_be, CMDSEQ_STATUS) &
+		CMDSEQ_STATUS_FIFOSPACE_MASK) < CMDSEQ_FIFO_SPACE_THRESHOLD)
+		usleep_range(30, 50);
+}
+
+static void dpu_cs_wait_idle(struct dpu_bliteng *dpu_be)
+{
+	while ((dpu_be_read(dpu_be, CMDSEQ_STATUS) &
+		CMDSEQ_STATUS_IDLE_MASK) == 0x0)
+		mdelay(1);
+}
+
+static int dpu_cs_alloc_command_buffer(struct dpu_bliteng *dpu_be)
+{
+	/* command buffer need 32 bit address */
+	dpu_be->buffer_addr_virt =
+		alloc_pages_exact(COMMAND_BUFFER_SIZE,
+			GFP_KERNEL | GFP_DMA | GFP_DMA32 | __GFP_ZERO);
+	if (!dpu_be->buffer_addr_virt) {
+		dev_err(dpu_be->dev, "memory alloc failed for dpu command buffer\n");
+		return -ENOMEM;
+	}
+
+	dpu_be->buffer_addr_phy =
+		(u32)virt_to_phys(dpu_be->buffer_addr_virt);
+
+	return 0;
+}
+
+static void dpu_cs_static_setup(struct dpu_bliteng *dpu_be)
+{
+	dpu_cs_wait_idle(dpu_be);
+
+	/* LockUnlock and LockUnlockHIF */
+	dpu_be_write(dpu_be, CMDSEQ_LOCKUNLOCKHIF_LOCKUNLOCKHIF__UNLOCK_KEY,
+		CMDSEQ_LOCKUNLOCKHIF);
+	dpu_be_write(dpu_be, CMDSEQ_LOCKUNLOCK_LOCKUNLOCK__UNLOCK_KEY,
+		CMDSEQ_LOCKUNLOCK);
+
+	/* Control */
+	dpu_be_write(dpu_be, 1 << CMDSEQ_CONTROL_CLEAR_SHIFT,
+		CMDSEQ_CONTROL);
+
+	/* BufferAddress and BufferSize */
+	dpu_be_write(dpu_be, dpu_be->buffer_addr_phy, CMDSEQ_BUFFERADDRESS);
+	dpu_be_write(dpu_be, COMMAND_BUFFER_SIZE / WORD_SIZE,
+		CMDSEQ_BUFFERSIZE);
+}
+
+static struct dprc *
+dpu_be_dprc_get(struct dpu_soc *dpu, int dprc_id)
+{
+	struct dprc *dprc;
+
+	dprc = dprc_lookup_by_phandle(dpu->dev,
+				      "fsl,dpr-channels",
+				      dprc_id);
+
+	return dprc;
+}
+
+void dpu_be_configure_prefetch(struct dpu_bliteng *dpu_be,
+			       u32 width, u32 height,
+			       u32 x_offset, u32 y_offset,
+			       u32 stride, u32 format, u64 modifier,
+			       u64 baddr, u64 uv_addr)
+{
+	struct dprc *dprc;
+	bool dprc_en=false;
+
+	/* Enable DPR, dprc1 is connected to plane0 */
+	dprc = dpu_be->dprc[1];
+
+	/*
+	 * Force sync command sequncer in conditions:
+	 * 1. tile work with dprc/prg (baddr)
+	 * 2. switch tile to linear (!start)
+	 */
+	if (!dpu_be->start || baddr) {
+		dpu_be_wait(dpu_be);
+	}
+
+	dpu_be->sync = true;
+
+	if (baddr == 0x0) {
+		if (!dpu_be->start) {
+			dprc_disable(dprc);
+			dpu_be->start = true;
+		}
+		return;
+	}
+
+	if (dpu_be->modifier != modifier && !dpu_be->start) {
+		dprc_disable(dprc);
+		dprc_en = true;
+	}
+
+	dpu_be->modifier = modifier;
+
+	dprc_configure(dprc, 0,
+		       width, height,
+		       x_offset, y_offset,
+		       stride, format, modifier,
+		       baddr, uv_addr,
+		       dpu_be->start,
+		       dpu_be->start,
+		       false);
+
+	if (dpu_be->start || dprc_en) {
+		dprc_enable(dprc);
+	}
+
+	dprc_reg_update(dprc);
+
+	dpu_be->start = false;
+}
+EXPORT_SYMBOL(dpu_be_configure_prefetch);
+
+int dpu_bliteng_get_empty_instance(struct dpu_bliteng **dpu_be,
+	struct device *dev)
+{
+	if (!dpu_be || !dev)
+		return -EINVAL;
+
+	*dpu_be = devm_kzalloc(dev, sizeof(struct dpu_bliteng), GFP_KERNEL);
+	if (!(*dpu_be))
+		return -ENOMEM;
+
+	return 0;
+}
+EXPORT_SYMBOL(dpu_bliteng_get_empty_instance);
+
+u32 *dpu_bliteng_get_cmd_list(struct dpu_bliteng *dpu_be)
+{
+	return dpu_be->cmd_list;
+}
+EXPORT_SYMBOL(dpu_bliteng_get_cmd_list);
+
+s32 dpu_bliteng_get_id(struct dpu_bliteng *dpu_be)
+{
+	return dpu_be->id;
+}
+EXPORT_SYMBOL(dpu_bliteng_get_id);
+
+void dpu_bliteng_set_id(struct dpu_bliteng *dpu_be, int id)
+{
+	dpu_be->id = id;
+}
+EXPORT_SYMBOL(dpu_bliteng_set_id);
+
+void dpu_bliteng_set_dev(struct dpu_bliteng *dpu_be, struct device *dev)
+{
+	dpu_be->dev = dev;
+}
+EXPORT_SYMBOL(dpu_bliteng_set_dev);
+
+int dpu_be_get(struct dpu_bliteng *dpu_be)
+{
+	mutex_lock(&dpu_be->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpu_be_get);
+
+void dpu_be_put(struct dpu_bliteng *dpu_be)
+{
+	mutex_unlock(&dpu_be->mutex);
+}
+EXPORT_SYMBOL(dpu_be_put);
+
+int dpu_be_blit(struct dpu_bliteng *dpu_be,
+	u32 *cmdlist, u32 cmdnum)
+{
+	int i;
+
+	if (cmdnum > CMDSEQ_FIFO_SPACE_THRESHOLD) {
+		dev_err(dpu_be->dev, "dpu blit cmdnum[%d] should be less than %d !\n",
+			cmdnum, CMDSEQ_FIFO_SPACE_THRESHOLD);
+		return -EINVAL;
+	}
+	dpu_cs_wait_fifo_space(dpu_be);
+
+	for (i = 0; i < cmdnum; i++)
+		dpu_be_write(dpu_be, cmdlist[i], CMDSEQ_HIF);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpu_be_blit);
+
+#define STORE9_SEQCOMPLETE_IRQ		2U
+#define STORE9_SEQCOMPLETE_IRQ_MASK	(1U<<STORE9_SEQCOMPLETE_IRQ)
+void dpu_be_wait(struct dpu_bliteng *dpu_be)
+{
+	if (!dpu_be->sync) return;
+
+	dpu_cs_wait_fifo_space(dpu_be);
+
+	dpu_be_write(dpu_be, 0x14000001, CMDSEQ_HIF);
+	dpu_be_write(dpu_be, PIXENGCFG_STORE9_TRIGGER, CMDSEQ_HIF);
+	dpu_be_write(dpu_be, 0x10, CMDSEQ_HIF);
+
+	while ((dpu_be_read(dpu_be, COMCTRL_INTERRUPTSTATUS0) &
+		STORE9_SEQCOMPLETE_IRQ_MASK) == 0)
+		usleep_range(30, 50);
+
+	dpu_be_write(dpu_be, STORE9_SEQCOMPLETE_IRQ_MASK,
+		COMCTRL_INTERRUPTCLEAR0);
+
+	dpu_be->sync = false;
+}
+EXPORT_SYMBOL(dpu_be_wait);
+
+static void dpu_be_init_units(struct dpu_bliteng *dpu_be)
+{
+	u32 staticcontrol;
+	u32 pixengcfg_unit_dynamic;
+
+	staticcontrol =
+	1 << FETCHDECODE9_STATICCONTROL_SHDEN_SHIFT |
+	0 << FETCHDECODE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT |
+	FETCHDECODE9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, FETCHDECODE9_STATICCONTROL);
+
+	staticcontrol =
+	1 << FETCHWARP9_STATICCONTROL_SHDEN_SHIFT |
+	0 << FETCHWARP9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT |
+	FETCHWARP9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, FETCHWARP9_STATICCONTROL);
+
+	staticcontrol =
+	1 << FETCHECO9_STATICCONTROL_SHDEN_SHIFT |
+	0 << FETCHECO9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT |
+	FETCHECO9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, FETCHECO9_STATICCONTROL);
+
+	staticcontrol =
+	1 << HSCALER9_STATICCONTROL_SHDEN_SHIFT |
+	HSCALER9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, HSCALER9_STATICCONTROL);
+
+	staticcontrol =
+	1 << VSCALER9_STATICCONTROL_SHDEN_SHIFT |
+	VSCALER9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, VSCALER9_STATICCONTROL);
+
+	staticcontrol =
+	1 << ROP9_STATICCONTROL_SHDEN_SHIFT |
+	ROP9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, ROP9_STATICCONTROL);
+
+	staticcontrol =
+	1 << MATRIX9_STATICCONTROL_SHDEN_SHIFT |
+	MATRIX9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, MATRIX9_STATICCONTROL);
+
+	staticcontrol =
+	1 << BLITBLEND9_STATICCONTROL_SHDEN_SHIFT |
+	BLITBLEND9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, BLITBLEND9_STATICCONTROL);
+
+	staticcontrol =
+	1 << STORE9_STATICCONTROL_SHDEN_SHIFT |
+	0 << STORE9_STATICCONTROL_BASEADDRESSAUTOUPDATE_SHIFT |
+	STORE9_STATICCONTROL_RESET_VALUE;
+	dpu_be_write(dpu_be, staticcontrol, STORE9_STATICCONTROL);
+
+	/* Safety_Pixengcfg Dynamic */
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_FETCHDECODE9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_FETCHDECODE9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_FETCHWARP9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_FETCHWARP9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_ROP9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_ROP9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_MATRIX9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_MATRIX9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_HSCALER9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_HSCALER9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_VSCALER9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_VSCALER9_DYNAMIC);
+
+	pixengcfg_unit_dynamic =
+	PIXENGCFG_CLKEN__AUTOMATIC << PIXENGCFG_CLKEN_SHIFT |
+	PIXENGCFG_BLITBLEND9_DYNAMIC_RESET_VALUE;
+	dpu_be_write(dpu_be, pixengcfg_unit_dynamic,
+		PIXENGCFG_BLITBLEND9_DYNAMIC);
+}
+
+int dpu_bliteng_init(struct dpu_bliteng *dpu_bliteng)
+{
+	struct dpu_soc *dpu = dev_get_drvdata(dpu_bliteng->dev->parent);
+	struct platform_device *dpu_pdev =
+		container_of(dpu->dev, struct platform_device, dev);
+	struct resource *res;
+	unsigned long dpu_base;
+	void __iomem *base;
+	u32 *cmd_list;
+	int ret;
+
+	cmd_list = kzalloc(sizeof(*cmd_list) * CMDSEQ_FIFO_SPACE_THRESHOLD,
+			GFP_KERNEL);
+	if (!cmd_list)
+		return -ENOMEM;
+	dpu_bliteng->cmd_list = cmd_list;
+
+	res = platform_get_resource(dpu_pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENODEV;
+	dpu_base = res->start;
+
+	/* remap with bigger size */
+	base = devm_ioremap(dpu->dev, dpu_base, 64*SZ_1K);
+	dpu_bliteng->base = base;
+	dpu_bliteng->dpu = dpu;
+
+	mutex_init(&dpu_bliteng->mutex);
+
+	/* Init the uints used by blit engine */
+	/* Maybe this should be in dpu-common.c */
+	dpu_be_init_units(dpu_bliteng);
+
+	/* Init for command sequencer */
+	ret = dpu_cs_alloc_command_buffer(dpu_bliteng);
+	if (ret)
+		return ret;
+
+	dpu_cs_static_setup(dpu_bliteng);
+
+	/* DPR, each blit engine has two dprc, 0 & 1 */
+	dpu_bliteng->dprc[0] = dpu_be_dprc_get(dpu, 0);
+	dpu_bliteng->dprc[1] = dpu_be_dprc_get(dpu, 1);
+
+	dprc_disable(dpu_bliteng->dprc[0]);
+	dprc_disable(dpu_bliteng->dprc[1]);
+
+	dpu_bliteng->start = true;
+	dpu_bliteng->sync = false;
+
+	dpu_bliteng->modifier = 0;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dpu_bliteng_init);
+
+void dpu_bliteng_fini(struct dpu_bliteng *dpu_bliteng)
+{
+	/* LockUnlock and LockUnlockHIF */
+	dpu_be_write(dpu_bliteng, CMDSEQ_LOCKUNLOCKHIF_LOCKUNLOCKHIF__LOCK_KEY,
+		CMDSEQ_LOCKUNLOCKHIF);
+	dpu_be_write(dpu_bliteng, CMDSEQ_LOCKUNLOCK_LOCKUNLOCK__LOCK_KEY,
+		CMDSEQ_LOCKUNLOCK);
+
+	kfree(dpu_bliteng->cmd_list);
+
+	if (dpu_bliteng->buffer_addr_virt)
+		free_pages_exact(dpu_bliteng->buffer_addr_virt,
+				 COMMAND_BUFFER_SIZE);
+}
+EXPORT_SYMBOL_GPL(dpu_bliteng_fini);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("NXP Semiconductor");
+MODULE_DESCRIPTION("i.MX DPU BLITENG");
+MODULE_ALIAS("platform:imx-dpu-bliteng");
diff --git a/drivers/gpu/imx/dpu-blit/dpu-blit.h b/drivers/gpu/imx/dpu-blit/dpu-blit.h
new file mode 100644
index 000000000..a3fe17276
--- /dev/null
+++ b/drivers/gpu/imx/dpu-blit/dpu-blit.h
@@ -0,0 +1,47 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2018 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#ifndef __DPU_BLIT_H__
+#define __DPU_BLIT_H__
+
+#define COMMAND_BUFFER_SIZE	65536 /* up to 64k bytes */
+#define CMDSEQ_FIFO_SPACE_THRESHOLD   192
+#define WORD_SIZE   4
+
+struct dpu_bliteng {
+	struct device		*dev;
+	void __iomem *base;
+	s32 id;
+	struct mutex mutex;
+	s32 irq_store9_shdload;
+	s32 irq_store9_framecomplete;
+	s32 irq_store9_seqcomplete;
+
+	void *buffer_addr_virt;
+	u32 buffer_addr_phy;
+
+	u32 *cmd_list;
+
+	struct dpu_soc *dpu;
+
+	struct dprc *dprc[2];
+
+	bool start;
+	bool sync;
+
+	u64 modifier;
+};
+
+#endif
diff --git a/drivers/gpu/imx/dpu/Kconfig b/drivers/gpu/imx/dpu/Kconfig
new file mode 100644
index 000000000..d62891118
--- /dev/null
+++ b/drivers/gpu/imx/dpu/Kconfig
@@ -0,0 +1,8 @@
+config IMX_DPU_CORE
+	tristate "i.MX DPU core support"
+	depends on ARCH_MXC
+	select GENERIC_IRQ_CHIP
+	help
+	  Choose this if you have a Freescale i.MX8QM or i.MX8QXP system and
+	  want to use the Display Processing Unit. This option only enables
+	  DPU base support.
diff --git a/drivers/gpu/imx/dpu/Makefile b/drivers/gpu/imx/dpu/Makefile
new file mode 100644
index 000000000..5b568e998
--- /dev/null
+++ b/drivers/gpu/imx/dpu/Makefile
@@ -0,0 +1,8 @@
+obj-$(CONFIG_IMX_DPU_CORE) += imx-dpu-core.o
+
+imx-dpu-core-objs := dpu-common.o dpu-constframe.o dpu-disengcfg.o \
+		     dpu-extdst.o dpu-fetchdecode.o dpu-fetcheco.o \
+		     dpu-fetchlayer.o dpu-fetchwarp.o dpu-fetchunit.o \
+		     dpu-framegen.o dpu-hscaler.o dpu-layerblend.o \
+		     dpu-sc-misc.o dpu-signature.o dpu-store.o dpu-tcon.o \
+		     dpu-vscaler.o
diff --git a/drivers/gpu/imx/dpu/dpu-common.c b/drivers/gpu/imx/dpu/dpu-common.c
new file mode 100644
index 000000000..5599f4ce3
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-common.c
@@ -0,0 +1,1333 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+#include <linux/clk.h>
+#include <linux/fb.h>
+#include <linux/io.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/irqdomain.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+#include <linux/platform_device.h>
+#include <linux/pm_domain.h>
+#include <video/dpu.h>
+#include <video/imx8-pc.h>
+#include <video/imx8-prefetch.h>
+#include "dpu-prv.h"
+
+#define IMX_DPU_BLITENG_NAME "imx-drm-dpu-bliteng"
+
+static bool display_plane_video_proc = true;
+module_param(display_plane_video_proc, bool, 0444);
+MODULE_PARM_DESC(display_plane_video_proc,
+		 "Enable video processing for display [default=true]");
+
+#define DPU_CM_REG_DEFINE1(name1, name2)		\
+static inline u32 name1(const struct cm_reg_ofs *ofs)	\
+{							\
+	return ofs->name2;				\
+}
+
+#define DPU_CM_REG_DEFINE2(name1, name2)		\
+static inline u32 name1(const struct cm_reg_ofs *ofs,	\
+			unsigned int n)			\
+{							\
+	return ofs->name2 + (4 * n);			\
+}
+
+DPU_CM_REG_DEFINE1(LOCKUNLOCK, lockunlock);
+DPU_CM_REG_DEFINE1(LOCKSTATUS, lockstatus);
+DPU_CM_REG_DEFINE2(USERINTERRUPTMASK, userinterruptmask);
+DPU_CM_REG_DEFINE2(INTERRUPTENABLE, interruptenable);
+DPU_CM_REG_DEFINE2(INTERRUPTPRESET, interruptpreset);
+DPU_CM_REG_DEFINE2(INTERRUPTCLEAR, interruptclear);
+DPU_CM_REG_DEFINE2(INTERRUPTSTATUS, interruptstatus);
+DPU_CM_REG_DEFINE2(USERINTERRUPTENABLE, userinterruptenable);
+DPU_CM_REG_DEFINE2(USERINTERRUPTPRESET, userinterruptpreset);
+DPU_CM_REG_DEFINE2(USERINTERRUPTCLEAR, userinterruptclear);
+DPU_CM_REG_DEFINE2(USERINTERRUPTSTATUS, userinterruptstatus);
+DPU_CM_REG_DEFINE1(GENERALPURPOSE, generalpurpose);
+
+static inline u32 dpu_cm_read(struct dpu_soc *dpu, unsigned int offset)
+{
+	return readl(dpu->cm_reg + offset);
+}
+
+static inline void dpu_cm_write(struct dpu_soc *dpu,
+				unsigned int offset, u32 value)
+{
+	writel(value, dpu->cm_reg + offset);
+}
+
+/* Constant Frame Unit */
+static const unsigned long cf_ofss[] = {0x4400, 0x5400, 0x4c00, 0x5c00};
+static const unsigned long cf_pec_ofss[] = {0x960, 0x9e0, 0x9a0, 0xa20};
+
+/* Display Engine Configuration Unit */
+static const unsigned long dec_ofss[] = {0xb400, 0xb420};
+
+/* External Destination Unit */
+static const unsigned long ed_ofss[] = {0x4800, 0x5800, 0x5000, 0x6000};
+static const unsigned long ed_pec_ofss[] = {0x980, 0xa00, 0x9c0, 0xa40};
+
+/* Fetch Decode Unit */
+static const unsigned long fd_ofss[] = {0x6c00, 0x7800};
+static const unsigned long fd_pec_ofss[] = {0xa80, 0xaa0};
+
+/* Fetch ECO Unit */
+static const unsigned long fe_ofss[] = {0x7400, 0x8000, 0x6800, 0x1c00};
+static const unsigned long fe_pec_ofss[] = {0xa90, 0xab0, 0xa70, 0x850};
+
+/* Frame Generator Unit */
+static const unsigned long fg_ofss[] = {0xb800, 0xd400};
+
+/* Fetch Layer Unit */
+static const unsigned long fl_ofss[] = {0x8400};
+static const unsigned long fl_pec_ofss[] = {0xac0};
+
+/* Fetch Warp Unit */
+static const unsigned long fw_ofss[] = {0x6400};
+static const unsigned long fw_pec_ofss[] = {0xa60};
+
+/* Horizontal Scaler Unit */
+static const unsigned long hs_ofss[] = {0x9000, 0x9c00, 0x3000};
+static const unsigned long hs_pec_ofss[] = {0xb00, 0xb60, 0x8c0};
+
+/* Layer Blend Unit */
+static const unsigned long lb_ofss[] = {0xa400, 0xa800, 0xac00, 0xb000};
+static const unsigned long lb_pec_ofss[] = {0xba0, 0xbc0, 0xbe0, 0xc00};
+
+/* Signature Unit */
+static const unsigned long sig_ofss[] = {0xd000, 0xec00};
+
+/* Store Unit */
+static const unsigned long st_ofss[] = {0x4000};
+static const unsigned long st_pec_ofss[] = {0x940};
+
+/* Timing Controller Unit */
+static const unsigned long tcon_ofss[] = {0xcc00, 0xe800};
+
+/* Vertical Scaler Unit */
+static const unsigned long vs_ofss[] = {0x9400, 0xa000, 0x3400};
+static const unsigned long vs_pec_ofss[] = {0xb20, 0xb80, 0x8e0};
+
+static const struct dpu_unit _cfs = {
+	.name = "ConstFrame",
+	.num = ARRAY_SIZE(cf_ids),
+	.ids = cf_ids,
+	.pec_ofss = cf_pec_ofss,
+	.ofss = cf_ofss,
+};
+
+static const struct dpu_unit _decs = {
+	.name = "DisEngCfg",
+	.num = ARRAY_SIZE(dec_ids),
+	.ids = dec_ids,
+	.pec_ofss = NULL,
+	.ofss = dec_ofss,
+};
+
+static const struct dpu_unit _eds = {
+	.name = "ExtDst",
+	.num = ARRAY_SIZE(ed_ids),
+	.ids = ed_ids,
+	.pec_ofss = ed_pec_ofss,
+	.ofss = ed_ofss,
+};
+
+static const struct dpu_unit _fds = {
+	.name = "FetchDecode",
+	.num = ARRAY_SIZE(fd_ids),
+	.ids = fd_ids,
+	.pec_ofss = fd_pec_ofss,
+	.ofss = fd_ofss,
+	.dprc_ids = fd_dprc_ids,
+};
+
+static const struct dpu_unit _fes = {
+	.name = "FetchECO",
+	.num = ARRAY_SIZE(fe_ids),
+	.ids = fe_ids,
+	.pec_ofss = fe_pec_ofss,
+	.ofss = fe_ofss,
+};
+
+static const struct dpu_unit _fgs = {
+	.name = "FrameGen",
+	.num = ARRAY_SIZE(fg_ids),
+	.ids = fg_ids,
+	.pec_ofss = NULL,
+	.ofss = fg_ofss,
+};
+
+static const struct dpu_unit _fls = {
+	.name = "FetchLayer",
+	.num = ARRAY_SIZE(fl_ids),
+	.ids = fl_ids,
+	.pec_ofss = fl_pec_ofss,
+	.ofss = fl_ofss,
+	.dprc_ids = fl_dprc_ids,
+};
+
+static const struct dpu_unit _fws = {
+	.name = "FetchWarp",
+	.num = ARRAY_SIZE(fw_ids),
+	.ids = fw_ids,
+	.pec_ofss = fw_pec_ofss,
+	.ofss = fw_ofss,
+	.dprc_ids = fw_dprc_ids,
+};
+
+static const struct dpu_unit _hss = {
+	.name = "HScaler",
+	.num = ARRAY_SIZE(hs_ids),
+	.ids = hs_ids,
+	.pec_ofss = hs_pec_ofss,
+	.ofss = hs_ofss,
+};
+
+static const struct dpu_unit _lbs = {
+	.name = "LayerBlend",
+	.num = ARRAY_SIZE(lb_ids),
+	.ids = lb_ids,
+	.pec_ofss = lb_pec_ofss,
+	.ofss = lb_ofss,
+};
+
+static const struct dpu_unit _sigs = {
+	.name = "Signature",
+	.num = ARRAY_SIZE(sig_ids),
+	.ids = sig_ids,
+	.pec_ofss = NULL,
+	.ofss = sig_ofss,
+};
+
+static const struct dpu_unit _sts = {
+	.name = "Store",
+	.num = ARRAY_SIZE(st_ids),
+	.ids = st_ids,
+	.pec_ofss = st_pec_ofss,
+	.ofss = st_ofss,
+};
+
+static const struct dpu_unit _tcons = {
+	.name = "TCon",
+	.num = ARRAY_SIZE(tcon_ids),
+	.ids = tcon_ids,
+	.pec_ofss = NULL,
+	.ofss = tcon_ofss,
+};
+
+static const struct dpu_unit _vss = {
+	.name = "VScaler",
+	.num = ARRAY_SIZE(vs_ids),
+	.ids = vs_ids,
+	.pec_ofss = vs_pec_ofss,
+	.ofss = vs_ofss,
+};
+
+static const struct cm_reg_ofs _cm_reg_ofs = {
+	.ipidentifier = 0,
+	.lockunlock = 0x40,
+	.lockstatus = 0x44,
+	.userinterruptmask = 0x48,
+	.interruptenable = 0x50,
+	.interruptpreset = 0x58,
+	.interruptclear = 0x60,
+	.interruptstatus = 0x68,
+	.userinterruptenable = 0x80,
+	.userinterruptpreset = 0x88,
+	.userinterruptclear = 0x90,
+	.userinterruptstatus = 0x98,
+	.generalpurpose = 0x100,
+};
+
+static const unsigned long unused_irq[] = {0x00000000, 0xfffe0008};
+
+static const struct dpu_data dpu_data_qxp = {
+	.cm_ofs = 0x0,
+	.cfs = &_cfs,
+	.decs = &_decs,
+	.eds = &_eds,
+	.fds = &_fds,
+	.fes = &_fes,
+	.fgs = &_fgs,
+	.fls = &_fls,
+	.fws = &_fws,
+	.hss = &_hss,
+	.lbs = &_lbs,
+	.sigs = &_sigs,
+	.sts = &_sts,
+	.tcons = &_tcons,
+	.vss = &_vss,
+	.cm_reg_ofs = &_cm_reg_ofs,
+	.unused_irq = unused_irq,
+	.plane_src_mask = DPU_PLANE_SRC_FL0_ID | DPU_PLANE_SRC_FW2_ID |
+			  DPU_PLANE_SRC_FD0_ID | DPU_PLANE_SRC_FD1_ID,
+	.has_dual_ldb = true,
+	.syncmode_min_prate = UINT_MAX,	/* pc is unused */
+	.singlemode_max_width = UINT_MAX, 	/* pc is unused */
+};
+
+static const struct dpu_data dpu_data_qm = {
+	.cm_ofs = 0x0,
+	.cfs = &_cfs,
+	.decs = &_decs,
+	.eds = &_eds,
+	.fds = &_fds,
+	.fes = &_fes,
+	.fgs = &_fgs,
+	.fls = &_fls,
+	.fws = &_fws,
+	.hss = &_hss,
+	.lbs = &_lbs,
+	.sigs = &_sigs,
+	.sts = &_sts,
+	.tcons = &_tcons,
+	.vss = &_vss,
+	.cm_reg_ofs = &_cm_reg_ofs,
+	.unused_irq = unused_irq,
+	.plane_src_mask = DPU_PLANE_SRC_FL0_ID | DPU_PLANE_SRC_FW2_ID |
+			  DPU_PLANE_SRC_FD0_ID | DPU_PLANE_SRC_FD1_ID,
+	.has_dual_ldb = false,
+	.syncmode_min_prate = 300000,
+	.singlemode_max_width = 2560,
+	.master_stream_id = 1,
+};
+
+static const struct of_device_id dpu_dt_ids[] = {
+	{
+		.compatible = "fsl,imx8qxp-dpu",
+		.data = &dpu_data_qxp,
+	}, {
+		.compatible = "fsl,imx8qm-dpu",
+		.data = &dpu_data_qm,
+	}, {
+		/* sentinel */
+	}
+};
+MODULE_DEVICE_TABLE(of, dpu_dt_ids);
+
+unsigned int dpu_get_syncmode_min_prate(struct dpu_soc *dpu)
+{
+	return dpu->data->syncmode_min_prate;
+}
+EXPORT_SYMBOL_GPL(dpu_get_syncmode_min_prate);
+
+unsigned int dpu_get_singlemode_max_width(struct dpu_soc *dpu)
+{
+	return dpu->data->singlemode_max_width;
+}
+EXPORT_SYMBOL_GPL(dpu_get_singlemode_max_width);
+
+unsigned int dpu_get_master_stream_id(struct dpu_soc *dpu)
+{
+	return dpu->data->master_stream_id;
+}
+EXPORT_SYMBOL_GPL(dpu_get_master_stream_id);
+
+bool dpu_vproc_has_fetcheco_cap(u32 cap_mask)
+{
+	return !!(cap_mask & DPU_VPROC_CAP_FETCHECO);
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_has_fetcheco_cap);
+
+bool dpu_vproc_has_hscale_cap(u32 cap_mask)
+{
+	return !!(cap_mask & DPU_VPROC_CAP_HSCALE);
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_has_hscale_cap);
+
+bool dpu_vproc_has_vscale_cap(u32 cap_mask)
+{
+	return !!(cap_mask & DPU_VPROC_CAP_VSCALE);
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_has_vscale_cap);
+
+u32 dpu_vproc_get_fetcheco_cap(u32 cap_mask)
+{
+	return cap_mask & DPU_VPROC_CAP_FETCHECO;
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_get_fetcheco_cap);
+
+u32 dpu_vproc_get_hscale_cap(u32 cap_mask)
+{
+	return cap_mask & DPU_VPROC_CAP_HSCALE;
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_get_hscale_cap);
+
+u32 dpu_vproc_get_vscale_cap(u32 cap_mask)
+{
+	return cap_mask & DPU_VPROC_CAP_VSCALE;
+}
+EXPORT_SYMBOL_GPL(dpu_vproc_get_vscale_cap);
+
+int dpu_format_horz_chroma_subsampling(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+		return 2;
+	default:
+		return 1;
+	}
+}
+
+int dpu_format_vert_chroma_subsampling(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+		return 2;
+	default:
+		return 1;
+	}
+}
+
+int dpu_format_num_planes(u32 format)
+{
+	switch (format) {
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+	case DRM_FORMAT_NV24:
+	case DRM_FORMAT_NV42:
+		return 2;
+	default:
+		return 1;
+	}
+}
+
+int dpu_format_plane_width(int width, u32 format, int plane)
+{
+	if (plane >= dpu_format_num_planes(format))
+		return 0;
+
+	if (plane == 0)
+		return width;
+
+	return width / dpu_format_horz_chroma_subsampling(format);
+}
+
+int dpu_format_plane_height(int height, u32 format, int plane)
+{
+	if (plane >= dpu_format_num_planes(format))
+		return 0;
+
+	if (plane == 0)
+		return height;
+
+	return height / dpu_format_vert_chroma_subsampling(format);
+}
+
+static void dpu_detach_pm_domains(struct dpu_soc *dpu)
+{
+	if (dpu->pd_pll1_link && !IS_ERR(dpu->pd_pll1_link))
+		device_link_del(dpu->pd_pll1_link);
+	if (dpu->pd_pll1_dev && !IS_ERR(dpu->pd_pll1_dev))
+		dev_pm_domain_detach(dpu->pd_pll1_dev, true);
+
+	if (dpu->pd_pll0_link && !IS_ERR(dpu->pd_pll0_link))
+		device_link_del(dpu->pd_pll0_link);
+	if (dpu->pd_pll0_dev && !IS_ERR(dpu->pd_pll0_dev))
+		dev_pm_domain_detach(dpu->pd_pll0_dev, true);
+
+	if (dpu->pd_dc_link && !IS_ERR(dpu->pd_dc_link))
+		device_link_del(dpu->pd_dc_link);
+	if (dpu->pd_dc_dev && !IS_ERR(dpu->pd_dc_dev))
+		dev_pm_domain_detach(dpu->pd_dc_dev, true);
+
+	dpu->pd_dc_dev = NULL;
+	dpu->pd_dc_link = NULL;
+	dpu->pd_pll0_dev = NULL;
+	dpu->pd_pll0_link = NULL;
+	dpu->pd_pll1_dev = NULL;
+	dpu->pd_pll1_link = NULL;
+}
+
+static int dpu_attach_pm_domains(struct dpu_soc *dpu)
+{
+	struct device *dev = dpu->dev;
+	u32 flags = DL_FLAG_STATELESS | DL_FLAG_PM_RUNTIME | DL_FLAG_RPM_ACTIVE;
+	int ret = 0;
+
+	dpu->pd_dc_dev = dev_pm_domain_attach_by_name(dev, "dc");
+	if (IS_ERR(dpu->pd_dc_dev)) {
+		ret = PTR_ERR(dpu->pd_dc_dev);
+		dev_err(dev, "Failed to attach dc pd dev: %d\n", ret);
+		goto fail;
+	}
+	dpu->pd_dc_link = device_link_add(dev, dpu->pd_dc_dev, flags);
+	if (IS_ERR(dpu->pd_dc_link)) {
+		ret = PTR_ERR(dpu->pd_dc_link);
+		dev_err(dev, "Failed to add device link to dc pd dev: %d\n",
+			ret);
+		goto fail;
+	}
+
+	dpu->pd_pll0_dev = dev_pm_domain_attach_by_name(dev, "pll0");
+	if (IS_ERR(dpu->pd_pll0_dev)) {
+		ret = PTR_ERR(dpu->pd_pll0_dev);
+		dev_err(dev, "Failed to attach pll0 pd dev: %d\n", ret);
+		goto fail;
+	}
+	dpu->pd_pll0_link = device_link_add(dev, dpu->pd_pll0_dev, flags);
+	if (IS_ERR(dpu->pd_pll0_link)) {
+		ret = PTR_ERR(dpu->pd_pll0_link);
+		dev_err(dev, "Failed to add device link to pll0 pd dev: %d\n",
+			ret);
+		goto fail;
+	}
+
+	dpu->pd_pll1_dev = dev_pm_domain_attach_by_name(dev, "pll1");
+	if (IS_ERR(dpu->pd_pll1_dev)) {
+		ret = PTR_ERR(dpu->pd_pll1_dev);
+		dev_err(dev, "Failed to attach pll0 pd dev: %d\n", ret);
+		goto fail;
+	}
+	dpu->pd_pll1_link = device_link_add(dev, dpu->pd_pll1_dev, flags);
+	if (IS_ERR(dpu->pd_pll1_link)) {
+		ret = PTR_ERR(dpu->pd_pll1_link);
+		dev_err(dev, "Failed to add device link to pll1 pd dev: %d\n",
+			ret);
+		goto fail;
+	}
+
+	return ret;
+fail:
+	dpu_detach_pm_domains(dpu);
+	return ret;
+}
+
+#define DPU_UNITS_ADDR_DBG(unit)					\
+{									\
+	const struct dpu_unit *us = data->unit##s;			\
+	int i;								\
+	for (i = 0; i < us->num; i++) {					\
+		if (us->pec_ofss) {					\
+			dev_dbg(&pdev->dev, "%s%d: pixengcfg @ 0x%08lx,"\
+				" unit @ 0x%08lx\n", us->name,		\
+				us->ids[i],				\
+				dpu_base + us->pec_ofss[i],		\
+				dpu_base + us->ofss[i]);		\
+		} else {						\
+			dev_dbg(&pdev->dev,				\
+				"%s%d: unit @ 0x%08lx\n", us->name,	\
+				us->ids[i], dpu_base + us->ofss[i]);	\
+		}							\
+	}								\
+}
+
+static void dpu_units_addr_dbg(struct dpu_soc *dpu,
+			struct platform_device *pdev, unsigned long dpu_base)
+{
+	const struct dpu_data *data = dpu->data;
+
+	dev_dbg(dpu->dev, "Common: 0x%08lx\n", dpu_base + data->cm_ofs);
+	DPU_UNITS_ADDR_DBG(cf);
+	DPU_UNITS_ADDR_DBG(dec);
+	DPU_UNITS_ADDR_DBG(ed);
+	DPU_UNITS_ADDR_DBG(fd);
+	DPU_UNITS_ADDR_DBG(fe);
+	DPU_UNITS_ADDR_DBG(fg);
+	DPU_UNITS_ADDR_DBG(fl);
+	DPU_UNITS_ADDR_DBG(fw);
+	DPU_UNITS_ADDR_DBG(hs);
+	DPU_UNITS_ADDR_DBG(lb);
+	DPU_UNITS_ADDR_DBG(sig);
+	DPU_UNITS_ADDR_DBG(st);
+	DPU_UNITS_ADDR_DBG(tcon);
+	DPU_UNITS_ADDR_DBG(vs);
+}
+
+static int dpu_get_irq(struct platform_device *pdev, struct dpu_soc *dpu)
+{
+#define DPU_GET_IRQ(name)						\
+{									\
+	dpu->irq_##name = platform_get_irq_byname(pdev, "" #name "");	\
+	dev_dbg(dpu->dev, "irq_" #name ": %d\n", dpu->irq_##name);	\
+	if (dpu->irq_##name < 0) {					\
+		dev_err(dpu->dev, "failed to get irq " #name "\n");	\
+		return dpu->irq_##name;					\
+	}								\
+}
+
+	DPU_GET_IRQ(extdst0_shdload);
+	DPU_GET_IRQ(extdst4_shdload);
+	DPU_GET_IRQ(extdst1_shdload);
+	DPU_GET_IRQ(extdst5_shdload);
+	DPU_GET_IRQ(disengcfg_shdload0);
+	DPU_GET_IRQ(disengcfg_framecomplete0);
+	DPU_GET_IRQ(sig0_shdload);
+	DPU_GET_IRQ(sig0_valid);
+	DPU_GET_IRQ(disengcfg_shdload1);
+	DPU_GET_IRQ(disengcfg_framecomplete1);
+	DPU_GET_IRQ(sig1_shdload);
+	DPU_GET_IRQ(sig1_valid);
+
+	return 0;
+}
+
+static void dpu_irq_handle(struct irq_desc *desc, enum dpu_irq irq)
+{
+	struct dpu_soc *dpu = irq_desc_get_handler_data(desc);
+	const struct dpu_data *data = dpu->data;
+	const struct cm_reg_ofs *ofs = data->cm_reg_ofs;
+	struct irq_chip *chip = irq_desc_get_chip(desc);
+	unsigned int virq;
+	u32 status;
+
+	chained_irq_enter(chip, desc);
+
+	status = dpu_cm_read(dpu, USERINTERRUPTSTATUS(ofs, irq / 32));
+	status &= dpu_cm_read(dpu, USERINTERRUPTENABLE(ofs, irq / 32));
+
+	if (status & BIT(irq % 32)) {
+		virq = irq_linear_revmap(dpu->domain, irq);
+		if (virq)
+			generic_handle_irq(virq);
+	}
+
+	chained_irq_exit(chip, desc);
+}
+
+#define DPU_IRQ_HANDLER_DEFINE(name1, name2)			\
+static void dpu_##name1##_irq_handler(struct irq_desc *desc)	\
+{								\
+	dpu_irq_handle(desc, IRQ_##name2);			\
+}
+
+DPU_IRQ_HANDLER_DEFINE(extdst0_shdload, EXTDST0_SHDLOAD)
+DPU_IRQ_HANDLER_DEFINE(extdst4_shdload, EXTDST4_SHDLOAD)
+DPU_IRQ_HANDLER_DEFINE(extdst1_shdload, EXTDST1_SHDLOAD)
+DPU_IRQ_HANDLER_DEFINE(extdst5_shdload, EXTDST5_SHDLOAD)
+DPU_IRQ_HANDLER_DEFINE(disengcfg_shdload0, DISENGCFG_SHDLOAD0)
+DPU_IRQ_HANDLER_DEFINE(disengcfg_framecomplete0, DISENGCFG_FRAMECOMPLETE0)
+DPU_IRQ_HANDLER_DEFINE(sig0_shdload, SIG0_SHDLOAD);
+DPU_IRQ_HANDLER_DEFINE(sig0_valid, SIG0_VALID);
+DPU_IRQ_HANDLER_DEFINE(disengcfg_shdload1, DISENGCFG_SHDLOAD1)
+DPU_IRQ_HANDLER_DEFINE(disengcfg_framecomplete1, DISENGCFG_FRAMECOMPLETE1)
+DPU_IRQ_HANDLER_DEFINE(sig1_shdload, SIG1_SHDLOAD);
+DPU_IRQ_HANDLER_DEFINE(sig1_valid, SIG1_VALID);
+
+int dpu_map_irq(struct dpu_soc *dpu, int irq)
+{
+	int virq = irq_linear_revmap(dpu->domain, irq);
+
+	if (!virq)
+		virq = irq_create_mapping(dpu->domain, irq);
+
+	return virq;
+}
+EXPORT_SYMBOL_GPL(dpu_map_irq);
+
+static int dpu_irq_init(struct dpu_soc *dpu)
+{
+	const struct dpu_data *data = dpu->data;
+	const struct cm_reg_ofs *ofs = data->cm_reg_ofs;
+	struct irq_chip_generic *gc;
+	struct irq_chip_type *ct;
+	int ret, i;
+
+	dpu->domain = irq_domain_add_linear(dpu->dev->of_node,
+					    dpu->irq_line_num,
+					    &irq_generic_chip_ops, dpu);
+	if (!dpu->domain) {
+		dev_err(dpu->dev, "failed to add irq domain\n");
+		return -ENODEV;
+	}
+
+	ret = irq_alloc_domain_generic_chips(dpu->domain, 32, 1, "DPU",
+					     handle_level_irq, 0, 0, 0);
+	if (ret < 0) {
+		dev_err(dpu->dev, "failed to alloc generic irq chips\n");
+		irq_domain_remove(dpu->domain);
+		return ret;
+	}
+
+	for (i = 0; i < dpu->irq_line_num; i += 32) {
+		/* Mask and clear all interrupts */
+		dpu_cm_write(dpu, USERINTERRUPTENABLE(ofs, i / 32), 0);
+		dpu_cm_write(dpu, USERINTERRUPTCLEAR(ofs, i / 32),
+					~data->unused_irq[i / 32]);
+		dpu_cm_write(dpu, INTERRUPTENABLE(ofs, i / 32), 0);
+		dpu_cm_write(dpu, INTERRUPTCLEAR(ofs, i / 32),
+					~data->unused_irq[i / 32]);
+
+		/* Set all interrupts to user mode */
+		dpu_cm_write(dpu, USERINTERRUPTMASK(ofs, i / 32),
+					~data->unused_irq[i / 32]);
+
+		gc = irq_get_domain_generic_chip(dpu->domain, i);
+		gc->reg_base = dpu->cm_reg;
+		gc->unused = data->unused_irq[i / 32];
+		ct = gc->chip_types;
+		ct->chip.irq_ack = irq_gc_ack_set_bit;
+		ct->chip.irq_mask = irq_gc_mask_clr_bit;
+		ct->chip.irq_unmask = irq_gc_mask_set_bit;
+		ct->regs.ack = USERINTERRUPTCLEAR(ofs, i / 32);
+		ct->regs.mask = USERINTERRUPTENABLE(ofs, i / 32);
+	}
+
+#define DPU_IRQ_CHIP_PM_GET(name)					\
+{									\
+	ret = irq_chip_pm_get(irq_get_irq_data(dpu->irq_##name));	\
+	if (ret < 0) {							\
+		dev_err(dpu->dev,					\
+			"failed to get irq chip PM for irq%d %d\n",	\
+						dpu->irq_##name, ret);	\
+		goto pm_get_rollback;					\
+	}								\
+	dpu->irq_chip_pm_get_##name = true;				\
+}
+
+	DPU_IRQ_CHIP_PM_GET(extdst0_shdload);
+	DPU_IRQ_CHIP_PM_GET(extdst4_shdload);
+	DPU_IRQ_CHIP_PM_GET(extdst1_shdload);
+	DPU_IRQ_CHIP_PM_GET(extdst5_shdload);
+	DPU_IRQ_CHIP_PM_GET(disengcfg_shdload0);
+	DPU_IRQ_CHIP_PM_GET(disengcfg_framecomplete0);
+	DPU_IRQ_CHIP_PM_GET(sig0_shdload);
+	DPU_IRQ_CHIP_PM_GET(sig0_valid);
+	DPU_IRQ_CHIP_PM_GET(disengcfg_shdload1);
+	DPU_IRQ_CHIP_PM_GET(disengcfg_framecomplete1);
+	DPU_IRQ_CHIP_PM_GET(sig1_shdload);
+	DPU_IRQ_CHIP_PM_GET(sig1_valid);
+
+#define DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(name)	\
+irq_set_chained_handler_and_data(dpu->irq_##name, dpu_##name##_irq_handler, dpu)
+
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(extdst0_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(extdst4_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(extdst1_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(extdst5_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(disengcfg_shdload0);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(disengcfg_framecomplete0);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(sig0_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(sig0_valid);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(disengcfg_shdload1);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(disengcfg_framecomplete1);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(sig1_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA1(sig1_valid);
+
+#define DPU_IRQ_CHIP_PM_PUT_CHECK(name)					\
+{									\
+	if (dpu->irq_chip_pm_get_##name) {				\
+		irq_chip_pm_put(irq_get_irq_data(dpu->irq_##name));	\
+		dpu->irq_chip_pm_get_##name = false;			\
+	}								\
+}
+
+	return 0;
+
+pm_get_rollback:
+	DPU_IRQ_CHIP_PM_PUT_CHECK(extdst0_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(extdst4_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(extdst1_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(extdst5_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(disengcfg_shdload0);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(disengcfg_framecomplete0);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(sig0_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(sig0_valid);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(disengcfg_shdload1);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(disengcfg_framecomplete1);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(sig1_shdload);
+	DPU_IRQ_CHIP_PM_PUT_CHECK(sig1_valid);
+
+	return ret;
+}
+
+static void dpu_irq_exit(struct dpu_soc *dpu)
+{
+	unsigned int i, irq;
+
+#define DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(name)	\
+irq_set_chained_handler_and_data(dpu->irq_##name, NULL, NULL)
+
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(extdst0_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(extdst4_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(extdst1_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(extdst5_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(disengcfg_shdload0);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(disengcfg_framecomplete0);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(sig0_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(sig0_valid);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(disengcfg_shdload1);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(disengcfg_framecomplete1);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(sig1_shdload);
+	DPU_IRQ_SET_CHAINED_HANDLER_AND_DATA2(sig1_valid);
+
+#define DPU_IRQ_CHIP_PM_PUT(name)				\
+{								\
+	irq_chip_pm_put(irq_get_irq_data(dpu->irq_##name));	\
+	dpu->irq_chip_pm_get_##name = false;			\
+}
+
+	DPU_IRQ_CHIP_PM_PUT(extdst0_shdload);
+	DPU_IRQ_CHIP_PM_PUT(extdst4_shdload);
+	DPU_IRQ_CHIP_PM_PUT(extdst1_shdload);
+	DPU_IRQ_CHIP_PM_PUT(extdst5_shdload);
+	DPU_IRQ_CHIP_PM_PUT(disengcfg_shdload0);
+	DPU_IRQ_CHIP_PM_PUT(disengcfg_framecomplete0);
+	DPU_IRQ_CHIP_PM_PUT(sig0_shdload);
+	DPU_IRQ_CHIP_PM_PUT(sig0_valid);
+	DPU_IRQ_CHIP_PM_PUT(disengcfg_shdload1);
+	DPU_IRQ_CHIP_PM_PUT(disengcfg_framecomplete1);
+	DPU_IRQ_CHIP_PM_PUT(sig1_shdload);
+	DPU_IRQ_CHIP_PM_PUT(sig1_valid);
+
+	for (i = 0; i < dpu->irq_line_num; i++) {
+		irq = irq_linear_revmap(dpu->domain, i);
+		if (irq)
+			irq_dispose_mapping(irq);
+	}
+
+	irq_domain_remove(dpu->domain);
+}
+
+#define _DPU_UNITS_INIT(unit)						\
+{									\
+	const struct dpu_unit *us = data->unit##s;			\
+	int i;								\
+									\
+	/* software check */						\
+	if (WARN_ON(us->num > ARRAY_SIZE(unit##_ids)))			\
+		return -EINVAL;						\
+									\
+	for (i = 0; i < us->num; i++)					\
+		_dpu_##unit##_init(dpu, us->ids[i]);			\
+}
+
+static int
+_dpu_submodules_init(struct dpu_soc *dpu, struct platform_device *pdev)
+{
+	const struct dpu_data *data = dpu->data;
+
+	_DPU_UNITS_INIT(cf);
+	_DPU_UNITS_INIT(dec);
+	_DPU_UNITS_INIT(ed);
+	_DPU_UNITS_INIT(fd);
+	_DPU_UNITS_INIT(fe);
+	_DPU_UNITS_INIT(fg);
+	_DPU_UNITS_INIT(fl);
+	_DPU_UNITS_INIT(fw);
+	_DPU_UNITS_INIT(hs);
+	_DPU_UNITS_INIT(lb);
+	_DPU_UNITS_INIT(sig);
+	_DPU_UNITS_INIT(st);
+	_DPU_UNITS_INIT(tcon);
+	_DPU_UNITS_INIT(vs);
+
+	return 0;
+}
+
+#define DPU_UNIT_INIT(dpu, base, unit, name, id, pec_ofs, ofs)		\
+{									\
+	int ret;							\
+	ret = dpu_##unit##_init((dpu),	(id),				\
+				(pec_ofs) ? (base) + (pec_ofs) : 0,	\
+				(base) + (ofs));			\
+	if (ret) {							\
+		dev_err((dpu)->dev, "init %s%d failed with %d\n",	\
+						(name), (id), ret);	\
+		return ret;						\
+	}								\
+}
+
+#define DPU_UNITS_INIT(unit)						\
+{									\
+	const struct dpu_unit *us = data->unit##s;			\
+	int i;								\
+									\
+	/* software check */						\
+	if (WARN_ON(us->num > ARRAY_SIZE(unit##_ids)))			\
+		return -EINVAL;						\
+									\
+	for (i = 0; i < us->num; i++)					\
+		DPU_UNIT_INIT(dpu, dpu_base, unit, us->name,		\
+			      us->ids[i],				\
+			      us->pec_ofss ? us->pec_ofss[i] : 0,	\
+			      us->ofss[i]);				\
+}
+
+static int dpu_submodules_init(struct dpu_soc *dpu,
+		struct platform_device *pdev, unsigned long dpu_base)
+{
+	const struct dpu_data *data = dpu->data;
+	const struct dpu_unit *fds = data->fds;
+	const struct dpu_unit *fls = data->fls;
+	const struct dpu_unit *fws = data->fws;
+	const struct dpu_unit *tcons = data->tcons;
+	struct dpu_fetchunit *fu;
+	struct dprc *dprc;
+	struct dpu_tcon *tcon;
+	struct pc *pc;
+	int i;
+
+	DPU_UNITS_INIT(cf);
+	DPU_UNITS_INIT(dec);
+	DPU_UNITS_INIT(ed);
+	DPU_UNITS_INIT(fd);
+	DPU_UNITS_INIT(fe);
+	DPU_UNITS_INIT(fg);
+	DPU_UNITS_INIT(fl);
+	DPU_UNITS_INIT(fw);
+	DPU_UNITS_INIT(hs);
+	DPU_UNITS_INIT(lb);
+	DPU_UNITS_INIT(sig);
+	DPU_UNITS_INIT(st);
+	DPU_UNITS_INIT(tcon);
+	DPU_UNITS_INIT(vs);
+
+	for (i = 0; i < fds->num; i++) {
+		dprc = dprc_lookup_by_phandle(dpu->dev, "fsl,dpr-channels",
+					      fds->dprc_ids[i]);
+		if (!dprc)
+			return -EPROBE_DEFER;
+
+		fu = dpu_fd_get(dpu, i);
+		fetchunit_get_dprc(fu, dprc);
+		dpu_fd_put(fu);
+	}
+
+	for (i = 0; i < fls->num; i++) {
+		dprc = dprc_lookup_by_phandle(dpu->dev, "fsl,dpr-channels",
+					      fls->dprc_ids[i]);
+		if (!dprc)
+			return -EPROBE_DEFER;
+
+		fu = dpu_fl_get(dpu, i);
+		fetchunit_get_dprc(fu, dprc);
+		dpu_fl_put(fu);
+	}
+
+	for (i = 0; i < fws->num; i++) {
+		dprc = dprc_lookup_by_phandle(dpu->dev, "fsl,dpr-channels",
+					      fws->dprc_ids[i]);
+		if (!dprc)
+			return -EPROBE_DEFER;
+
+		fu = dpu_fw_get(dpu, fw_ids[i]);
+		fetchunit_get_dprc(fu, dprc);
+		dpu_fw_put(fu);
+	}
+
+	pc = pc_lookup_by_phandle(dpu->dev, "fsl,pixel-combiner");
+	if (!pc)
+		return -EPROBE_DEFER;
+
+	for (i = 0; i < tcons->num; i++) {
+		tcon = dpu_tcon_get(dpu, i);
+		tcon_get_pc(tcon, pc);
+		dpu_tcon_put(tcon);
+	}
+
+	return 0;
+}
+
+static int platform_remove_devices_fn(struct device *dev, void *unused)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	platform_device_unregister(pdev);
+
+	return 0;
+}
+
+static void platform_device_unregister_children(struct platform_device *pdev)
+{
+	device_for_each_child(&pdev->dev, NULL, platform_remove_devices_fn);
+}
+
+struct dpu_platform_reg {
+	struct dpu_client_platformdata pdata;
+	const char *name;
+};
+
+static struct dpu_platform_reg client_reg[] = {
+	{
+		.pdata = {
+			.stream_id = 0,
+		},
+		.name = "imx-dpu-crtc",
+	}, {
+		.pdata = {
+			.stream_id = 1,
+		},
+		.name = "imx-dpu-crtc",
+	}, {
+		.pdata = { },
+		.name = IMX_DPU_BLITENG_NAME,
+	}
+};
+
+static DEFINE_MUTEX(dpu_client_id_mutex);
+static int dpu_client_id;
+
+static int dpu_get_plane_resource(struct dpu_soc *dpu,
+				  struct dpu_plane_res *res)
+{
+	const struct dpu_unit *fds = dpu->data->fds;
+	const struct dpu_unit *fls = dpu->data->fls;
+	const struct dpu_unit *fws = dpu->data->fws;
+	const struct dpu_unit *lbs = dpu->data->lbs;
+	struct dpu_plane_grp *grp = plane_res_to_grp(res);
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(res->ed); i++) {
+		res->ed[i] = dpu_ed_get(dpu, i);
+		if (IS_ERR(res->ed[i]))
+			return PTR_ERR(res->ed[i]);
+	}
+	for (i = 0; i < fds->num; i++) {
+		res->fd[i] = dpu_fd_get(dpu, i);
+		if (IS_ERR(res->fd[i]))
+			return PTR_ERR(res->fd[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->fe); i++) {
+		res->fe[i] = dpu_fe_get(dpu, i);
+		if (IS_ERR(res->fe[i]))
+			return PTR_ERR(res->fe[i]);
+		grp->hw_plane_fetcheco_num = ARRAY_SIZE(res->fe);
+	}
+	for (i = 0; i < fls->num; i++) {
+		res->fl[i] = dpu_fl_get(dpu, i);
+		if (IS_ERR(res->fl[i]))
+			return PTR_ERR(res->fl[i]);
+	}
+	for (i = 0; i < fws->num; i++) {
+		res->fw[i] = dpu_fw_get(dpu, fw_ids[i]);
+		if (IS_ERR(res->fw[i]))
+			return PTR_ERR(res->fw[i]);
+	}
+	/* HScaler could be shared with capture. */
+	if (display_plane_video_proc) {
+		for (i = 0; i < ARRAY_SIZE(res->hs); i++) {
+			res->hs[i] = dpu_hs_get(dpu, hs_ids[i]);
+			if (IS_ERR(res->hs[i]))
+				return PTR_ERR(res->hs[i]);
+		}
+		grp->hw_plane_hscaler_num = ARRAY_SIZE(res->hs);
+	}
+	for (i = 0; i < lbs->num; i++) {
+		res->lb[i] = dpu_lb_get(dpu, i);
+		if (IS_ERR(res->lb[i]))
+			return PTR_ERR(res->lb[i]);
+	}
+	/* VScaler could be shared with capture. */
+	if (display_plane_video_proc) {
+		for (i = 0; i < ARRAY_SIZE(res->vs); i++) {
+			res->vs[i] = dpu_vs_get(dpu, vs_ids[i]);
+			if (IS_ERR(res->vs[i]))
+				return PTR_ERR(res->vs[i]);
+		}
+		grp->hw_plane_vscaler_num = ARRAY_SIZE(res->vs);
+	}
+
+	grp->hw_plane_num = fds->num + fls->num + fws->num;
+
+	return 0;
+}
+
+static void dpu_put_plane_resource(struct dpu_plane_res *res)
+{
+	struct dpu_plane_grp *grp = plane_res_to_grp(res);
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(res->ed); i++) {
+		if (!IS_ERR_OR_NULL(res->ed[i]))
+			dpu_ed_put(res->ed[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->fd); i++) {
+		if (!IS_ERR_OR_NULL(res->fd[i]))
+			dpu_fd_put(res->fd[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->fe); i++) {
+		if (!IS_ERR_OR_NULL(res->fe[i]))
+			dpu_fe_put(res->fe[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->fl); i++) {
+		if (!IS_ERR_OR_NULL(res->fl[i]))
+			dpu_fl_put(res->fl[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->fw); i++) {
+		if (!IS_ERR_OR_NULL(res->fw[i]))
+			dpu_fw_put(res->fw[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->hs); i++) {
+		if (!IS_ERR_OR_NULL(res->hs[i]))
+			dpu_hs_put(res->hs[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->lb); i++) {
+		if (!IS_ERR_OR_NULL(res->lb[i]))
+			dpu_lb_put(res->lb[i]);
+	}
+	for (i = 0; i < ARRAY_SIZE(res->vs); i++) {
+		if (!IS_ERR_OR_NULL(res->vs[i]))
+			dpu_vs_put(res->vs[i]);
+	}
+
+	grp->hw_plane_num = 0;
+}
+
+static int dpu_add_client_devices(struct dpu_soc *dpu)
+{
+	const struct dpu_data *data = dpu->data;
+	struct device *dev = dpu->dev;
+	struct dpu_platform_reg *reg;
+	struct dpu_plane_grp *plane_grp;
+	struct dpu_store *st9 = NULL;
+	size_t client_num, reg_size;
+	int i, id, ret;
+
+	client_num = ARRAY_SIZE(client_reg);
+
+	reg = devm_kcalloc(dev, client_num, sizeof(*reg), GFP_KERNEL);
+	if (!reg)
+		return -ENODEV;
+
+	plane_grp = devm_kzalloc(dev, sizeof(*plane_grp), GFP_KERNEL);
+	if (!plane_grp)
+		return -ENODEV;
+
+	mutex_init(&plane_grp->mutex);
+
+	mutex_lock(&dpu_client_id_mutex);
+	id = dpu_client_id;
+	dpu_client_id += client_num;
+	mutex_unlock(&dpu_client_id_mutex);
+
+	reg_size = client_num * sizeof(struct dpu_platform_reg);
+	memcpy(reg, &client_reg[0], reg_size);
+
+	plane_grp->src_mask = data->plane_src_mask;
+	plane_grp->id = id / client_num;
+	plane_grp->has_vproc = display_plane_video_proc;
+
+	ret = dpu_get_plane_resource(dpu, &plane_grp->res);
+	if (ret)
+		goto err_get_plane_res;
+
+	st9 = dpu_st_get(dpu, 9);
+	if (IS_ERR(st9)) {
+		ret = PTR_ERR(st9);
+		goto err_get_plane_res;
+	}
+
+	for (i = 0; i < client_num; i++) {
+		struct platform_device *pdev;
+		struct device_node *of_node = NULL;
+
+		if (!strcmp(reg[i].name, IMX_DPU_BLITENG_NAME)) {
+			/* As bliteng has no of_node, so to use dpu's. */
+			of_node = dev->of_node;
+		} else {
+			/* Associate subdevice with the corresponding port node. */
+			of_node = of_graph_get_port_by_id(dev->of_node, i);
+			if (!of_node) {
+				dev_info(dev,
+					"no port@%d node in %s, not using DISP%d\n",
+					i, dev->of_node->full_name, i);
+				continue;
+			}
+		}
+
+		reg[i].pdata.plane_grp = plane_grp;
+		reg[i].pdata.di_grp_id = plane_grp->id;
+		reg[i].pdata.st9 = st9;
+
+		pdev = platform_device_alloc(reg[i].name, id++);
+		if (!pdev) {
+			ret = -ENOMEM;
+			goto err_register;
+		}
+
+		pdev->dev.parent = dev;
+
+		reg[i].pdata.of_node = of_node;
+		ret = platform_device_add_data(pdev, &reg[i].pdata,
+					       sizeof(reg[i].pdata));
+		if (!ret)
+			ret = platform_device_add(pdev);
+		if (ret) {
+			platform_device_put(pdev);
+			goto err_register;
+		}
+	}
+
+	return 0;
+
+err_register:
+	platform_device_unregister_children(to_platform_device(dev));
+	dpu_st_put(st9);
+err_get_plane_res:
+	dpu_put_plane_resource(&plane_grp->res);
+
+	return ret;
+}
+
+static int dpu_probe(struct platform_device *pdev)
+{
+	const struct of_device_id *of_id;
+	struct device_node *np = pdev->dev.of_node;
+	struct dpu_soc *dpu;
+	struct resource *res;
+	unsigned long dpu_base;
+	const struct dpu_data *data;
+	int ret;
+
+	of_id = of_match_device(dpu_dt_ids, &pdev->dev);
+	if (!of_id)
+		return -ENODEV;
+
+	data = of_id->data;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENODEV;
+
+	dpu_base = res->start;
+
+	dpu = devm_kzalloc(&pdev->dev, sizeof(*dpu), GFP_KERNEL);
+	if (!dpu)
+		return -ENODEV;
+
+	dpu->dev = &pdev->dev;
+	dpu->data = data;
+	dpu->id = of_alias_get_id(np, "dpu");
+	dpu->irq_line_num = platform_irq_count(pdev);
+	if (dpu->irq_line_num < 0)
+		return dpu->irq_line_num;
+
+	dpu_units_addr_dbg(dpu, pdev, dpu_base);
+
+	ret = dpu_get_irq(pdev, dpu);
+	if (ret < 0)
+		return ret;
+
+	ret = dpu_sc_misc_get_handle(dpu);
+	if (ret < 0)
+		return ret;
+
+	spin_lock_init(&dpu->lock);
+
+	dpu->cm_reg = devm_ioremap(dpu->dev, dpu_base + data->cm_ofs, SZ_1K);
+	if (!dpu->cm_reg)
+		return -ENOMEM;
+
+	ret = dpu_attach_pm_domains(dpu);
+	if (ret)
+		return ret;
+
+	ret = dpu_irq_init(dpu);
+	if (ret)
+		goto failed_irq;
+
+	ret = dpu_submodules_init(dpu, pdev, dpu_base);
+	if (ret)
+		goto failed_submodules_init;
+
+	ret = dpu_sc_misc_init(dpu);
+	if (ret < 0) {
+		dev_err(dpu->dev,
+			"failed to initialize pixel link %d\n", ret);
+		goto failed_sc_misc_init;
+	}
+
+	platform_set_drvdata(pdev, dpu);
+
+	ret = dpu_add_client_devices(dpu);
+	if (ret) {
+		dev_err(dpu->dev,
+			"adding client devices failed with %d\n", ret);
+		goto failed_add_clients;
+	}
+
+	dev_info(dpu->dev, "driver probed\n");
+
+	return 0;
+
+failed_add_clients:
+	platform_set_drvdata(pdev, NULL);
+failed_sc_misc_init:
+failed_submodules_init:
+	dpu_irq_exit(dpu);
+failed_irq:
+	dpu_detach_pm_domains(dpu);
+	return ret;
+}
+
+static int dpu_remove(struct platform_device *pdev)
+{
+	struct dpu_soc *dpu = platform_get_drvdata(pdev);
+
+	platform_device_unregister_children(pdev);
+
+	dpu_irq_exit(dpu);
+	dpu_detach_pm_domains(dpu);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int dpu_suspend(struct device *dev)
+{
+	/*
+	 * The dpu core driver currently depends on the client drivers
+	 * to do suspend operations to leave dpu a cleaned up state
+	 * machine status before the system enters sleep mode.
+	 */
+	return 0;
+}
+
+static int dpu_resume(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct dpu_soc *dpu = platform_get_drvdata(pdev);
+
+	dpu_sc_misc_init(dpu);
+
+	_dpu_submodules_init(dpu, pdev);
+
+	return 0;
+}
+#endif
+
+static const struct dev_pm_ops dpu_pm_ops = {
+	SET_LATE_SYSTEM_SLEEP_PM_OPS(dpu_suspend, dpu_resume)
+};
+
+static struct platform_driver dpu_driver = {
+	.driver = {
+		.pm = &dpu_pm_ops,
+		.name = "dpu-core",
+		.of_match_table = dpu_dt_ids,
+	},
+	.probe = dpu_probe,
+	.remove = dpu_remove,
+};
+
+module_platform_driver(dpu_driver);
+
+MODULE_DESCRIPTION("i.MX DPU driver");
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/dpu/dpu-constframe.c b/drivers/gpu/imx/dpu/dpu-constframe.c
new file mode 100644
index 000000000..26c7f85fa
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-constframe.c
@@ -0,0 +1,253 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+static unsigned int safety_stream_cf_color = 0x0;
+module_param(safety_stream_cf_color, uint, 0444);
+MODULE_PARM_DESC(safety_stream_cf_color,
+"Safety stream constframe color in hex(0xRRGGBBAA) [default=0x00000000]");
+
+#define FRAMEDIMENSIONS		0xC
+#define WIDTH(w)		(((w) - 1) & 0x3FFF)
+#define HEIGHT(h)		((((h) - 1) & 0x3FFF) << 16)
+#define CONSTANTCOLOR		0x10
+#define RED(r)			(((r) & 0xFF) << 24)
+#define GREEN(g)		(((g) & 0xFF) << 16)
+#define BLUE(b)			(((b) & 0xFF) << 8)
+#define ALPHA(a)		((a) & 0xFF)
+#define CONTROLTRIGGER		0x14
+#define START			0x18
+#define STATUS			0x1C
+
+struct dpu_constframe {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_cf_read(struct dpu_constframe *cf, unsigned int offset)
+{
+	return readl(cf->base + offset);
+}
+
+static inline void dpu_cf_write(struct dpu_constframe *cf,
+				unsigned int offset, u32 value)
+{
+	writel(value, cf->base + offset);
+}
+
+void constframe_shden(struct dpu_constframe *cf, bool enable)
+{
+	u32 val;
+
+	val = enable ? SHDEN : 0;
+
+	mutex_lock(&cf->mutex);
+	dpu_cf_write(cf, STATICCONTROL, val);
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(constframe_shden);
+
+void constframe_framedimensions(struct dpu_constframe *cf, unsigned int w,
+				unsigned int h)
+{
+	u32 val;
+
+	val = WIDTH(w) | HEIGHT(h);
+
+	mutex_lock(&cf->mutex);
+	dpu_cf_write(cf, FRAMEDIMENSIONS, val);
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(constframe_framedimensions);
+
+void constframe_framedimensions_copy_prim(struct dpu_constframe *cf)
+{
+	struct dpu_constframe *prim_cf = NULL;
+	unsigned int prim_id;
+	int i;
+	u32 val;
+
+	if (cf->id != 0 && cf->id != 1) {
+		dev_warn(cf->dpu->dev, "ConstFrame%d is not a secondary one\n",
+								cf->id);
+		return;
+	}
+
+	prim_id = cf->id + 4;
+
+	for (i = 0; i < ARRAY_SIZE(cf_ids); i++)
+		if (cf_ids[i] == prim_id)
+			prim_cf = cf->dpu->cf_priv[i];
+
+	if (!prim_cf) {
+		dev_warn(cf->dpu->dev, "cannot find ConstFrame%d's primary peer\n",
+								cf->id);
+		return;
+	}
+
+	mutex_lock(&cf->mutex);
+	val = dpu_cf_read(prim_cf, FRAMEDIMENSIONS);
+	dpu_cf_write(cf, FRAMEDIMENSIONS, val);
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(constframe_framedimensions_copy_prim);
+
+void constframe_constantcolor(struct dpu_constframe *cf, unsigned int r,
+			      unsigned int g, unsigned int b, unsigned int a)
+{
+	u32 val;
+
+	val = RED(r) | GREEN(g) | BLUE(b) | ALPHA(a);
+
+	mutex_lock(&cf->mutex);
+	dpu_cf_write(cf, CONSTANTCOLOR, val);
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(constframe_constantcolor);
+
+void constframe_controltrigger(struct dpu_constframe *cf, bool trigger)
+{
+	u32 val;
+
+	val = trigger ? SHDTOKGEN : 0;
+
+	mutex_lock(&cf->mutex);
+	dpu_cf_write(cf, CONTROLTRIGGER, val);
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(constframe_controltrigger);
+
+struct dpu_constframe *dpu_cf_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_constframe *cf;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(cf_ids); i++)
+		if (cf_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(cf_ids))
+		return ERR_PTR(-EINVAL);
+
+	cf = dpu->cf_priv[i];
+
+	mutex_lock(&cf->mutex);
+
+	if (cf->inuse) {
+		mutex_unlock(&cf->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	cf->inuse = true;
+
+	mutex_unlock(&cf->mutex);
+
+	return cf;
+}
+EXPORT_SYMBOL_GPL(dpu_cf_get);
+
+void dpu_cf_put(struct dpu_constframe *cf)
+{
+	mutex_lock(&cf->mutex);
+
+	cf->inuse = false;
+
+	mutex_unlock(&cf->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_cf_put);
+
+struct dpu_constframe *dpu_aux_cf_peek(struct dpu_constframe *cf)
+{
+	unsigned int aux_id = cf->id ^ 1;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(cf_ids); i++)
+		if (cf_ids[i] == aux_id)
+			return cf->dpu->cf_priv[i];
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(dpu_aux_cf_peek);
+
+void _dpu_cf_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_constframe *cf;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(cf_ids); i++)
+		if (cf_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(cf_ids)))
+		return;
+
+	cf = dpu->cf_priv[i];
+
+	constframe_shden(cf, true);
+
+	if (id == 4 || id == 5) {
+		mutex_lock(&cf->mutex);
+		dpu_cf_write(cf, CONSTANTCOLOR, safety_stream_cf_color);
+		mutex_unlock(&cf->mutex);
+	}
+}
+
+int dpu_cf_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_constframe *cf;
+	int i;
+
+	cf = devm_kzalloc(dpu->dev, sizeof(*cf), GFP_KERNEL);
+	if (!cf)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(cf_ids); i++)
+		if (cf_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(cf_ids))
+		return -EINVAL;
+
+	dpu->cf_priv[i] = cf;
+
+	cf->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_16);
+	if (!cf->pec_base)
+		return -ENOMEM;
+
+	cf->base = devm_ioremap(dpu->dev, base, SZ_32);
+	if (!cf->base)
+		return -ENOMEM;
+
+	cf->dpu = dpu;
+	cf->id = id;
+
+	mutex_init(&cf->mutex);
+
+	_dpu_cf_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-disengcfg.c b/drivers/gpu/imx/dpu/dpu-disengcfg.c
new file mode 100644
index 000000000..be7e8011c
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-disengcfg.c
@@ -0,0 +1,158 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <drm/drm_mode.h>
+#include <linux/io.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include "dpu-prv.h"
+
+#define CLOCKCTRL		0x8
+typedef enum {
+	DSPCLKDIVIDE__DIV1,	/* Ext disp clk signal has pix clk freq. */
+	DSPCLKDIVIDE__DIV2,	/* Ext disp clk signal has 2x the pix clk freq. */
+} clkdivide_t;
+#define POLARITYCTRL		0xC
+#define POLHS_HIGH		BIT(0)
+#define POLVS_HIGH		BIT(1)
+#define POLEN_HIGH		BIT(2)
+#define PIXINV_INV		BIT(3)
+#define SRCSELECT		0x10
+#define SIG_SELECT_MASK		0x3
+
+struct dpu_disengcfg {
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_dec_read(struct dpu_disengcfg *dec, unsigned int offset)
+{
+	return readl(dec->base + offset);
+}
+
+static inline void dpu_dec_write(struct dpu_disengcfg *dec,
+				 unsigned int offset, u32 value)
+{
+	writel(value, dec->base + offset);
+}
+
+void disengcfg_sig_select(struct dpu_disengcfg *dec, dec_sig_sel_t sig_sel)
+{
+	u32 val;
+
+	mutex_lock(&dec->mutex);
+	val = dpu_dec_read(dec, SRCSELECT);
+	val &= ~SIG_SELECT_MASK;
+	val |= sig_sel;
+	dpu_dec_write(dec, SRCSELECT, val);
+	mutex_unlock(&dec->mutex);
+}
+EXPORT_SYMBOL_GPL(disengcfg_sig_select);
+
+struct dpu_disengcfg *dpu_dec_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_disengcfg *dec;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(dec_ids); i++)
+		if (dec_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(dec_ids))
+		return ERR_PTR(-EINVAL);
+
+	dec = dpu->dec_priv[i];
+
+	mutex_lock(&dec->mutex);
+
+	if (dec->inuse) {
+		mutex_unlock(&dec->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	dec->inuse = true;
+
+	mutex_unlock(&dec->mutex);
+
+	return dec;
+}
+EXPORT_SYMBOL_GPL(dpu_dec_get);
+
+void dpu_dec_put(struct dpu_disengcfg *dec)
+{
+	mutex_lock(&dec->mutex);
+
+	dec->inuse = false;
+
+	mutex_unlock(&dec->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_dec_put);
+
+struct dpu_disengcfg *dpu_aux_dec_peek(struct dpu_disengcfg *dec)
+{
+	return dec->dpu->dec_priv[dec->id ^ 1];
+}
+EXPORT_SYMBOL_GPL(dpu_aux_dec_peek);
+
+void _dpu_dec_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_disengcfg *dec;
+	u32 val;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(dec_ids); i++)
+		if (ed_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(dec_ids)))
+		return;
+
+	dec = dpu->dec_priv[i];
+
+	val = dpu_dec_read(dec, POLARITYCTRL);
+	val &= ~POLHS_HIGH;
+	val &= ~POLVS_HIGH;
+	dpu_dec_write(dec, POLARITYCTRL, val);
+
+	disengcfg_sig_select(dec, DEC_SIG_SEL_FRAMEGEN);
+}
+
+int dpu_dec_init(struct dpu_soc *dpu, unsigned int id,
+			unsigned long unused, unsigned long base)
+{
+	struct dpu_disengcfg *dec;
+
+	dec = devm_kzalloc(dpu->dev, sizeof(*dec), GFP_KERNEL);
+	if (!dec)
+		return -ENOMEM;
+
+	dpu->dec_priv[id] = dec;
+
+	dec->base = devm_ioremap(dpu->dev, base, SZ_16);
+	if (!dec->base)
+		return -ENOMEM;
+
+	dec->dpu = dpu;
+	dec->id = id;
+	mutex_init(&dec->mutex);
+
+	_dpu_dec_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-extdst.c b/drivers/gpu/imx/dpu/dpu-extdst.c
new file mode 100644
index 000000000..013e03a25
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-extdst.c
@@ -0,0 +1,521 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_STATIC		0x8
+#define POWERDOWN			BIT(4)
+#define SYNC_MODE			BIT(8)
+#define SW_RESET			BIT(11)
+#define DIV(n)				(((n) & 0xFF) << 16)
+#define DIV_RESET			0x80
+#define PIXENGCFG_DYNAMIC		0xC
+#define PIXENGCFG_REQUEST		0x10
+#define SHDLDREQ(n)			BIT(n)
+#define SEL_SHDLDREQ			BIT(0)
+#define PIXENGCFG_TRIGGER		0x14
+#define SYNC_TRIGGER			BIT(0)
+#define TRIGGER_SEQUENCE_COMPLETE	BIT(4)
+#define PIXENGCFG_STATUS		0x18
+#define SYNC_BUSY			BIT(8)
+#define KICK_MODE			BIT(8)
+#define PERFCOUNTMODE			BIT(12)
+#define CONTROL				0xC
+#define GAMMAAPPLYENABLE		BIT(0)
+#define SOFTWAREKICK			0x10
+#define KICK				BIT(0)
+#define STATUS				0x14
+#define CNT_ERR_STS			BIT(0)
+#define CONTROLWORD			0x18
+#define CURPIXELCNT			0x1C
+static u16 get_xval(u32 pixel_cnt)
+{
+	return pixel_cnt & 0xFFFF;
+}
+
+static u16 get_yval(u32 pixel_cnt)
+{
+	return pixel_cnt >> 16;
+}
+#define LASTPIXELCNT			0x20
+#define PERFCOUNTER			0x24
+
+struct dpu_extdst {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_pec_ed_read(struct dpu_extdst *ed, unsigned int offset)
+{
+	return readl(ed->pec_base + offset);
+}
+
+static inline void dpu_pec_ed_write(struct dpu_extdst *ed,
+				unsigned int offset, u32 value)
+{
+	writel(value, ed->pec_base + offset);
+}
+
+static inline u32 dpu_ed_read(struct dpu_extdst *ed, unsigned int offset)
+{
+	return readl(ed->base + offset);
+}
+
+static inline void dpu_ed_write(struct dpu_extdst *ed,
+				unsigned int offset, u32 value)
+{
+	writel(value, ed->base + offset);
+}
+
+static inline bool dpu_ed_is_safety_stream(struct dpu_extdst *ed)
+{
+	if (ed->id == 4 || ed->id == 5)
+		return true;
+
+	return false;
+}
+
+void extdst_pixengcfg_shden(struct dpu_extdst *ed, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_shden);
+
+void extdst_pixengcfg_powerdown(struct dpu_extdst *ed, bool powerdown)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	if (powerdown)
+		val |= POWERDOWN;
+	else
+		val &= ~POWERDOWN;
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_powerdown);
+
+void extdst_pixengcfg_sync_mode(struct dpu_extdst *ed, ed_sync_mode_t mode)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	if (mode == AUTO)
+		val |= SYNC_MODE;
+	else
+		val &= ~SYNC_MODE;
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_sync_mode);
+
+void extdst_pixengcfg_reset(struct dpu_extdst *ed, bool reset)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	if (reset)
+		val |= SW_RESET;
+	else
+		val &= ~SW_RESET;
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_reset);
+
+void extdst_pixengcfg_div(struct dpu_extdst *ed, u16 div)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	val &= ~0xFF0000;
+	val |= DIV(div);
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_div);
+
+void extdst_pixengcfg_syncmode_master(struct dpu_extdst *ed, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATIC);
+	if (enable)
+		val |= BIT(16);
+	else
+		val &= ~BIT(16);
+	dpu_pec_ed_write(ed, PIXENGCFG_STATIC, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_syncmode_master);
+
+int extdst_pixengcfg_src_sel(struct dpu_extdst *ed, extdst_src_sel_t src)
+{
+	mutex_lock(&ed->mutex);
+	dpu_pec_ed_write(ed, PIXENGCFG_DYNAMIC, src);
+	mutex_unlock(&ed->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_src_sel);
+
+void extdst_pixengcfg_sel_shdldreq(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_REQUEST);
+	val |= SEL_SHDLDREQ;
+	dpu_pec_ed_write(ed, PIXENGCFG_REQUEST, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_sel_shdldreq);
+
+void extdst_pixengcfg_shdldreq(struct dpu_extdst *ed, u32 req_mask)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_REQUEST);
+	val |= req_mask;
+	dpu_pec_ed_write(ed, PIXENGCFG_REQUEST, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_shdldreq);
+
+void extdst_pixengcfg_sync_trigger(struct dpu_extdst *ed)
+{
+	mutex_lock(&ed->mutex);
+	dpu_pec_ed_write(ed, PIXENGCFG_TRIGGER, SYNC_TRIGGER);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_sync_trigger);
+
+void extdst_pixengcfg_trigger_sequence_complete(struct dpu_extdst *ed)
+{
+	mutex_lock(&ed->mutex);
+	dpu_pec_ed_write(ed, PIXENGCFG_TRIGGER, TRIGGER_SEQUENCE_COMPLETE);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_trigger_sequence_complete);
+
+bool extdst_pixengcfg_is_sync_busy(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATUS);
+	mutex_unlock(&ed->mutex);
+
+	return val & SYNC_BUSY;
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_is_sync_busy);
+
+ed_pipeline_status_t extdst_pixengcfg_pipeline_status(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_pec_ed_read(ed, PIXENGCFG_STATUS);
+	mutex_unlock(&ed->mutex);
+
+	return val & 0x3;
+}
+EXPORT_SYMBOL_GPL(extdst_pixengcfg_pipeline_status);
+
+void extdst_shden(struct dpu_extdst *ed, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_ed_write(ed, STATICCONTROL, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_shden);
+
+void extdst_kick_mode(struct dpu_extdst *ed, ed_kick_mode_t mode)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, STATICCONTROL);
+	val &= ~KICK_MODE;
+	val |= mode;
+	dpu_ed_write(ed, STATICCONTROL, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_kick_mode);
+
+void extdst_perfcountmode(struct dpu_extdst *ed, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, STATICCONTROL);
+	if (enable)
+		val |= PERFCOUNTMODE;
+	else
+		val &= ~PERFCOUNTMODE;
+	dpu_ed_write(ed, STATICCONTROL, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_perfcountmode);
+
+void extdst_gamma_apply_enable(struct dpu_extdst *ed, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, CONTROL);
+	if (enable)
+		val |= GAMMAAPPLYENABLE;
+	else
+		val &= ~GAMMAAPPLYENABLE;
+	dpu_ed_write(ed, CONTROL, val);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_gamma_apply_enable);
+
+void extdst_kick(struct dpu_extdst *ed)
+{
+	mutex_lock(&ed->mutex);
+	dpu_ed_write(ed, SOFTWAREKICK, KICK);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_kick);
+
+void extdst_cnt_err_clear(struct dpu_extdst *ed)
+{
+	mutex_lock(&ed->mutex);
+	dpu_ed_write(ed, STATUS, CNT_ERR_STS);
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(extdst_cnt_err_clear);
+
+bool extdst_cnt_err_status(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, STATUS);
+	mutex_unlock(&ed->mutex);
+
+	return val & CNT_ERR_STS;
+}
+EXPORT_SYMBOL_GPL(extdst_cnt_err_status);
+
+u32 extdst_last_control_word(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, CONTROLWORD);
+	mutex_unlock(&ed->mutex);
+
+	return val;
+}
+EXPORT_SYMBOL_GPL(extdst_last_control_word);
+
+void extdst_pixel_cnt(struct dpu_extdst *ed, u16 *x, u16 *y)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, CURPIXELCNT);
+	mutex_unlock(&ed->mutex);
+
+	*x = get_xval(val);
+	*y = get_yval(val);
+}
+EXPORT_SYMBOL_GPL(extdst_pixel_cnt);
+
+void extdst_last_pixel_cnt(struct dpu_extdst *ed, u16 *x, u16 *y)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, LASTPIXELCNT);
+	mutex_unlock(&ed->mutex);
+
+	*x = get_xval(val);
+	*y = get_yval(val);
+}
+EXPORT_SYMBOL_GPL(extdst_last_pixel_cnt);
+
+u32 extdst_perfresult(struct dpu_extdst *ed)
+{
+	u32 val;
+
+	mutex_lock(&ed->mutex);
+	val = dpu_ed_read(ed, PERFCOUNTER);
+	mutex_unlock(&ed->mutex);
+
+	return val;
+}
+EXPORT_SYMBOL_GPL(extdst_perfresult);
+
+bool extdst_is_master(struct dpu_extdst *ed)
+{
+	const struct dpu_data *data = ed->dpu->data;
+
+	return ed->id == data->master_stream_id;
+}
+EXPORT_SYMBOL_GPL(extdst_is_master);
+
+struct dpu_extdst *dpu_ed_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_extdst *ed;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(ed_ids); i++)
+		if (ed_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(ed_ids))
+		return ERR_PTR(-EINVAL);
+
+	ed = dpu->ed_priv[i];
+
+	mutex_lock(&ed->mutex);
+
+	if (ed->inuse) {
+		mutex_unlock(&ed->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	ed->inuse = true;
+
+	mutex_unlock(&ed->mutex);
+
+	return ed;
+}
+EXPORT_SYMBOL_GPL(dpu_ed_get);
+
+void dpu_ed_put(struct dpu_extdst *ed)
+{
+	mutex_lock(&ed->mutex);
+
+	ed->inuse = false;
+
+	mutex_unlock(&ed->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_ed_put);
+
+struct dpu_extdst *dpu_aux_ed_peek(struct dpu_extdst *ed)
+{
+	unsigned int aux_id = ed->id ^ 1;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(ed_ids); i++)
+		if (ed_ids[i] == aux_id)
+			return ed->dpu->ed_priv[i];
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(dpu_aux_ed_peek);
+
+void _dpu_ed_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_extdst *ed;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(ed_ids); i++)
+		if (ed_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(ed_ids)))
+		return;
+
+	ed = dpu->ed_priv[i];
+
+	extdst_pixengcfg_src_sel(ed, ED_SRC_DISABLE);
+	extdst_pixengcfg_shden(ed, true);
+	extdst_pixengcfg_powerdown(ed, false);
+	extdst_pixengcfg_sync_mode(ed, SINGLE);
+	extdst_pixengcfg_reset(ed, false);
+	extdst_pixengcfg_div(ed, DIV_RESET);
+	extdst_shden(ed, true);
+	extdst_perfcountmode(ed, false);
+	extdst_kick_mode(ed, EXTERNAL);
+}
+
+int dpu_ed_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_extdst *ed;
+	int ret, i;
+
+	ed = devm_kzalloc(dpu->dev, sizeof(*ed), GFP_KERNEL);
+	if (!ed)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(ed_ids); i++)
+		if (ed_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(ed_ids))
+		return -EINVAL;
+
+	dpu->ed_priv[i] = ed;
+
+	ed->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_32);
+	if (!ed->pec_base)
+		return -ENOMEM;
+
+	ed->base = devm_ioremap(dpu->dev, base, SZ_64);
+	if (!ed->base)
+		return -ENOMEM;
+
+	ed->dpu = dpu;
+	ed->id = id;
+	mutex_init(&ed->mutex);
+
+	ret = extdst_pixengcfg_src_sel(ed, ED_SRC_DISABLE);
+	if (ret < 0)
+		return ret;
+
+	_dpu_ed_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-fetchdecode.c b/drivers/gpu/imx/dpu/dpu-fetchdecode.c
new file mode 100644
index 000000000..66d5862fb
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-fetchdecode.c
@@ -0,0 +1,673 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019,2021 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <drm/drm_blend.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+static const u32 fd_vproc_cap[2] = {
+	DPU_VPROC_CAP_HSCALER4 | DPU_VPROC_CAP_VSCALER4 |
+	DPU_VPROC_CAP_FETCHECO0,
+	DPU_VPROC_CAP_HSCALER5 | DPU_VPROC_CAP_VSCALER5 |
+	DPU_VPROC_CAP_FETCHECO1,
+};
+
+#define PIXENGCFG_DYNAMIC		0x8
+static const fd_dynamic_src_sel_t fd_srcs[2][4] = {
+	{
+	  FD_SRC_DISABLE,	FD_SRC_FETCHECO0,
+	  FD_SRC_FETCHDECODE1,	FD_SRC_FETCHWARP2
+	}, {
+	  FD_SRC_DISABLE,	FD_SRC_FETCHECO1,
+	  FD_SRC_FETCHDECODE0,	FD_SRC_FETCHWARP2
+	},
+};
+
+#define PIXENGCFG_STATUS		0xC
+
+#define RINGBUFSTARTADDR0		0x10
+#define RINGBUFWRAPADDR0		0x14
+#define FRAMEPROPERTIES0		0x18
+#define BASEADDRESS0			0x1C
+#define SOURCEBUFFERATTRIBUTES0		0x20
+#define SOURCEBUFFERDIMENSION0		0x24
+#define COLORCOMPONENTBITS0		0x28
+#define COLORCOMPONENTSHIFT0		0x2C
+#define LAYEROFFSET0			0x30
+#define CLIPWINDOWOFFSET0		0x34
+#define CLIPWINDOWDIMENSIONS0		0x38
+#define CONSTANTCOLOR0			0x3C
+#define LAYERPROPERTY0			0x40
+#define FRAMEDIMENSIONS			0x44
+#define FRAMERESAMPLING			0x48
+#define DECODECONTROL			0x4C
+#define SOURCEBUFFERLENGTH		0x50
+#define CONTROL				0x54
+#define CONTROLTRIGGER			0x58
+#define START				0x5C
+#define FETCHTYPE			0x60
+#define DECODERSTATUS			0x64
+#define READADDRESS0			0x68
+#define BURSTBUFFERPROPERTIES		0x6C
+#define STATUS				0x70
+#define HIDDENSTATUS			0x74
+
+struct dpu_fetchdecode {
+	struct dpu_fetchunit fu;
+	fetchtype_t fetchtype;
+};
+
+int fetchdecode_pixengcfg_dynamic_src_sel(struct dpu_fetchunit *fu,
+					  fd_dynamic_src_sel_t src)
+{
+	int i;
+
+	mutex_lock(&fu->mutex);
+	for (i = 0; i < 4; i++) {
+		if (fd_srcs[fu->id][i] == src) {
+			dpu_pec_fu_write(fu, PIXENGCFG_DYNAMIC, src);
+			mutex_unlock(&fu->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&fu->mutex);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(fetchdecode_pixengcfg_dynamic_src_sel);
+
+static void
+fetchdecode_set_baseaddress(struct dpu_fetchunit *fu, unsigned int width,
+			    unsigned int x_offset, unsigned int y_offset,
+			    unsigned int mt_w, unsigned int mt_h,
+			    int bpp, dma_addr_t baddr)
+{
+	unsigned int burst_size, stride;
+	bool nonzero_mod = !!mt_w;
+
+	if (nonzero_mod) {
+		/* consider PRG x offset to calculate buffer address */
+		baddr += (dma_addr_t)(x_offset % mt_w) * (bpp / 8);
+
+		burst_size = fetchunit_burst_size_fixup_tkt343664(baddr);
+
+		stride = width * (bpp / 8);
+		stride = fetchunit_stride_fixup_tkt339017(stride, burst_size,
+							  baddr, nonzero_mod);
+
+		/* consider PRG y offset to calculate buffer address */
+		baddr += (dma_addr_t)(y_offset % mt_h) * stride;
+	}
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BASEADDRESS0, baddr);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchdecode_set_src_bpp(struct dpu_fetchunit *fu, int bpp)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, SOURCEBUFFERATTRIBUTES0);
+	val &= ~0x3f0000;
+	val |= BITSPERPIXEL(bpp);
+	dpu_fu_write(fu, SOURCEBUFFERATTRIBUTES0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void
+fetchdecode_set_src_stride(struct dpu_fetchunit *fu,
+			   unsigned int width, unsigned int x_offset,
+			   unsigned int mt_w, int bpp, unsigned int stride,
+			   dma_addr_t baddr, bool use_prefetch)
+{
+	unsigned int burst_size;
+	bool nonzero_mod = !!mt_w;
+	u32 val;
+
+	if (use_prefetch) {
+		/* consider PRG x offset to calculate buffer address */
+		if (nonzero_mod)
+			baddr += (dma_addr_t)(x_offset % mt_w) * (bpp / 8);
+
+		burst_size = fetchunit_burst_size_fixup_tkt343664(baddr);
+
+		stride = width * (bpp / 8);
+		stride = fetchunit_stride_fixup_tkt339017(stride, burst_size,
+							  baddr, nonzero_mod);
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, SOURCEBUFFERATTRIBUTES0);
+	val &= ~0xffff;
+	val |= STRIDE(stride);
+	dpu_fu_write(fu, SOURCEBUFFERATTRIBUTES0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void
+fetchdecode_set_src_buf_dimensions(struct dpu_fetchunit *fu,
+				   unsigned int w, unsigned int h,
+				   u32 unused, bool deinterlace)
+{
+	u32 val;
+
+	if (deinterlace)
+		h /= 2;
+
+	val = LINEWIDTH(w) | LINECOUNT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, SOURCEBUFFERDIMENSION0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchdecode_set_fmt(struct dpu_fetchunit *fu,
+				u32 fmt,
+				enum drm_color_encoding color_encoding,
+				enum drm_color_range color_range,
+				bool deinterlace)
+{
+	u32 val, bits, shift;
+	bool is_planar_yuv = false, is_rastermode_yuv422 = false;
+	bool is_yuv422upsamplingmode_interpolate = false;
+	bool is_inputselect_compact = false;
+	bool need_csc = false;
+	int i;
+
+	switch (fmt) {
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+		is_rastermode_yuv422 = true;
+		is_yuv422upsamplingmode_interpolate = true;
+		need_csc = true;
+		break;
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+		is_yuv422upsamplingmode_interpolate = true;
+		fallthrough;
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+		if (deinterlace)
+			is_yuv422upsamplingmode_interpolate = true;
+		is_planar_yuv = true;
+		is_rastermode_yuv422 = true;
+		is_inputselect_compact = true;
+		need_csc = true;
+		break;
+	case DRM_FORMAT_NV24:
+	case DRM_FORMAT_NV42:
+		is_planar_yuv = true;
+		is_yuv422upsamplingmode_interpolate = true;
+		is_inputselect_compact = true;
+		need_csc = true;
+		break;
+	default:
+		break;
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, CONTROL);
+	val &= ~YUV422UPSAMPLINGMODE_MASK;
+	val &= ~INPUTSELECT_MASK;
+	val &= ~RASTERMODE_MASK;
+	if (is_yuv422upsamplingmode_interpolate)
+		val |= YUV422UPSAMPLINGMODE(YUV422UPSAMPLINGMODE__INTERPOLATE);
+	else
+		val |= YUV422UPSAMPLINGMODE(YUV422UPSAMPLINGMODE__REPLICATE);
+	if (is_inputselect_compact)
+		val |= INPUTSELECT(INPUTSELECT__COMPPACK);
+	else
+		val |= INPUTSELECT(INPUTSELECT__INACTIVE);
+	if (is_rastermode_yuv422)
+		val |= RASTERMODE(RASTERMODE__YUV422);
+	else
+		val |= RASTERMODE(RASTERMODE__NORMAL);
+	dpu_fu_write(fu, CONTROL, val);
+
+	val = dpu_fu_read(fu, LAYERPROPERTY0);
+	val &= ~YUVCONVERSIONMODE_MASK;
+	if (need_csc) {
+		/* assuming fetchdecode always ouputs RGB pixel formats */
+		if (color_encoding == DRM_COLOR_YCBCR_BT709)
+			val |= YUVCONVERSIONMODE(YUVCONVERSIONMODE__ITU709);
+		else if (color_encoding == DRM_COLOR_YCBCR_BT601 &&
+			 color_range == DRM_COLOR_YCBCR_FULL_RANGE)
+			val |= YUVCONVERSIONMODE(YUVCONVERSIONMODE__ITU601_FR);
+		else
+			val |= YUVCONVERSIONMODE(YUVCONVERSIONMODE__ITU601);
+	} else {
+		val |= YUVCONVERSIONMODE(YUVCONVERSIONMODE__OFF);
+	}
+	dpu_fu_write(fu, LAYERPROPERTY0, val);
+	mutex_unlock(&fu->mutex);
+
+	for (i = 0; i < ARRAY_SIZE(dpu_pixel_format_matrix); i++) {
+		if (dpu_pixel_format_matrix[i].pixel_format == fmt) {
+			bits = dpu_pixel_format_matrix[i].bits;
+			shift = dpu_pixel_format_matrix[i].shift;
+
+			if (is_planar_yuv) {
+				bits &= ~(U_BITS_MASK | V_BITS_MASK);
+				shift &= ~(U_SHIFT_MASK | V_SHIFT_MASK);
+			}
+
+			mutex_lock(&fu->mutex);
+			dpu_fu_write(fu, COLORCOMPONENTBITS0, bits);
+			dpu_fu_write(fu, COLORCOMPONENTSHIFT0, shift);
+			mutex_unlock(&fu->mutex);
+			return;
+		}
+	}
+
+	WARN_ON(1);
+}
+
+void fetchdecode_layeroffset(struct dpu_fetchunit *fu, unsigned int x,
+			     unsigned int y)
+{
+	u32 val;
+
+	val = LAYERXOFFSET(x) | LAYERYOFFSET(y);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, LAYEROFFSET0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_layeroffset);
+
+void fetchdecode_clipoffset(struct dpu_fetchunit *fu, unsigned int x,
+			    unsigned int y)
+{
+	u32 val;
+
+	val = CLIPWINDOWXOFFSET(x) | CLIPWINDOWYOFFSET(y);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CLIPWINDOWOFFSET0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_clipoffset);
+
+static void
+fetchdecode_set_pixel_blend_mode(struct dpu_fetchunit *fu,
+				 unsigned int pixel_blend_mode, u16 alpha,
+				 u32 fb_format)
+{
+	u32 mode = 0, val;
+
+	if (pixel_blend_mode == DRM_MODE_BLEND_PREMULTI ||
+	    pixel_blend_mode == DRM_MODE_BLEND_COVERAGE) {
+		mode = ALPHACONSTENABLE;
+
+		switch (fb_format) {
+		case DRM_FORMAT_ARGB8888:
+		case DRM_FORMAT_ABGR8888:
+		case DRM_FORMAT_RGBA8888:
+		case DRM_FORMAT_BGRA8888:
+			mode |= ALPHASRCENABLE;
+			break;
+		}
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY0);
+	val &= ~(PREMULCONSTRGB | ALPHA_ENABLE_MASK | RGB_ENABLE_MASK);
+	val |= mode;
+	dpu_fu_write(fu, LAYERPROPERTY0, val);
+
+	val = dpu_fu_read(fu, CONSTANTCOLOR0);
+	val &= ~CONSTANTALPHA_MASK;
+	val |= CONSTANTALPHA(alpha >> 8);
+	dpu_fu_write(fu, CONSTANTCOLOR0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchdecode_enable_src_buf(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY0);
+	val |= SOURCEBUFFERENABLE;
+	dpu_fu_write(fu, LAYERPROPERTY0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchdecode_disable_src_buf(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY0);
+	val &= ~SOURCEBUFFERENABLE;
+	dpu_fu_write(fu, LAYERPROPERTY0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static bool fetchdecode_is_enabled(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY0);
+	mutex_unlock(&fu->mutex);
+
+	return !!(val & SOURCEBUFFERENABLE);
+}
+
+void fetchdecode_clipdimensions(struct dpu_fetchunit *fu, unsigned int w,
+				unsigned int h)
+{
+	u32 val;
+
+	val = CLIPWINDOWWIDTH(w) | CLIPWINDOWHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CLIPWINDOWDIMENSIONS0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_clipdimensions);
+
+static void
+fetchdecode_set_framedimensions(struct dpu_fetchunit *fu,
+				unsigned int w, unsigned int h,
+				bool deinterlace)
+{
+	u32 val;
+
+	if (deinterlace)
+		h /= 2;
+
+	val = FRAMEWIDTH(w) | FRAMEHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, FRAMEDIMENSIONS, val);
+	mutex_unlock(&fu->mutex);
+}
+
+void fetchdecode_rgb_constantcolor(struct dpu_fetchunit *fu,
+					u8 r, u8 g, u8 b, u8 a)
+{
+	u32 val;
+
+	val = rgb_color(r, g, b, a);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_rgb_constantcolor);
+
+void fetchdecode_yuv_constantcolor(struct dpu_fetchunit *fu, u8 y, u8 u, u8 v)
+{
+	u32 val;
+
+	val = yuv_color(y, u, v);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_yuv_constantcolor);
+
+static void fetchdecode_set_controltrigger(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONTROLTRIGGER, SHDTOKGEN);
+	mutex_unlock(&fu->mutex);
+}
+
+int fetchdecode_fetchtype(struct dpu_fetchunit *fu, fetchtype_t *type)
+{
+	struct dpu_soc *dpu = fu->dpu;
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FETCHTYPE);
+	val &= FETCHTYPE_MASK;
+	mutex_unlock(&fu->mutex);
+
+	switch (val) {
+	case FETCHTYPE__DECODE:
+	case FETCHTYPE__LAYER:
+	case FETCHTYPE__WARP:
+	case FETCHTYPE__ECO:
+	case FETCHTYPE__PERSP:
+	case FETCHTYPE__ROT:
+	case FETCHTYPE__DECODEL:
+	case FETCHTYPE__LAYERL:
+	case FETCHTYPE__ROTL:
+		break;
+	default:
+		dev_warn(dpu->dev, "Invalid fetch type %u for FetchDecode%d\n",
+				val, fu->id);
+		return -EINVAL;
+	}
+
+	*type = val;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(fetchdecode_fetchtype);
+
+u32 fetchdecode_get_vproc_mask(struct dpu_fetchunit *fu)
+{
+	return fd_vproc_cap[fu->id];
+}
+EXPORT_SYMBOL_GPL(fetchdecode_get_vproc_mask);
+
+struct dpu_fetchunit *fetchdecode_get_fetcheco(struct dpu_fetchunit *fu)
+{
+	struct dpu_soc *dpu = fu->dpu;
+
+	switch (fu->id) {
+	case 0:
+	case 1:
+		return dpu->fe_priv[fu->id];
+	default:
+		WARN_ON(1);
+	}
+
+	return ERR_PTR(-EINVAL);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_get_fetcheco);
+
+bool fetchdecode_need_fetcheco(struct dpu_fetchunit *fu, u32 fmt)
+{
+	struct dpu_fetchunit *fe = fetchdecode_get_fetcheco(fu);
+
+	if (IS_ERR_OR_NULL(fe))
+		return false;
+
+	switch (fmt) {
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+	case DRM_FORMAT_NV24:
+	case DRM_FORMAT_NV42:
+		return true;
+	}
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(fetchdecode_need_fetcheco);
+
+struct dpu_hscaler *fetchdecode_get_hscaler(struct dpu_fetchunit *fu)
+{
+	struct dpu_soc *dpu = fu->dpu;
+
+	switch (fu->id) {
+	case 0:
+	case 2:
+		return dpu->hs_priv[0];
+	case 1:
+	case 3:
+		return dpu->hs_priv[1];
+	default:
+		WARN_ON(1);
+	}
+
+	return ERR_PTR(-EINVAL);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_get_hscaler);
+
+struct dpu_vscaler *fetchdecode_get_vscaler(struct dpu_fetchunit *fu)
+{
+	struct dpu_soc *dpu = fu->dpu;
+
+	switch (fu->id) {
+	case 0:
+	case 2:
+		return dpu->vs_priv[0];
+	case 1:
+	case 3:
+		return dpu->vs_priv[1];
+	default:
+		WARN_ON(1);
+	}
+
+	return ERR_PTR(-EINVAL);
+}
+EXPORT_SYMBOL_GPL(fetchdecode_get_vscaler);
+
+struct dpu_fetchunit *dpu_fd_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fd_ids); i++)
+		if (fd_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fd_ids))
+		return ERR_PTR(-EINVAL);
+
+	fu = dpu->fd_priv[i];
+
+	mutex_lock(&fu->mutex);
+
+	if (fu->inuse) {
+		mutex_unlock(&fu->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	fu->inuse = true;
+
+	mutex_unlock(&fu->mutex);
+
+	return fu;
+}
+EXPORT_SYMBOL_GPL(dpu_fd_get);
+
+void dpu_fd_put(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+
+	fu->inuse = false;
+
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_fd_put);
+
+static const struct dpu_fetchunit_ops fd_ops = {
+	.set_burstlength	= fetchunit_set_burstlength,
+	.set_baseaddress	= fetchdecode_set_baseaddress,
+	.set_src_bpp		= fetchdecode_set_src_bpp,
+	.set_src_stride		= fetchdecode_set_src_stride,
+	.set_src_buf_dimensions	= fetchdecode_set_src_buf_dimensions,
+	.set_fmt		= fetchdecode_set_fmt,
+	.set_pixel_blend_mode	= fetchdecode_set_pixel_blend_mode,
+	.enable_src_buf		= fetchdecode_enable_src_buf,
+	.disable_src_buf	= fetchdecode_disable_src_buf,
+	.is_enabled		= fetchdecode_is_enabled,
+	.set_framedimensions	= fetchdecode_set_framedimensions,
+	.set_controltrigger	= fetchdecode_set_controltrigger,
+	.get_stream_id		= fetchunit_get_stream_id,
+	.set_stream_id		= fetchunit_set_stream_id,
+};
+
+void _dpu_fd_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fd_ids); i++)
+		if (fd_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(fd_ids)))
+		return;
+
+	fu = dpu->fd_priv[i];
+
+	fetchdecode_pixengcfg_dynamic_src_sel(fu, FD_SRC_DISABLE);
+	fetchunit_baddr_autoupdate(fu, 0x0);
+	fetchunit_shden(fu, true);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BURSTBUFFERMANAGEMENT,
+			SETNUMBUFFERS(16) | SETBURSTLENGTH(16));
+	mutex_unlock(&fu->mutex);
+}
+
+int dpu_fd_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_fetchdecode *fd;
+	struct dpu_fetchunit *fu;
+	int ret;
+
+	fd = devm_kzalloc(dpu->dev, sizeof(*fd), GFP_KERNEL);
+	if (!fd)
+		return -ENOMEM;
+
+	fu = &fd->fu;
+	dpu->fd_priv[id] = fu;
+
+	fu->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_16);
+	if (!fu->pec_base)
+		return -ENOMEM;
+
+	fu->base = devm_ioremap(dpu->dev, base, SZ_1K);
+	if (!fu->base)
+		return -ENOMEM;
+
+	fu->dpu = dpu;
+	fu->id = id;
+	fu->type = FU_T_FD;
+	fu->ops = &fd_ops;
+	fu->name = "fetchdecode";
+
+	mutex_init(&fu->mutex);
+
+	ret = fetchdecode_pixengcfg_dynamic_src_sel(fu, FD_SRC_DISABLE);
+	if (ret < 0)
+		return ret;
+
+	ret = fetchdecode_fetchtype(fu, &fd->fetchtype);
+	if (ret < 0)
+		return ret;
+
+	_dpu_fd_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-fetcheco.c b/drivers/gpu/imx/dpu/dpu-fetcheco.c
new file mode 100644
index 000000000..d8bfb79e3
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-fetcheco.c
@@ -0,0 +1,407 @@
+/*
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define BASEADDRESS0			0x10
+#define SOURCEBUFFERATTRIBUTES0		0x14
+#define SOURCEBUFFERDIMENSION0		0x18
+#define COLORCOMPONENTBITS0		0x1C
+#define COLORCOMPONENTSHIFT0		0x20
+#define LAYEROFFSET0			0x24
+#define CLIPWINDOWOFFSET0		0x28
+#define CLIPWINDOWDIMENSIONS0		0x2C
+#define CONSTANTCOLOR0			0x30
+#define LAYERPROPERTY0			0x34
+#define FRAMEDIMENSIONS			0x38
+#define FRAMERESAMPLING			0x3C
+#define CONTROL				0x40
+#define CONTROLTRIGGER			0x44
+#define START				0x48
+#define FETCHTYPE			0x4C
+#define BURSTBUFFERPROPERTIES		0x50
+#define HIDDENSTATUS			0x54
+
+struct dpu_fetcheco {
+	struct dpu_fetchunit fu;
+};
+
+static void
+fetcheco_set_src_buf_dimensions(struct dpu_fetchunit *fu,
+				unsigned int w, unsigned int h,
+				u32 fmt, bool deinterlace)
+{
+	int width, height;
+	u32 val;
+
+	if (deinterlace) {
+		width = w;
+		height = h / 2;
+	} else {
+		width = dpu_format_plane_width(w, fmt, 1);
+		height = dpu_format_plane_height(h, fmt, 1);
+	}
+
+	switch (fmt) {
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+	case DRM_FORMAT_NV24:
+	case DRM_FORMAT_NV42:
+		break;
+	default:
+		WARN(1, "Unsupported FetchEco pixel format 0x%08x\n", fmt);
+		return;
+	}
+
+	val = LINEWIDTH(width) | LINECOUNT(height);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, SOURCEBUFFERDIMENSION0, val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetcheco_set_fmt(struct dpu_fetchunit *fu,
+			     u32 fmt,
+			     enum drm_color_encoding unused1,
+			     enum drm_color_range unused2,
+			     bool unused3)
+{
+	u32 val, bits, shift;
+	int i, hsub, vsub;
+	unsigned int x, y;
+
+	switch (fmt) {
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+	case DRM_FORMAT_NV24:
+	case DRM_FORMAT_NV42:
+		break;
+	default:
+		WARN(1, "Unsupported FetchEco pixel format 0x%08x\n", fmt);
+		return;
+	}
+
+	hsub = dpu_format_horz_chroma_subsampling(fmt);
+	switch (hsub) {
+	case 1:
+		x = 0x4;
+		break;
+	case 2:
+		x = 0x2;
+		break;
+	default:
+		WARN_ON(1);
+		return;
+	}
+
+	vsub = dpu_format_vert_chroma_subsampling(fmt);
+	switch (vsub) {
+	case 1:
+		y = 0x4;
+		break;
+	case 2:
+		y = 0x2;
+		break;
+	default:
+		WARN_ON(1);
+		return;
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FRAMERESAMPLING);
+	val &= ~(DELTAX_MASK | DELTAY_MASK);
+	val |= DELTAX(x) | DELTAY(y);
+	dpu_fu_write(fu, FRAMERESAMPLING, val);
+
+	val = dpu_fu_read(fu, CONTROL);
+	val &= ~RASTERMODE_MASK;
+	val |= RASTERMODE(RASTERMODE__NORMAL);
+	dpu_fu_write(fu, CONTROL, val);
+	mutex_unlock(&fu->mutex);
+
+	for (i = 0; i < ARRAY_SIZE(dpu_pixel_format_matrix); i++) {
+		if (dpu_pixel_format_matrix[i].pixel_format == fmt) {
+			bits = dpu_pixel_format_matrix[i].bits;
+			shift = dpu_pixel_format_matrix[i].shift;
+
+			bits &= ~Y_BITS_MASK;
+			shift &= ~Y_SHIFT_MASK;
+
+			mutex_lock(&fu->mutex);
+			dpu_fu_write(fu, COLORCOMPONENTBITS0, bits);
+			dpu_fu_write(fu, COLORCOMPONENTSHIFT0, shift);
+			mutex_unlock(&fu->mutex);
+			return;
+		}
+	}
+
+	WARN_ON(1);
+}
+
+void fetcheco_layeroffset(struct dpu_fetchunit *fu, unsigned int x,
+			  unsigned int y)
+{
+	u32 val;
+
+	val = LAYERXOFFSET(x) | LAYERYOFFSET(y);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, LAYEROFFSET0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetcheco_layeroffset);
+
+void fetcheco_clipoffset(struct dpu_fetchunit *fu, unsigned int x,
+			 unsigned int y)
+{
+	u32 val;
+
+	val = CLIPWINDOWXOFFSET(x) | CLIPWINDOWYOFFSET(y);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CLIPWINDOWOFFSET0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetcheco_clipoffset);
+
+void fetcheco_clipdimensions(struct dpu_fetchunit *fu, unsigned int w,
+			     unsigned int h)
+{
+	u32 val;
+
+	val = CLIPWINDOWWIDTH(w) | CLIPWINDOWHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CLIPWINDOWDIMENSIONS0, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetcheco_clipdimensions);
+
+static void
+fetcheco_set_framedimensions(struct dpu_fetchunit *fu,
+			     unsigned int w, unsigned int h,
+			     bool deinterlace)
+{
+	u32 val;
+
+	if (deinterlace)
+		h /= 2;
+
+	val = FRAMEWIDTH(w) | FRAMEHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, FRAMEDIMENSIONS, val);
+	mutex_unlock(&fu->mutex);
+}
+
+void fetcheco_frameresampling(struct dpu_fetchunit *fu, unsigned int x,
+			      unsigned int y)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FRAMERESAMPLING);
+	val &= ~(DELTAX_MASK | DELTAY_MASK);
+	val |= DELTAX(x) | DELTAY(y);
+	dpu_fu_write(fu, FRAMERESAMPLING, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetcheco_frameresampling);
+
+static void fetcheco_set_controltrigger(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONTROLTRIGGER, SHDTOKGEN);
+	mutex_unlock(&fu->mutex);
+}
+
+int fetcheco_fetchtype(struct dpu_fetchunit *fu, fetchtype_t *type)
+{
+	struct dpu_soc *dpu = fu->dpu;
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FETCHTYPE);
+	val &= FETCHTYPE_MASK;
+	mutex_unlock(&fu->mutex);
+
+	switch (val) {
+	case FETCHTYPE__DECODE:
+	case FETCHTYPE__LAYER:
+	case FETCHTYPE__WARP:
+	case FETCHTYPE__ECO:
+	case FETCHTYPE__PERSP:
+	case FETCHTYPE__ROT:
+	case FETCHTYPE__DECODEL:
+	case FETCHTYPE__LAYERL:
+	case FETCHTYPE__ROTL:
+		break;
+	default:
+		dev_warn(dpu->dev, "Invalid fetch type %u for FetchEco%d\n",
+				val, fu->id);
+		return -EINVAL;
+	}
+
+	*type = val;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(fetcheco_fetchtype);
+
+dpu_block_id_t fetcheco_get_block_id(struct dpu_fetchunit *fu)
+{
+	switch (fu->id) {
+	case 0:
+		return ID_FETCHECO0;
+	case 1:
+		return ID_FETCHECO1;
+	case 2:
+		return ID_FETCHECO2;
+	case 9:
+		return ID_FETCHECO9;
+	default:
+		WARN_ON(1);
+	}
+
+	return ID_NONE;
+}
+EXPORT_SYMBOL_GPL(fetcheco_get_block_id);
+
+struct dpu_fetchunit *dpu_fe_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fe_ids); i++)
+		if (fe_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fe_ids))
+		return ERR_PTR(-EINVAL);
+
+	fu = dpu->fe_priv[i];
+
+	mutex_lock(&fu->mutex);
+
+	if (fu->inuse) {
+		mutex_unlock(&fu->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	fu->inuse = true;
+
+	mutex_unlock(&fu->mutex);
+
+	return fu;
+}
+EXPORT_SYMBOL_GPL(dpu_fe_get);
+
+void dpu_fe_put(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+
+	fu->inuse = false;
+
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_fe_put);
+
+static const struct dpu_fetchunit_ops fe_ops = {
+	.set_burstlength	= fetchunit_set_burstlength,
+	.set_baseaddress	= fetchunit_set_baseaddress,
+	.set_src_bpp		= fetchunit_set_src_bpp,
+	.set_src_stride		= fetchunit_set_src_stride,
+	.set_src_buf_dimensions	= fetcheco_set_src_buf_dimensions,
+	.set_fmt		= fetcheco_set_fmt,
+	.enable_src_buf		= fetchunit_enable_src_buf,
+	.disable_src_buf	= fetchunit_disable_src_buf,
+	.is_enabled		= fetchunit_is_enabled,
+	.set_framedimensions	= fetcheco_set_framedimensions,
+	.set_controltrigger	= fetcheco_set_controltrigger,
+	.get_stream_id		= fetchunit_get_stream_id,
+	.set_stream_id		= fetchunit_set_stream_id,
+};
+
+void _dpu_fe_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fe_ids); i++)
+		if (fe_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(fe_ids)))
+		return;
+
+	fu = dpu->fe_priv[i];
+
+	fetchunit_shden(fu, true);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BURSTBUFFERMANAGEMENT,
+			SETNUMBUFFERS(16) | SETBURSTLENGTH(16));
+	mutex_unlock(&fu->mutex);
+}
+
+int dpu_fe_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_fetcheco *fe;
+	struct dpu_fetchunit *fu;
+	int i;
+
+	fe = devm_kzalloc(dpu->dev, sizeof(*fe), GFP_KERNEL);
+	if (!fe)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(fe_ids); i++)
+		if (fe_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fe_ids))
+		return -EINVAL;
+
+	fu = &fe->fu;
+	dpu->fe_priv[i] = fu;
+
+	fu->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_16);
+	if (!fu->pec_base)
+		return -ENOMEM;
+
+	fu->base = devm_ioremap(dpu->dev, base, SZ_128);
+	if (!fu->base)
+		return -ENOMEM;
+
+	fu->dpu = dpu;
+	fu->id = id;
+	fu->type = FU_T_FE;
+	fu->ops = &fe_ops;
+	fu->name = "fetcheco";
+
+	mutex_init(&fu->mutex);
+
+	_dpu_fe_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-fetchlayer.c b/drivers/gpu/imx/dpu/dpu-fetchlayer.c
new file mode 100644
index 000000000..3a72a8e65
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-fetchlayer.c
@@ -0,0 +1,294 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_STATUS		0x8
+#define BASEADDRESS(n)			(0x10 + (n) * 0x28)
+#define SOURCEBUFFERATTRIBUTES(n)	(0x14 + (n) * 0x28)
+#define SOURCEBUFFERDIMENSION(n)	(0x18 + (n) * 0x28)
+#define COLORCOMPONENTBITS(n)		(0x1C + (n) * 0x28)
+#define COLORCOMPONENTSHIFT(n)		(0x20 + (n) * 0x28)
+#define LAYEROFFSET(n)			(0x24 + (n) * 0x28)
+#define CLIPWINDOWOFFSET(n)		(0x28 + (n) * 0x28)
+#define CLIPWINDOWDIMENSIONS(n)		(0x2C + (n) * 0x28)
+#define CONSTANTCOLOR(n)		(0x30 + (n) * 0x28)
+#define LAYERPROPERTY(n)		(0x34 + (n) * 0x28)
+#define FRAMEDIMENSIONS			0x150
+#define FRAMERESAMPLING			0x154
+#define CONTROL				0x158
+#define TRIGGERENABLE			0x15C
+#define SHDLDREQ(lm)			((lm) & 0xFF)
+#define CONTROLTRIGGER			0x160
+#define START				0x164
+#define FETCHTYPE			0x168
+#define BURSTBUFFERPROPERTIES		0x16C
+#define STATUS				0x170
+#define HIDDENSTATUS			0x174
+
+struct dpu_fetchlayer {
+	struct dpu_fetchunit fu;
+	fetchtype_t fetchtype;
+};
+
+static void
+fetchlayer_set_src_buf_dimensions(struct dpu_fetchunit *fu,
+				  unsigned int w, unsigned int h,
+				  u32 unused1, bool unused2)
+{
+	u32 val;
+
+	val = LINEWIDTH(w) | LINECOUNT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, SOURCEBUFFERDIMENSION(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchlayer_set_fmt(struct dpu_fetchunit *fu,
+			       u32 fmt,
+			       enum drm_color_encoding color_encoding,
+			       enum drm_color_range color_range,
+			       bool unused)
+{
+	u32 val, bits, shift;
+	int i, sub_id = fu->sub_id;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(sub_id));
+	val &= ~YUVCONVERSIONMODE_MASK;
+	val |= YUVCONVERSIONMODE(YUVCONVERSIONMODE__OFF);
+	dpu_fu_write(fu, LAYERPROPERTY(sub_id), val);
+	mutex_unlock(&fu->mutex);
+
+	for (i = 0; i < ARRAY_SIZE(dpu_pixel_format_matrix); i++) {
+		if (dpu_pixel_format_matrix[i].pixel_format == fmt) {
+			bits = dpu_pixel_format_matrix[i].bits;
+			shift = dpu_pixel_format_matrix[i].shift;
+
+			mutex_lock(&fu->mutex);
+			dpu_fu_write(fu, COLORCOMPONENTBITS(sub_id), bits);
+			dpu_fu_write(fu, COLORCOMPONENTSHIFT(sub_id), shift);
+			mutex_unlock(&fu->mutex);
+			return;
+		}
+	}
+
+	WARN_ON(1);
+}
+
+static void
+fetchlayer_set_framedimensions(struct dpu_fetchunit *fu, unsigned int w,
+			       unsigned int h, bool unused)
+{
+	u32 val;
+
+	val = FRAMEWIDTH(w) | FRAMEHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, FRAMEDIMENSIONS, val);
+	mutex_unlock(&fu->mutex);
+}
+
+void fetchlayer_rgb_constantcolor(struct dpu_fetchunit *fu,
+					u8 r, u8 g, u8 b, u8 a)
+{
+	u32 val;
+
+	val = rgb_color(r, g, b, a);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR(fu->id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchlayer_rgb_constantcolor);
+
+void fetchlayer_yuv_constantcolor(struct dpu_fetchunit *fu, u8 y, u8 u, u8 v)
+{
+	u32 val;
+
+	val = yuv_color(y, u, v);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR(fu->id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchlayer_yuv_constantcolor);
+
+static void fetchlayer_set_controltrigger(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONTROLTRIGGER, SHDTOKGEN);
+	mutex_unlock(&fu->mutex);
+}
+
+int fetchlayer_fetchtype(struct dpu_fetchunit *fu, fetchtype_t *type)
+{
+	struct dpu_soc *dpu = fu->dpu;
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FETCHTYPE);
+	val &= FETCHTYPE_MASK;
+	mutex_unlock(&fu->mutex);
+
+	switch (val) {
+	case FETCHTYPE__DECODE:
+	case FETCHTYPE__LAYER:
+	case FETCHTYPE__WARP:
+	case FETCHTYPE__ECO:
+	case FETCHTYPE__PERSP:
+	case FETCHTYPE__ROT:
+	case FETCHTYPE__DECODEL:
+	case FETCHTYPE__LAYERL:
+	case FETCHTYPE__ROTL:
+		break;
+	default:
+		dev_warn(dpu->dev, "Invalid fetch type %u for FetchLayer%d\n",
+				val, fu->id);
+		return -EINVAL;
+	}
+
+	*type = val;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(fetchlayer_fetchtype);
+
+struct dpu_fetchunit *dpu_fl_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fl_ids); i++)
+		if (fl_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fl_ids))
+		return ERR_PTR(-EINVAL);
+
+	fu = dpu->fl_priv[i];
+
+	mutex_lock(&fu->mutex);
+
+	if (fu->inuse) {
+		mutex_unlock(&fu->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	fu->inuse = true;
+
+	mutex_unlock(&fu->mutex);
+
+	return fu;
+}
+EXPORT_SYMBOL_GPL(dpu_fl_get);
+
+void dpu_fl_put(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+
+	fu->inuse = false;
+
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_fl_put);
+
+static const struct dpu_fetchunit_ops fl_ops = {
+	.set_burstlength	= fetchunit_set_burstlength,
+	.set_baseaddress	= fetchunit_set_baseaddress,
+	.set_src_bpp		= fetchunit_set_src_bpp,
+	.set_src_stride		= fetchunit_set_src_stride,
+	.set_src_buf_dimensions	= fetchlayer_set_src_buf_dimensions,
+	.set_fmt		= fetchlayer_set_fmt,
+	.set_pixel_blend_mode	= fetchunit_set_pixel_blend_mode,
+	.enable_src_buf		= fetchunit_enable_src_buf,
+	.disable_src_buf	= fetchunit_disable_src_buf,
+	.is_enabled		= fetchunit_is_enabled,
+	.set_framedimensions	= fetchlayer_set_framedimensions,
+	.set_controltrigger	= fetchlayer_set_controltrigger,
+	.get_stream_id		= fetchunit_get_stream_id,
+	.set_stream_id		= fetchunit_set_stream_id,
+};
+
+void _dpu_fl_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fl_ids); i++)
+		if (fl_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(fl_ids)))
+		return;
+
+	fu = dpu->fl_priv[i];
+
+	fetchunit_baddr_autoupdate(fu, 0x0);
+	fetchunit_shden(fu, true);
+	fetchunit_shdldreq_sticky(fu, 0xFF);
+	fetchunit_disable_src_buf(fu);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BURSTBUFFERMANAGEMENT,
+			SETNUMBUFFERS(16) | SETBURSTLENGTH(16));
+	mutex_unlock(&fu->mutex);
+}
+
+int dpu_fl_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_fetchlayer *fl;
+	struct dpu_fetchunit *fu;
+	int ret;
+
+	fl = devm_kzalloc(dpu->dev, sizeof(*fl), GFP_KERNEL);
+	if (!fl)
+		return -ENOMEM;
+
+	fu = &fl->fu;
+	dpu->fl_priv[id] = fu;
+
+	fu->pec_base = devm_ioremap(dpu->dev, base, SZ_16);
+	if (!fu->pec_base)
+		return -ENOMEM;
+
+	fu->base = devm_ioremap(dpu->dev, base, SZ_512);
+	if (!fu->base)
+		return -ENOMEM;
+
+	fu->dpu = dpu;
+	fu->id = id;
+	fu->sub_id = 0;
+	fu->type = FU_T_FL;
+	fu->ops = &fl_ops;
+	fu->name = "fetchlayer";
+
+	mutex_init(&fu->mutex);
+
+	ret = fetchlayer_fetchtype(fu, &fl->fetchtype);
+	if (ret < 0)
+		return ret;
+
+	_dpu_fl_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-fetchunit.c b/drivers/gpu/imx/dpu/dpu-fetchunit.c
new file mode 100644
index 000000000..e6a49874a
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-fetchunit.c
@@ -0,0 +1,346 @@
+/*
+ * Copyright 2018-2019,2021 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <drm/drm_blend.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define BASEADDRESS(n)			(0x10 + (n) * 0x28)
+#define SOURCEBUFFERATTRIBUTES(n)	(0x14 + (n) * 0x28)
+#define SOURCEBUFFERDIMENSION(n)	(0x18 + (n) * 0x28)
+#define COLORCOMPONENTBITS(n)		(0x1C + (n) * 0x28)
+#define COLORCOMPONENTSHIFT(n)		(0x20 + (n) * 0x28)
+#define LAYEROFFSET(n)			(0x24 + (n) * 0x28)
+#define CLIPWINDOWOFFSET(n)		(0x28 + (n) * 0x28)
+#define CLIPWINDOWDIMENSIONS(n)		(0x2C + (n) * 0x28)
+#define CONSTANTCOLOR(n)		(0x30 + (n) * 0x28)
+#define LAYERPROPERTY(n)		(0x34 + (n) * 0x28)
+
+/* base address has to align to burst size */
+unsigned int fetchunit_burst_size_fixup_tkt343664(dma_addr_t baddr)
+{
+	unsigned int burst_size;
+
+	burst_size = 1 << (ffs(baddr) - 1);
+	burst_size = round_up(burst_size, 8);
+	burst_size = min(burst_size, 128U);
+
+	return burst_size;
+}
+EXPORT_SYMBOL_GPL(fetchunit_burst_size_fixup_tkt343664);
+
+/* fixup for burst size vs stride mismatch */
+unsigned int
+fetchunit_stride_fixup_tkt339017(unsigned int stride, unsigned int burst_size,
+				 dma_addr_t baddr, bool nonzero_mod)
+{
+	if (nonzero_mod)
+		stride = round_up(stride + round_up(baddr % 8, 8), burst_size);
+	else
+		stride = round_up(stride, burst_size);
+
+	return stride;
+}
+EXPORT_SYMBOL_GPL(fetchunit_stride_fixup_tkt339017);
+
+void fetchunit_get_dprc(struct dpu_fetchunit *fu, void *data)
+{
+	if (WARN_ON(!fu))
+		return;
+
+	fu->dprc = data;
+}
+EXPORT_SYMBOL_GPL(fetchunit_get_dprc);
+
+void fetchunit_shden(struct dpu_fetchunit *fu, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_fu_write(fu, STATICCONTROL, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_shden);
+
+void fetchunit_baddr_autoupdate(struct dpu_fetchunit *fu, u8 layer_mask)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, STATICCONTROL);
+	val &= ~BASEADDRESSAUTOUPDATE_MASK;
+	val |= BASEADDRESSAUTOUPDATE(layer_mask);
+	dpu_fu_write(fu, STATICCONTROL, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_baddr_autoupdate);
+
+void fetchunit_shdldreq_sticky(struct dpu_fetchunit *fu, u8 layer_mask)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, STATICCONTROL);
+	val &= ~SHDLDREQSTICKY_MASK;
+	val |= SHDLDREQSTICKY(layer_mask);
+	dpu_fu_write(fu, STATICCONTROL, val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_shdldreq_sticky);
+
+void fetchunit_set_burstlength(struct dpu_fetchunit *fu,
+			       unsigned int x_offset, unsigned int mt_w,
+			       int bpp, dma_addr_t baddr, bool use_prefetch)
+{
+	struct dpu_soc *dpu = fu->dpu;
+	unsigned int burst_size, burst_length;
+	bool nonzero_mod = !!mt_w;
+	u32 val;
+
+	if (use_prefetch) {
+		/* consider PRG x offset to calculate buffer address */
+		if (nonzero_mod)
+			baddr += (dma_addr_t)(x_offset % mt_w) * (bpp / 8);
+
+		burst_size = fetchunit_burst_size_fixup_tkt343664(baddr);
+		burst_length = burst_size / 8;
+	} else {
+		burst_length = 16;
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, BURSTBUFFERMANAGEMENT);
+	val &= ~SETBURSTLENGTH_MASK;
+	val |= SETBURSTLENGTH(burst_length);
+	dpu_fu_write(fu, BURSTBUFFERMANAGEMENT, val);
+	mutex_unlock(&fu->mutex);
+
+	dev_dbg(dpu->dev, "%s%d burst length is %u\n",
+					fu->name, fu->id, burst_length);
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_burstlength);
+
+void fetchunit_set_baseaddress(struct dpu_fetchunit *fu, unsigned int width,
+			       unsigned int x_offset, unsigned int y_offset,
+			       unsigned int mt_w, unsigned int mt_h,
+			       int bpp, dma_addr_t baddr)
+{
+	unsigned int burst_size, stride;
+	bool nonzero_mod = !!mt_w;
+
+	if (nonzero_mod) {
+		/* consider PRG x offset to calculate buffer address */
+		baddr += (dma_addr_t)(x_offset % mt_w) * (bpp / 8);
+
+		burst_size = fetchunit_burst_size_fixup_tkt343664(baddr);
+
+		stride = width * (bpp / 8);
+		stride = fetchunit_stride_fixup_tkt339017(stride, burst_size,
+							  baddr, nonzero_mod);
+
+		/* consider PRG y offset to calculate buffer address */
+		baddr += (dma_addr_t)(y_offset % mt_h) * stride;
+	}
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BASEADDRESS(fu->sub_id), baddr);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_baseaddress);
+
+void fetchunit_set_src_bpp(struct dpu_fetchunit *fu, int bpp)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, SOURCEBUFFERATTRIBUTES(fu->sub_id));
+	val &= ~0x3f0000;
+	val |= BITSPERPIXEL(bpp);
+	dpu_fu_write(fu, SOURCEBUFFERATTRIBUTES(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_src_bpp);
+
+/*
+ * The arguments width and bpp are valid only when use_prefetch is true.
+ * For fetcheco, since the pixel format has to be NV12 or NV21 when
+ * use_prefetch is true, we assume width stands for how many UV we have
+ * in bytes for one line, while bpp should be 8bits for every U or V component.
+ */
+void fetchunit_set_src_stride(struct dpu_fetchunit *fu,
+			      unsigned int width, unsigned int x_offset,
+			      unsigned int mt_w, int bpp, unsigned int stride,
+			      dma_addr_t baddr, bool use_prefetch)
+{
+	unsigned int burst_size;
+	bool nonzero_mod = !!mt_w;
+	u32 val;
+
+	if (use_prefetch) {
+		/* consider PRG x offset to calculate buffer address */
+		if (nonzero_mod)
+			baddr += (dma_addr_t)(x_offset % mt_w) * (bpp / 8);
+
+		burst_size = fetchunit_burst_size_fixup_tkt343664(baddr);
+
+		stride = width * (bpp / 8);
+		stride = fetchunit_stride_fixup_tkt339017(stride, burst_size,
+							  baddr, nonzero_mod);
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, SOURCEBUFFERATTRIBUTES(fu->sub_id));
+	val &= ~0xffff;
+	val |= STRIDE(stride);
+	dpu_fu_write(fu, SOURCEBUFFERATTRIBUTES(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_src_stride);
+
+void fetchunit_set_pixel_blend_mode(struct dpu_fetchunit *fu,
+				    unsigned int pixel_blend_mode, u16 alpha,
+				    u32 fb_format)
+{
+	u32 mode = 0, val;
+
+	if (pixel_blend_mode == DRM_MODE_BLEND_PREMULTI ||
+	    pixel_blend_mode == DRM_MODE_BLEND_COVERAGE) {
+		mode = ALPHACONSTENABLE;
+
+		switch (fb_format) {
+		case DRM_FORMAT_ARGB8888:
+		case DRM_FORMAT_ABGR8888:
+		case DRM_FORMAT_RGBA8888:
+		case DRM_FORMAT_BGRA8888:
+			mode |= ALPHASRCENABLE;
+			break;
+		}
+	}
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(fu->sub_id));
+	val &= ~(PREMULCONSTRGB | ALPHA_ENABLE_MASK | RGB_ENABLE_MASK);
+	val |= mode;
+	dpu_fu_write(fu, LAYERPROPERTY(fu->sub_id), val);
+
+	val = dpu_fu_read(fu, CONSTANTCOLOR(fu->sub_id));
+	val &= ~CONSTANTALPHA_MASK;
+	val |= CONSTANTALPHA(alpha >> 8);
+	dpu_fu_write(fu, CONSTANTCOLOR(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_pixel_blend_mode);
+
+void fetchunit_enable_src_buf(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(fu->sub_id));
+	val |= SOURCEBUFFERENABLE;
+	dpu_fu_write(fu, LAYERPROPERTY(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_enable_src_buf);
+
+void fetchunit_disable_src_buf(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(fu->sub_id));
+	val &= ~SOURCEBUFFERENABLE;
+	dpu_fu_write(fu, LAYERPROPERTY(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchunit_disable_src_buf);
+
+bool fetchunit_is_enabled(struct dpu_fetchunit *fu)
+{
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(fu->sub_id));
+	mutex_unlock(&fu->mutex);
+
+	return !!(val & SOURCEBUFFERENABLE);
+}
+EXPORT_SYMBOL_GPL(fetchunit_is_enabled);
+
+unsigned int fetchunit_get_stream_id(struct dpu_fetchunit *fu)
+{
+	if (WARN_ON(!fu))
+		return DPU_PLANE_SRC_DISABLED;
+
+	return fu->stream_id;
+}
+EXPORT_SYMBOL_GPL(fetchunit_get_stream_id);
+
+void fetchunit_set_stream_id(struct dpu_fetchunit *fu, unsigned int id)
+{
+	if (WARN_ON(!fu))
+		return;
+
+	switch (id) {
+	case DPU_PLANE_SRC_TO_DISP_STREAM0:
+	case DPU_PLANE_SRC_TO_DISP_STREAM1:
+	case DPU_PLANE_SRC_DISABLED:
+		fu->stream_id = id;
+		break;
+	default:
+		WARN_ON(1);
+	}
+}
+EXPORT_SYMBOL_GPL(fetchunit_set_stream_id);
+
+bool fetchunit_is_fetchdecode(struct dpu_fetchunit *fu)
+{
+	if (WARN_ON(!fu))
+		return false;
+
+	return fu->type == FU_T_FD;
+}
+EXPORT_SYMBOL_GPL(fetchunit_is_fetchdecode);
+
+bool fetchunit_is_fetcheco(struct dpu_fetchunit *fu)
+{
+	if (WARN_ON(!fu))
+		return false;
+
+	return fu->type == FU_T_FE;
+}
+EXPORT_SYMBOL_GPL(fetchunit_is_fetcheco);
+
+bool fetchunit_is_fetchlayer(struct dpu_fetchunit *fu)
+{
+	if (WARN_ON(!fu))
+		return false;
+
+	return fu->type == FU_T_FL;
+}
+EXPORT_SYMBOL_GPL(fetchunit_is_fetchlayer);
+
+bool fetchunit_is_fetchwarp(struct dpu_fetchunit *fu)
+{
+	if (WARN_ON(!fu))
+		return false;
+
+	return fu->type == FU_T_FW;
+}
+EXPORT_SYMBOL_GPL(fetchunit_is_fetchwarp);
diff --git a/drivers/gpu/imx/dpu/dpu-fetchwarp.c b/drivers/gpu/imx/dpu/dpu-fetchwarp.c
new file mode 100644
index 000000000..953368e3f
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-fetchwarp.c
@@ -0,0 +1,305 @@
+/*
+ * Copyright 2018-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_STATUS		0x8
+#define BASEADDRESS(n)			(0x10 + (n) * 0x28)
+#define SOURCEBUFFERATTRIBUTES(n)	(0x14 + (n) * 0x28)
+#define SOURCEBUFFERDIMENSION(n)	(0x18 + (n) * 0x28)
+#define COLORCOMPONENTBITS(n)		(0x1C + (n) * 0x28)
+#define COLORCOMPONENTSHIFT(n)		(0x20 + (n) * 0x28)
+#define LAYEROFFSET(n)			(0x24 + (n) * 0x28)
+#define CLIPWINDOWOFFSET(n)		(0x28 + (n) * 0x28)
+#define CLIPWINDOWDIMENSIONS(n)		(0x2C + (n) * 0x28)
+#define CONSTANTCOLOR(n)		(0x30 + (n) * 0x28)
+#define LAYERPROPERTY(n)		(0x34 + (n) * 0x28)
+#define FRAMEDIMENSIONS			0x150
+#define FRAMERESAMPLING			0x154
+#define WARPCONTROL			0x158
+#define ARBSTARTX			0x15c
+#define ARBSTARTY			0x160
+#define ARBDELTA			0x164
+#define FIRPOSITIONS			0x168
+#define FIRCOEFFICIENTS			0x16c
+#define CONTROL				0x170
+#define TRIGGERENABLE			0x174
+#define SHDLDREQ(lm)			((lm) & 0xFF)
+#define CONTROLTRIGGER			0x178
+#define START				0x17c
+#define FETCHTYPE			0x180
+#define BURSTBUFFERPROPERTIES		0x184
+#define STATUS				0x188
+#define HIDDENSTATUS			0x18c
+
+struct dpu_fetchwarp {
+	struct dpu_fetchunit fu;
+	fetchtype_t fetchtype;
+};
+
+static void
+fetchwarp_set_src_buf_dimensions(struct dpu_fetchunit *fu,
+				 unsigned int w, unsigned int h,
+				 u32 unused1, bool unused2)
+{
+	u32 val;
+
+	val = LINEWIDTH(w) | LINECOUNT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, SOURCEBUFFERDIMENSION(fu->sub_id), val);
+	mutex_unlock(&fu->mutex);
+}
+
+static void fetchwarp_set_fmt(struct dpu_fetchunit *fu,
+			      u32 fmt,
+			      enum drm_color_encoding color_encoding,
+			      enum drm_color_range color_range,
+			      bool unused)
+{
+	u32 val, bits, shift;
+	int i, sub_id = fu->sub_id;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, LAYERPROPERTY(sub_id));
+	val &= ~YUVCONVERSIONMODE_MASK;
+	dpu_fu_write(fu, LAYERPROPERTY(sub_id), val);
+	mutex_unlock(&fu->mutex);
+
+	for (i = 0; i < ARRAY_SIZE(dpu_pixel_format_matrix); i++) {
+		if (dpu_pixel_format_matrix[i].pixel_format == fmt) {
+			bits = dpu_pixel_format_matrix[i].bits;
+			shift = dpu_pixel_format_matrix[i].shift;
+
+			mutex_lock(&fu->mutex);
+			dpu_fu_write(fu, COLORCOMPONENTBITS(sub_id), bits);
+			dpu_fu_write(fu, COLORCOMPONENTSHIFT(sub_id), shift);
+			mutex_unlock(&fu->mutex);
+			return;
+		}
+	}
+
+	WARN_ON(1);
+}
+
+static void
+fetchwarp_set_framedimensions(struct dpu_fetchunit *fu,
+			      unsigned int w, unsigned int h, bool unused)
+{
+	u32 val;
+
+	val = FRAMEWIDTH(w) | FRAMEHEIGHT(h);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, FRAMEDIMENSIONS, val);
+	mutex_unlock(&fu->mutex);
+}
+
+void fetchwarp_rgb_constantcolor(struct dpu_fetchunit *fu,
+				 u8 r, u8 g, u8 b, u8 a)
+{
+	u32 val;
+
+	val = rgb_color(r, g, b, a);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR(fu->id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchwarp_rgb_constantcolor);
+
+void fetchwarp_yuv_constantcolor(struct dpu_fetchunit *fu, u8 y, u8 u, u8 v)
+{
+	u32 val;
+
+	val = yuv_color(y, u, v);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONSTANTCOLOR(fu->id), val);
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(fetchwarp_yuv_constantcolor);
+
+static void fetchwarp_set_controltrigger(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, CONTROLTRIGGER, SHDTOKGEN);
+	mutex_unlock(&fu->mutex);
+}
+
+int fetchwarp_fetchtype(struct dpu_fetchunit *fu, fetchtype_t *type)
+{
+	struct dpu_soc *dpu = fu->dpu;
+	u32 val;
+
+	mutex_lock(&fu->mutex);
+	val = dpu_fu_read(fu, FETCHTYPE);
+	val &= FETCHTYPE_MASK;
+	mutex_unlock(&fu->mutex);
+
+	switch (val) {
+	case FETCHTYPE__DECODE:
+	case FETCHTYPE__LAYER:
+	case FETCHTYPE__WARP:
+	case FETCHTYPE__ECO:
+	case FETCHTYPE__PERSP:
+	case FETCHTYPE__ROT:
+	case FETCHTYPE__DECODEL:
+	case FETCHTYPE__LAYERL:
+	case FETCHTYPE__ROTL:
+		break;
+	default:
+		dev_warn(dpu->dev, "Invalid fetch type %u for FetchWarp%d\n",
+				val, fu->id);
+		return -EINVAL;
+	}
+
+	*type = val;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(fetchwarp_fetchtype);
+
+struct dpu_fetchunit *dpu_fw_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fw_ids); i++)
+		if (fw_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fw_ids))
+		return ERR_PTR(-EINVAL);
+
+	fu = dpu->fw_priv[i];
+
+	mutex_lock(&fu->mutex);
+
+	if (fu->inuse) {
+		mutex_unlock(&fu->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	fu->inuse = true;
+
+	mutex_unlock(&fu->mutex);
+
+	return fu;
+}
+EXPORT_SYMBOL_GPL(dpu_fw_get);
+
+void dpu_fw_put(struct dpu_fetchunit *fu)
+{
+	mutex_lock(&fu->mutex);
+
+	fu->inuse = false;
+
+	mutex_unlock(&fu->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_fw_put);
+
+static const struct dpu_fetchunit_ops fw_ops = {
+	.set_burstlength	= fetchunit_set_burstlength,
+	.set_baseaddress	= fetchunit_set_baseaddress,
+	.set_src_bpp		= fetchunit_set_src_bpp,
+	.set_src_stride		= fetchunit_set_src_stride,
+	.set_src_buf_dimensions	= fetchwarp_set_src_buf_dimensions,
+	.set_fmt		= fetchwarp_set_fmt,
+	.set_pixel_blend_mode	= fetchunit_set_pixel_blend_mode,
+	.enable_src_buf		= fetchunit_enable_src_buf,
+	.disable_src_buf	= fetchunit_disable_src_buf,
+	.is_enabled		= fetchunit_is_enabled,
+	.set_framedimensions	= fetchwarp_set_framedimensions,
+	.set_controltrigger	= fetchwarp_set_controltrigger,
+	.get_stream_id		= fetchunit_get_stream_id,
+	.set_stream_id		= fetchunit_set_stream_id,
+};
+
+void _dpu_fw_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_fetchunit *fu;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fw_ids); i++)
+		if (fw_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(fw_ids)))
+		return;
+
+	fu = dpu->fw_priv[i];
+
+	fetchunit_baddr_autoupdate(fu, 0x0);
+	fetchunit_shden(fu, true);
+	fetchunit_shdldreq_sticky(fu, 0xFF);
+	fetchunit_disable_src_buf(fu);
+
+	mutex_lock(&fu->mutex);
+	dpu_fu_write(fu, BURSTBUFFERMANAGEMENT,
+			SETNUMBUFFERS(16) | SETBURSTLENGTH(16));
+	mutex_unlock(&fu->mutex);
+}
+
+int dpu_fw_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_fetchwarp *fw;
+	struct dpu_fetchunit *fu;
+	int i, ret;
+
+	fw = devm_kzalloc(dpu->dev, sizeof(*fw), GFP_KERNEL);
+	if (!fw)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(fw_ids); i++)
+		if (fw_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fw_ids))
+		return -EINVAL;
+
+	fu = &fw->fu;
+	dpu->fw_priv[i] = fu;
+
+	fu->pec_base = devm_ioremap(dpu->dev, base, SZ_16);
+	if (!fu->pec_base)
+		return -ENOMEM;
+
+	fu->base = devm_ioremap(dpu->dev, base, SZ_512);
+	if (!fu->base)
+		return -ENOMEM;
+
+	fu->dpu = dpu;
+	fu->id = id;
+	fu->sub_id = 0;
+	fu->type = FU_T_FW;
+	fu->ops = &fw_ops;
+	fu->name = "fetchwarp";
+
+	mutex_init(&fu->mutex);
+
+	ret = fetchwarp_fetchtype(fu, &fw->fetchtype);
+	if (ret < 0)
+		return ret;
+
+	_dpu_fw_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-framegen.c b/drivers/gpu/imx/dpu/dpu-framegen.c
new file mode 100644
index 000000000..50d7d50e1
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-framegen.c
@@ -0,0 +1,601 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <drm/drm_mode.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define FGSTCTRL		0x8
+#define FGSYNCMODE_MASK		0x6
+#define HTCFG1			0xC
+#define HTOTAL(n)		((((n) - 1) & 0x3FFF) << 16)
+#define HACT(n)			((n) & 0x3FFF)
+#define HTCFG2			0x10
+#define HSEN			BIT(31)
+#define HSBP(n)			((((n) - 1) & 0x3FFF) << 16)
+#define HSYNC(n)		(((n) - 1) & 0x3FFF)
+#define VTCFG1			0x14
+#define VTOTAL(n)		((((n) - 1) & 0x3FFF) << 16)
+#define VACT(n)			((n) & 0x3FFF)
+#define VTCFG2			0x18
+#define VSEN			BIT(31)
+#define VSBP(n)			((((n) - 1) & 0x3FFF) << 16)
+#define VSYNC(n)		(((n) - 1) & 0x3FFF)
+#define INTCONFIG(n)		(0x1C + 4 * (n))
+#define EN			BIT(31)
+#define ROW(n)			(((n) & 0x3FFF) << 16)
+#define COL(n)			((n) & 0x3FFF)
+#define PKICKCONFIG		0x2C
+#define SKICKCONFIG		0x30
+#define SECSTATCONFIG		0x34
+#define FGSRCR1			0x38
+#define FGSRCR2			0x3C
+#define FGSRCR3			0x40
+#define FGSRCR4			0x44
+#define FGSRCR5			0x48
+#define FGSRCR6			0x4C
+#define FGKSDR			0x50
+#define PACFG			0x54
+#define STARTX(n)		(((n) + 1) & 0x3FFF)
+#define STARTY(n)		(((((n) + 1) & 0x3FFF)) << 16)
+#define SACFG			0x58
+#define FGINCTRL		0x5C
+#define FGDM_MASK		0x7
+#define ENPRIMALPHA		BIT(3)
+#define ENSECALPHA		BIT(4)
+#define FGINCTRLPANIC		0x60
+#define FGCCR			0x64
+#define CCALPHA(a)		(((a) & 0x1) << 30)
+#define CCRED(r)		(((r) & 0x3FF) << 20)
+#define CCGREEN(g)		(((g) & 0x3FF) << 10)
+#define CCBLUE(b)		((b) & 0x3FF)
+#define FGENABLE		0x68
+#define FGEN			BIT(0)
+#define FGSLR			0x6C
+#define FGENSTS			0x70
+#define ENSTS			BIT(0)
+#define FGTIMESTAMP		0x74
+#define LINEINDEX_MASK		0x3FFF
+#define LINEINDEX_SHIFT		0
+#define FRAMEINDEX_MASK		0xFFFFC000
+#define FRAMEINDEX_SHIFT	14
+#define FGCHSTAT		0x78
+#define SECSYNCSTAT		BIT(24)
+#define SFIFOEMPTY		BIT(16)
+#define FGCHSTATCLR		0x7C
+#define CLRSECSTAT		BIT(16)
+#define FGSKEWMON		0x80
+#define FGSFIFOMIN		0x84
+#define FGSFIFOMAX		0x88
+#define FGSFIFOFILLCLR		0x8C
+#define FGSREPD			0x90
+#define FGSRFTD			0x94
+
+#define KHZ			1000
+#define PLL_MIN_FREQ_HZ		648000000
+
+struct dpu_framegen {
+	void __iomem *base;
+	struct clk *clk_pll;
+	struct clk *clk_bypass;
+	struct clk *clk_disp;
+	struct clk *clk_disp_lpcg;
+	struct mutex mutex;
+	int id;
+	unsigned int encoder_type;
+	bool inuse;
+	bool use_bypass_clk;
+	bool side_by_side;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_fg_read(struct dpu_framegen *fg, unsigned int offset)
+{
+	return readl(fg->base + offset);
+}
+
+static inline void dpu_fg_write(struct dpu_framegen *fg,
+				unsigned int offset, u32 value)
+{
+	writel(value, fg->base + offset);
+}
+
+void framegen_enable(struct dpu_framegen *fg)
+{
+	dpu_fg_write(fg, FGENABLE, FGEN);
+}
+EXPORT_SYMBOL_GPL(framegen_enable);
+
+void framegen_disable(struct dpu_framegen *fg)
+{
+	dpu_fg_write(fg, FGENABLE, 0);
+}
+EXPORT_SYMBOL_GPL(framegen_disable);
+
+void framegen_enable_pixel_link(struct dpu_framegen *fg)
+{
+	struct dpu_soc *dpu = fg->dpu;
+	const struct dpu_data *data = dpu->data;
+
+	if (!(data->has_dual_ldb && fg->encoder_type == DRM_MODE_ENCODER_LVDS))
+		dpu_pxlink_set_mst_enable(fg->dpu, fg->id, true);
+
+	if (fg->encoder_type == DRM_MODE_ENCODER_DPI) {
+		dpu_pxlink_set_mst_valid(fg->dpu, fg->id, true);
+		dpu_pxlink_set_sync_ctrl(fg->dpu, fg->id, true);
+	}
+}
+EXPORT_SYMBOL_GPL(framegen_enable_pixel_link);
+
+void framegen_disable_pixel_link(struct dpu_framegen *fg)
+{
+	struct dpu_soc *dpu = fg->dpu;
+	const struct dpu_data *data = dpu->data;
+
+	if (fg->encoder_type == DRM_MODE_ENCODER_DPI) {
+		dpu_pxlink_set_mst_valid(fg->dpu, fg->id, false);
+		dpu_pxlink_set_sync_ctrl(fg->dpu, fg->id, false);
+	}
+
+	if (!(data->has_dual_ldb && fg->encoder_type == DRM_MODE_ENCODER_LVDS))
+		dpu_pxlink_set_mst_enable(fg->dpu, fg->id, false);
+}
+EXPORT_SYMBOL_GPL(framegen_disable_pixel_link);
+
+void framegen_shdtokgen(struct dpu_framegen *fg)
+{
+	dpu_fg_write(fg, FGSLR, SHDTOKGEN);
+}
+EXPORT_SYMBOL_GPL(framegen_shdtokgen);
+
+void framegen_syncmode(struct dpu_framegen *fg, fgsyncmode_t mode)
+{
+	u32 val;
+
+	val = dpu_fg_read(fg, FGSTCTRL);
+	val &= ~FGSYNCMODE_MASK;
+	val |= mode;
+	dpu_fg_write(fg, FGSTCTRL, val);
+
+	dpu_pxlink_set_dc_sync_mode(fg->dpu, mode != FGSYNCMODE__OFF);
+}
+EXPORT_SYMBOL_GPL(framegen_syncmode);
+
+void framegen_cfg_videomode(struct dpu_framegen *fg, struct drm_display_mode *m,
+			    bool side_by_side, unsigned int encoder_type)
+{
+	struct dpu_soc *dpu = fg->dpu;
+	u32 hact, htotal, hsync, hsbp;
+	u32 vact, vtotal, vsync, vsbp;
+	u32 kick_row, kick_col;
+	u32 val;
+	unsigned long disp_clock_rate, pll_clock_rate = 0;
+	int div = 0;
+
+	fg->side_by_side = side_by_side;
+	fg->encoder_type = encoder_type;
+
+	hact = m->crtc_hdisplay;
+	htotal = m->crtc_htotal;
+	hsync = m->crtc_hsync_end - m->crtc_hsync_start;
+	hsbp = m->crtc_htotal - m->crtc_hsync_start;
+
+	if (side_by_side) {
+		hact /= 2;
+		htotal /= 2;
+		hsync /= 2;
+		hsbp /= 2;
+	}
+
+	vact = m->crtc_vdisplay;
+	vtotal = m->crtc_vtotal;
+	vsync = m->crtc_vsync_end - m->crtc_vsync_start;
+	vsbp = m->crtc_vtotal - m->crtc_vsync_start;
+
+	/* video mode */
+	dpu_fg_write(fg, HTCFG1, HACT(hact)   | HTOTAL(htotal));
+	dpu_fg_write(fg, HTCFG2, HSYNC(hsync) | HSBP(hsbp) | HSEN);
+	dpu_fg_write(fg, VTCFG1, VACT(vact)   | VTOTAL(vtotal));
+	dpu_fg_write(fg, VTCFG2, VSYNC(vsync) | VSBP(vsbp) | VSEN);
+
+	kick_col = hact + 1;
+	kick_row = vact;
+	/*
+	 * FrameGen as slave needs to be kicked later for
+	 * one line comparing to the master.
+	 */
+	if (side_by_side && framegen_is_slave(fg))
+		kick_row++;
+
+	/* pkickconfig */
+	dpu_fg_write(fg, PKICKCONFIG, COL(kick_col) | ROW(kick_row) | EN);
+
+	/* skikconfig */
+	dpu_fg_write(fg, SKICKCONFIG, COL(kick_col) | ROW(kick_row) | EN);
+
+	/* primary and secondary area position config */
+	dpu_fg_write(fg, PACFG, STARTX(0) | STARTY(0));
+	dpu_fg_write(fg, SACFG, STARTX(0) | STARTY(0));
+
+	/* alpha */
+	val = dpu_fg_read(fg, FGINCTRL);
+	val &= ~(ENPRIMALPHA | ENSECALPHA);
+	dpu_fg_write(fg, FGINCTRL, val);
+
+	val = dpu_fg_read(fg, FGINCTRLPANIC);
+	val &= ~(ENPRIMALPHA | ENSECALPHA);
+	dpu_fg_write(fg, FGINCTRLPANIC, val);
+
+	/* constant color */
+	dpu_fg_write(fg, FGCCR, 0);
+
+	disp_clock_rate = m->crtc_clock * 1000;
+
+	if (encoder_type == DRM_MODE_ENCODER_TMDS) {
+		clk_set_parent(fg->clk_disp, fg->clk_bypass);
+		if (side_by_side) {
+			dpu_pxlink_set_mst_addr(dpu, fg->id, fg->id ? 2 : 1);
+			clk_set_rate(fg->clk_bypass, disp_clock_rate / 2);
+			clk_set_rate(fg->clk_disp, disp_clock_rate / 2);
+		} else {
+			dpu_pxlink_set_mst_addr(dpu, fg->id, 1);
+			clk_set_rate(fg->clk_bypass, disp_clock_rate);
+			clk_set_rate(fg->clk_disp, disp_clock_rate);
+		}
+
+		fg->use_bypass_clk = true;
+	} else {
+		dpu_pxlink_set_mst_addr(dpu, fg->id,
+				encoder_type == DRM_MODE_ENCODER_DPI ? 1 : 0);
+
+		clk_set_parent(fg->clk_disp, fg->clk_pll);
+
+		/* find an even divisor for PLL */
+		do {
+			div += 2;
+			pll_clock_rate = disp_clock_rate * div;
+		} while (pll_clock_rate < PLL_MIN_FREQ_HZ);
+
+		clk_set_rate(fg->clk_pll, pll_clock_rate);
+		clk_set_rate(fg->clk_disp, disp_clock_rate);
+
+		fg->use_bypass_clk = false;
+	}
+}
+EXPORT_SYMBOL_GPL(framegen_cfg_videomode);
+
+void framegen_pkickconfig(struct dpu_framegen *fg, bool enable)
+{
+	u32 val;
+
+	val = dpu_fg_read(fg, PKICKCONFIG);
+	if (enable)
+		val |= EN;
+	else
+		val &= ~EN;
+	dpu_fg_write(fg, PKICKCONFIG, val);
+}
+EXPORT_SYMBOL_GPL(framegen_pkickconfig);
+
+void framegen_syncmode_fixup(struct dpu_framegen *fg, bool enable)
+{
+	u32 val;
+
+	val = dpu_fg_read(fg, SECSTATCONFIG);
+	if (enable)
+		val |= BIT(7);
+	else
+		val &= ~BIT(7);
+	dpu_fg_write(fg, SECSTATCONFIG, val);
+}
+EXPORT_SYMBOL_GPL(framegen_syncmode_fixup);
+
+void framegen_displaymode(struct dpu_framegen *fg, fgdm_t mode)
+{
+	u32 val;
+
+	val = dpu_fg_read(fg, FGINCTRL);
+	val &= ~FGDM_MASK;
+	val |= mode;
+	dpu_fg_write(fg, FGINCTRL, val);
+}
+EXPORT_SYMBOL_GPL(framegen_displaymode);
+
+void framegen_panic_displaymode(struct dpu_framegen *fg, fgdm_t mode)
+{
+	u32 val;
+
+	val = dpu_fg_read(fg, FGINCTRLPANIC);
+	val &= ~FGDM_MASK;
+	val |= mode;
+	dpu_fg_write(fg, FGINCTRLPANIC, val);
+}
+EXPORT_SYMBOL_GPL(framegen_panic_displaymode);
+
+void framegen_wait_done(struct dpu_framegen *fg, struct drm_display_mode *m)
+{
+	unsigned long timeout, pending_framedur_jiffies;
+	int frame_size = m->crtc_htotal * m->crtc_vtotal;
+	int dotclock, pending_framedur_ns;
+	u32 val;
+
+	dotclock = clk_get_rate(fg->clk_disp) / KHZ;
+	if (dotclock == 0) {
+		/* fall back to display mode's clock */
+		dotclock = m->crtc_clock;
+	}
+
+	/*
+	 * The SoC designer indicates that there are two pending frames
+	 * to complete in the worst case.
+	 * So, three pending frames are enough for sure.
+	 */
+	pending_framedur_ns = div_u64((u64) 3 * frame_size * 1000000, dotclock);
+	pending_framedur_jiffies = nsecs_to_jiffies(pending_framedur_ns);
+	if (pending_framedur_jiffies > (3 * HZ)) {
+		pending_framedur_jiffies = 3 * HZ;
+
+		dev_warn(fg->dpu->dev,
+			 "truncate FrameGen%d pending frame duration to 3sec\n",
+			 fg->id);
+	}
+	timeout = jiffies + pending_framedur_jiffies;
+
+	do {
+		val = dpu_fg_read(fg, FGENSTS);
+	} while ((val & ENSTS) && time_before(jiffies, timeout));
+
+	dev_dbg(fg->dpu->dev, "FrameGen%d pending frame duration is %ums\n",
+			 fg->id, jiffies_to_msecs(pending_framedur_jiffies));
+
+	if (val & ENSTS)
+		dev_err(fg->dpu->dev, "failed to wait for FrameGen%d done\n",
+			fg->id);
+}
+EXPORT_SYMBOL_GPL(framegen_wait_done);
+
+static inline u32 framegen_frame_index(u32 stamp)
+{
+	return (stamp & FRAMEINDEX_MASK) >> FRAMEINDEX_SHIFT;
+}
+
+static inline u32 framegen_line_index(u32 stamp)
+{
+	return (stamp & LINEINDEX_MASK) >> LINEINDEX_SHIFT;
+}
+
+void framegen_read_timestamp(struct dpu_framegen *fg,
+			     u32 *frame_index, u32 *line_index)
+{
+	u32 stamp;
+
+	stamp = dpu_fg_read(fg, FGTIMESTAMP);
+	*frame_index = framegen_frame_index(stamp);
+	*line_index = framegen_line_index(stamp);
+}
+EXPORT_SYMBOL_GPL(framegen_read_timestamp);
+
+void framegen_wait_for_frame_counter_moving(struct dpu_framegen *fg)
+{
+	u32 frame_index, line_index, last_frame_index;
+	unsigned long timeout = jiffies + msecs_to_jiffies(100);
+
+	framegen_read_timestamp(fg, &frame_index, &line_index);
+	do {
+		last_frame_index = frame_index;
+		framegen_read_timestamp(fg, &frame_index, &line_index);
+	} while (last_frame_index == frame_index &&
+						time_before(jiffies, timeout));
+
+	if (last_frame_index == frame_index)
+		dev_err(fg->dpu->dev,
+			"failed to wait for FrameGen%d frame counter moving\n",
+			fg->id);
+	else
+		dev_dbg(fg->dpu->dev,
+			"FrameGen%d frame counter moves - last %u, curr %d\n",
+			fg->id, last_frame_index, frame_index);
+}
+EXPORT_SYMBOL_GPL(framegen_wait_for_frame_counter_moving);
+
+bool framegen_secondary_requests_to_read_empty_fifo(struct dpu_framegen *fg)
+{
+	u32 val;
+	bool empty;
+
+	val = dpu_fg_read(fg, FGCHSTAT);
+
+	empty = !!(val & SFIFOEMPTY);
+
+	if (empty)
+		dev_dbg(fg->dpu->dev,
+			"FrameGen%d secondary requests to read empty FIFO\n",
+			fg->id);
+
+	return empty;
+}
+EXPORT_SYMBOL_GPL(framegen_secondary_requests_to_read_empty_fifo);
+
+void framegen_secondary_clear_channel_status(struct dpu_framegen *fg)
+{
+	dpu_fg_write(fg, FGCHSTATCLR, CLRSECSTAT);
+}
+EXPORT_SYMBOL_GPL(framegen_secondary_clear_channel_status);
+
+bool framegen_secondary_is_syncup(struct dpu_framegen *fg)
+{
+	u32 val = dpu_fg_read(fg, FGCHSTAT);
+
+	return val & SECSYNCSTAT;
+}
+EXPORT_SYMBOL_GPL(framegen_secondary_is_syncup);
+
+void framegen_wait_for_secondary_syncup(struct dpu_framegen *fg)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(100);
+	bool syncup;
+
+	do {
+		syncup = framegen_secondary_is_syncup(fg);
+	} while (!syncup && time_before(jiffies, timeout));
+
+	if (syncup)
+		dev_dbg(fg->dpu->dev, "FrameGen%d secondary syncup\n", fg->id);
+	else
+		dev_err(fg->dpu->dev,
+			"failed to wait for FrameGen%d secondary syncup\n",
+			fg->id);
+}
+EXPORT_SYMBOL_GPL(framegen_wait_for_secondary_syncup);
+
+void framegen_enable_clock(struct dpu_framegen *fg)
+{
+	if (!fg->use_bypass_clk)
+		clk_prepare_enable(fg->clk_pll);
+	clk_prepare_enable(fg->clk_disp);
+	clk_prepare_enable(fg->clk_disp_lpcg);
+}
+EXPORT_SYMBOL_GPL(framegen_enable_clock);
+
+void framegen_disable_clock(struct dpu_framegen *fg)
+{
+	if (!fg->use_bypass_clk)
+		clk_disable_unprepare(fg->clk_pll);
+	clk_disable_unprepare(fg->clk_disp);
+	clk_disable_unprepare(fg->clk_disp_lpcg);
+}
+EXPORT_SYMBOL_GPL(framegen_disable_clock);
+
+bool framegen_is_master(struct dpu_framegen *fg)
+{
+	const struct dpu_data *data = fg->dpu->data;
+
+	return fg->id == data->master_stream_id;
+}
+EXPORT_SYMBOL_GPL(framegen_is_master);
+
+bool framegen_is_slave(struct dpu_framegen *fg)
+{
+	return !framegen_is_master(fg);
+}
+EXPORT_SYMBOL_GPL(framegen_is_slave);
+
+struct dpu_framegen *dpu_fg_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_framegen *fg;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fg_ids); i++)
+		if (fg_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(fg_ids))
+		return ERR_PTR(-EINVAL);
+
+	fg = dpu->fg_priv[i];
+
+	mutex_lock(&fg->mutex);
+
+	if (fg->inuse) {
+		mutex_unlock(&fg->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	fg->inuse = true;
+
+	mutex_unlock(&fg->mutex);
+
+	return fg;
+}
+EXPORT_SYMBOL_GPL(dpu_fg_get);
+
+void dpu_fg_put(struct dpu_framegen *fg)
+{
+	mutex_lock(&fg->mutex);
+
+	fg->inuse = false;
+
+	mutex_unlock(&fg->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_fg_put);
+
+struct dpu_framegen *dpu_aux_fg_peek(struct dpu_framegen *fg)
+{
+	return fg->dpu->fg_priv[fg->id ^ 1];
+}
+EXPORT_SYMBOL_GPL(dpu_aux_fg_peek);
+
+void _dpu_fg_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_framegen *fg;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fg_ids); i++)
+		if (fg_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(fg_ids)))
+		return;
+
+	fg = dpu->fg_priv[i];
+
+	framegen_syncmode(fg, FGSYNCMODE__OFF);
+}
+
+int dpu_fg_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long unused, unsigned long base)
+{
+	struct dpu_framegen *fg;
+
+	fg = devm_kzalloc(dpu->dev, sizeof(*fg), GFP_KERNEL);
+	if (!fg)
+		return -ENOMEM;
+
+	dpu->fg_priv[id] = fg;
+
+	fg->base = devm_ioremap(dpu->dev, base, SZ_256);
+	if (!fg->base)
+		return -ENOMEM;
+
+	fg->clk_pll = devm_clk_get(dpu->dev, id ? "pll1" : "pll0");
+	if (IS_ERR(fg->clk_pll))
+		return PTR_ERR(fg->clk_pll);
+
+	fg->clk_bypass = devm_clk_get(dpu->dev, "bypass0");
+	if (IS_ERR(fg->clk_bypass))
+		return PTR_ERR(fg->clk_bypass);
+
+	fg->clk_disp = devm_clk_get(dpu->dev, id ? "disp1" : "disp0");
+	if (IS_ERR(fg->clk_disp))
+		return PTR_ERR(fg->clk_disp);
+
+	fg->clk_disp_lpcg = devm_clk_get(dpu->dev, id ? "disp1_lpcg" : "disp0_lpcg");
+	if (IS_ERR(fg->clk_disp_lpcg))
+		return PTR_ERR(fg->clk_disp_lpcg);
+
+	fg->dpu = dpu;
+	fg->id = id;
+	mutex_init(&fg->mutex);
+
+	_dpu_fg_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-hscaler.c b/drivers/gpu/imx/dpu/dpu-hscaler.c
new file mode 100644
index 000000000..9e69c619b
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-hscaler.c
@@ -0,0 +1,386 @@
+/*
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_DYNAMIC		0x8
+#define PIXENGCFG_DYNAMIC_SRC_SEL_MASK	0x3F
+
+#define SETUP1				0xC
+#define SCALE_FACTOR_MASK		0xFFFFF
+#define SCALE_FACTOR(n)			((n) & 0xFFFFF)
+#define SETUP2				0x10
+#define PHASE_OFFSET_MASK		0x1FFFFF
+#define PHASE_OFFSET(n)			((n) & 0x1FFFFF)
+#define CONTROL				0x14
+#define OUTPUT_SIZE_MASK		0x3FFF0000
+#define OUTPUT_SIZE(n)			((((n) - 1) << 16) & OUTPUT_SIZE_MASK)
+#define FILTER_MODE			0x100
+#define SCALE_MODE			0x10
+#define MODE				0x1
+
+static const hs_src_sel_t src_sels[3][6] = {
+	{
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__FETCHDECODE0,
+		HS_SRC_SEL__MATRIX4,
+		HS_SRC_SEL__VSCALER4,
+	}, {
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__FETCHDECODE1,
+		HS_SRC_SEL__MATRIX5,
+		HS_SRC_SEL__VSCALER5,
+	}, {
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__MATRIX9,
+		HS_SRC_SEL__VSCALER9,
+		HS_SRC_SEL__FILTER9,
+	},
+};
+
+struct dpu_hscaler {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+	/* see DPU_PLANE_SRC_xxx */
+	unsigned int stream_id;
+};
+
+static inline u32 dpu_pec_hs_read(struct dpu_hscaler *hs,
+				  unsigned int offset)
+{
+	return readl(hs->pec_base + offset);
+}
+
+static inline void dpu_pec_hs_write(struct dpu_hscaler *hs,
+				    unsigned int offset, u32 value)
+{
+	writel(value, hs->pec_base + offset);
+}
+
+static inline u32 dpu_hs_read(struct dpu_hscaler *hs, unsigned int offset)
+{
+	return readl(hs->base + offset);
+}
+
+static inline void dpu_hs_write(struct dpu_hscaler *hs,
+				unsigned int offset, u32 value)
+{
+	writel(value, hs->base + offset);
+}
+
+int hscaler_pixengcfg_dynamic_src_sel(struct dpu_hscaler *hs, hs_src_sel_t src)
+{
+	struct dpu_soc *dpu = hs->dpu;
+	const unsigned int hs_id_array[] = {4, 5, 9};
+	int i, j;
+	u32 val;
+
+	for (i = 0; i < ARRAY_SIZE(hs_id_array); i++)
+		if (hs_id_array[i] == hs->id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(hs_id_array)))
+		return -EINVAL;
+
+	mutex_lock(&hs->mutex);
+	for (j = 0; j < ARRAY_SIZE(src_sels[0]); j++) {
+		if (src_sels[i][j] == src) {
+			val = dpu_pec_hs_read(hs, PIXENGCFG_DYNAMIC);
+			val &= ~PIXENGCFG_DYNAMIC_SRC_SEL_MASK;
+			val |= src;
+			dpu_pec_hs_write(hs, PIXENGCFG_DYNAMIC, val);
+			mutex_unlock(&hs->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&hs->mutex);
+
+	dev_err(dpu->dev, "Invalid source for HScaler%d\n", hs->id);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(hscaler_pixengcfg_dynamic_src_sel);
+
+void hscaler_pixengcfg_clken(struct dpu_hscaler *hs, pixengcfg_clken_t clken)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_pec_hs_read(hs, PIXENGCFG_DYNAMIC);
+	val &= ~CLKEN_MASK;
+	val |= clken << CLKEN_MASK_SHIFT;
+	dpu_pec_hs_write(hs, PIXENGCFG_DYNAMIC, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_pixengcfg_clken);
+
+void hscaler_shden(struct dpu_hscaler *hs, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_hs_write(hs, STATICCONTROL, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_shden);
+
+void hscaler_setup1(struct dpu_hscaler *hs, u32 src, u32 dst)
+{
+	struct dpu_soc *dpu = hs->dpu;
+	u32 scale_factor;
+	u64 tmp64;
+
+	if (src == dst) {
+		scale_factor = 0x80000;
+	} else {
+		if (src > dst) {
+			tmp64 = (u64)((u64)dst * 0x80000);
+			do_div(tmp64, src);
+
+		} else {
+			tmp64 = (u64)((u64)src * 0x80000);
+			do_div(tmp64, dst);
+		}
+		scale_factor = (u32)tmp64;
+	}
+
+	WARN_ON(scale_factor > 0x80000);
+
+	mutex_lock(&hs->mutex);
+	dpu_hs_write(hs, SETUP1, SCALE_FACTOR(scale_factor));
+	mutex_unlock(&hs->mutex);
+
+	dev_dbg(dpu->dev, "Hscaler%d scale factor 0x%08x\n",
+						hs->id, scale_factor);
+}
+EXPORT_SYMBOL_GPL(hscaler_setup1);
+
+void hscaler_setup2(struct dpu_hscaler *hs, u32 phase_offset)
+{
+	mutex_lock(&hs->mutex);
+	dpu_hs_write(hs, SETUP2, PHASE_OFFSET(phase_offset));
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_setup2);
+
+void hscaler_output_size(struct dpu_hscaler *hs, u32 line_num)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~OUTPUT_SIZE_MASK;
+	val |= OUTPUT_SIZE(line_num);
+	dpu_hs_write(hs, CONTROL, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_output_size);
+
+void hscaler_filter_mode(struct dpu_hscaler *hs, scaler_filter_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~FILTER_MODE;
+	val |= m;
+	dpu_hs_write(hs, CONTROL, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_filter_mode);
+
+void hscaler_scale_mode(struct dpu_hscaler *hs, scaler_scale_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~SCALE_MODE;
+	val |= m;
+	dpu_hs_write(hs, CONTROL, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_scale_mode);
+
+void hscaler_mode(struct dpu_hscaler *hs, scaler_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~MODE;
+	val |= m;
+	dpu_hs_write(hs, CONTROL, val);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_mode);
+
+bool hscaler_is_enabled(struct dpu_hscaler *hs)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	mutex_unlock(&hs->mutex);
+
+	return (val & MODE) == SCALER_ACTIVE;
+}
+EXPORT_SYMBOL_GPL(hscaler_is_enabled);
+
+dpu_block_id_t hscaler_get_block_id(struct dpu_hscaler *hs)
+{
+	switch (hs->id) {
+	case 4:
+		return ID_HSCALER4;
+	case 5:
+		return ID_HSCALER5;
+	case 9:
+		return ID_HSCALER9;
+	default:
+		WARN_ON(1);
+	}
+
+	return ID_NONE;
+}
+EXPORT_SYMBOL_GPL(hscaler_get_block_id);
+
+unsigned int hscaler_get_stream_id(struct dpu_hscaler *hs)
+{
+	return hs->stream_id;
+}
+EXPORT_SYMBOL_GPL(hscaler_get_stream_id);
+
+void hscaler_set_stream_id(struct dpu_hscaler *hs, unsigned int id)
+{
+	switch (id) {
+	case DPU_PLANE_SRC_TO_DISP_STREAM0:
+	case DPU_PLANE_SRC_TO_DISP_STREAM1:
+	case DPU_PLANE_SRC_DISABLED:
+		hs->stream_id = id;
+		break;
+	default:
+		WARN_ON(1);
+	}
+}
+EXPORT_SYMBOL_GPL(hscaler_set_stream_id);
+
+struct dpu_hscaler *dpu_hs_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_hscaler *hs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(hs_ids); i++)
+		if (hs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(hs_ids))
+		return ERR_PTR(-EINVAL);
+
+	hs = dpu->hs_priv[i];
+
+	mutex_lock(&hs->mutex);
+
+	if (hs->inuse) {
+		mutex_unlock(&hs->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	hs->inuse = true;
+
+	mutex_unlock(&hs->mutex);
+
+	return hs;
+}
+EXPORT_SYMBOL_GPL(dpu_hs_get);
+
+void dpu_hs_put(struct dpu_hscaler *hs)
+{
+	mutex_lock(&hs->mutex);
+
+	hs->inuse = false;
+
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_hs_put);
+
+void _dpu_hs_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_hscaler *hs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(hs_ids); i++)
+		if (hs_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(hs_ids)))
+		return;
+
+	hs = dpu->hs_priv[i];
+
+	hscaler_shden(hs, true);
+	hscaler_setup2(hs, 0);
+	hscaler_pixengcfg_dynamic_src_sel(hs, HS_SRC_SEL__DISABLE);
+}
+
+int dpu_hs_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_hscaler *hs;
+	int i;
+
+	hs = devm_kzalloc(dpu->dev, sizeof(*hs), GFP_KERNEL);
+	if (!hs)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(hs_ids); i++)
+		if (hs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(hs_ids))
+		return -EINVAL;
+
+	dpu->hs_priv[i] = hs;
+
+	hs->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_8);
+	if (!hs->pec_base)
+		return -ENOMEM;
+
+	hs->base = devm_ioremap(dpu->dev, base, SZ_1K);
+	if (!hs->base)
+		return -ENOMEM;
+
+	hs->dpu = dpu;
+	hs->id = id;
+
+	mutex_init(&hs->mutex);
+
+	_dpu_hs_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-layerblend.c b/drivers/gpu/imx/dpu/dpu-layerblend.c
new file mode 100644
index 000000000..c19fcbdb1
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-layerblend.c
@@ -0,0 +1,346 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <drm/drm_blend.h>
+#include <linux/io.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_DYNAMIC			0x8
+#define PIXENGCFG_DYNAMIC_PRIM_SEL_MASK		0x3F
+#define PIXENGCFG_DYNAMIC_SEC_SEL_MASK		0x3F00
+#define PIXENGCFG_DYNAMIC_SEC_SEL_SHIFT		8
+
+static const lb_prim_sel_t prim_sels[] = {
+	LB_PRIM_SEL__DISABLE,
+	LB_PRIM_SEL__BLITBLEND9,
+	LB_PRIM_SEL__CONSTFRAME0,
+	LB_PRIM_SEL__CONSTFRAME1,
+	LB_PRIM_SEL__CONSTFRAME4,
+	LB_PRIM_SEL__CONSTFRAME5,
+	LB_PRIM_SEL__MATRIX4,
+	LB_PRIM_SEL__HSCALER4,
+	LB_PRIM_SEL__VSCALER4,
+	LB_PRIM_SEL__MATRIX5,
+	LB_PRIM_SEL__HSCALER5,
+	LB_PRIM_SEL__VSCALER5,
+	LB_PRIM_SEL__LAYERBLEND0,
+	LB_PRIM_SEL__LAYERBLEND1,
+	LB_PRIM_SEL__LAYERBLEND2,
+	LB_PRIM_SEL__LAYERBLEND3,
+};
+
+#define PIXENGCFG_STATUS			0xC
+#define SHDTOKSEL				(0x3 << 3)
+#define SHDTOKSEL_SHIFT				3
+#define SHDLDSEL				(0x3 << 1)
+#define SHDLDSEL_SHIFT				1
+#define CONTROL					0xC
+#define OPERATION_MODE_MASK			BIT(0)
+#define BLENDCONTROL				0x10
+#define ALPHA(a)				(((a) & 0xFF) << 16)
+#define PRIM_C_BLD_FUNC__ONE_MINUS_CONST_ALPHA	0x7
+#define PRIM_C_BLD_FUNC__ONE_MINUS_SEC_ALPHA	0x5
+#define PRIM_C_BLD_FUNC__ZERO			0x0
+#define SEC_C_BLD_FUNC__CONST_ALPHA		(0x6 << 4)
+#define SEC_C_BLD_FUNC__SEC_ALPHA		(0x4 << 4)
+#define PRIM_A_BLD_FUNC__ZERO			(0x0 << 8)
+#define SEC_A_BLD_FUNC__ZERO			(0x0 << 12)
+#define POSITION				0x14
+#define XPOS(x)					((x) & 0x7FFF)
+#define YPOS(y)					(((y) & 0x7FFF) << 16)
+#define PRIMCONTROLWORD				0x18
+#define SECCONTROLWORD				0x1C
+
+struct dpu_layerblend {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_pec_lb_read(struct dpu_layerblend *lb,
+				  unsigned int offset)
+{
+	return readl(lb->pec_base + offset);
+}
+
+static inline void dpu_pec_lb_write(struct dpu_layerblend *lb,
+				    unsigned int offset, u32 value)
+{
+	writel(value, lb->pec_base + offset);
+}
+
+static inline u32 dpu_lb_read(struct dpu_layerblend *lb, unsigned int offset)
+{
+	return readl(lb->base + offset);
+}
+
+static inline void dpu_lb_write(struct dpu_layerblend *lb,
+				unsigned int offset, u32 value)
+{
+	writel(value, lb->base + offset);
+}
+
+int layerblend_pixengcfg_dynamic_prim_sel(struct dpu_layerblend *lb,
+					  lb_prim_sel_t prim)
+{
+	struct dpu_soc *dpu = lb->dpu;
+	int fixed_sels_num = ARRAY_SIZE(prim_sels) - 4;
+	int i;
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	for (i = 0; i < fixed_sels_num + lb->id; i++) {
+		if (prim_sels[i] == prim) {
+			val = dpu_pec_lb_read(lb, PIXENGCFG_DYNAMIC);
+			val &= ~PIXENGCFG_DYNAMIC_PRIM_SEL_MASK;
+			val |= prim;
+			dpu_pec_lb_write(lb, PIXENGCFG_DYNAMIC, val);
+			mutex_unlock(&lb->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&lb->mutex);
+
+	dev_err(dpu->dev, "Invalid primary source for LayerBlend%d\n", lb->id);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(layerblend_pixengcfg_dynamic_prim_sel);
+
+void layerblend_pixengcfg_dynamic_sec_sel(struct dpu_layerblend *lb,
+					  lb_sec_sel_t sec)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_pec_lb_read(lb, PIXENGCFG_DYNAMIC);
+	val &= ~PIXENGCFG_DYNAMIC_SEC_SEL_MASK;
+	val |= sec << PIXENGCFG_DYNAMIC_SEC_SEL_SHIFT;
+	dpu_pec_lb_write(lb, PIXENGCFG_DYNAMIC, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_pixengcfg_dynamic_sec_sel);
+
+void layerblend_pixengcfg_clken(struct dpu_layerblend *lb,
+				pixengcfg_clken_t clken)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_pec_lb_read(lb, PIXENGCFG_DYNAMIC);
+	val &= ~CLKEN_MASK;
+	val |= clken << CLKEN_MASK_SHIFT;
+	dpu_pec_lb_write(lb, PIXENGCFG_DYNAMIC, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_pixengcfg_clken);
+
+void layerblend_shden(struct dpu_layerblend *lb, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_lb_read(lb, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_lb_write(lb, STATICCONTROL, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_shden);
+
+void layerblend_shdtoksel(struct dpu_layerblend *lb, lb_shadow_sel_t sel)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_lb_read(lb, STATICCONTROL);
+	val &= ~SHDTOKSEL;
+	val |= (sel << SHDTOKSEL_SHIFT);
+	dpu_lb_write(lb, STATICCONTROL, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_shdtoksel);
+
+void layerblend_shdldsel(struct dpu_layerblend *lb, lb_shadow_sel_t sel)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_lb_read(lb, STATICCONTROL);
+	val &= ~SHDLDSEL;
+	val |= (sel << SHDLDSEL_SHIFT);
+	dpu_lb_write(lb, STATICCONTROL, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_shdldsel);
+
+void layerblend_control(struct dpu_layerblend *lb, lb_mode_t mode)
+{
+	u32 val;
+
+	mutex_lock(&lb->mutex);
+	val = dpu_lb_read(lb, CONTROL);
+	val &= ~OPERATION_MODE_MASK;
+	val |= mode;
+	dpu_lb_write(lb, CONTROL, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_control);
+
+void layerblend_blendcontrol(struct dpu_layerblend *lb, unsigned int zpos,
+			     unsigned int pixel_blend_mode, u16 alpha)
+{
+	u32 val = PRIM_A_BLD_FUNC__ZERO | SEC_A_BLD_FUNC__ZERO;
+
+	if (zpos == 0) {
+		val |= PRIM_C_BLD_FUNC__ZERO | SEC_C_BLD_FUNC__CONST_ALPHA;
+		alpha = DRM_BLEND_ALPHA_OPAQUE;
+	} else {
+		switch (pixel_blend_mode) {
+		case DRM_MODE_BLEND_PIXEL_NONE:
+			val |= PRIM_C_BLD_FUNC__ONE_MINUS_CONST_ALPHA |
+			       SEC_C_BLD_FUNC__CONST_ALPHA;
+			break;
+		case DRM_MODE_BLEND_PREMULTI:
+			val |= PRIM_C_BLD_FUNC__ONE_MINUS_SEC_ALPHA |
+			       SEC_C_BLD_FUNC__CONST_ALPHA;
+			break;
+		case DRM_MODE_BLEND_COVERAGE:
+			val |= PRIM_C_BLD_FUNC__ONE_MINUS_SEC_ALPHA |
+			       SEC_C_BLD_FUNC__SEC_ALPHA;
+			break;
+		default:
+			break;
+		}
+	}
+
+	val |= ALPHA(alpha >> 8);
+
+	mutex_lock(&lb->mutex);
+	dpu_lb_write(lb, BLENDCONTROL, val);
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_blendcontrol);
+
+void layerblend_position(struct dpu_layerblend *lb, int x, int y)
+{
+	mutex_lock(&lb->mutex);
+	dpu_lb_write(lb, POSITION, XPOS(x) | YPOS(y));
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(layerblend_position);
+
+struct dpu_layerblend *dpu_lb_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_layerblend *lb;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(lb_ids); i++)
+		if (lb_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(lb_ids))
+		return ERR_PTR(-EINVAL);
+
+	lb = dpu->lb_priv[i];
+
+	mutex_lock(&lb->mutex);
+
+	if (lb->inuse) {
+		mutex_unlock(&lb->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	lb->inuse = true;
+
+	mutex_unlock(&lb->mutex);
+
+	return lb;
+}
+EXPORT_SYMBOL_GPL(dpu_lb_get);
+
+void dpu_lb_put(struct dpu_layerblend *lb)
+{
+	mutex_lock(&lb->mutex);
+
+	lb->inuse = false;
+
+	mutex_unlock(&lb->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_lb_put);
+
+void _dpu_lb_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_layerblend *lb;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(lb_ids); i++)
+		if (lb_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(lb_ids)))
+		return;
+
+	lb = dpu->lb_priv[i];
+
+	layerblend_pixengcfg_dynamic_prim_sel(lb, LB_PRIM_SEL__DISABLE);
+	layerblend_pixengcfg_dynamic_sec_sel(lb, LB_SEC_SEL__DISABLE);
+	layerblend_pixengcfg_clken(lb, CLKEN__AUTOMATIC);
+	layerblend_shdldsel(lb, BOTH);
+	layerblend_shdtoksel(lb, BOTH);
+	layerblend_shden(lb, true);
+}
+
+int dpu_lb_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_layerblend *lb;
+	int ret;
+
+	lb = devm_kzalloc(dpu->dev, sizeof(*lb), GFP_KERNEL);
+	if (!lb)
+		return -ENOMEM;
+
+	dpu->lb_priv[id] = lb;
+
+	lb->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_16);
+	if (!lb->pec_base)
+		return -ENOMEM;
+
+	lb->base = devm_ioremap(dpu->dev, base, SZ_32);
+	if (!lb->base)
+		return -ENOMEM;
+
+	lb->dpu = dpu;
+	lb->id = id;
+	mutex_init(&lb->mutex);
+
+	ret = layerblend_pixengcfg_dynamic_prim_sel(lb, LB_PRIM_SEL__DISABLE);
+	if (ret < 0)
+		return ret;
+
+	_dpu_lb_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-prv.h b/drivers/gpu/imx/dpu/dpu-prv.h
new file mode 100644
index 000000000..2c1b5a39a
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-prv.h
@@ -0,0 +1,467 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+#ifndef __DPU_PRV_H__
+#define __DPU_PRV_H__
+
+#include <linux/firmware/imx/sci.h>
+#include <drm/drm_fourcc.h>
+#include <video/dpu.h>
+
+#define STATICCONTROL			0x8
+#define SHDLDREQSTICKY(lm)		(((lm) & 0xFF) << 24)
+#define SHDLDREQSTICKY_MASK		(0xFF << 24)
+#define BASEADDRESSAUTOUPDATE(lm)	(((lm) & 0xFF) << 16)
+#define BASEADDRESSAUTOUPDATE_MASK	(0xFF << 16)
+#define SHDEN				BIT(0)
+#define BURSTBUFFERMANAGEMENT		0xC
+#define SETNUMBUFFERS(n)		((n) & 0xFF)
+#define SETBURSTLENGTH(n)		(((n) & 0x1F) << 8)
+#define SETBURSTLENGTH_MASK		0x1F00
+#define LINEMODE_MASK			0x80000000U
+#define LINEMODE_SHIFT			31U
+enum linemode {
+	/*
+	 * Mandatory setting for operation in the Display Controller.
+	 * Works also for Blit Engine with marginal performance impact.
+	 */
+	LINEMODE__DISPLAY = 0,
+	/* Recommended setting for operation in the Blit Engine. */
+	LINEMODE__BLIT = 1 << LINEMODE_SHIFT,
+};
+
+#define BITSPERPIXEL(bpp)		(((bpp) & 0x3F) << 16)
+#define STRIDE(n)			(((n) - 1) & 0xFFFF)
+#define LINEWIDTH(w)			(((w) - 1) & 0x3FFF)
+#define LINECOUNT(h)			((((h) - 1) & 0x3FFF) << 16)
+#define ITUFORMAT			BIT(31)
+#define R_BITS(n)			(((n) & 0xF) << 24)
+#define G_BITS(n)			(((n) & 0xF) << 16)
+#define B_BITS(n)			(((n) & 0xF) << 8)
+#define A_BITS(n)			((n) & 0xF)
+#define R_SHIFT(n)			(((n) & 0x1F) << 24)
+#define G_SHIFT(n)			(((n) & 0x1F) << 16)
+#define B_SHIFT(n)			(((n) & 0x1F) << 8)
+#define A_SHIFT(n)			((n) & 0x1F)
+#define Y_BITS(n)			R_BITS(n)
+#define Y_BITS_MASK			0xF000000
+#define U_BITS(n)			G_BITS(n)
+#define U_BITS_MASK			0xF0000
+#define V_BITS(n)			B_BITS(n)
+#define V_BITS_MASK			0xF00
+#define Y_SHIFT(n)			R_SHIFT(n)
+#define Y_SHIFT_MASK			0x1F000000
+#define U_SHIFT(n)			G_SHIFT(n)
+#define U_SHIFT_MASK			0x1F0000
+#define V_SHIFT(n)			B_SHIFT(n)
+#define V_SHIFT_MASK			0x1F00
+#define LAYERXOFFSET(x)			((x) & 0x7FFF)
+#define LAYERYOFFSET(y)			(((y) & 0x7FFF) << 16)
+#define CLIPWINDOWXOFFSET(x)		((x) & 0x7FFF)
+#define CLIPWINDOWYOFFSET(y)		(((y) & 0x7FFF) << 16)
+#define CLIPWINDOWWIDTH(w)		(((w) - 1) & 0x3FFF)
+#define CLIPWINDOWHEIGHT(h)		((((h) - 1) & 0x3FFF) << 16)
+#define CONSTANTALPHA_MASK		0xFF
+#define CONSTANTALPHA(n)		((n) & CONSTANTALPHA_MASK)
+#define	PALETTEENABLE			BIT(0)
+typedef enum {
+	TILE_FILL_ZERO,
+	TILE_FILL_CONSTANT,
+	TILE_PAD,
+	TILE_PAD_ZERO,
+} tilemode_t;
+#define ALPHASRCENABLE			BIT(8)
+#define ALPHACONSTENABLE		BIT(9)
+#define ALPHAMASKENABLE			BIT(10)
+#define ALPHATRANSENABLE		BIT(11)
+#define ALPHA_ENABLE_MASK		(ALPHASRCENABLE  | ALPHACONSTENABLE | \
+					 ALPHAMASKENABLE | ALPHATRANSENABLE)
+#define RGBALPHASRCENABLE		BIT(12)
+#define RGBALPHACONSTENABLE		BIT(13)
+#define RGBALPHAMASKENABLE		BIT(14)
+#define RGBALPHATRANSENABLE		BIT(15)
+#define RGB_ENABLE_MASK			(RGBALPHASRCENABLE   | \
+					 RGBALPHACONSTENABLE | \
+					 RGBALPHAMASKENABLE  | \
+					 RGBALPHATRANSENABLE)
+#define PREMULCONSTRGB			BIT(16)
+typedef enum {
+	YUVCONVERSIONMODE__OFF,
+	YUVCONVERSIONMODE__ITU601,
+	YUVCONVERSIONMODE__ITU601_FR,
+	YUVCONVERSIONMODE__ITU709,
+} yuvconversionmode_t;
+#define YUVCONVERSIONMODE_MASK		0x60000
+#define YUVCONVERSIONMODE(m)		(((m) & 0x3) << 17)
+#define GAMMAREMOVEENABLE		BIT(20)
+#define CLIPWINDOWENABLE		BIT(30)
+#define SOURCEBUFFERENABLE		BIT(31)
+#define EMPTYFRAME			BIT(31)
+#define FRAMEWIDTH(w)			(((w) - 1) & 0x3FFF)
+#define FRAMEHEIGHT(h)			((((h) - 1) & 0x3FFF) << 16)
+#define DELTAX_MASK			0x3F000
+#define DELTAY_MASK			0xFC0000
+#define DELTAX(x)			(((x) & 0x3F) << 12)
+#define DELTAY(y)			(((y) & 0x3F) << 18)
+#define YUV422UPSAMPLINGMODE_MASK	BIT(5)
+#define YUV422UPSAMPLINGMODE(m)		(((m) & 0x1) << 5)
+typedef enum {
+	YUV422UPSAMPLINGMODE__REPLICATE,
+	YUV422UPSAMPLINGMODE__INTERPOLATE,
+} yuv422upsamplingmode_t;
+#define INPUTSELECT_MASK		0x18
+#define INPUTSELECT(s)			(((s) & 0x3) << 3)
+typedef enum {
+	INPUTSELECT__INACTIVE,
+	INPUTSELECT__COMPPACK,
+	INPUTSELECT__ALPHAMASK,
+	INPUTSELECT__COORDINATE,
+} inputselect_t;
+#define RASTERMODE_MASK			0x7
+#define RASTERMODE(m)			((m) & 0x7)
+typedef enum {
+	RASTERMODE__NORMAL,
+	RASTERMODE__DECODE,
+	RASTERMODE__ARBITRARY,
+	RASTERMODE__PERSPECTIVE,
+	RASTERMODE__YUV422,
+	RASTERMODE__AFFINE,
+} rastermode_t;
+#define SHDTOKGEN			BIT(0)
+#define FETCHTYPE_MASK			0xF
+
+#define DPU_FRAC_PLANE_LAYER_NUM	8
+
+#define DPU_VPROC_CAP_HSCALER4	BIT(0)
+#define DPU_VPROC_CAP_VSCALER4	BIT(1)
+#define DPU_VPROC_CAP_HSCALER5	BIT(2)
+#define DPU_VPROC_CAP_VSCALER5	BIT(3)
+#define DPU_VPROC_CAP_FETCHECO0	BIT(4)
+#define DPU_VPROC_CAP_FETCHECO1	BIT(5)
+
+#define DPU_VPROC_CAP_HSCALE	(DPU_VPROC_CAP_HSCALER4 | \
+				 DPU_VPROC_CAP_HSCALER5)
+#define DPU_VPROC_CAP_VSCALE	(DPU_VPROC_CAP_VSCALER4 | \
+				 DPU_VPROC_CAP_VSCALER5)
+#define DPU_VPROC_CAP_FETCHECO	(DPU_VPROC_CAP_FETCHECO0 | \
+				 DPU_VPROC_CAP_FETCHECO1)
+
+struct dpu_unit {
+	char *name;
+	unsigned int num;
+	const unsigned int *ids;
+	const unsigned long *pec_ofss;	/* PixEngCFG */
+	const unsigned long *ofss;
+	const unsigned int *dprc_ids;
+};
+
+struct cm_reg_ofs {
+	u32 ipidentifier;
+	u32 lockunlock;
+	u32 lockstatus;
+	u32 userinterruptmask;
+	u32 interruptenable;
+	u32 interruptpreset;
+	u32 interruptclear;
+	u32 interruptstatus;
+	u32 userinterruptenable;
+	u32 userinterruptpreset;
+	u32 userinterruptclear;
+	u32 userinterruptstatus;
+	u32 generalpurpose;
+};
+
+struct dpu_data {
+	unsigned long cm_ofs;			/* common */
+	const struct dpu_unit *cfs;
+	const struct dpu_unit *decs;
+	const struct dpu_unit *eds;
+	const struct dpu_unit *fds;
+	const struct dpu_unit *fes;
+	const struct dpu_unit *fgs;
+	const struct dpu_unit *fls;
+	const struct dpu_unit *fws;
+	const struct dpu_unit *hss;
+	const struct dpu_unit *lbs;
+	const struct dpu_unit *sigs;
+	const struct dpu_unit *sts;
+	const struct dpu_unit *tcons;
+	const struct dpu_unit *vss;
+	const struct cm_reg_ofs *cm_reg_ofs;
+	const unsigned long *unused_irq;
+
+	unsigned int syncmode_min_prate;	/* need pixel combiner, KHz */
+	unsigned int singlemode_max_width;
+	unsigned int master_stream_id;
+
+	u32 plane_src_mask;
+
+	bool has_dual_ldb;
+};
+
+struct dpu_soc {
+	struct device		*dev;
+	const struct dpu_data	*data;
+	spinlock_t		lock;
+	struct list_head	list;
+
+	struct device		*pd_dc_dev;
+	struct device		*pd_pll0_dev;
+	struct device		*pd_pll1_dev;
+	struct device_link	*pd_dc_link;
+	struct device_link	*pd_pll0_link;
+	struct device_link	*pd_pll1_link;
+
+	void __iomem		*cm_reg;
+
+	int			id;
+	int			usecount;
+
+	int			irq_extdst0_shdload;
+	int			irq_extdst4_shdload;
+	int			irq_extdst1_shdload;
+	int			irq_extdst5_shdload;
+	int			irq_disengcfg_shdload0;
+	int			irq_disengcfg_framecomplete0;
+	int			irq_sig0_shdload;
+	int			irq_sig0_valid;
+	int			irq_disengcfg_shdload1;
+	int			irq_disengcfg_framecomplete1;
+	int			irq_sig1_shdload;
+	int			irq_sig1_valid;
+	int			irq_line_num;
+
+	bool			irq_chip_pm_get_extdst0_shdload;
+	bool			irq_chip_pm_get_extdst4_shdload;
+	bool			irq_chip_pm_get_extdst1_shdload;
+	bool			irq_chip_pm_get_extdst5_shdload;
+	bool			irq_chip_pm_get_disengcfg_shdload0;
+	bool			irq_chip_pm_get_disengcfg_framecomplete0;
+	bool			irq_chip_pm_get_sig0_shdload;
+	bool			irq_chip_pm_get_sig0_valid;
+	bool			irq_chip_pm_get_disengcfg_shdload1;
+	bool			irq_chip_pm_get_disengcfg_framecomplete1;
+	bool			irq_chip_pm_get_sig1_shdload;
+	bool			irq_chip_pm_get_sig1_valid;
+
+	struct irq_domain	*domain;
+
+	struct imx_sc_ipc	*dpu_ipc_handle;
+
+	struct dpu_constframe	*cf_priv[4];
+	struct dpu_disengcfg	*dec_priv[2];
+	struct dpu_extdst	*ed_priv[4];
+	struct dpu_fetchunit	*fd_priv[2];
+	struct dpu_fetchunit	*fe_priv[4];
+	struct dpu_framegen	*fg_priv[2];
+	struct dpu_fetchunit	*fl_priv[1];
+	struct dpu_fetchunit	*fw_priv[1];
+	struct dpu_hscaler	*hs_priv[3];
+	struct dpu_layerblend	*lb_priv[4];
+	struct dpu_signature	*sig_priv[2];
+	struct dpu_store	*st_priv[1];
+	struct dpu_tcon		*tcon_priv[2];
+	struct dpu_vscaler	*vs_priv[3];
+};
+
+int dpu_format_horz_chroma_subsampling(u32 format);
+int dpu_format_vert_chroma_subsampling(u32 format);
+int dpu_format_num_planes(u32 format);
+int dpu_format_plane_width(int width, u32 format, int plane);
+int dpu_format_plane_height(int height, u32 format, int plane);
+
+#define _DECLARE_DPU_UNIT_INIT_FUNC(block)			\
+void _dpu_##block##_init(struct dpu_soc *dpu, unsigned int id)	\
+
+_DECLARE_DPU_UNIT_INIT_FUNC(cf);
+_DECLARE_DPU_UNIT_INIT_FUNC(dec);
+_DECLARE_DPU_UNIT_INIT_FUNC(ed);
+_DECLARE_DPU_UNIT_INIT_FUNC(fd);
+_DECLARE_DPU_UNIT_INIT_FUNC(fe);
+_DECLARE_DPU_UNIT_INIT_FUNC(fg);
+_DECLARE_DPU_UNIT_INIT_FUNC(fl);
+_DECLARE_DPU_UNIT_INIT_FUNC(fw);
+_DECLARE_DPU_UNIT_INIT_FUNC(hs);
+_DECLARE_DPU_UNIT_INIT_FUNC(lb);
+_DECLARE_DPU_UNIT_INIT_FUNC(sig);
+_DECLARE_DPU_UNIT_INIT_FUNC(st);
+_DECLARE_DPU_UNIT_INIT_FUNC(tcon);
+_DECLARE_DPU_UNIT_INIT_FUNC(vs);
+
+#define DECLARE_DPU_UNIT_INIT_FUNC(block)			\
+int dpu_##block##_init(struct dpu_soc *dpu, unsigned int id,	\
+			 unsigned long pec_base, unsigned long base)
+
+DECLARE_DPU_UNIT_INIT_FUNC(cf);
+DECLARE_DPU_UNIT_INIT_FUNC(dec);
+DECLARE_DPU_UNIT_INIT_FUNC(ed);
+DECLARE_DPU_UNIT_INIT_FUNC(fd);
+DECLARE_DPU_UNIT_INIT_FUNC(fe);
+DECLARE_DPU_UNIT_INIT_FUNC(fg);
+DECLARE_DPU_UNIT_INIT_FUNC(fl);
+DECLARE_DPU_UNIT_INIT_FUNC(fw);
+DECLARE_DPU_UNIT_INIT_FUNC(hs);
+DECLARE_DPU_UNIT_INIT_FUNC(lb);
+DECLARE_DPU_UNIT_INIT_FUNC(sig);
+DECLARE_DPU_UNIT_INIT_FUNC(st);
+DECLARE_DPU_UNIT_INIT_FUNC(tcon);
+DECLARE_DPU_UNIT_INIT_FUNC(vs);
+
+static inline u32 dpu_pec_fu_read(struct dpu_fetchunit *fu, unsigned int offset)
+{
+	return readl(fu->pec_base + offset);
+}
+
+static inline void dpu_pec_fu_write(struct dpu_fetchunit *fu,
+				    unsigned int offset, u32 value)
+{
+	writel(value, fu->pec_base + offset);
+}
+
+static inline u32 dpu_fu_read(struct dpu_fetchunit *fu, unsigned int offset)
+{
+	return readl(fu->base + offset);
+}
+
+static inline void dpu_fu_write(struct dpu_fetchunit *fu,
+				unsigned int offset, u32 value)
+{
+	writel(value, fu->base + offset);
+}
+
+static inline u32 rgb_color(u8 r, u8 g, u8 b, u8 a)
+{
+	return (r << 24) | (g << 16) | (b << 8) | a;
+}
+
+static inline u32 yuv_color(u8 y, u8 u, u8 v)
+{
+	return (y << 24) | (u << 16) | (v << 8);
+}
+
+void tcon_get_pc(struct dpu_tcon *tcon, void *data);
+
+static const unsigned int cf_ids[] = {0, 1, 4, 5};
+static const unsigned int dec_ids[] = {0, 1};
+static const unsigned int ed_ids[] = {0, 1, 4, 5};
+static const unsigned int fd_ids[] = {0, 1};
+static const unsigned int fe_ids[] = {0, 1, 2, 9};
+static const unsigned int fg_ids[] = {0, 1};
+static const unsigned int fl_ids[] = {0};
+static const unsigned int fw_ids[] = {2};
+static const unsigned int hs_ids[] = {4, 5, 9};
+static const unsigned int lb_ids[] = {0, 1, 2, 3};
+static const unsigned int sig_ids[] = {0, 1};
+static const unsigned int st_ids[] = {9};
+static const unsigned int tcon_ids[] = {0, 1};
+static const unsigned int vs_ids[] = {4, 5, 9};
+
+static const unsigned int fd_dprc_ids[] = {3, 4};
+static const unsigned int fl_dprc_ids[] = {2};
+static const unsigned int fw_dprc_ids[] = {5};
+
+struct dpu_pixel_format {
+	u32 pixel_format;
+	u32 bits;
+	u32 shift;
+};
+
+static const struct dpu_pixel_format dpu_pixel_format_matrix[] = {
+	{
+		DRM_FORMAT_ARGB8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(8),
+		R_SHIFT(16) | G_SHIFT(8)  | B_SHIFT(0)  | A_SHIFT(24),
+	}, {
+		DRM_FORMAT_XRGB8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(16) | G_SHIFT(8)  | B_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_ABGR8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(8),
+		R_SHIFT(0)  | G_SHIFT(8)  | B_SHIFT(16) | A_SHIFT(24),
+	}, {
+		DRM_FORMAT_XBGR8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(0)  | G_SHIFT(8)  | B_SHIFT(16) | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_RGBA8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(8),
+		R_SHIFT(24) | G_SHIFT(16) | B_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_RGBX8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(24) | G_SHIFT(16) | B_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_BGRA8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(8),
+		R_SHIFT(8)  | G_SHIFT(16) | B_SHIFT(24) | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_BGRX8888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(8)  | G_SHIFT(16) | B_SHIFT(24) | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_RGB888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(16) | G_SHIFT(8)  | B_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_BGR888,
+		R_BITS(8)   | G_BITS(8)   | B_BITS(8)   | A_BITS(0),
+		R_SHIFT(0)  | G_SHIFT(8)  | B_SHIFT(16) | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_RGB565,
+		R_BITS(5)   | G_BITS(6)   | B_BITS(5)   | A_BITS(0),
+		R_SHIFT(11) | G_SHIFT(5)  | B_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_YUYV,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(8)  | V_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_UYVY,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(8)  | U_SHIFT(0)  | V_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV12,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(0)  | V_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV21,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(8)  | V_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV16,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(0)  | V_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV61,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(8)  | V_SHIFT(0)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV24,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(0)  | V_SHIFT(8)  | A_SHIFT(0),
+	}, {
+		DRM_FORMAT_NV42,
+		Y_BITS(8)   | U_BITS(8)   | V_BITS(8)   | A_BITS(0),
+		Y_SHIFT(0)  | U_SHIFT(8)  | V_SHIFT(0)  | A_SHIFT(0),
+	},
+};
+
+int dpu_sc_misc_get_handle(struct dpu_soc *dpu);
+int dpu_pxlink_set_mst_addr(struct dpu_soc *dpu, int disp_id, u32 val);
+int dpu_pxlink_set_mst_enable(struct dpu_soc *dpu, int disp_id, bool enable);
+int dpu_pxlink_set_mst_valid(struct dpu_soc *dpu, int disp_id, bool enable);
+int dpu_pxlink_set_sync_ctrl(struct dpu_soc *dpu, int disp_id, bool enable);
+int dpu_pxlink_set_dc_sync_mode(struct dpu_soc *dpu, bool enable);
+int dpu_sc_misc_init(struct dpu_soc *dpu);
+#endif				/* __DPU_PRV_H__ */
diff --git a/drivers/gpu/imx/dpu/dpu-sc-misc.c b/drivers/gpu/imx/dpu/dpu-sc-misc.c
new file mode 100644
index 000000000..20f600cb5
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-sc-misc.c
@@ -0,0 +1,93 @@
+/*
+ * Copyright 2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <dt-bindings/firmware/imx/rsrc.h>
+#include "dpu-prv.h"
+
+static inline int
+dpu_sc_misc_set_ctrl(struct dpu_soc *dpu, u32 rsc, u8 ctrl, u32 val)
+{
+	return imx_sc_misc_set_control(dpu->dpu_ipc_handle, rsc, ctrl, val);
+}
+
+int dpu_sc_misc_get_handle(struct dpu_soc *dpu)
+{
+	return imx_scu_get_handle(&dpu->dpu_ipc_handle);
+}
+
+int dpu_pxlink_set_mst_addr(struct dpu_soc *dpu, int disp_id, u32 val)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+	u8 ctrl = disp_id ?
+		IMX_SC_C_PXL_LINK_MST2_ADDR : IMX_SC_C_PXL_LINK_MST1_ADDR;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, ctrl, val);
+}
+
+int dpu_pxlink_set_mst_enable(struct dpu_soc *dpu, int disp_id, bool enable)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+	u8 ctrl = disp_id ?
+		IMX_SC_C_PXL_LINK_MST2_ENB: IMX_SC_C_PXL_LINK_MST1_ENB;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, ctrl, enable);
+}
+
+int dpu_pxlink_set_mst_valid(struct dpu_soc *dpu, int disp_id, bool enable)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+	u8 ctrl = disp_id ?
+		IMX_SC_C_PXL_LINK_MST2_VLD : IMX_SC_C_PXL_LINK_MST1_VLD;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, ctrl, enable);
+}
+
+int dpu_pxlink_set_sync_ctrl(struct dpu_soc *dpu, int disp_id, bool enable)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+	u8 ctrl = disp_id ? IMX_SC_C_SYNC_CTRL1 : IMX_SC_C_SYNC_CTRL0;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, ctrl, enable);
+}
+
+int dpu_pxlink_set_dc_sync_mode(struct dpu_soc *dpu, bool enable)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, IMX_SC_C_MODE, enable);
+}
+
+/* KACHUNK_CNT is needed for blit engine */
+int dpu_sc_misc_set_kachunk_cnt(struct dpu_soc *dpu, u32 cnt)
+{
+	u32 rsc = dpu->id ? IMX_SC_R_DC_1 : IMX_SC_R_DC_0;
+
+	return dpu_sc_misc_set_ctrl(dpu, rsc, IMX_SC_C_KACHUNK_CNT, cnt);
+}
+
+int dpu_sc_misc_init(struct dpu_soc *dpu)
+{
+	int disp_id, ret = 0;
+
+	for (disp_id = 0; disp_id < 2; disp_id++) {
+		ret |= dpu_pxlink_set_mst_addr(dpu, disp_id, 0);
+		ret |= dpu_pxlink_set_mst_enable(dpu, disp_id, false);
+		ret |= dpu_pxlink_set_mst_valid(dpu, disp_id, false);
+		ret |= dpu_pxlink_set_sync_ctrl(dpu, disp_id, false);
+	}
+
+	ret |= dpu_sc_misc_set_kachunk_cnt(dpu, 32);
+
+	return ret;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-signature.c b/drivers/gpu/imx/dpu/dpu-signature.c
new file mode 100644
index 000000000..5fca7a1c4
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-signature.c
@@ -0,0 +1,392 @@
+/*
+ * Copyright 2019,2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include "dpu-prv.h"
+
+#define STATICCONTROL		0x8
+#define SHDLDSEL		BIT(4)
+#define LOCAL			0
+#define GLOBAL			BIT(4)
+#define PANICCOLOR		0xC
+#define EVALCONTRL(n)		(0x10 + (n) * 0x24)
+#define ENGLOBALPANIC		BIT(17)
+#define ENLOCALPANIC		BIT(16)
+#define ALPHAINV		BIT(9)
+#define ALPHAMASK		BIT(8)
+#define ENCRC			BIT(1)
+#define ENEVALWIN		BIT(0)
+#define EVALUPPERLEFT(n)	(0x14 + (n) * 0x24)
+#define EVALLOWERRIGHT(n)	(0x18 + (n) * 0x24)
+#define YEVAL(y)		(((y) & 0x3FFF) << 16)
+#define XEVAL(x)		((x) & 0x3FFF)
+#define SIGCRCREDREF(n)		(0x1C + (n) * 0x24)
+#define SIGCRCGREENREF(n)	(0x20 + (n) * 0x24)
+#define SIGCRCBLUEREF(n)	(0x24 + (n) * 0x24)
+#define SIGCRCRED(n)		(0x28 + (n) * 0x24)
+#define SIGCRCGREEN(n)		(0x2C + (n) * 0x24)
+#define SIGCRCBLUE(n)		(0x30 + (n) * 0x24)
+#define SHADOWLOAD		0x130
+#define SHDLDREQ(n)		BIT(n)
+#define CONTINUOUSMODE		0x134
+#define ENCONT			BIT(0)
+#define SOFTWAREKICK		0x138
+#define KICK			BIT(0)
+#define STATUS			0x13C
+#define STSSIGIDLE		BIT(20)
+#define STSSIGVALID		BIT(16)
+#define STSSIGERROR(n)		BIT(n)
+#define STSSIGERROR_MASK	0xFF
+
+struct dpu_signature {
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_sig_read(struct dpu_signature *sig, unsigned int offset)
+{
+	return readl(sig->base + offset);
+}
+
+static inline void dpu_sig_write(struct dpu_signature *sig,
+				 unsigned int offset, u32 value)
+{
+	writel(value, sig->base + offset);
+}
+
+void signature_shden(struct dpu_signature *sig, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_sig_write(sig, STATICCONTROL, val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_shden);
+
+void signature_shdldsel_local(struct dpu_signature *sig)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATICCONTROL);
+	val &= ~GLOBAL;
+	dpu_sig_write(sig, STATICCONTROL, val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_shdldsel_local);
+
+void signature_shdldsel_global(struct dpu_signature *sig)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATICCONTROL);
+	dpu_sig_write(sig, STATICCONTROL, val | GLOBAL);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_shdldsel_global);
+
+void
+signature_global_panic(struct dpu_signature *sig, unsigned int win, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, EVALCONTRL(win));
+	if (enable)
+		val |= ENGLOBALPANIC;
+	else
+		val &= ~ENGLOBALPANIC;
+	dpu_sig_write(sig, EVALCONTRL(win), val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_global_panic);
+
+void
+signature_local_panic(struct dpu_signature *sig, unsigned int win, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, EVALCONTRL(win));
+	if (enable)
+		val |= ENLOCALPANIC;
+	else
+		val &= ~ENLOCALPANIC;
+	dpu_sig_write(sig, EVALCONTRL(win), val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_local_panic);
+
+void
+signature_alpha_mask(struct dpu_signature *sig, unsigned int win, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, EVALCONTRL(win));
+	if (enable)
+		val |= ALPHAMASK;
+	else
+		val &= ~ALPHAMASK;
+	dpu_sig_write(sig, EVALCONTRL(win), val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_alpha_mask);
+
+void signature_crc(struct dpu_signature *sig, unsigned int win, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, EVALCONTRL(win));
+	if (enable)
+		val |= ENCRC;
+	else
+		val &= ~ENCRC;
+	dpu_sig_write(sig, EVALCONTRL(win), val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_crc);
+
+void
+signature_eval_win(struct dpu_signature *sig, unsigned int win, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, EVALCONTRL(win));
+	if (enable)
+		val |= ENEVALWIN;
+	else
+		val &= ~ENEVALWIN;
+	dpu_sig_write(sig, EVALCONTRL(win), val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_eval_win);
+
+void signature_win(struct dpu_signature *sig, unsigned int win,
+		   int xul, int yul, int xlr, int ylr)
+{
+	mutex_lock(&sig->mutex);
+	dpu_sig_write(sig, EVALUPPERLEFT(win),  XEVAL(xul)   | YEVAL(yul));
+	dpu_sig_write(sig, EVALLOWERRIGHT(win), XEVAL(--xlr) | YEVAL(--ylr));
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_win);
+
+void signature_crc_value(struct dpu_signature *sig, unsigned int win,
+			 u32 *red, u32 *green, u32 *blue)
+{
+	mutex_lock(&sig->mutex);
+	*red   = dpu_sig_read(sig, SIGCRCRED(win));
+	*green = dpu_sig_read(sig, SIGCRCGREEN(win));
+	*blue  = dpu_sig_read(sig, SIGCRCBLUE(win));
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_crc_value);
+
+void signature_shdldreq(struct dpu_signature *sig, u8 win_mask)
+{
+	mutex_lock(&sig->mutex);
+	dpu_sig_write(sig, SHADOWLOAD, win_mask);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_shdldreq);
+
+void signature_continuous_mode(struct dpu_signature *sig, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, CONTINUOUSMODE);
+	if (enable)
+		val |= ENCONT;
+	else
+		val &= ~ENCONT;
+	dpu_sig_write(sig, CONTINUOUSMODE, val);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_continuous_mode);
+
+void signature_kick(struct dpu_signature *sig)
+{
+	mutex_lock(&sig->mutex);
+	dpu_sig_write(sig, SOFTWAREKICK, KICK);
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(signature_kick);
+
+bool signature_is_idle(struct dpu_signature *sig)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATUS);
+	mutex_unlock(&sig->mutex);
+
+	return !!(val & STSSIGIDLE);
+}
+EXPORT_SYMBOL_GPL(signature_is_idle);
+
+void signature_wait_for_idle(struct dpu_signature *sig)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(100);
+	bool idle;
+
+	do {
+		idle = signature_is_idle(sig);
+	} while (!idle && time_before(jiffies, timeout));
+
+	if (idle)
+		dev_dbg(sig->dpu->dev, "Signature%d is idle\n", sig->id);
+	else
+		dev_err(sig->dpu->dev,
+			"failed to wait for Signature%d idle\n", sig->id);
+}
+EXPORT_SYMBOL_GPL(signature_wait_for_idle);
+
+bool signature_is_valid(struct dpu_signature *sig)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATUS);
+	mutex_unlock(&sig->mutex);
+
+	return !!(val & STSSIGVALID);
+}
+EXPORT_SYMBOL_GPL(signature_is_valid);
+
+bool signature_is_error(struct dpu_signature *sig, u8 *err_win_mask)
+{
+	u32 val;
+
+	mutex_lock(&sig->mutex);
+	val = dpu_sig_read(sig, STATUS);
+	mutex_unlock(&sig->mutex);
+
+	*err_win_mask = val & STSSIGERROR_MASK;
+
+	return !!(*err_win_mask);
+}
+EXPORT_SYMBOL_GPL(signature_is_error);
+
+struct dpu_signature *dpu_sig_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_signature *sig;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(sig_ids); i++)
+		if (sig_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(sig_ids))
+		return ERR_PTR(-EINVAL);
+
+	sig = dpu->sig_priv[i];
+
+	mutex_lock(&sig->mutex);
+
+	if (sig->inuse) {
+		mutex_unlock(&sig->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	sig->inuse = true;
+
+	mutex_unlock(&sig->mutex);
+
+	return sig;
+}
+EXPORT_SYMBOL_GPL(dpu_sig_get);
+
+void dpu_sig_put(struct dpu_signature *sig)
+{
+	mutex_lock(&sig->mutex);
+
+	sig->inuse = false;
+
+	mutex_unlock(&sig->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_sig_put);
+
+struct dpu_signature *dpu_aux_sig_peek(struct dpu_signature *sig)
+{
+	return sig->dpu->sig_priv[sig->id ^ 1];
+}
+EXPORT_SYMBOL_GPL(dpu_aux_sig_peek);
+
+void _dpu_sig_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_signature *sig;
+	int i, j;
+
+	for (i = 0; i < ARRAY_SIZE(sig_ids); i++)
+		if (sig_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(sig_ids)))
+		return;
+
+	sig = dpu->sig_priv[i];
+
+	signature_shden(sig, true);
+	signature_shdldsel_local(sig);
+	for (j = 0; j < MAX_DPU_SIGNATURE_WIN_NUM; j++) {
+		signature_global_panic(sig, j, false);
+		signature_local_panic(sig, j, false);
+		signature_alpha_mask(sig, j, false);
+		signature_crc(sig, j, false);
+		signature_eval_win(sig, j, false);
+		signature_continuous_mode(sig, false);
+	}
+}
+
+int dpu_sig_init(struct dpu_soc *dpu, unsigned int id,
+			unsigned long unused, unsigned long base)
+{
+	struct dpu_signature *sig;
+
+	sig = devm_kzalloc(dpu->dev, sizeof(*sig), GFP_KERNEL);
+	if (!sig)
+		return -ENOMEM;
+
+	dpu->sig_priv[id] = sig;
+
+	sig->base = devm_ioremap(dpu->dev, base, SZ_512);
+	if (!sig->base)
+		return -ENOMEM;
+
+	sig->dpu = dpu;
+	sig->id = id;
+	mutex_init(&sig->mutex);
+
+	_dpu_sig_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-store.c b/drivers/gpu/imx/dpu/dpu-store.c
new file mode 100644
index 000000000..cbd06b835
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-store.c
@@ -0,0 +1,157 @@
+/*
+ * Copyright 2018-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_STATIC		0x8
+#define DIV(n)				(((n) & 0xFF) << 16)
+#define DIV_RESET			0x80
+
+struct dpu_store {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+};
+
+static inline u32 dpu_pec_st_read(struct dpu_store *st, unsigned int offset)
+{
+	return readl(st->pec_base + offset);
+}
+
+static inline void dpu_pec_st_write(struct dpu_store *st,
+				    unsigned int offset, u32 value)
+{
+	writel(value, st->pec_base + offset);
+}
+
+void store_pixengcfg_syncmode_fixup(struct dpu_store *st, bool enable)
+{
+	struct dpu_soc *dpu;
+	u32 val;
+
+	if (!st)
+		return;
+
+	dpu = st->dpu;
+
+	mutex_lock(&st->mutex);
+	val = dpu_pec_st_read(st, PIXENGCFG_STATIC);
+	if (enable)
+		val |= BIT(16);
+	else
+		val &= ~BIT(16);
+	dpu_pec_st_write(st, PIXENGCFG_STATIC, val);
+	mutex_unlock(&st->mutex);
+}
+EXPORT_SYMBOL_GPL(store_pixengcfg_syncmode_fixup);
+
+struct dpu_store *dpu_st_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_store *st;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(st_ids); i++)
+		if (st_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(st_ids))
+		return ERR_PTR(-EINVAL);
+
+	st = dpu->st_priv[i];
+
+	mutex_lock(&st->mutex);
+
+	if (st->inuse) {
+		mutex_unlock(&st->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	st->inuse = true;
+
+	mutex_unlock(&st->mutex);
+
+	return st;
+}
+EXPORT_SYMBOL_GPL(dpu_st_get);
+
+void dpu_st_put(struct dpu_store *st)
+{
+	mutex_lock(&st->mutex);
+
+	st->inuse = false;
+
+	mutex_unlock(&st->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_st_put);
+
+void _dpu_st_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_store *st;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(st_ids); i++)
+		if (st_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(st_ids)))
+		return;
+
+	st = dpu->st_priv[i];
+
+	dpu_pec_st_write(st, PIXENGCFG_STATIC, SHDEN | DIV(DIV_RESET));
+}
+
+int dpu_st_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_store *st;
+	int i;
+
+	st = devm_kzalloc(dpu->dev, sizeof(*st), GFP_KERNEL);
+	if (!st)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(st_ids); i++)
+		if (st_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(st_ids))
+		return -EINVAL;
+
+	dpu->st_priv[i] = st;
+
+	st->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_32);
+	if (!st->pec_base)
+		return -ENOMEM;
+
+	st->base = devm_ioremap(dpu->dev, base, SZ_256);
+	if (!st->base)
+		return -ENOMEM;
+
+	st->dpu = dpu;
+	st->id = id;
+	mutex_init(&st->mutex);
+
+	_dpu_st_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-tcon.c b/drivers/gpu/imx/dpu/dpu-tcon.c
new file mode 100644
index 000000000..bbecc2c72
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-tcon.c
@@ -0,0 +1,330 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017-2020 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/media-bus-format.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include <video/imx8-pc.h>
+#include "dpu-prv.h"
+
+#define SSQCNTS			0
+#define SSQCYCLE		0x8
+#define SWRESET			0xC
+#define TCON_CTRL		0x10
+#define BYPASS			BIT(3)
+#define RSDSINVCTRL		0x14
+#define MAPBIT3_0		0x18
+#define MAPBIT7_4		0x1C
+#define MAPBIT11_8		0x20
+#define MAPBIT15_12		0x24
+#define MAPBIT19_16		0x28
+#define MAPBIT23_20		0x2C
+#define MAPBIT27_24		0x30
+#define MAPBIT31_28		0x34
+#define MAPBIT34_32		0x38
+#define MAPBIT3_0_DUAL		0x3C
+#define MAPBIT7_4_DUAL		0x40
+#define MAPBIT11_8_DUAL		0x44
+#define MAPBIT15_12_DUAL	0x48
+#define MAPBIT19_16_DUAL	0x4C
+#define MAPBIT23_20_DUAL	0x50
+#define MAPBIT27_24_DUAL	0x54
+#define MAPBIT31_28_DUAL	0x58
+#define MAPBIT34_32_DUAL	0x5C
+#define SPGPOSON(n)		(0x60 + (n) * 16)
+#define X(n)			(((n) & 0x7FFF) << 16)
+#define Y(n)			((n) & 0x7FFF)
+#define SPGMASKON(n)		(0x64 + (n) * 16)
+#define SPGPOSOFF(n)		(0x68 + (n) * 16)
+#define SPGMASKOFF(n)		(0x6C + (n) * 16)
+#define SMXSIGS(n)		(0x120 + (n) * 8)
+#define SMXFCTTABLE(n)		(0x124 + (n) * 8)
+#define RESET_OVER_UNFERFLOW	0x180
+#define DUAL_DEBUG		0x184
+
+struct dpu_tcon {
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+	struct pc *pc;
+};
+
+static inline u32 dpu_tcon_read(struct dpu_tcon *tcon, unsigned int offset)
+{
+	return readl(tcon->base + offset);
+}
+
+static inline void dpu_tcon_write(struct dpu_tcon *tcon,
+				  unsigned int offset, u32 value)
+{
+	writel(value, tcon->base + offset);
+}
+
+int tcon_set_fmt(struct dpu_tcon *tcon, u32 bus_format)
+{
+	switch (bus_format) {
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		dpu_tcon_write(tcon, MAPBIT3_0,   0x19181716);
+		dpu_tcon_write(tcon, MAPBIT7_4,   0x1d1c1b1a);
+		dpu_tcon_write(tcon, MAPBIT11_8,  0x0f0e0d0c);
+		dpu_tcon_write(tcon, MAPBIT15_12, 0x13121110);
+		dpu_tcon_write(tcon, MAPBIT19_16, 0x05040302);
+		dpu_tcon_write(tcon, MAPBIT23_20, 0x09080706);
+		break;
+	case MEDIA_BUS_FMT_RGB101010_1X30:
+	case MEDIA_BUS_FMT_RGB888_1X30_PADLO:
+	case MEDIA_BUS_FMT_RGB666_1X30_PADLO:
+	case MEDIA_BUS_FMT_RGB565_1X30_PADLO:
+		dpu_tcon_write(tcon, MAPBIT3_0,   0x17161514);
+		dpu_tcon_write(tcon, MAPBIT7_4,   0x1b1a1918);
+		dpu_tcon_write(tcon, MAPBIT11_8,  0x0b0a1d1c);
+		dpu_tcon_write(tcon, MAPBIT15_12, 0x0f0e0d0c);
+		dpu_tcon_write(tcon, MAPBIT19_16, 0x13121110);
+		dpu_tcon_write(tcon, MAPBIT23_20, 0x03020100);
+		dpu_tcon_write(tcon, MAPBIT27_24, 0x07060504);
+		dpu_tcon_write(tcon, MAPBIT31_28, 0x00000908);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(tcon_set_fmt);
+
+/* This function is used to workaround TKT320590 which is related to DPR/PRG. */
+void tcon_set_operation_mode(struct dpu_tcon *tcon)
+{
+	u32 val;
+
+	val = dpu_tcon_read(tcon, TCON_CTRL);
+	val &= ~BYPASS;
+	dpu_tcon_write(tcon, TCON_CTRL, val);
+}
+EXPORT_SYMBOL_GPL(tcon_set_operation_mode);
+
+void tcon_cfg_videomode(struct dpu_tcon *tcon,
+			struct drm_display_mode *m, bool side_by_side)
+{
+	u32 val;
+	int hdisplay, hsync_start, hsync_end;
+	int vdisplay, vsync_start, vsync_end;
+	int y;
+
+	hdisplay = m->hdisplay;
+	vdisplay = m->vdisplay;
+	hsync_start = m->hsync_start;
+	vsync_start = m->vsync_start;
+	hsync_end = m->hsync_end;
+	vsync_end = m->vsync_end;
+
+	if (side_by_side) {
+		hdisplay /= 2;
+		hsync_start /= 2;
+		hsync_end /= 2;
+	}
+
+	/*
+	 * TKT320590:
+	 * Turn TCON into operation mode later after the first dumb frame is
+	 * generated by DPU.  This makes DPR/PRG be able to evade the frame.
+	 */
+	val = dpu_tcon_read(tcon, TCON_CTRL);
+	val |= BYPASS;
+	dpu_tcon_write(tcon, TCON_CTRL, val);
+
+	/* dsp_control[0]: hsync */
+	dpu_tcon_write(tcon, SPGPOSON(0), X(hsync_start));
+	dpu_tcon_write(tcon, SPGMASKON(0), 0xffff);
+
+	dpu_tcon_write(tcon, SPGPOSOFF(0), X(hsync_end));
+	dpu_tcon_write(tcon, SPGMASKOFF(0), 0xffff);
+
+	dpu_tcon_write(tcon, SMXSIGS(0), 0x2);
+	dpu_tcon_write(tcon, SMXFCTTABLE(0), 0x1);
+
+	/* dsp_control[1]: vsync */
+	dpu_tcon_write(tcon, SPGPOSON(1), X(hsync_start) | Y(vsync_start - 1));
+	dpu_tcon_write(tcon, SPGMASKON(1), 0x0);
+
+	dpu_tcon_write(tcon, SPGPOSOFF(1), X(hsync_start) | Y(vsync_end - 1));
+	dpu_tcon_write(tcon, SPGMASKOFF(1), 0x0);
+
+	dpu_tcon_write(tcon, SMXSIGS(1), 0x3);
+	dpu_tcon_write(tcon, SMXFCTTABLE(1), 0x1);
+
+	/* dsp_control[2]: data enable */
+	/* horizontal */
+	dpu_tcon_write(tcon, SPGPOSON(2), 0x0);
+	dpu_tcon_write(tcon, SPGMASKON(2), 0xffff);
+
+	dpu_tcon_write(tcon, SPGPOSOFF(2), X(hdisplay));
+	dpu_tcon_write(tcon, SPGMASKOFF(2), 0xffff);
+
+	/* vertical */
+	dpu_tcon_write(tcon, SPGPOSON(3), 0x0);
+	dpu_tcon_write(tcon, SPGMASKON(3), 0x7fff0000);
+
+	dpu_tcon_write(tcon, SPGPOSOFF(3), Y(vdisplay));
+	dpu_tcon_write(tcon, SPGMASKOFF(3), 0x7fff0000);
+
+	dpu_tcon_write(tcon, SMXSIGS(2), 0x2c);
+	dpu_tcon_write(tcon, SMXFCTTABLE(2), 0x8);
+
+	/* dsp_control[3]: kachuck */
+	y = vdisplay + 1;
+	/*
+	 * If sync mode fixup is present, the kachuck signal from slave tcon
+	 * should be one line later than the one from master tcon.
+	 */
+	if (side_by_side && tcon_is_slave(tcon))
+		y++;
+
+	dpu_tcon_write(tcon, SPGPOSON(4), X(0x0) | Y(y));
+	dpu_tcon_write(tcon, SPGMASKON(4), 0x0);
+
+	dpu_tcon_write(tcon, SPGPOSOFF(4), X(0x20) | Y(y));
+	dpu_tcon_write(tcon, SPGMASKOFF(4), 0x0);
+
+	dpu_tcon_write(tcon, SMXSIGS(3), 0x6);
+	dpu_tcon_write(tcon, SMXFCTTABLE(3), 0x2);
+}
+EXPORT_SYMBOL_GPL(tcon_cfg_videomode);
+
+bool tcon_is_master(struct dpu_tcon *tcon)
+{
+	const struct dpu_data *data = tcon->dpu->data;
+
+	return tcon->id == data->master_stream_id;
+}
+EXPORT_SYMBOL_GPL(tcon_is_master);
+
+bool tcon_is_slave(struct dpu_tcon *tcon)
+{
+	return !tcon_is_master(tcon);
+}
+EXPORT_SYMBOL_GPL(tcon_is_slave);
+
+void tcon_configure_pc(struct dpu_tcon *tcon, unsigned int di,
+			unsigned int frame_width, u32 mode, u32 format)
+{
+	if (WARN_ON(!tcon || !tcon->pc))
+		return;
+
+	pc_configure(tcon->pc, di, frame_width, mode, format);
+}
+EXPORT_SYMBOL_GPL(tcon_configure_pc);
+
+void tcon_enable_pc(struct dpu_tcon *tcon)
+{
+	if (WARN_ON(!tcon || !tcon->pc))
+		return;
+
+	pc_enable(tcon->pc);
+}
+EXPORT_SYMBOL_GPL(tcon_enable_pc);
+
+void tcon_disable_pc(struct dpu_tcon *tcon)
+{
+	if (WARN_ON(!tcon || !tcon->pc))
+		return;
+
+	pc_disable(tcon->pc);
+}
+EXPORT_SYMBOL_GPL(tcon_disable_pc);
+
+struct dpu_tcon *dpu_tcon_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_tcon *tcon;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(tcon_ids); i++)
+		if (tcon_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(tcon_ids))
+		return ERR_PTR(-EINVAL);
+
+	tcon = dpu->tcon_priv[i];
+
+	mutex_lock(&tcon->mutex);
+
+	if (tcon->inuse) {
+		mutex_unlock(&tcon->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	tcon->inuse = true;
+
+	mutex_unlock(&tcon->mutex);
+
+	return tcon;
+}
+EXPORT_SYMBOL_GPL(dpu_tcon_get);
+
+void dpu_tcon_put(struct dpu_tcon *tcon)
+{
+	mutex_lock(&tcon->mutex);
+
+	tcon->inuse = false;
+
+	mutex_unlock(&tcon->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_tcon_put);
+
+struct dpu_tcon *dpu_aux_tcon_peek(struct dpu_tcon *tcon)
+{
+	return tcon->dpu->tcon_priv[tcon->id ^ 1];
+}
+EXPORT_SYMBOL_GPL(dpu_aux_tcon_peek);
+
+void _dpu_tcon_init(struct dpu_soc *dpu, unsigned int id)
+{
+}
+
+int dpu_tcon_init(struct dpu_soc *dpu, unsigned int id,
+			unsigned long unused, unsigned long base)
+{
+	struct dpu_tcon *tcon;
+
+	tcon = devm_kzalloc(dpu->dev, sizeof(*tcon), GFP_KERNEL);
+	if (!tcon)
+		return -ENOMEM;
+
+	dpu->tcon_priv[id] = tcon;
+
+	tcon->base = devm_ioremap(dpu->dev, base, SZ_512);
+	if (!tcon->base)
+		return -ENOMEM;
+
+	tcon->dpu = dpu;
+	mutex_init(&tcon->mutex);
+
+	return 0;
+}
+
+void tcon_get_pc(struct dpu_tcon *tcon, void *data)
+{
+	if (WARN_ON(!tcon))
+		return;
+
+	tcon->pc = data;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-vscaler.c b/drivers/gpu/imx/dpu/dpu-vscaler.c
new file mode 100644
index 000000000..b1bdcd596
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-vscaler.c
@@ -0,0 +1,438 @@
+/*
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_DYNAMIC		0x8
+#define PIXENGCFG_DYNAMIC_SRC_SEL_MASK	0x3F
+
+#define SETUP1				0xC
+#define SCALE_FACTOR_MASK		0xFFFFF
+#define SCALE_FACTOR(n)			((n) & 0xFFFFF)
+#define SETUP2				0x10
+#define SETUP3				0x14
+#define SETUP4				0x18
+#define SETUP5				0x1C
+#define PHASE_OFFSET_MASK		0x1FFFFF
+#define PHASE_OFFSET(n)			((n) & 0x1FFFFF)
+#define CONTROL				0x20
+#define OUTPUT_SIZE_MASK		0x3FFF0000
+#define OUTPUT_SIZE(n)			((((n) - 1) << 16) & OUTPUT_SIZE_MASK)
+#define FIELD_MODE			0x3000
+#define FILTER_MODE			0x100
+#define SCALE_MODE			0x10
+#define MODE				0x1
+
+static const vs_src_sel_t src_sels[3][6] = {
+	{
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__FETCHDECODE0,
+		VS_SRC_SEL__MATRIX4,
+		VS_SRC_SEL__HSCALER4,
+	}, {
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__FETCHDECODE1,
+		VS_SRC_SEL__MATRIX5,
+		VS_SRC_SEL__HSCALER5,
+	}, {
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__MATRIX9,
+		VS_SRC_SEL__HSCALER9,
+	},
+};
+
+struct dpu_vscaler {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+	/* see DPU_PLANE_SRC_xxx */
+	unsigned int stream_id;
+};
+
+static inline u32 dpu_pec_vs_read(struct dpu_vscaler *vs,
+				  unsigned int offset)
+{
+	return readl(vs->pec_base + offset);
+}
+
+static inline void dpu_pec_vs_write(struct dpu_vscaler *vs,
+				    unsigned int offset, u32 value)
+{
+	writel(value, vs->pec_base + offset);
+}
+
+static inline u32 dpu_vs_read(struct dpu_vscaler *vs, unsigned int offset)
+{
+	return readl(vs->base + offset);
+}
+
+static inline void dpu_vs_write(struct dpu_vscaler *vs,
+				unsigned int offset, u32 value)
+{
+	writel(value, vs->base + offset);
+}
+
+int vscaler_pixengcfg_dynamic_src_sel(struct dpu_vscaler *vs, vs_src_sel_t src)
+{
+	struct dpu_soc *dpu = vs->dpu;
+	const unsigned int vs_id_array[] = {4, 5, 9};
+	int i, j;
+	u32 val;
+
+	for (i = 0; i < ARRAY_SIZE(vs_id_array); i++)
+		if (vs_id_array[i] == vs->id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(vs_id_array)))
+		return -EINVAL;
+
+	mutex_lock(&vs->mutex);
+	for (j = 0; j < ARRAY_SIZE(src_sels[0]); j++) {
+		if (src_sels[i][j] == src) {
+			val = dpu_pec_vs_read(vs, PIXENGCFG_DYNAMIC);
+			val &= ~PIXENGCFG_DYNAMIC_SRC_SEL_MASK;
+			val |= src;
+			dpu_pec_vs_write(vs, PIXENGCFG_DYNAMIC, val);
+			mutex_unlock(&vs->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&vs->mutex);
+
+	dev_err(dpu->dev, "Invalid source for VScaler%d\n", vs->id);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(vscaler_pixengcfg_dynamic_src_sel);
+
+void vscaler_pixengcfg_clken(struct dpu_vscaler *vs, pixengcfg_clken_t clken)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_pec_vs_read(vs, PIXENGCFG_DYNAMIC);
+	val &= ~CLKEN_MASK;
+	val |= clken << CLKEN_MASK_SHIFT;
+	dpu_pec_vs_write(vs, PIXENGCFG_DYNAMIC, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_pixengcfg_clken);
+
+void vscaler_shden(struct dpu_vscaler *vs, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_vs_write(vs, STATICCONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_shden);
+
+void vscaler_setup1(struct dpu_vscaler *vs, u32 src, u32 dst, bool deinterlace)
+{
+	struct dpu_soc *dpu = vs->dpu;
+	u32 scale_factor;
+	u64 tmp64;
+
+	if (deinterlace)
+		dst *= 2;
+
+	if (src == dst) {
+		scale_factor = 0x80000;
+	} else {
+		if (src > dst) {
+			tmp64 = (u64)((u64)dst * 0x80000);
+			do_div(tmp64, src);
+
+		} else {
+			tmp64 = (u64)((u64)src * 0x80000);
+			do_div(tmp64, dst);
+		}
+		scale_factor = (u32)tmp64;
+	}
+
+	WARN_ON(scale_factor > 0x80000);
+
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SETUP1, SCALE_FACTOR(scale_factor));
+	mutex_unlock(&vs->mutex);
+
+	dev_dbg(dpu->dev, "Vscaler%d scale factor 0x%08x\n",
+						vs->id, scale_factor);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup1);
+
+void vscaler_setup2(struct dpu_vscaler *vs, bool deinterlace)
+{
+	/* 0x20000: +0.25 phase offset for deinterlace */
+	u32 phase_offset = deinterlace ? 0x20000 : 0;
+
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SETUP2, PHASE_OFFSET(phase_offset));
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup2);
+
+void vscaler_setup3(struct dpu_vscaler *vs, bool deinterlace)
+{
+	/* 0x1e0000: -0.25 phase offset for deinterlace */
+	u32 phase_offset = deinterlace ? 0x1e0000 : 0;
+
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SETUP3, PHASE_OFFSET(phase_offset));
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup3);
+
+void vscaler_setup4(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SETUP4, PHASE_OFFSET(phase_offset));
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup4);
+
+void vscaler_setup5(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SETUP5, PHASE_OFFSET(phase_offset));
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup5);
+
+void vscaler_output_size(struct dpu_vscaler *vs, u32 line_num)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~OUTPUT_SIZE_MASK;
+	val |= OUTPUT_SIZE(line_num);
+	dpu_vs_write(vs, CONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_output_size);
+
+void vscaler_field_mode(struct dpu_vscaler *vs, scaler_field_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~FIELD_MODE;
+	val |= m;
+	dpu_vs_write(vs, CONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_field_mode);
+
+void vscaler_filter_mode(struct dpu_vscaler *vs, scaler_filter_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~FILTER_MODE;
+	val |= m;
+	dpu_vs_write(vs, CONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_filter_mode);
+
+void vscaler_scale_mode(struct dpu_vscaler *vs, scaler_scale_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~SCALE_MODE;
+	val |= m;
+	dpu_vs_write(vs, CONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_scale_mode);
+
+void vscaler_mode(struct dpu_vscaler *vs, scaler_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~MODE;
+	val |= m;
+	dpu_vs_write(vs, CONTROL, val);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_mode);
+
+bool vscaler_is_enabled(struct dpu_vscaler *vs)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	mutex_unlock(&vs->mutex);
+
+	return (val & MODE) == SCALER_ACTIVE;
+}
+EXPORT_SYMBOL_GPL(vscaler_is_enabled);
+
+dpu_block_id_t vscaler_get_block_id(struct dpu_vscaler *vs)
+{
+	switch (vs->id) {
+	case 4:
+		return ID_VSCALER4;
+	case 5:
+		return ID_VSCALER5;
+	case 9:
+		return ID_VSCALER9;
+	default:
+		WARN_ON(1);
+	}
+
+	return ID_NONE;
+}
+EXPORT_SYMBOL_GPL(vscaler_get_block_id);
+
+unsigned int vscaler_get_stream_id(struct dpu_vscaler *vs)
+{
+	return vs->stream_id;
+}
+EXPORT_SYMBOL_GPL(vscaler_get_stream_id);
+
+void vscaler_set_stream_id(struct dpu_vscaler *vs, unsigned int id)
+{
+	switch (id) {
+	case DPU_PLANE_SRC_TO_DISP_STREAM0:
+	case DPU_PLANE_SRC_TO_DISP_STREAM1:
+	case DPU_PLANE_SRC_DISABLED:
+		vs->stream_id = id;
+		break;
+	default:
+		WARN_ON(1);
+	}
+}
+EXPORT_SYMBOL_GPL(vscaler_set_stream_id);
+
+struct dpu_vscaler *dpu_vs_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_vscaler *vs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(vs_ids); i++)
+		if (vs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(vs_ids))
+		return ERR_PTR(-EINVAL);
+
+	vs = dpu->vs_priv[i];
+
+	mutex_lock(&vs->mutex);
+
+	if (vs->inuse) {
+		mutex_unlock(&vs->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	vs->inuse = true;
+
+	mutex_unlock(&vs->mutex);
+
+	return vs;
+}
+EXPORT_SYMBOL_GPL(dpu_vs_get);
+
+void dpu_vs_put(struct dpu_vscaler *vs)
+{
+	mutex_lock(&vs->mutex);
+
+	vs->inuse = false;
+
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_vs_put);
+
+void _dpu_vs_init(struct dpu_soc *dpu, unsigned int id)
+{
+	struct dpu_vscaler *vs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(vs_ids); i++)
+		if (vs_ids[i] == id)
+			break;
+
+	if (WARN_ON(i == ARRAY_SIZE(vs_ids)))
+		return;
+
+	vs = dpu->vs_priv[i];
+
+	vscaler_shden(vs, true);
+	vscaler_setup2(vs, false);
+	vscaler_setup3(vs, false);
+	vscaler_setup4(vs, 0);
+	vscaler_setup5(vs, 0);
+	vscaler_pixengcfg_dynamic_src_sel(vs, VS_SRC_SEL__DISABLE);
+}
+
+int dpu_vs_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_vscaler *vs;
+	int i;
+
+	vs = devm_kzalloc(dpu->dev, sizeof(*vs), GFP_KERNEL);
+	if (!vs)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(vs_ids); i++)
+		if (vs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(vs_ids))
+		return -EINVAL;
+
+	dpu->vs_priv[i] = vs;
+
+	vs->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_8);
+	if (!vs->pec_base)
+		return -ENOMEM;
+
+	vs->base = devm_ioremap(dpu->dev, base, SZ_1K);
+	if (!vs->base)
+		return -ENOMEM;
+
+	vs->dpu = dpu;
+	vs->id = id;
+
+	mutex_init(&vs->mutex);
+
+	_dpu_vs_init(dpu, id);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/imx8_dprc.c b/drivers/gpu/imx/imx8_dprc.c
new file mode 100644
index 000000000..fc7508c52
--- /dev/null
+++ b/drivers/gpu/imx/imx8_dprc.c
@@ -0,0 +1,893 @@
+/*
+ * Copyright 2017-2021 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+#include <drm/drm_fourcc.h>
+#include <dt-bindings/firmware/imx/rsrc.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/firmware/imx/sci.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <video/imx8-prefetch.h>
+
+#define SET					0x4
+#define CLR					0x8
+#define TOG					0xc
+
+#define SYSTEM_CTRL0				0x00
+#define BCMD2AXI_MASTR_ID_CTRL			BIT(16)
+#define SW_SHADOW_LOAD_SEL			BIT(4)
+#define SHADOW_LOAD_EN				BIT(3)
+#define REPEAT_EN				BIT(2)
+#define SOFT_RESET				BIT(1)
+#define RUN_EN					BIT(0)	/* self-clearing */
+
+#define IRQ_MASK				0x20
+#define IRQ_MASK_STATUS				0x30
+#define IRQ_NONMASK_STATUS			0x40
+#define DPR2RTR_FIFO_LOAD_BUF_RDY_UV_ERROR	BIT(7)
+#define DPR2RTR_FIFO_LOAD_BUF_RDY_YRGB_ERROR	BIT(6)
+#define DPR2RTR_UV_FIFO_OVFL			BIT(5)
+#define DPR2RTR_YRGB_FIFO_OVFL			BIT(4)
+#define IRQ_AXI_READ_ERROR			BIT(3)
+#define IRQ_DPR_SHADOW_LOADED_MASK		BIT(2)
+#define IRQ_DPR_RUN				BIT(1)
+#define IRQ_DPR_CRTL_DONE			BIT(0)
+#define IRQ_ERROR_MASK				0xf8
+#define IRQ_CTRL_MASK				0x7
+
+#define MODE_CTRL0				0x50
+#define PIX_COMP_SEL_MASK			0x3fc00
+#define A_COMP_SEL(byte)			(((byte) & 0x3) << 16)
+#define R_COMP_SEL(byte)			(((byte) & 0x3) << 14)
+#define G_COMP_SEL(byte)			(((byte) & 0x3) << 12)
+#define B_COMP_SEL(byte)			(((byte) & 0x3) << 10)
+#define PIX_UV_SWAP				BIT(9)
+#define VU					BIT(9)
+#define UV					0
+#define PIXEL_LUMA_UV_SWAP			BIT(8)
+#define UYVY					BIT(8)
+#define YUYV					0
+#define PIX_SIZE				0xc0
+enum {
+	PIX_SIZE_8BIT = (0 << 6),
+	PIX_SIZE_16BIT = (1 << 6),
+	PIX_SIZE_32BIT = (2 << 6),
+	PIX_SIZE_RESERVED = (3 << 6),
+};
+#define COMP_2PLANE_EN				BIT(5)
+#define YUV_EN					BIT(4)
+#define TILE_TYPE				0xc
+enum {
+	LINEAR_TILE = (0 << 2),
+	GPU_STANDARD_TILE = (1 << 2),
+	GPU_SUPER_TILE = (2 << 2),
+	VPU_TILE = (3 << 2),
+};
+#define RTR_4LINE_BUF_EN			BIT(1)
+#define LINE4					BIT(1)
+#define LINE8					0
+#define RTR_3BUF_EN				BIT(0)
+#define BUF3					BIT(0)
+#define BUF2					0
+
+#define FRAME_CTRL0				0x70
+#define PITCH(n)				(((n) & 0xffff) << 16)
+#define ROT_FLIP_ORDER_EN			BIT(4)
+#define ROT_FIRST				BIT(4)
+#define FLIP_FIRST				0
+#define ROT_ENC					0xc
+#define DEGREE(n)				((((n) / 90) & 0x3) << 2)
+#define VFLIP_EN				BIT(1)
+#define HFLIP_EN				BIT(0)
+
+#define FRAME_1P_CTRL0				0x90
+#define FRAME_2P_CTRL0				0xe0
+#define MAX_BYTES_PREQ				0x7
+enum {
+	BYTE_64 = 0x0,
+	BYTE_128 = 0x1,
+	BYTE_256 = 0x2,
+	BYTE_512 = 0x3,
+	BYTE_1K = 0x4,
+	BYTE_2K = 0x5,
+	BYTE_4K = 0x6,
+};
+
+#define FRAME_1P_PIX_X_CTRL			0xa0
+#define FRAME_2P_PIX_X_CTRL			0xf0
+#define NUM_X_PIX_WIDE(n)			((n) & 0xffff)
+#define FRAME_PIX_X_ULC_CTRL			0xf0
+#define CROP_ULC_X(n)				((n) & 0xffff)
+
+#define FRAME_1P_PIX_Y_CTRL			0xb0
+#define FRAME_2P_PIX_Y_CTRL			0x100
+#define NUM_Y_PIX_HIGH(n)			((n) & 0xffff)
+#define FRAME_PIX_Y_ULC_CTRL			0x100
+#define CROP_ULC_Y(n)				((n) & 0xffff)
+
+#define FRAME_1P_BASE_ADDR_CTRL0		0xc0
+#define FRAME_2P_BASE_ADDR_CTRL0		0x110
+
+#define STATUS_CTRL0				0x130
+#define STATUS_SRC_SEL				0x70000
+enum {
+	DPR_CTRL = 0x0,
+	PREFETCH_1PLANE = 0x1,
+	RESPONSE_1PLANE = 0x2,
+	PREFETCH_2PLANE = 0x3,
+	RESPONSE_2PLANE = 0x4,
+};
+#define STATUS_MUX_SEL				0x7
+
+#define STATUS_CTRL1				0x140
+
+#define RTRAM_CTRL0				0x200
+#define ABORT_SEL				BIT(7)
+#define ABORT					BIT(7)
+#define STALL					0
+#define THRES_LOW_MASK				0x70
+#define THRES_LOW(n)				(((n) & 0x7) << 4)
+#define THRES_HIGH_MASK				0xe
+#define THRES_HIGH(n)				(((n) & 0x7) << 1)
+#define NUM_ROWS_ACTIVE				BIT(0)
+#define ROWS_0_6				BIT(0)
+#define ROWS_0_4				0
+
+struct dprc {
+	struct device *dev;
+	void __iomem *base;
+	struct list_head list;
+	struct clk *clk_apb;
+	struct clk *clk_b;
+	struct clk *clk_rtram;
+	struct imx_sc_ipc *ipc_handle;
+	spinlock_t spin_lock;
+	u32 sc_resource;
+	bool is_blit_chan;
+
+	/* The second one, if non-NULL, is auxiliary for UV buffer. */
+	struct prg *prgs[2];
+	bool has_aux_prg;
+	bool use_aux_prg;
+};
+
+struct dprc_format_info {
+	u32 format;
+	u8 depth;
+	u8 num_planes;
+	u8 cpp[3];
+	u8 hsub;
+	u8 vsub;
+};
+
+static const struct dprc_format_info formats[] = {
+	{
+	  .format = DRM_FORMAT_RGB565,
+	  .depth = 16, .num_planes = 1, .cpp = { 2, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_ARGB8888,
+	  .depth = 32, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_XRGB8888,
+	  .depth = 24, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_ABGR8888,
+	  .depth = 32, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_XBGR8888,
+	  .depth = 24, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_RGBA8888,
+	  .depth = 32, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_RGBX8888,
+	  .depth = 24, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_BGRA8888,
+	  .depth = 32, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_BGRX8888,
+	  .depth = 24, .num_planes = 1, .cpp = { 4, 0, 0 },
+	  .hsub = 1,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_NV12,
+	  .depth = 0,  .num_planes = 2, .cpp = { 1, 2, 0 },
+	  .hsub = 2,   .vsub = 2,
+	}, {
+	  .format = DRM_FORMAT_NV21,
+	  .depth = 0,  .num_planes = 2, .cpp = { 1, 2, 0 },
+	  .hsub = 2,   .vsub = 2,
+	}, {
+	  .format = DRM_FORMAT_YUYV,
+	  .depth = 0,  .num_planes = 1, .cpp = { 2, 0, 0 },
+	  .hsub = 2,   .vsub = 1,
+	}, {
+	  .format = DRM_FORMAT_UYVY,
+	  .depth = 0,  .num_planes = 1, .cpp = { 2, 0, 0 },
+	  .hsub = 2,   .vsub = 1,
+	}
+};
+
+static const struct dprc_format_info *dprc_format_info(u32 format)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(formats); ++i) {
+		if (formats[i].format == format)
+			return &formats[i];
+	}
+
+	return NULL;
+}
+
+static DEFINE_MUTEX(dprc_list_mutex);
+static LIST_HEAD(dprc_list);
+
+static inline u32 dprc_read(struct dprc *dprc, unsigned int offset)
+{
+	return readl(dprc->base + offset);
+}
+
+static inline void dprc_write(struct dprc *dprc, u32 value, unsigned int offset)
+{
+	writel(value, dprc->base + offset);
+}
+
+static void dprc_reset(struct dprc *dprc)
+{
+	dprc_write(dprc, SOFT_RESET, SYSTEM_CTRL0 + SET);
+
+	if (dprc->is_blit_chan)
+		usleep_range(10, 20);
+	else
+		usleep_range(1000, 2000);
+
+	dprc_write(dprc, SOFT_RESET, SYSTEM_CTRL0 + CLR);
+}
+
+void dprc_enable(struct dprc *dprc)
+{
+	if (WARN_ON(!dprc))
+		return;
+
+	prg_enable(dprc->prgs[0]);
+	if (dprc->use_aux_prg)
+		prg_enable(dprc->prgs[1]);
+}
+EXPORT_SYMBOL_GPL(dprc_enable);
+
+void dprc_disable(struct dprc *dprc)
+{
+	if (WARN_ON(!dprc))
+		return;
+
+	dprc_write(dprc, SHADOW_LOAD_EN | SW_SHADOW_LOAD_SEL, SYSTEM_CTRL0);
+
+	prg_disable(dprc->prgs[0]);
+	if (dprc->has_aux_prg)
+		prg_disable(dprc->prgs[1]);
+
+	prg_reg_update(dprc->prgs[0]);
+	if (dprc->has_aux_prg)
+		prg_reg_update(dprc->prgs[1]);
+}
+EXPORT_SYMBOL_GPL(dprc_disable);
+
+static inline void
+dprc_dpu_gpr_configure(struct dprc *dprc, unsigned int stream_id)
+{
+	int ret;
+
+	ret = imx_sc_misc_set_control(dprc->ipc_handle,
+		dprc->sc_resource, IMX_SC_C_KACHUNK_SEL, stream_id);
+	if (ret)
+		dev_warn(dprc->dev, "failed to set KACHUNK_SEL: %d\n", ret);
+}
+
+static inline void
+dprc_prg_sel_configure(struct dprc *dprc, u32 resource, bool enable)
+{
+	int ret;
+
+	ret = imx_sc_misc_set_control(dprc->ipc_handle,
+				resource, IMX_SC_C_SEL0, enable);
+	if (ret)
+		dev_warn(dprc->dev, "failed to set SEL0: %d\n", ret);
+}
+
+void dprc_configure(struct dprc *dprc, unsigned int stream_id,
+		    unsigned int width, unsigned int height,
+		    unsigned int x_offset, unsigned int y_offset,
+		    unsigned int stride, u32 format, u64 modifier,
+		    unsigned long baddr, unsigned long uv_baddr,
+		    bool start, bool aux_start, bool interlace_frame)
+{
+	const struct dprc_format_info *info = dprc_format_info(format);
+	unsigned int dprc_width = width + x_offset;
+	unsigned int dprc_height;
+	unsigned int p1_w, p1_h, p2_w, p2_h;
+	unsigned int prg_stride = width * info->cpp[0];
+	unsigned int bpp = 8 * info->cpp[0];
+	unsigned int preq;
+	unsigned int mt_w = 0, mt_h = 0;	/* w/h in a micro-tile */
+	u32 val;
+
+	if (WARN_ON(!dprc))
+		return;
+
+	dprc->use_aux_prg = false;
+
+	if (start) {
+		dprc_reset(dprc);
+
+		if (!dprc->is_blit_chan)
+			dprc_dpu_gpr_configure(dprc, stream_id);
+	}
+
+	if (interlace_frame) {
+		height /= 2;
+		y_offset /= 2;
+	}
+
+	dprc_height = height + y_offset;
+
+	/* disable all control irqs and enable all error irqs */
+	dprc_write(dprc, IRQ_CTRL_MASK, IRQ_MASK);
+
+	if (info->num_planes > 1) {
+		p1_w = round_up(dprc_width, modifier ? 8 : 64);
+		p1_h = round_up(dprc_height, 8);
+
+		p2_w = p1_w;
+		if (modifier)
+			p2_h = dprc_height / info->vsub;
+		else
+			p2_h = round_up((dprc_height / info->vsub), 8);
+
+		preq = modifier ? BYTE_64 : BYTE_1K;
+
+		dprc_write(dprc, preq, FRAME_2P_CTRL0);
+		if (dprc->sc_resource == IMX_SC_R_DC_0_BLIT1 ||
+		    dprc->sc_resource == IMX_SC_R_DC_1_BLIT1) {
+			dprc_prg_sel_configure(dprc,
+				dprc->sc_resource == IMX_SC_R_DC_0_BLIT1 ?
+				IMX_SC_R_DC_0_BLIT0 : IMX_SC_R_DC_1_BLIT0,
+				true);
+			prg_set_auxiliary(dprc->prgs[1]);
+			dprc->has_aux_prg = true;
+		}
+		dprc_write(dprc, uv_baddr, FRAME_2P_BASE_ADDR_CTRL0);
+	} else {
+		switch (dprc->sc_resource) {
+		case IMX_SC_R_DC_0_BLIT0:
+		case IMX_SC_R_DC_1_BLIT0:
+			dprc_prg_sel_configure(dprc, dprc->sc_resource, false);
+			prg_set_primary(dprc->prgs[0]);
+			break;
+		case IMX_SC_R_DC_0_BLIT1:
+		case IMX_SC_R_DC_1_BLIT1:
+			dprc->has_aux_prg = false;
+			break;
+		default:
+			break;
+		}
+
+		switch (modifier) {
+		case DRM_FORMAT_MOD_VIVANTE_TILED:
+			p1_w = round_up(dprc_width, info->cpp[0] == 2 ? 8 : 4);
+			break;
+		case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+			if (dprc->is_blit_chan)
+				p1_w = round_up(dprc_width,
+						info->cpp[0] == 2 ? 8 : 4);
+			else
+				p1_w = round_up(dprc_width, 64);
+			break;
+		default:
+			p1_w = round_up(dprc_width,
+					info->cpp[0] == 2 ? 32 : 16);
+			break;
+		}
+		p1_h = round_up(dprc_height, 4);
+	}
+
+	dprc_write(dprc, PITCH(stride), FRAME_CTRL0);
+	switch (modifier) {
+	case DRM_FORMAT_MOD_AMPHION_TILED:
+		preq = BYTE_64;
+		mt_w = 8;
+		mt_h = 8;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_TILED:
+		preq = BYTE_256;
+		mt_w = bpp == 16 ? 8 : 4;
+		mt_h = 4;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+		if (bpp == 16) {
+			preq = BYTE_64;
+			mt_w = 8;
+		} else {
+			preq = (x_offset % 8) ? BYTE_64 : BYTE_128;
+			mt_w = 4;
+		}
+		mt_h = 4;
+		break;
+	default:
+		preq = BYTE_1K;
+		break;
+	}
+	dprc_write(dprc, preq, FRAME_1P_CTRL0);
+	dprc_write(dprc, NUM_X_PIX_WIDE(p1_w), FRAME_1P_PIX_X_CTRL);
+	dprc_write(dprc, NUM_Y_PIX_HIGH(p1_h), FRAME_1P_PIX_Y_CTRL);
+	dprc_write(dprc, baddr, FRAME_1P_BASE_ADDR_CTRL0);
+	if (modifier) {
+		dprc_write(dprc, CROP_ULC_X(round_down(x_offset, mt_w)),
+							FRAME_PIX_X_ULC_CTRL);
+		dprc_write(dprc, CROP_ULC_Y(round_down(y_offset, mt_h)),
+							FRAME_PIX_Y_ULC_CTRL);
+	} else {
+		dprc_write(dprc, CROP_ULC_X(0), FRAME_PIX_X_ULC_CTRL);
+		dprc_write(dprc, CROP_ULC_Y(0), FRAME_PIX_Y_ULC_CTRL);
+	}
+
+	val = dprc_read(dprc, RTRAM_CTRL0);
+	val &= ~THRES_LOW_MASK;
+	val |= THRES_LOW(3);
+	val &= ~THRES_HIGH_MASK;
+	val |= THRES_HIGH(7);
+	dprc_write(dprc, val, RTRAM_CTRL0);
+
+	val = dprc_read(dprc, MODE_CTRL0);
+	val &= ~PIX_UV_SWAP;
+	val &= ~PIXEL_LUMA_UV_SWAP;
+	val &= ~COMP_2PLANE_EN;
+	val &= ~YUV_EN;
+	val &= ~TILE_TYPE;
+	switch (modifier) {
+	case DRM_FORMAT_MOD_NONE:
+		break;
+	case DRM_FORMAT_MOD_AMPHION_TILED:
+		val |= VPU_TILE;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_TILED:
+		val |= GPU_STANDARD_TILE;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+		val |= GPU_SUPER_TILE;
+		break;
+	default:
+		dev_err(dprc->dev, "unsupported modifier 0x%016llx\n",
+								modifier);
+		return;
+	}
+	val &= ~RTR_4LINE_BUF_EN;
+	val |= info->num_planes > 1 ? LINE8 : LINE4;
+	val &= ~RTR_3BUF_EN;
+	val |= BUF2;
+	val &= ~(PIX_COMP_SEL_MASK | PIX_SIZE);
+	switch (format) {
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_BGRX8888:
+		/*
+		 * It turns out pixel components are mapped directly
+		 * without position change via DPR processing with
+		 * the following color component configurations.
+		 * Leave the pixel format to be handled by the
+		 * display controllers.
+		 */
+		val |= A_COMP_SEL(3) | R_COMP_SEL(2) |
+		       G_COMP_SEL(1) | B_COMP_SEL(0);
+		val |= PIX_SIZE_32BIT;
+		break;
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+		val |= YUV_EN;
+		fallthrough;
+	case DRM_FORMAT_RGB565:
+		val |= PIX_SIZE_16BIT;
+		break;
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+		dprc->use_aux_prg = true;
+
+		val |= COMP_2PLANE_EN;
+		val |= YUV_EN;
+		val |= PIX_SIZE_8BIT;
+		break;
+	default:
+		dev_err(dprc->dev, "unsupported format 0x%08x\n", format);
+		return;
+	}
+	dprc_write(dprc, val, MODE_CTRL0);
+
+	if (dprc->is_blit_chan) {
+		val = SW_SHADOW_LOAD_SEL | RUN_EN | SHADOW_LOAD_EN;
+		dprc_write(dprc, val, SYSTEM_CTRL0);
+	} else if (start) {
+		/* software shadow load for the first frame */
+		val = SW_SHADOW_LOAD_SEL | SHADOW_LOAD_EN;
+		dprc_write(dprc, val, SYSTEM_CTRL0);
+
+		/* and then, run... */
+		val |= RUN_EN | REPEAT_EN;
+		dprc_write(dprc, val, SYSTEM_CTRL0);
+	}
+
+	prg_configure(dprc->prgs[0], width, height, x_offset, y_offset,
+			prg_stride, bpp, baddr, format, modifier, start);
+	if (dprc->use_aux_prg)
+		prg_configure(dprc->prgs[1], width, height, x_offset, y_offset,
+			prg_stride, 8, uv_baddr, format, modifier, aux_start);
+
+	dev_dbg(dprc->dev, "w-%u, h-%u, s-%u, fmt-0x%08x, mod-0x%016llx\n",
+				width, height, stride, format, modifier);
+}
+EXPORT_SYMBOL_GPL(dprc_configure);
+
+void dprc_disable_repeat_en(struct dprc *dprc)
+{
+	if (WARN_ON(!dprc))
+		return;
+
+	dprc_write(dprc, REPEAT_EN, SYSTEM_CTRL0 + CLR);
+}
+EXPORT_SYMBOL_GPL(dprc_disable_repeat_en);
+
+void dprc_reg_update(struct dprc *dprc)
+{
+	if (WARN_ON(!dprc))
+		return;
+
+	prg_reg_update(dprc->prgs[0]);
+	if (dprc->use_aux_prg)
+		prg_reg_update(dprc->prgs[1]);
+}
+EXPORT_SYMBOL_GPL(dprc_reg_update);
+
+void dprc_first_frame_handle(struct dprc *dprc)
+{
+	if (WARN_ON(!dprc))
+		return;
+
+	if (dprc->is_blit_chan)
+		return;
+
+	dprc_write(dprc, REPEAT_EN, SYSTEM_CTRL0);
+
+	prg_shadow_enable(dprc->prgs[0]);
+	if (dprc->use_aux_prg)
+		prg_shadow_enable(dprc->prgs[1]);
+}
+EXPORT_SYMBOL_GPL(dprc_first_frame_handle);
+
+void dprc_irq_handle(struct dprc *dprc)
+{
+	u32 mask, status;
+
+	if (WARN_ON(!dprc))
+		return;
+
+	spin_lock(&dprc->spin_lock);
+
+	mask = dprc_read(dprc, IRQ_MASK);
+	mask = ~mask;
+	status = dprc_read(dprc, IRQ_MASK_STATUS);
+	status &= mask;
+
+	/* disable irqs to be handled */
+	dprc_write(dprc, status, IRQ_MASK + SET);
+
+	/* clear status */
+	dprc_write(dprc, status, IRQ_MASK_STATUS);
+
+	if (status & DPR2RTR_FIFO_LOAD_BUF_RDY_UV_ERROR)
+		dev_err(dprc->dev,
+			"DPR to RTRAM FIFO load UV buffer ready error\n");
+
+	if (status & DPR2RTR_FIFO_LOAD_BUF_RDY_YRGB_ERROR)
+		dev_err(dprc->dev,
+			"DPR to RTRAM FIFO load YRGB buffer ready error\n");
+
+	if (status & DPR2RTR_UV_FIFO_OVFL)
+		dev_err(dprc->dev, "DPR to RTRAM FIFO UV FIFO overflow\n");
+
+	if (status & DPR2RTR_YRGB_FIFO_OVFL)
+		dev_err(dprc->dev, "DPR to RTRAM FIFO YRGB FIFO overflow\n");
+
+	if (status & IRQ_AXI_READ_ERROR)
+		dev_err(dprc->dev, "AXI read error\n");
+
+	if (status & IRQ_DPR_CRTL_DONE)
+		dprc_first_frame_handle(dprc);
+
+	spin_unlock(&dprc->spin_lock);
+}
+EXPORT_SYMBOL_GPL(dprc_irq_handle);
+
+void dprc_enable_ctrl_done_irq(struct dprc *dprc)
+{
+	unsigned long lock_flags;
+
+	if (WARN_ON(!dprc))
+		return;
+
+	spin_lock_irqsave(&dprc->spin_lock, lock_flags);
+	dprc_write(dprc, IRQ_DPR_CRTL_DONE, IRQ_MASK + CLR);
+	spin_unlock_irqrestore(&dprc->spin_lock, lock_flags);
+}
+EXPORT_SYMBOL_GPL(dprc_enable_ctrl_done_irq);
+
+bool dprc_format_supported(struct dprc *dprc, u32 format, u64 modifier)
+{
+	if (WARN_ON(!dprc))
+		return false;
+
+	switch (format) {
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_RGB565:
+		return (modifier == DRM_FORMAT_MOD_NONE ||
+			modifier == DRM_FORMAT_MOD_VIVANTE_TILED ||
+			modifier == DRM_FORMAT_MOD_VIVANTE_SUPER_TILED);
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+		switch (dprc->sc_resource) {
+		case IMX_SC_R_DC_0_FRAC0:
+		case IMX_SC_R_DC_1_FRAC0:
+		case IMX_SC_R_DC_0_WARP:
+		case IMX_SC_R_DC_1_WARP:
+			return false;
+		}
+		return modifier == DRM_FORMAT_MOD_NONE;
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+		switch (dprc->sc_resource) {
+		case IMX_SC_R_DC_0_FRAC0:
+		case IMX_SC_R_DC_1_FRAC0:
+		case IMX_SC_R_DC_0_WARP:
+		case IMX_SC_R_DC_1_WARP:
+			return false;
+		case IMX_SC_R_DC_0_BLIT1:
+		case IMX_SC_R_DC_1_BLIT1:
+			return (modifier == DRM_FORMAT_MOD_NONE ||
+				modifier == DRM_FORMAT_MOD_AMPHION_TILED);
+		}
+		return (dprc->has_aux_prg &&
+			(modifier == DRM_FORMAT_MOD_NONE ||
+			 modifier == DRM_FORMAT_MOD_AMPHION_TILED));
+	}
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(dprc_format_supported);
+
+bool dprc_stride_supported(struct dprc *dprc,
+			   unsigned int stride, unsigned int uv_stride,
+			   unsigned int width, u32 format)
+{
+	const struct dprc_format_info *info = dprc_format_info(format);
+	unsigned int prg_stride = width * info->cpp[0];
+
+	if (WARN_ON(!dprc))
+		return false;
+
+	if (stride > 0xffff)
+		return false;
+
+	if (info->num_planes > 1 && stride != uv_stride)
+		return false;
+
+	return prg_stride_supported(dprc->prgs[0], prg_stride);
+}
+EXPORT_SYMBOL_GPL(dprc_stride_supported);
+
+bool dprc_stride_double_check(struct dprc *dprc,
+			      unsigned int width, unsigned int x_offset,
+			      u32 format, u64 modifier,
+			      dma_addr_t baddr, dma_addr_t uv_baddr)
+{
+	const struct dprc_format_info *info = dprc_format_info(format);
+	unsigned int bpp = 8 * info->cpp[0];
+	unsigned int prg_stride = width * info->cpp[0];
+
+	if (WARN_ON(!dprc))
+		return false;
+
+	if (!prg_stride_double_check(dprc->prgs[0], width, x_offset,
+				     bpp, modifier, prg_stride, baddr))
+		return false;
+
+	if (info->num_planes > 1 &&
+	    !prg_stride_double_check(dprc->prgs[1], width, x_offset,
+				     bpp, modifier, prg_stride, uv_baddr))
+		return false;
+
+	return true;
+}
+EXPORT_SYMBOL_GPL(dprc_stride_double_check);
+
+struct dprc *
+dprc_lookup_by_phandle(struct device *dev, const char *name, int index)
+{
+	struct device_node *dprc_node = of_parse_phandle(dev->of_node,
+							 name, index);
+	struct dprc *dprc;
+
+	mutex_lock(&dprc_list_mutex);
+	list_for_each_entry(dprc, &dprc_list, list) {
+		if (dprc_node == dprc->dev->of_node) {
+			mutex_unlock(&dprc_list_mutex);
+			device_link_add(dev, dprc->dev,
+					DL_FLAG_AUTOREMOVE_CONSUMER);
+			return dprc;
+		}
+	}
+	mutex_unlock(&dprc_list_mutex);
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(dprc_lookup_by_phandle);
+
+static const struct of_device_id dprc_dt_ids[] = {
+	{ .compatible = "fsl,imx8qm-dpr-channel", },
+	{ .compatible = "fsl,imx8qxp-dpr-channel", },
+	{ /* sentinel */ },
+};
+
+static int dprc_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct dprc *dprc;
+	int ret, i;
+
+	dprc = devm_kzalloc(dev, sizeof(*dprc), GFP_KERNEL);
+	if (!dprc)
+		return -ENOMEM;
+
+	ret = imx_scu_get_handle(&dprc->ipc_handle);
+	if (ret)
+		return ret;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	dprc->base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(dprc->base))
+		return PTR_ERR(dprc->base);
+
+	dprc->clk_apb = devm_clk_get(dev, "apb");
+	if (IS_ERR(dprc->clk_apb))
+		return PTR_ERR(dprc->clk_apb);
+	clk_prepare_enable(dprc->clk_apb);
+
+	dprc->clk_b = devm_clk_get(dev, "b");
+	if (IS_ERR(dprc->clk_b))
+		return PTR_ERR(dprc->clk_b);
+	clk_prepare_enable(dprc->clk_b);
+
+	dprc->clk_rtram = devm_clk_get(dev, "rtram");
+	if (IS_ERR(dprc->clk_rtram))
+		return PTR_ERR(dprc->clk_rtram);
+	clk_prepare_enable(dprc->clk_rtram);
+
+	ret = of_property_read_u32(pdev->dev.of_node,
+					"fsl,sc-resource", &dprc->sc_resource);
+	if (ret) {
+		dev_err(dev, "cannot get SC resource %d\n", ret);
+		return ret;
+	}
+
+	switch (dprc->sc_resource) {
+	case IMX_SC_R_DC_0_BLIT1:
+	case IMX_SC_R_DC_1_BLIT1:
+		dprc->has_aux_prg = true;
+		fallthrough;
+	case IMX_SC_R_DC_0_BLIT0:
+	case IMX_SC_R_DC_1_BLIT0:
+		dprc->is_blit_chan = true;
+		fallthrough;
+	case IMX_SC_R_DC_0_FRAC0:
+	case IMX_SC_R_DC_1_FRAC0:
+		break;
+	case IMX_SC_R_DC_0_VIDEO0:
+	case IMX_SC_R_DC_0_VIDEO1:
+	case IMX_SC_R_DC_1_VIDEO0:
+	case IMX_SC_R_DC_1_VIDEO1:
+	case IMX_SC_R_DC_0_WARP:
+	case IMX_SC_R_DC_1_WARP:
+		dprc->has_aux_prg = true;
+		break;
+	default:
+		dev_err(dev, "wrong SC resource %u\n", dprc->sc_resource);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < 2; i++) {
+		if (i == 1 && !dprc->has_aux_prg)
+			break;
+
+		dprc->prgs[i] = prg_lookup_by_phandle(dev, "fsl,prgs", i);
+		if (!dprc->prgs[i])
+			return -EPROBE_DEFER;
+
+		if (i == 1)
+			prg_set_auxiliary(dprc->prgs[i]);
+
+		if (dprc->is_blit_chan)
+			prg_set_blit(dprc->prgs[i]);
+	}
+
+	dprc->dev = dev;
+	spin_lock_init(&dprc->spin_lock);
+	platform_set_drvdata(pdev, dprc);
+	mutex_lock(&dprc_list_mutex);
+	list_add(&dprc->list, &dprc_list);
+	mutex_unlock(&dprc_list_mutex);
+
+	dprc_reset(dprc);
+
+	return 0;
+}
+
+static int dprc_remove(struct platform_device *pdev)
+{
+	struct dprc *dprc = platform_get_drvdata(pdev);
+
+	mutex_lock(&dprc_list_mutex);
+	list_del(&dprc->list);
+	mutex_unlock(&dprc_list_mutex);
+
+	clk_disable_unprepare(dprc->clk_rtram);
+	clk_disable_unprepare(dprc->clk_b);
+	clk_disable_unprepare(dprc->clk_apb);
+
+	return 0;
+}
+
+struct platform_driver dprc_drv = {
+	.probe = dprc_probe,
+	.remove = dprc_remove,
+	.driver = {
+		.name = "imx8-dpr-channel",
+		.of_match_table = dprc_dt_ids,
+	},
+};
+module_platform_driver(dprc_drv);
+
+MODULE_DESCRIPTION("i.MX8 DPRC driver");
+MODULE_AUTHOR("NXP Semiconductor");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/imx8_pc.c b/drivers/gpu/imx/imx8_pc.c
new file mode 100644
index 000000000..f5386b9f6
--- /dev/null
+++ b/drivers/gpu/imx/imx8_pc.c
@@ -0,0 +1,218 @@
+/*
+ * Copyright 2018,2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <video/imx8-pc.h>
+
+#define REG0				0x0
+#define PIX_COMBINE_ENABLE		BIT(0)
+#define DISP_PIX_COMBINE_BYPASS(n)	BIT(1 + 21 * (n))
+#define DISP_HSYNC_POLARITY(n)		BIT(2 + 11 * (n))
+#define DISP_HSYNC_POLARITY_POS(n)	DISP_HSYNC_POLARITY(n)
+#define DISP_VSYNC_POLARITY(n)		BIT(3 + 11 * (n))
+#define DISP_VSYNC_POLARITY_POS(n)	DISP_VSYNC_POLARITY(n)
+#define DISP_DVALID_POLARITY(n)		BIT(4 + 11 * (n))
+#define DISP_DVALID_POLARITY_POS(n)	DISP_DVALID_POLARITY(n)
+#define VSYNC_MASK_ENABLE		BIT(5)
+#define SKIP_MODE			BIT(6)
+#define SKIP_NUMBER(n)			(((n) & 0x3F) << 7)
+#define DISP_PIX_DATA_FORMAT_MASK(n)    (0x7 << (16 + (n) * 3))
+#define DISP_PIX_DATA_FORMAT_SHIFT(n)   (16 + (n) * 3)
+enum {
+	RGB = 0,
+	YUV444,
+	YUV422,
+	SPLIT_RGB,
+};
+
+#define REG1				0x10
+#define BUF_ACTIVE_DEPTH(n)		((n) & 0x7FF)
+
+#define REG2				0x20
+#define PC_SW_RESET_N			BIT(0)
+#define DISP_SW_RESET_N(n)		BIT(1 + (n))
+#define PC_FULL_RESET_N			(PC_SW_RESET_N |	\
+					 DISP_SW_RESET_N(0) |	\
+					 DISP_SW_RESET_N(1))
+
+struct pc {
+	struct device *dev;
+	void __iomem *base;
+	struct list_head list;
+};
+
+static DEFINE_MUTEX(pc_list_mutex);
+static LIST_HEAD(pc_list);
+
+static inline u32 pc_read(struct pc *pc, unsigned int offset)
+{
+	return readl(pc->base + offset);
+}
+
+static inline void pc_write(struct pc *pc, unsigned int offset, u32 value)
+{
+	writel(value, pc->base + offset);
+}
+
+static void pc_reset(struct pc *pc)
+{
+	pc_write(pc, REG2, 0);
+	usleep_range(1000, 2000);
+	pc_write(pc, REG2, PC_FULL_RESET_N);
+}
+
+void pc_enable(struct pc *pc)
+{
+	u32 val;
+
+	if (WARN_ON(!pc))
+		return;
+
+	val = pc_read(pc, REG0);
+	val |= PIX_COMBINE_ENABLE;
+	pc_write(pc, REG0, val);
+
+	dev_dbg(pc->dev, "enable\n");
+}
+EXPORT_SYMBOL_GPL(pc_enable);
+
+void pc_disable(struct pc *pc)
+{
+	if (WARN_ON(!pc))
+		return;
+
+	pc_reset(pc);
+
+	dev_dbg(pc->dev, "disable\n");
+}
+EXPORT_SYMBOL_GPL(pc_disable);
+
+void pc_configure(struct pc *pc, unsigned int di, unsigned int frame_width,
+		u32 mode, u32 format)
+{
+	u32 val;
+
+	if (WARN_ON(!pc))
+		return;
+
+	if (WARN_ON(di != 0 && di != 1))
+		return;
+
+	dev_dbg(pc->dev, "configure mode-0x%08x frame_width-%u\n",
+							mode, frame_width);
+
+	val = pc_read(pc, REG0);
+	if (mode == PC_BYPASS) {
+		val |= DISP_PIX_COMBINE_BYPASS(di);
+	} else if (mode == PC_COMBINE) {
+		val &= ~DISP_PIX_COMBINE_BYPASS(di);
+		frame_width /= 4;
+	}
+
+	pc_write(pc, REG0, val);
+	pc_write(pc, REG1, BUF_ACTIVE_DEPTH(frame_width));
+}
+EXPORT_SYMBOL_GPL(pc_configure);
+
+struct pc *pc_lookup_by_phandle(struct device *dev, const char *name)
+{
+	struct device_node *pc_node = of_parse_phandle(dev->of_node,
+							name, 0);
+	struct pc *pc;
+
+	mutex_lock(&pc_list_mutex);
+	list_for_each_entry(pc, &pc_list, list) {
+		if (pc_node == pc->dev->of_node) {
+			mutex_unlock(&pc_list_mutex);
+			device_link_add(dev, pc->dev,
+					DL_FLAG_AUTOREMOVE_CONSUMER);
+			return pc;
+		}
+	}
+	mutex_unlock(&pc_list_mutex);
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(pc_lookup_by_phandle);
+
+static int pc_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct pc *pc;
+	u32 val;
+
+	pc = devm_kzalloc(dev, sizeof(*pc), GFP_KERNEL);
+	if (!pc)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	pc->base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(pc->base))
+		return PTR_ERR(pc->base);
+
+	pc->dev = dev;
+	platform_set_drvdata(pdev, pc);
+	mutex_lock(&pc_list_mutex);
+	list_add(&pc->list, &pc_list);
+	mutex_unlock(&pc_list_mutex);
+
+	pc_reset(pc);
+
+	/*
+	 * assume data enable is active high and HSYNC/VSYNC are active low
+	 * also, bypass combine at startup
+	 */
+	val = DISP_DVALID_POLARITY_POS(0) | DISP_DVALID_POLARITY_POS(1) |
+	      DISP_PIX_COMBINE_BYPASS(0)  | DISP_PIX_COMBINE_BYPASS(1)  |
+	      VSYNC_MASK_ENABLE;
+
+	pc_write(pc, REG0, val);
+
+	return 0;
+}
+
+static int pc_remove(struct platform_device *pdev)
+{
+	struct pc *pc = platform_get_drvdata(pdev);
+
+	mutex_lock(&pc_list_mutex);
+	list_del(&pc->list);
+	mutex_unlock(&pc_list_mutex);
+
+	return 0;
+}
+
+static const struct of_device_id pc_dt_ids[] = {
+	{ .compatible = "fsl,imx8qm-pixel-combiner", },
+	{ .compatible = "fsl,imx8qxp-pixel-combiner", },
+	{ /* sentinel */ },
+};
+
+struct platform_driver pc_drv = {
+	.probe = pc_probe,
+	.remove = pc_remove,
+	.driver = {
+		.name = "imx8-pixel-combiner",
+		.of_match_table = pc_dt_ids,
+	},
+};
+module_platform_driver(pc_drv);
+
+MODULE_DESCRIPTION("i.MX8 Pixel Combiner driver");
+MODULE_AUTHOR("NXP Semiconductor");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/imx8_prg.c b/drivers/gpu/imx/imx8_prg.c
new file mode 100644
index 000000000..4dbcb1cb9
--- /dev/null
+++ b/drivers/gpu/imx/imx8_prg.c
@@ -0,0 +1,452 @@
+/*
+ * Copyright 2017-2019 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+#include <drm/drm_fourcc.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <video/imx8-prefetch.h>
+
+#define SET			0x4
+#define CLR			0x8
+#define TOG			0xc
+
+#define PRG_CTRL		0x00
+#define BYPASS			BIT(0)
+#define SC_DATA_TYPE		BIT(2)
+#define SC_DATA_TYPE_8BIT	0
+#define SC_DATA_TYPE_10BIT	BIT(2)
+#define UV_EN			BIT(3)
+#define HANDSHAKE_MODE		BIT(4)
+#define HANDSHAKE_MODE_4LINES	0
+#define HANDSHAKE_MODE_8LINES	BIT(4)
+#define SHADOW_LOAD_MODE	BIT(5)
+#define DES_DATA_TYPE		0x30000
+enum {
+	DES_DATA_TYPE_32BPP = (0 << 16),
+	DES_DATA_TYPE_24BPP = (1 << 16),
+	DES_DATA_TYPE_16BPP = (2 << 16),
+	DES_DATA_TYPE_8BPP = (3 << 16),
+};
+#define SOFTRST			BIT(30)
+#define SHADOW_EN		BIT(31)
+
+#define PRG_STATUS		0x10
+#define BUFFER_VALID_B		BIT(1)
+#define BUFFER_VALID_A		BIT(0)
+
+#define PRG_REG_UPDATE		0x20
+#define REG_UPDATE		BIT(0)
+
+#define PRG_STRIDE		0x30
+#define STRIDE(n)		(((n) - 1) & 0xffff)
+
+#define PRG_HEIGHT		0x40
+#define HEIGHT(n)		(((n) - 1) & 0xffff)
+
+#define PRG_BADDR		0x50
+
+#define PRG_OFFSET		0x60
+#define Y(n)			(((n) & 0x7) << 16)
+#define X(n)			((n) & 0xffff)
+
+#define PRG_WIDTH		0x70
+#define WIDTH(n)		(((n) - 1) & 0xffff)
+
+struct prg {
+	struct device *dev;
+	void __iomem *base;
+	struct list_head list;
+	struct clk *clk_apb;
+	struct clk *clk_rtram;
+	bool is_auxiliary;
+	bool is_blit;
+};
+
+static DEFINE_MUTEX(prg_list_mutex);
+static LIST_HEAD(prg_list);
+
+static inline u32 prg_read(struct prg *prg, unsigned int offset)
+{
+	return readl(prg->base + offset);
+}
+
+static inline void prg_write(struct prg *prg, u32 value, unsigned int offset)
+{
+	writel(value, prg->base + offset);
+}
+
+static void prg_reset(struct prg *prg)
+{
+	if (prg->is_blit)
+		usleep_range(10, 20);
+
+	prg_write(prg, SOFTRST, PRG_CTRL + SET);
+
+	if (prg->is_blit)
+		usleep_range(10, 20);
+	else
+		usleep_range(1000, 2000);
+
+	prg_write(prg, SOFTRST, PRG_CTRL + CLR);
+}
+
+void prg_enable(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg_write(prg, BYPASS, PRG_CTRL + CLR);
+}
+EXPORT_SYMBOL_GPL(prg_enable);
+
+void prg_disable(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg_write(prg, BYPASS, PRG_CTRL);
+}
+EXPORT_SYMBOL_GPL(prg_disable);
+
+void prg_configure(struct prg *prg, unsigned int width, unsigned int height,
+		   unsigned int x_offset, unsigned int y_offset,
+		   unsigned int stride, unsigned int bits_per_pixel,
+		   unsigned long baddr, u32 format, u64 modifier,
+		   bool start)
+{
+	unsigned int burst_size;
+	unsigned int mt_w = 0, mt_h = 0;	/* w/h in a micro-tile */
+	unsigned long _baddr;
+	u32 val;
+
+	if (WARN_ON(!prg))
+		return;
+
+	if (start)
+		prg_reset(prg);
+
+	/* prg finer cropping into micro-tile block - top/left start point */
+	switch (modifier) {
+	case DRM_FORMAT_MOD_NONE:
+		break;
+	case DRM_FORMAT_MOD_AMPHION_TILED:
+		mt_w = 8;
+		mt_h = 8;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_TILED:
+	case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+		mt_w = (bits_per_pixel == 16) ? 8 : 4;
+		mt_h = 4;
+		break;
+	default:
+		dev_err(prg->dev, "unsupported modifier 0x%016llx\n", modifier);
+		return;
+	}
+
+	if (modifier) {
+		x_offset %= mt_w;
+		y_offset %= mt_h;
+
+		/* consider x offset to calculate stride */
+		_baddr = baddr + (x_offset * (bits_per_pixel / 8));
+	} else {
+		x_offset = 0;
+		y_offset = 0;
+		_baddr = baddr;
+	}
+
+	/*
+	 * address TKT343664:
+	 * fetch unit base address has to align to burst_size
+	 */
+	burst_size = 1 << (ffs(_baddr) - 1);
+	burst_size = round_up(burst_size, 8);
+	burst_size = min(burst_size, 128U);
+
+	/*
+	 * address TKT339017:
+	 * fixup for burst size vs stride mismatch
+	 */
+	if (modifier)
+		stride = round_up(stride + round_up(_baddr % 8, 8), burst_size);
+	else
+		stride = round_up(stride, burst_size);
+
+	/*
+	 * address TKT342628(part 1):
+	 * when prg stride is less or equals to burst size,
+	 * the auxiliary prg height needs to be a half
+	 */
+	if (prg->is_auxiliary && stride <= burst_size) {
+		height /= 2;
+		if (modifier)
+			y_offset /= 2;
+	}
+
+	prg_write(prg, STRIDE(stride), PRG_STRIDE);
+	prg_write(prg, WIDTH(width), PRG_WIDTH);
+	prg_write(prg, HEIGHT(height), PRG_HEIGHT);
+	prg_write(prg, X(x_offset) | Y(y_offset), PRG_OFFSET);
+	prg_write(prg, baddr, PRG_BADDR);
+
+	val = prg_read(prg, PRG_CTRL);
+	val &= ~SC_DATA_TYPE;
+	val |= SC_DATA_TYPE_8BIT;
+	val &= ~HANDSHAKE_MODE;
+	if (format == DRM_FORMAT_NV21 || format == DRM_FORMAT_NV12) {
+		val |= HANDSHAKE_MODE_8LINES;
+		/*
+		 * address TKT342628(part 2):
+		 * when prg stride is less or equals to burst size,
+		 * we disable UV_EN bit for the auxiliary prg
+		 */
+		if (prg->is_auxiliary && stride > burst_size)
+			val |= UV_EN;
+		else
+			val &= ~UV_EN;
+	} else {
+		val |= HANDSHAKE_MODE_4LINES;
+		val &= ~UV_EN;
+	}
+	val |= SHADOW_LOAD_MODE;
+	val &= ~DES_DATA_TYPE;
+	switch (bits_per_pixel) {
+	case 32:
+		val |= DES_DATA_TYPE_32BPP;
+		break;
+	case 24:
+		val |= DES_DATA_TYPE_24BPP;
+		break;
+	case 16:
+		val |= DES_DATA_TYPE_16BPP;
+		break;
+	case 8:
+		val |= DES_DATA_TYPE_8BPP;
+		break;
+	}
+	if (start)
+		/* no shadow for the first frame */
+		val &= ~SHADOW_EN;
+	else
+		val |= SHADOW_EN;
+	prg_write(prg, val, PRG_CTRL);
+
+	dev_dbg(prg->dev, "bits per pixel %u\n", bits_per_pixel);
+}
+EXPORT_SYMBOL_GPL(prg_configure);
+
+void prg_reg_update(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg_write(prg, REG_UPDATE, PRG_REG_UPDATE);
+}
+EXPORT_SYMBOL_GPL(prg_reg_update);
+
+void prg_shadow_enable(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg_write(prg, SHADOW_EN, PRG_CTRL + SET);
+}
+EXPORT_SYMBOL_GPL(prg_shadow_enable);
+
+bool prg_stride_supported(struct prg *prg, unsigned int stride)
+{
+	return stride < 0x10000;
+}
+EXPORT_SYMBOL_GPL(prg_stride_supported);
+
+bool prg_stride_double_check(struct prg *prg,
+			     unsigned int width, unsigned int x_offset,
+			     unsigned int bits_per_pixel, u64 modifier,
+			     unsigned int stride, dma_addr_t baddr)
+{
+	unsigned int burst_size;
+	unsigned int mt_w = 0;	/* w in a micro-tile */
+	dma_addr_t _baddr;
+
+	if (WARN_ON(!prg))
+		return false;
+
+	/* prg finer cropping into micro-tile block - top/left start point */
+	switch (modifier) {
+	case DRM_FORMAT_MOD_NONE:
+		break;
+	case DRM_FORMAT_MOD_AMPHION_TILED:
+		mt_w = 8;
+		break;
+	case DRM_FORMAT_MOD_VIVANTE_TILED:
+	case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+		mt_w = (bits_per_pixel == 16) ? 8 : 4;
+		break;
+	default:
+		dev_err(prg->dev, "unsupported modifier 0x%016llx\n", modifier);
+		return false;
+	}
+
+	if (modifier) {
+		x_offset %= mt_w;
+
+		/* consider x offset to calculate stride */
+		_baddr = baddr + (x_offset * (bits_per_pixel / 8));
+	} else {
+		_baddr = baddr;
+	}
+
+	/*
+	 * address TKT343664:
+	 * fetch unit base address has to align to burst size
+	 */
+	burst_size = 1 << (ffs(_baddr) - 1);
+	burst_size = round_up(burst_size, 8);
+	burst_size = min(burst_size, 128U);
+
+	/*
+	 * address TKT339017:
+	 * fixup for burst size vs stride mismatch
+	 */
+	if (modifier)
+		stride = round_up(stride + round_up(_baddr % 8, 8), burst_size);
+	else
+		stride = round_up(stride, burst_size);
+
+	return stride < 0x10000;
+}
+EXPORT_SYMBOL_GPL(prg_stride_double_check);
+
+void prg_set_auxiliary(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg->is_auxiliary = true;
+}
+EXPORT_SYMBOL_GPL(prg_set_auxiliary);
+
+void prg_set_primary(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg->is_auxiliary = false;
+}
+EXPORT_SYMBOL_GPL(prg_set_primary);
+
+void prg_set_blit(struct prg *prg)
+{
+	if (WARN_ON(!prg))
+		return;
+
+	prg->is_blit = true;
+}
+EXPORT_SYMBOL_GPL(prg_set_blit);
+
+struct prg *
+prg_lookup_by_phandle(struct device *dev, const char *name, int index)
+{
+	struct device_node *prg_node = of_parse_phandle(dev->of_node,
+							name, index);
+	struct prg *prg;
+
+	mutex_lock(&prg_list_mutex);
+	list_for_each_entry(prg, &prg_list, list) {
+		if (prg_node == prg->dev->of_node) {
+			mutex_unlock(&prg_list_mutex);
+			device_link_add(dev, prg->dev,
+					DL_FLAG_AUTOREMOVE_CONSUMER);
+			return prg;
+		}
+	}
+	mutex_unlock(&prg_list_mutex);
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(prg_lookup_by_phandle);
+
+static const struct of_device_id prg_dt_ids[] = {
+	{ .compatible = "fsl,imx8qm-prg", },
+	{ .compatible = "fsl,imx8qxp-prg", },
+	{ /* sentinel */ },
+};
+
+static int prg_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct prg *prg;
+
+	prg = devm_kzalloc(dev, sizeof(*prg), GFP_KERNEL);
+	if (!prg)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	prg->base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(prg->base))
+		return PTR_ERR(prg->base);
+
+	prg->clk_apb = devm_clk_get(dev, "apb");
+	if (IS_ERR(prg->clk_apb))
+		return PTR_ERR(prg->clk_apb);
+	clk_prepare_enable(prg->clk_apb);
+
+	prg->clk_rtram = devm_clk_get(dev, "rtram");
+	if (IS_ERR(prg->clk_rtram))
+		return PTR_ERR(prg->clk_rtram);
+	clk_prepare_enable(prg->clk_rtram);
+
+	prg->dev = dev;
+	platform_set_drvdata(pdev, prg);
+	mutex_lock(&prg_list_mutex);
+	list_add(&prg->list, &prg_list);
+	mutex_unlock(&prg_list_mutex);
+
+	prg_reset(prg);
+
+	return 0;
+}
+
+static int prg_remove(struct platform_device *pdev)
+{
+	struct prg *prg = platform_get_drvdata(pdev);
+
+	mutex_lock(&prg_list_mutex);
+	list_del(&prg->list);
+	mutex_unlock(&prg_list_mutex);
+
+	clk_disable_unprepare(prg->clk_rtram);
+	clk_disable_unprepare(prg->clk_apb);
+
+	return 0;
+}
+
+struct platform_driver prg_drv = {
+	.probe = prg_probe,
+	.remove = prg_remove,
+	.driver = {
+		.name = "imx8-prg",
+		.of_match_table = prg_dt_ids,
+	},
+};
+module_platform_driver(prg_drv);
+
+MODULE_DESCRIPTION("i.MX8 PRG driver");
+MODULE_AUTHOR("NXP Semiconductor");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/ipu-v3/Kconfig b/drivers/gpu/imx/ipu-v3/Kconfig
new file mode 100644
index 000000000..061fb990c
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/Kconfig
@@ -0,0 +1,11 @@
+# SPDX-License-Identifier: GPL-2.0-only
+config IMX_IPUV3_CORE
+	tristate "IPUv3 core support"
+	depends on SOC_IMX5 || SOC_IMX6Q || ARCH_MULTIPLATFORM || COMPILE_TEST
+	depends on DRM || !DRM # if DRM=m, this can't be 'y'
+	select BITREVERSE
+	select GENERIC_ALLOCATOR if DRM
+	select GENERIC_IRQ_CHIP
+	help
+	  Choose this if you have a i.MX5/6 system and want to use the Image
+	  Processing Unit. This option only enables IPU base support.
diff --git a/drivers/gpu/imx/ipu-v3/Makefile b/drivers/gpu/imx/ipu-v3/Makefile
new file mode 100644
index 000000000..5fe5ef207
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/Makefile
@@ -0,0 +1,10 @@
+# SPDX-License-Identifier: GPL-2.0
+obj-$(CONFIG_IMX_IPUV3_CORE) += imx-ipu-v3.o
+
+imx-ipu-v3-objs := ipu-common.o ipu-cpmem.o ipu-csi.o ipu-dc.o ipu-di.o \
+		ipu-dp.o ipu-dmfc.o ipu-ic.o ipu-ic-csc.o \
+		ipu-image-convert.o ipu-smfc.o ipu-vdi.o
+
+ifdef CONFIG_DRM
+	imx-ipu-v3-objs += ipu-pre.o ipu-prg.o
+endif
diff --git a/drivers/gpu/imx/ipu-v3/ipu-common.c b/drivers/gpu/imx/ipu-v3/ipu-common.c
new file mode 100644
index 000000000..118318513
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-common.c
@@ -0,0 +1,1497 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/module.h>
+#include <linux/export.h>
+#include <linux/types.h>
+#include <linux/reset.h>
+#include <linux/platform_device.h>
+#include <linux/err.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/list.h>
+#include <linux/irq.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/irqdomain.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+
+#include <drm/drm_fourcc.h>
+
+#include <video/imx-ipu-v3.h>
+#include "ipu-prv.h"
+
+static inline u32 ipu_cm_read(struct ipu_soc *ipu, unsigned offset)
+{
+	return readl(ipu->cm_reg + offset);
+}
+
+static inline void ipu_cm_write(struct ipu_soc *ipu, u32 value, unsigned offset)
+{
+	writel(value, ipu->cm_reg + offset);
+}
+
+int ipu_get_num(struct ipu_soc *ipu)
+{
+	return ipu->id;
+}
+EXPORT_SYMBOL_GPL(ipu_get_num);
+
+void ipu_srm_dp_update(struct ipu_soc *ipu, bool sync)
+{
+	u32 val;
+
+	val = ipu_cm_read(ipu, IPU_SRM_PRI2);
+	val &= ~DP_S_SRM_MODE_MASK;
+	val |= sync ? DP_S_SRM_MODE_NEXT_FRAME :
+		      DP_S_SRM_MODE_NOW;
+	ipu_cm_write(ipu, val, IPU_SRM_PRI2);
+}
+EXPORT_SYMBOL_GPL(ipu_srm_dp_update);
+
+enum ipu_color_space ipu_drm_fourcc_to_colorspace(u32 drm_fourcc)
+{
+	switch (drm_fourcc) {
+	case DRM_FORMAT_ARGB1555:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_RGBA5551:
+	case DRM_FORMAT_BGRA5551:
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_ARGB4444:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_RGB565_A8:
+	case DRM_FORMAT_BGR565_A8:
+	case DRM_FORMAT_RGB888_A8:
+	case DRM_FORMAT_BGR888_A8:
+	case DRM_FORMAT_RGBX8888_A8:
+	case DRM_FORMAT_BGRX8888_A8:
+		return IPUV3_COLORSPACE_RGB;
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_YUV420:
+	case DRM_FORMAT_YVU420:
+	case DRM_FORMAT_YUV422:
+	case DRM_FORMAT_YVU422:
+	case DRM_FORMAT_YUV444:
+	case DRM_FORMAT_YVU444:
+	case DRM_FORMAT_NV12:
+	case DRM_FORMAT_NV21:
+	case DRM_FORMAT_NV16:
+	case DRM_FORMAT_NV61:
+		return IPUV3_COLORSPACE_YUV;
+	default:
+		return IPUV3_COLORSPACE_UNKNOWN;
+	}
+}
+EXPORT_SYMBOL_GPL(ipu_drm_fourcc_to_colorspace);
+
+enum ipu_color_space ipu_pixelformat_to_colorspace(u32 pixelformat)
+{
+	switch (pixelformat) {
+	case V4L2_PIX_FMT_YUV420:
+	case V4L2_PIX_FMT_YVU420:
+	case V4L2_PIX_FMT_YUV422P:
+	case V4L2_PIX_FMT_UYVY:
+	case V4L2_PIX_FMT_YUYV:
+	case V4L2_PIX_FMT_NV12:
+	case V4L2_PIX_FMT_NV21:
+	case V4L2_PIX_FMT_NV16:
+	case V4L2_PIX_FMT_NV61:
+		return IPUV3_COLORSPACE_YUV;
+	case V4L2_PIX_FMT_RGB565:
+	case V4L2_PIX_FMT_BGR24:
+	case V4L2_PIX_FMT_RGB24:
+	case V4L2_PIX_FMT_ABGR32:
+	case V4L2_PIX_FMT_XBGR32:
+	case V4L2_PIX_FMT_BGRA32:
+	case V4L2_PIX_FMT_BGRX32:
+	case V4L2_PIX_FMT_RGBA32:
+	case V4L2_PIX_FMT_RGBX32:
+	case V4L2_PIX_FMT_ARGB32:
+	case V4L2_PIX_FMT_XRGB32:
+	case V4L2_PIX_FMT_RGB32:
+	case V4L2_PIX_FMT_BGR32:
+		return IPUV3_COLORSPACE_RGB;
+	default:
+		return IPUV3_COLORSPACE_UNKNOWN;
+	}
+}
+EXPORT_SYMBOL_GPL(ipu_pixelformat_to_colorspace);
+
+int ipu_degrees_to_rot_mode(enum ipu_rotate_mode *mode, int degrees,
+			    bool hflip, bool vflip)
+{
+	u32 r90, vf, hf;
+
+	switch (degrees) {
+	case 0:
+		vf = hf = r90 = 0;
+		break;
+	case 90:
+		vf = hf = 0;
+		r90 = 1;
+		break;
+	case 180:
+		vf = hf = 1;
+		r90 = 0;
+		break;
+	case 270:
+		vf = hf = r90 = 1;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	hf ^= (u32)hflip;
+	vf ^= (u32)vflip;
+
+	*mode = (enum ipu_rotate_mode)((r90 << 2) | (hf << 1) | vf);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_degrees_to_rot_mode);
+
+int ipu_rot_mode_to_degrees(int *degrees, enum ipu_rotate_mode mode,
+			    bool hflip, bool vflip)
+{
+	u32 r90, vf, hf;
+
+	r90 = ((u32)mode >> 2) & 0x1;
+	hf = ((u32)mode >> 1) & 0x1;
+	vf = ((u32)mode >> 0) & 0x1;
+	hf ^= (u32)hflip;
+	vf ^= (u32)vflip;
+
+	switch ((enum ipu_rotate_mode)((r90 << 2) | (hf << 1) | vf)) {
+	case IPU_ROTATE_NONE:
+		*degrees = 0;
+		break;
+	case IPU_ROTATE_90_RIGHT:
+		*degrees = 90;
+		break;
+	case IPU_ROTATE_180:
+		*degrees = 180;
+		break;
+	case IPU_ROTATE_90_LEFT:
+		*degrees = 270;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_rot_mode_to_degrees);
+
+struct ipuv3_channel *ipu_idmac_get(struct ipu_soc *ipu, unsigned num)
+{
+	struct ipuv3_channel *channel;
+
+	dev_dbg(ipu->dev, "%s %d\n", __func__, num);
+
+	if (num > 63)
+		return ERR_PTR(-ENODEV);
+
+	mutex_lock(&ipu->channel_lock);
+
+	list_for_each_entry(channel, &ipu->channels, list) {
+		if (channel->num == num) {
+			channel = ERR_PTR(-EBUSY);
+			goto out;
+		}
+	}
+
+	channel = kzalloc(sizeof(*channel), GFP_KERNEL);
+	if (!channel) {
+		channel = ERR_PTR(-ENOMEM);
+		goto out;
+	}
+
+	channel->num = num;
+	channel->ipu = ipu;
+	list_add(&channel->list, &ipu->channels);
+
+out:
+	mutex_unlock(&ipu->channel_lock);
+
+	return channel;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_get);
+
+void ipu_idmac_put(struct ipuv3_channel *channel)
+{
+	struct ipu_soc *ipu = channel->ipu;
+
+	dev_dbg(ipu->dev, "%s %d\n", __func__, channel->num);
+
+	mutex_lock(&ipu->channel_lock);
+
+	list_del(&channel->list);
+	kfree(channel);
+
+	mutex_unlock(&ipu->channel_lock);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_put);
+
+#define idma_mask(ch)			(1 << ((ch) & 0x1f))
+
+/*
+ * This is an undocumented feature, a write one to a channel bit in
+ * IPU_CHA_CUR_BUF and IPU_CHA_TRIPLE_CUR_BUF will reset the channel's
+ * internal current buffer pointer so that transfers start from buffer
+ * 0 on the next channel enable (that's the theory anyway, the imx6 TRM
+ * only says these are read-only registers). This operation is required
+ * for channel linking to work correctly, for instance video capture
+ * pipelines that carry out image rotations will fail after the first
+ * streaming unless this function is called for each channel before
+ * re-enabling the channels.
+ */
+static void __ipu_idmac_reset_current_buffer(struct ipuv3_channel *channel)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned int chno = channel->num;
+
+	ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_CUR_BUF(chno));
+}
+
+void ipu_idmac_set_double_buffer(struct ipuv3_channel *channel,
+		bool doublebuffer)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	reg = ipu_cm_read(ipu, IPU_CHA_DB_MODE_SEL(channel->num));
+	if (doublebuffer)
+		reg |= idma_mask(channel->num);
+	else
+		reg &= ~idma_mask(channel->num);
+	ipu_cm_write(ipu, reg, IPU_CHA_DB_MODE_SEL(channel->num));
+
+	__ipu_idmac_reset_current_buffer(channel);
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_set_double_buffer);
+
+static const struct {
+	int chnum;
+	u32 reg;
+	int shift;
+} idmac_lock_en_info[] = {
+	{ .chnum =  5, .reg = IDMAC_CH_LOCK_EN_1, .shift =  0, },
+	{ .chnum = 11, .reg = IDMAC_CH_LOCK_EN_1, .shift =  2, },
+	{ .chnum = 12, .reg = IDMAC_CH_LOCK_EN_1, .shift =  4, },
+	{ .chnum = 14, .reg = IDMAC_CH_LOCK_EN_1, .shift =  6, },
+	{ .chnum = 15, .reg = IDMAC_CH_LOCK_EN_1, .shift =  8, },
+	{ .chnum = 20, .reg = IDMAC_CH_LOCK_EN_1, .shift = 10, },
+	{ .chnum = 21, .reg = IDMAC_CH_LOCK_EN_1, .shift = 12, },
+	{ .chnum = 22, .reg = IDMAC_CH_LOCK_EN_1, .shift = 14, },
+	{ .chnum = 23, .reg = IDMAC_CH_LOCK_EN_1, .shift = 16, },
+	{ .chnum = 27, .reg = IDMAC_CH_LOCK_EN_1, .shift = 18, },
+	{ .chnum = 28, .reg = IDMAC_CH_LOCK_EN_1, .shift = 20, },
+	{ .chnum = 45, .reg = IDMAC_CH_LOCK_EN_2, .shift =  0, },
+	{ .chnum = 46, .reg = IDMAC_CH_LOCK_EN_2, .shift =  2, },
+	{ .chnum = 47, .reg = IDMAC_CH_LOCK_EN_2, .shift =  4, },
+	{ .chnum = 48, .reg = IDMAC_CH_LOCK_EN_2, .shift =  6, },
+	{ .chnum = 49, .reg = IDMAC_CH_LOCK_EN_2, .shift =  8, },
+	{ .chnum = 50, .reg = IDMAC_CH_LOCK_EN_2, .shift = 10, },
+};
+
+int ipu_idmac_lock_enable(struct ipuv3_channel *channel, int num_bursts)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned long flags;
+	u32 bursts, regval;
+	int i;
+
+	switch (num_bursts) {
+	case 0:
+	case 1:
+		bursts = 0x00; /* locking disabled */
+		break;
+	case 2:
+		bursts = 0x01;
+		break;
+	case 4:
+		bursts = 0x02;
+		break;
+	case 8:
+		bursts = 0x03;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/*
+	 * IPUv3EX / i.MX51 has a different register layout, and on IPUv3M /
+	 * i.MX53 channel arbitration locking doesn't seem to work properly.
+	 * Allow enabling the lock feature on IPUv3H / i.MX6 only.
+	 */
+	if (bursts && ipu->ipu_type != IPUV3H)
+		return -EINVAL;
+
+	for (i = 0; i < ARRAY_SIZE(idmac_lock_en_info); i++) {
+		if (channel->num == idmac_lock_en_info[i].chnum)
+			break;
+	}
+	if (i >= ARRAY_SIZE(idmac_lock_en_info))
+		return -EINVAL;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	regval = ipu_idmac_read(ipu, idmac_lock_en_info[i].reg);
+	regval &= ~(0x03 << idmac_lock_en_info[i].shift);
+	regval |= (bursts << idmac_lock_en_info[i].shift);
+	ipu_idmac_write(ipu, regval, idmac_lock_en_info[i].reg);
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_lock_enable);
+
+int ipu_module_enable(struct ipu_soc *ipu, u32 mask)
+{
+	unsigned long lock_flags;
+	u32 val;
+
+	spin_lock_irqsave(&ipu->lock, lock_flags);
+
+	val = ipu_cm_read(ipu, IPU_DISP_GEN);
+
+	if (mask & IPU_CONF_DI0_EN)
+		val |= IPU_DI0_COUNTER_RELEASE;
+	if (mask & IPU_CONF_DI1_EN)
+		val |= IPU_DI1_COUNTER_RELEASE;
+
+	ipu_cm_write(ipu, val, IPU_DISP_GEN);
+
+	val = ipu_cm_read(ipu, IPU_CONF);
+	val |= mask;
+	ipu_cm_write(ipu, val, IPU_CONF);
+
+	spin_unlock_irqrestore(&ipu->lock, lock_flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_module_enable);
+
+int ipu_module_disable(struct ipu_soc *ipu, u32 mask)
+{
+	unsigned long lock_flags;
+	u32 val;
+
+	spin_lock_irqsave(&ipu->lock, lock_flags);
+
+	val = ipu_cm_read(ipu, IPU_CONF);
+	val &= ~mask;
+	ipu_cm_write(ipu, val, IPU_CONF);
+
+	val = ipu_cm_read(ipu, IPU_DISP_GEN);
+
+	if (mask & IPU_CONF_DI0_EN)
+		val &= ~IPU_DI0_COUNTER_RELEASE;
+	if (mask & IPU_CONF_DI1_EN)
+		val &= ~IPU_DI1_COUNTER_RELEASE;
+
+	ipu_cm_write(ipu, val, IPU_DISP_GEN);
+
+	spin_unlock_irqrestore(&ipu->lock, lock_flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_module_disable);
+
+int ipu_idmac_get_current_buffer(struct ipuv3_channel *channel)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned int chno = channel->num;
+
+	return (ipu_cm_read(ipu, IPU_CHA_CUR_BUF(chno)) & idma_mask(chno)) ? 1 : 0;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_get_current_buffer);
+
+bool ipu_idmac_buffer_is_ready(struct ipuv3_channel *channel, u32 buf_num)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned long flags;
+	u32 reg = 0;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+	switch (buf_num) {
+	case 0:
+		reg = ipu_cm_read(ipu, IPU_CHA_BUF0_RDY(channel->num));
+		break;
+	case 1:
+		reg = ipu_cm_read(ipu, IPU_CHA_BUF1_RDY(channel->num));
+		break;
+	case 2:
+		reg = ipu_cm_read(ipu, IPU_CHA_BUF2_RDY(channel->num));
+		break;
+	}
+	spin_unlock_irqrestore(&ipu->lock, flags);
+
+	return ((reg & idma_mask(channel->num)) != 0);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_buffer_is_ready);
+
+void ipu_idmac_select_buffer(struct ipuv3_channel *channel, u32 buf_num)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned int chno = channel->num;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	/* Mark buffer as ready. */
+	if (buf_num == 0)
+		ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_BUF0_RDY(chno));
+	else
+		ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_BUF1_RDY(chno));
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_select_buffer);
+
+void ipu_idmac_clear_buffer(struct ipuv3_channel *channel, u32 buf_num)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned int chno = channel->num;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	ipu_cm_write(ipu, 0xF0300000, IPU_GPR); /* write one to clear */
+	switch (buf_num) {
+	case 0:
+		ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_BUF0_RDY(chno));
+		break;
+	case 1:
+		ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_BUF1_RDY(chno));
+		break;
+	case 2:
+		ipu_cm_write(ipu, idma_mask(chno), IPU_CHA_BUF2_RDY(chno));
+		break;
+	default:
+		break;
+	}
+	ipu_cm_write(ipu, 0x0, IPU_GPR); /* write one to set */
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_clear_buffer);
+
+int ipu_idmac_enable_channel(struct ipuv3_channel *channel)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	u32 val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	val = ipu_idmac_read(ipu, IDMAC_CHA_EN(channel->num));
+	val |= idma_mask(channel->num);
+	ipu_idmac_write(ipu, val, IDMAC_CHA_EN(channel->num));
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_enable_channel);
+
+bool ipu_idmac_channel_busy(struct ipu_soc *ipu, unsigned int chno)
+{
+	return (ipu_idmac_read(ipu, IDMAC_CHA_BUSY(chno)) & idma_mask(chno));
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_channel_busy);
+
+int ipu_idmac_wait_busy(struct ipuv3_channel *channel, int ms)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned long timeout;
+
+	timeout = jiffies + msecs_to_jiffies(ms);
+	while (ipu_idmac_read(ipu, IDMAC_CHA_BUSY(channel->num)) &
+			idma_mask(channel->num)) {
+		if (time_after(jiffies, timeout))
+			return -ETIMEDOUT;
+		cpu_relax();
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_wait_busy);
+
+int ipu_idmac_disable_channel(struct ipuv3_channel *channel)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	u32 val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	/* Disable DMA channel(s) */
+	val = ipu_idmac_read(ipu, IDMAC_CHA_EN(channel->num));
+	val &= ~idma_mask(channel->num);
+	ipu_idmac_write(ipu, val, IDMAC_CHA_EN(channel->num));
+
+	__ipu_idmac_reset_current_buffer(channel);
+
+	/* Set channel buffers NOT to be ready */
+	ipu_cm_write(ipu, 0xf0000000, IPU_GPR); /* write one to clear */
+
+	if (ipu_cm_read(ipu, IPU_CHA_BUF0_RDY(channel->num)) &
+			idma_mask(channel->num)) {
+		ipu_cm_write(ipu, idma_mask(channel->num),
+			     IPU_CHA_BUF0_RDY(channel->num));
+	}
+
+	if (ipu_cm_read(ipu, IPU_CHA_BUF1_RDY(channel->num)) &
+			idma_mask(channel->num)) {
+		ipu_cm_write(ipu, idma_mask(channel->num),
+			     IPU_CHA_BUF1_RDY(channel->num));
+	}
+
+	ipu_cm_write(ipu, 0x0, IPU_GPR); /* write one to set */
+
+	/* Reset the double buffer */
+	val = ipu_cm_read(ipu, IPU_CHA_DB_MODE_SEL(channel->num));
+	val &= ~idma_mask(channel->num);
+	ipu_cm_write(ipu, val, IPU_CHA_DB_MODE_SEL(channel->num));
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_disable_channel);
+
+/*
+ * The imx6 rev. D TRM says that enabling the WM feature will increase
+ * a channel's priority. Refer to Table 36-8 Calculated priority value.
+ * The sub-module that is the sink or source for the channel must enable
+ * watermark signal for this to take effect (SMFC_WM for instance).
+ */
+void ipu_idmac_enable_watermark(struct ipuv3_channel *channel, bool enable)
+{
+	struct ipu_soc *ipu = channel->ipu;
+	unsigned long flags;
+	u32 val;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	val = ipu_idmac_read(ipu, IDMAC_WM_EN(channel->num));
+	if (enable)
+		val |= 1 << (channel->num % 32);
+	else
+		val &= ~(1 << (channel->num % 32));
+	ipu_idmac_write(ipu, val, IDMAC_WM_EN(channel->num));
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_enable_watermark);
+
+static int ipu_memory_reset(struct ipu_soc *ipu)
+{
+	unsigned long timeout;
+
+	ipu_cm_write(ipu, 0x807FFFFF, IPU_MEM_RST);
+
+	timeout = jiffies + msecs_to_jiffies(1000);
+	while (ipu_cm_read(ipu, IPU_MEM_RST) & 0x80000000) {
+		if (time_after(jiffies, timeout))
+			return -ETIME;
+		cpu_relax();
+	}
+
+	return 0;
+}
+
+/*
+ * Set the source mux for the given CSI. Selects either parallel or
+ * MIPI CSI2 sources.
+ */
+void ipu_set_csi_src_mux(struct ipu_soc *ipu, int csi_id, bool mipi_csi2)
+{
+	unsigned long flags;
+	u32 val, mask;
+
+	mask = (csi_id == 1) ? IPU_CONF_CSI1_DATA_SOURCE :
+		IPU_CONF_CSI0_DATA_SOURCE;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	val = ipu_cm_read(ipu, IPU_CONF);
+	if (mipi_csi2)
+		val |= mask;
+	else
+		val &= ~mask;
+	ipu_cm_write(ipu, val, IPU_CONF);
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_set_csi_src_mux);
+
+/*
+ * Set the source mux for the IC. Selects either CSI[01] or the VDI.
+ */
+void ipu_set_ic_src_mux(struct ipu_soc *ipu, int csi_id, bool vdi)
+{
+	unsigned long flags;
+	u32 val;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	val = ipu_cm_read(ipu, IPU_CONF);
+	if (vdi)
+		val |= IPU_CONF_IC_INPUT;
+	else
+		val &= ~IPU_CONF_IC_INPUT;
+
+	if (csi_id == 1)
+		val |= IPU_CONF_CSI_SEL;
+	else
+		val &= ~IPU_CONF_CSI_SEL;
+
+	ipu_cm_write(ipu, val, IPU_CONF);
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_set_ic_src_mux);
+
+
+/* Frame Synchronization Unit Channel Linking */
+
+struct fsu_link_reg_info {
+	int chno;
+	u32 reg;
+	u32 mask;
+	u32 val;
+};
+
+struct fsu_link_info {
+	struct fsu_link_reg_info src;
+	struct fsu_link_reg_info sink;
+};
+
+static const struct fsu_link_info fsu_link_info[] = {
+	{
+		.src  = { IPUV3_CHANNEL_IC_PRP_ENC_MEM, IPU_FS_PROC_FLOW2,
+			  FS_PRP_ENC_DEST_SEL_MASK, FS_PRP_ENC_DEST_SEL_IRT_ENC },
+		.sink = { IPUV3_CHANNEL_MEM_ROT_ENC, IPU_FS_PROC_FLOW1,
+			  FS_PRPENC_ROT_SRC_SEL_MASK, FS_PRPENC_ROT_SRC_SEL_ENC },
+	}, {
+		.src =  { IPUV3_CHANNEL_IC_PRP_VF_MEM, IPU_FS_PROC_FLOW2,
+			  FS_PRPVF_DEST_SEL_MASK, FS_PRPVF_DEST_SEL_IRT_VF },
+		.sink = { IPUV3_CHANNEL_MEM_ROT_VF, IPU_FS_PROC_FLOW1,
+			  FS_PRPVF_ROT_SRC_SEL_MASK, FS_PRPVF_ROT_SRC_SEL_VF },
+	}, {
+		.src =  { IPUV3_CHANNEL_IC_PP_MEM, IPU_FS_PROC_FLOW2,
+			  FS_PP_DEST_SEL_MASK, FS_PP_DEST_SEL_IRT_PP },
+		.sink = { IPUV3_CHANNEL_MEM_ROT_PP, IPU_FS_PROC_FLOW1,
+			  FS_PP_ROT_SRC_SEL_MASK, FS_PP_ROT_SRC_SEL_PP },
+	}, {
+		.src =  { IPUV3_CHANNEL_CSI_DIRECT, 0 },
+		.sink = { IPUV3_CHANNEL_CSI_VDI_PREV, IPU_FS_PROC_FLOW1,
+			  FS_VDI_SRC_SEL_MASK, FS_VDI_SRC_SEL_CSI_DIRECT },
+	},
+};
+
+static const struct fsu_link_info *find_fsu_link_info(int src, int sink)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fsu_link_info); i++) {
+		if (src == fsu_link_info[i].src.chno &&
+		    sink == fsu_link_info[i].sink.chno)
+			return &fsu_link_info[i];
+	}
+
+	return NULL;
+}
+
+/*
+ * Links a source channel to a sink channel in the FSU.
+ */
+int ipu_fsu_link(struct ipu_soc *ipu, int src_ch, int sink_ch)
+{
+	const struct fsu_link_info *link;
+	u32 src_reg, sink_reg;
+	unsigned long flags;
+
+	link = find_fsu_link_info(src_ch, sink_ch);
+	if (!link)
+		return -EINVAL;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	if (link->src.mask) {
+		src_reg = ipu_cm_read(ipu, link->src.reg);
+		src_reg &= ~link->src.mask;
+		src_reg |= link->src.val;
+		ipu_cm_write(ipu, src_reg, link->src.reg);
+	}
+
+	if (link->sink.mask) {
+		sink_reg = ipu_cm_read(ipu, link->sink.reg);
+		sink_reg &= ~link->sink.mask;
+		sink_reg |= link->sink.val;
+		ipu_cm_write(ipu, sink_reg, link->sink.reg);
+	}
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_fsu_link);
+
+/*
+ * Unlinks source and sink channels in the FSU.
+ */
+int ipu_fsu_unlink(struct ipu_soc *ipu, int src_ch, int sink_ch)
+{
+	const struct fsu_link_info *link;
+	u32 src_reg, sink_reg;
+	unsigned long flags;
+
+	link = find_fsu_link_info(src_ch, sink_ch);
+	if (!link)
+		return -EINVAL;
+
+	spin_lock_irqsave(&ipu->lock, flags);
+
+	if (link->src.mask) {
+		src_reg = ipu_cm_read(ipu, link->src.reg);
+		src_reg &= ~link->src.mask;
+		ipu_cm_write(ipu, src_reg, link->src.reg);
+	}
+
+	if (link->sink.mask) {
+		sink_reg = ipu_cm_read(ipu, link->sink.reg);
+		sink_reg &= ~link->sink.mask;
+		ipu_cm_write(ipu, sink_reg, link->sink.reg);
+	}
+
+	spin_unlock_irqrestore(&ipu->lock, flags);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_fsu_unlink);
+
+/* Link IDMAC channels in the FSU */
+int ipu_idmac_link(struct ipuv3_channel *src, struct ipuv3_channel *sink)
+{
+	return ipu_fsu_link(src->ipu, src->num, sink->num);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_link);
+
+/* Unlink IDMAC channels in the FSU */
+int ipu_idmac_unlink(struct ipuv3_channel *src, struct ipuv3_channel *sink)
+{
+	return ipu_fsu_unlink(src->ipu, src->num, sink->num);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_unlink);
+
+struct ipu_devtype {
+	const char *name;
+	unsigned long cm_ofs;
+	unsigned long cpmem_ofs;
+	unsigned long srm_ofs;
+	unsigned long tpm_ofs;
+	unsigned long csi0_ofs;
+	unsigned long csi1_ofs;
+	unsigned long ic_ofs;
+	unsigned long disp0_ofs;
+	unsigned long disp1_ofs;
+	unsigned long dc_tmpl_ofs;
+	unsigned long vdi_ofs;
+	enum ipuv3_type type;
+};
+
+static struct ipu_devtype ipu_type_imx51 = {
+	.name = "IPUv3EX",
+	.cm_ofs = 0x1e000000,
+	.cpmem_ofs = 0x1f000000,
+	.srm_ofs = 0x1f040000,
+	.tpm_ofs = 0x1f060000,
+	.csi0_ofs = 0x1e030000,
+	.csi1_ofs = 0x1e038000,
+	.ic_ofs = 0x1e020000,
+	.disp0_ofs = 0x1e040000,
+	.disp1_ofs = 0x1e048000,
+	.dc_tmpl_ofs = 0x1f080000,
+	.vdi_ofs = 0x1e068000,
+	.type = IPUV3EX,
+};
+
+static struct ipu_devtype ipu_type_imx53 = {
+	.name = "IPUv3M",
+	.cm_ofs = 0x06000000,
+	.cpmem_ofs = 0x07000000,
+	.srm_ofs = 0x07040000,
+	.tpm_ofs = 0x07060000,
+	.csi0_ofs = 0x06030000,
+	.csi1_ofs = 0x06038000,
+	.ic_ofs = 0x06020000,
+	.disp0_ofs = 0x06040000,
+	.disp1_ofs = 0x06048000,
+	.dc_tmpl_ofs = 0x07080000,
+	.vdi_ofs = 0x06068000,
+	.type = IPUV3M,
+};
+
+static struct ipu_devtype ipu_type_imx6q = {
+	.name = "IPUv3H",
+	.cm_ofs = 0x00200000,
+	.cpmem_ofs = 0x00300000,
+	.srm_ofs = 0x00340000,
+	.tpm_ofs = 0x00360000,
+	.csi0_ofs = 0x00230000,
+	.csi1_ofs = 0x00238000,
+	.ic_ofs = 0x00220000,
+	.disp0_ofs = 0x00240000,
+	.disp1_ofs = 0x00248000,
+	.dc_tmpl_ofs = 0x00380000,
+	.vdi_ofs = 0x00268000,
+	.type = IPUV3H,
+};
+
+static const struct of_device_id imx_ipu_dt_ids[] = {
+	{ .compatible = "fsl,imx51-ipu", .data = &ipu_type_imx51, },
+	{ .compatible = "fsl,imx53-ipu", .data = &ipu_type_imx53, },
+	{ .compatible = "fsl,imx6q-ipu", .data = &ipu_type_imx6q, },
+	{ .compatible = "fsl,imx6qp-ipu", .data = &ipu_type_imx6q, },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, imx_ipu_dt_ids);
+
+static int ipu_submodules_init(struct ipu_soc *ipu,
+		struct platform_device *pdev, unsigned long ipu_base,
+		struct clk *ipu_clk)
+{
+	char *unit;
+	int ret;
+	struct device *dev = &pdev->dev;
+	const struct ipu_devtype *devtype = ipu->devtype;
+
+	ret = ipu_cpmem_init(ipu, dev, ipu_base + devtype->cpmem_ofs);
+	if (ret) {
+		unit = "cpmem";
+		goto err_cpmem;
+	}
+
+	ret = ipu_csi_init(ipu, dev, 0, ipu_base + devtype->csi0_ofs,
+			   IPU_CONF_CSI0_EN, ipu_clk);
+	if (ret) {
+		unit = "csi0";
+		goto err_csi_0;
+	}
+
+	ret = ipu_csi_init(ipu, dev, 1, ipu_base + devtype->csi1_ofs,
+			   IPU_CONF_CSI1_EN, ipu_clk);
+	if (ret) {
+		unit = "csi1";
+		goto err_csi_1;
+	}
+
+	ret = ipu_ic_init(ipu, dev,
+			  ipu_base + devtype->ic_ofs,
+			  ipu_base + devtype->tpm_ofs);
+	if (ret) {
+		unit = "ic";
+		goto err_ic;
+	}
+
+	ret = ipu_vdi_init(ipu, dev, ipu_base + devtype->vdi_ofs,
+			   IPU_CONF_VDI_EN | IPU_CONF_ISP_EN |
+			   IPU_CONF_IC_INPUT);
+	if (ret) {
+		unit = "vdi";
+		goto err_vdi;
+	}
+
+	ret = ipu_image_convert_init(ipu, dev);
+	if (ret) {
+		unit = "image_convert";
+		goto err_image_convert;
+	}
+
+	ret = ipu_di_init(ipu, dev, 0, ipu_base + devtype->disp0_ofs,
+			  IPU_CONF_DI0_EN, ipu_clk);
+	if (ret) {
+		unit = "di0";
+		goto err_di_0;
+	}
+
+	ret = ipu_di_init(ipu, dev, 1, ipu_base + devtype->disp1_ofs,
+			IPU_CONF_DI1_EN, ipu_clk);
+	if (ret) {
+		unit = "di1";
+		goto err_di_1;
+	}
+
+	ret = ipu_dc_init(ipu, dev, ipu_base + devtype->cm_ofs +
+			IPU_CM_DC_REG_OFS, ipu_base + devtype->dc_tmpl_ofs);
+	if (ret) {
+		unit = "dc_template";
+		goto err_dc;
+	}
+
+	ret = ipu_dmfc_init(ipu, dev, ipu_base +
+			devtype->cm_ofs + IPU_CM_DMFC_REG_OFS, ipu_clk);
+	if (ret) {
+		unit = "dmfc";
+		goto err_dmfc;
+	}
+
+	ret = ipu_dp_init(ipu, dev, ipu_base + devtype->srm_ofs);
+	if (ret) {
+		unit = "dp";
+		goto err_dp;
+	}
+
+	ret = ipu_smfc_init(ipu, dev, ipu_base +
+			devtype->cm_ofs + IPU_CM_SMFC_REG_OFS);
+	if (ret) {
+		unit = "smfc";
+		goto err_smfc;
+	}
+
+	return 0;
+
+err_smfc:
+	ipu_dp_exit(ipu);
+err_dp:
+	ipu_dmfc_exit(ipu);
+err_dmfc:
+	ipu_dc_exit(ipu);
+err_dc:
+	ipu_di_exit(ipu, 1);
+err_di_1:
+	ipu_di_exit(ipu, 0);
+err_di_0:
+	ipu_image_convert_exit(ipu);
+err_image_convert:
+	ipu_vdi_exit(ipu);
+err_vdi:
+	ipu_ic_exit(ipu);
+err_ic:
+	ipu_csi_exit(ipu, 1);
+err_csi_1:
+	ipu_csi_exit(ipu, 0);
+err_csi_0:
+	ipu_cpmem_exit(ipu);
+err_cpmem:
+	dev_err(&pdev->dev, "init %s failed with %d\n", unit, ret);
+	return ret;
+}
+
+static void ipu_irq_handle(struct ipu_soc *ipu, const int *regs, int num_regs)
+{
+	unsigned long status;
+	int i, bit;
+
+	for (i = 0; i < num_regs; i++) {
+
+		status = ipu_cm_read(ipu, IPU_INT_STAT(regs[i]));
+		status &= ipu_cm_read(ipu, IPU_INT_CTRL(regs[i]));
+
+		for_each_set_bit(bit, &status, 32)
+			generic_handle_domain_irq(ipu->domain,
+						  regs[i] * 32 + bit);
+	}
+}
+
+static void ipu_irq_handler(struct irq_desc *desc)
+{
+	struct ipu_soc *ipu = irq_desc_get_handler_data(desc);
+	struct irq_chip *chip = irq_desc_get_chip(desc);
+	static const int int_reg[] = { 0, 1, 2, 3, 10, 11, 12, 13, 14};
+
+	chained_irq_enter(chip, desc);
+
+	ipu_irq_handle(ipu, int_reg, ARRAY_SIZE(int_reg));
+
+	chained_irq_exit(chip, desc);
+}
+
+static void ipu_err_irq_handler(struct irq_desc *desc)
+{
+	struct ipu_soc *ipu = irq_desc_get_handler_data(desc);
+	struct irq_chip *chip = irq_desc_get_chip(desc);
+	static const int int_reg[] = { 4, 5, 8, 9};
+
+	chained_irq_enter(chip, desc);
+
+	ipu_irq_handle(ipu, int_reg, ARRAY_SIZE(int_reg));
+
+	chained_irq_exit(chip, desc);
+}
+
+int ipu_map_irq(struct ipu_soc *ipu, int irq)
+{
+	int virq;
+
+	virq = irq_linear_revmap(ipu->domain, irq);
+	if (!virq)
+		virq = irq_create_mapping(ipu->domain, irq);
+
+	return virq;
+}
+EXPORT_SYMBOL_GPL(ipu_map_irq);
+
+int ipu_idmac_channel_irq(struct ipu_soc *ipu, struct ipuv3_channel *channel,
+		enum ipu_channel_irq irq_type)
+{
+	return ipu_map_irq(ipu, irq_type + channel->num);
+}
+EXPORT_SYMBOL_GPL(ipu_idmac_channel_irq);
+
+static void ipu_submodules_exit(struct ipu_soc *ipu)
+{
+	ipu_smfc_exit(ipu);
+	ipu_dp_exit(ipu);
+	ipu_dmfc_exit(ipu);
+	ipu_dc_exit(ipu);
+	ipu_di_exit(ipu, 1);
+	ipu_di_exit(ipu, 0);
+	ipu_image_convert_exit(ipu);
+	ipu_vdi_exit(ipu);
+	ipu_ic_exit(ipu);
+	ipu_csi_exit(ipu, 1);
+	ipu_csi_exit(ipu, 0);
+	ipu_cpmem_exit(ipu);
+}
+
+static int platform_remove_devices_fn(struct device *dev, void *unused)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	platform_device_unregister(pdev);
+
+	return 0;
+}
+
+static void platform_device_unregister_children(struct platform_device *pdev)
+{
+	device_for_each_child(&pdev->dev, NULL, platform_remove_devices_fn);
+}
+
+struct ipu_platform_reg {
+	struct ipu_client_platformdata pdata;
+	const char *name;
+};
+
+/* These must be in the order of the corresponding device tree port nodes */
+static struct ipu_platform_reg client_reg[] = {
+	{
+		.pdata = {
+			.csi = 0,
+			.dma[0] = IPUV3_CHANNEL_CSI0,
+			.dma[1] = -EINVAL,
+		},
+		.name = "imx-ipuv3-csi",
+	}, {
+		.pdata = {
+			.csi = 1,
+			.dma[0] = IPUV3_CHANNEL_CSI1,
+			.dma[1] = -EINVAL,
+		},
+		.name = "imx-ipuv3-csi",
+	}, {
+		.pdata = {
+			.di = 0,
+			.dc = 5,
+			.dp = IPU_DP_FLOW_SYNC_BG,
+			.dma[0] = IPUV3_CHANNEL_MEM_BG_SYNC,
+			.dma[1] = IPUV3_CHANNEL_MEM_FG_SYNC,
+		},
+		.name = "imx-ipuv3-crtc",
+	}, {
+		.pdata = {
+			.di = 1,
+			.dc = 1,
+			.dp = -EINVAL,
+			.dma[0] = IPUV3_CHANNEL_MEM_DC_SYNC,
+			.dma[1] = -EINVAL,
+		},
+		.name = "imx-ipuv3-crtc",
+	},
+};
+
+static DEFINE_MUTEX(ipu_client_id_mutex);
+static int ipu_client_id;
+
+static int ipu_add_client_devices(struct ipu_soc *ipu, unsigned long ipu_base)
+{
+	struct device *dev = ipu->dev;
+	unsigned i;
+	int id, ret;
+
+	mutex_lock(&ipu_client_id_mutex);
+	id = ipu_client_id;
+	ipu_client_id += ARRAY_SIZE(client_reg);
+	mutex_unlock(&ipu_client_id_mutex);
+
+	for (i = 0; i < ARRAY_SIZE(client_reg); i++) {
+		struct ipu_platform_reg *reg = &client_reg[i];
+		struct platform_device *pdev;
+		struct device_node *of_node;
+
+		/* Associate subdevice with the corresponding port node */
+		of_node = of_graph_get_port_by_id(dev->of_node, i);
+		if (!of_node) {
+			dev_info(dev,
+				 "no port@%d node in %pOF, not using %s%d\n",
+				 i, dev->of_node,
+				 (i / 2) ? "DI" : "CSI", i % 2);
+			continue;
+		}
+
+		pdev = platform_device_alloc(reg->name, id++);
+		if (!pdev) {
+			ret = -ENOMEM;
+			goto err_register;
+		}
+
+		pdev->dev.parent = dev;
+
+		reg->pdata.of_node = of_node;
+		ret = platform_device_add_data(pdev, &reg->pdata,
+					       sizeof(reg->pdata));
+		if (!ret)
+			ret = platform_device_add(pdev);
+		if (ret) {
+			platform_device_put(pdev);
+			goto err_register;
+		}
+	}
+
+	return 0;
+
+err_register:
+	platform_device_unregister_children(to_platform_device(dev));
+
+	return ret;
+}
+
+
+static int ipu_irq_init(struct ipu_soc *ipu)
+{
+	struct irq_chip_generic *gc;
+	struct irq_chip_type *ct;
+	unsigned long unused[IPU_NUM_IRQS / 32] = {
+		0x400100d0, 0xffe000fd,
+		0x400100d0, 0xffe000fd,
+		0x400100d0, 0xffe000fd,
+		0x4077ffff, 0xffe7e1fd,
+		0x23fffffe, 0x8880fff0,
+		0xf98fe7d0, 0xfff81fff,
+		0x400100d0, 0xffe000fd,
+		0x00000000,
+	};
+	int ret, i;
+
+	ipu->domain = irq_domain_add_linear(ipu->dev->of_node, IPU_NUM_IRQS,
+					    &irq_generic_chip_ops, ipu);
+	if (!ipu->domain) {
+		dev_err(ipu->dev, "failed to add irq domain\n");
+		return -ENODEV;
+	}
+
+	ret = irq_alloc_domain_generic_chips(ipu->domain, 32, 1, "IPU",
+					     handle_level_irq, 0, 0, 0);
+	if (ret < 0) {
+		dev_err(ipu->dev, "failed to alloc generic irq chips\n");
+		irq_domain_remove(ipu->domain);
+		return ret;
+	}
+
+	/* Mask and clear all interrupts */
+	for (i = 0; i < IPU_NUM_IRQS; i += 32) {
+		ipu_cm_write(ipu, 0, IPU_INT_CTRL(i / 32));
+		ipu_cm_write(ipu, ~unused[i / 32], IPU_INT_STAT(i / 32));
+	}
+
+	for (i = 0; i < IPU_NUM_IRQS; i += 32) {
+		gc = irq_get_domain_generic_chip(ipu->domain, i);
+		gc->reg_base = ipu->cm_reg;
+		gc->unused = unused[i / 32];
+		ct = gc->chip_types;
+		ct->chip.irq_ack = irq_gc_ack_set_bit;
+		ct->chip.irq_mask = irq_gc_mask_clr_bit;
+		ct->chip.irq_unmask = irq_gc_mask_set_bit;
+		ct->regs.ack = IPU_INT_STAT(i / 32);
+		ct->regs.mask = IPU_INT_CTRL(i / 32);
+	}
+
+	irq_set_chained_handler_and_data(ipu->irq_sync, ipu_irq_handler, ipu);
+	irq_set_chained_handler_and_data(ipu->irq_err, ipu_err_irq_handler,
+					 ipu);
+
+	return 0;
+}
+
+static void ipu_irq_exit(struct ipu_soc *ipu)
+{
+	int i, irq;
+
+	irq_set_chained_handler_and_data(ipu->irq_err, NULL, NULL);
+	irq_set_chained_handler_and_data(ipu->irq_sync, NULL, NULL);
+
+	/* TODO: remove irq_domain_generic_chips */
+
+	for (i = 0; i < IPU_NUM_IRQS; i++) {
+		irq = irq_linear_revmap(ipu->domain, i);
+		if (irq)
+			irq_dispose_mapping(irq);
+	}
+
+	irq_domain_remove(ipu->domain);
+}
+
+void ipu_dump(struct ipu_soc *ipu)
+{
+	int i;
+
+	dev_dbg(ipu->dev, "IPU_CONF = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_CONF));
+	dev_dbg(ipu->dev, "IDMAC_CONF = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_CONF));
+	dev_dbg(ipu->dev, "IDMAC_CHA_EN1 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_CHA_EN(0)));
+	dev_dbg(ipu->dev, "IDMAC_CHA_EN2 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_CHA_EN(32)));
+	dev_dbg(ipu->dev, "IDMAC_CHA_PRI1 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_CHA_PRI(0)));
+	dev_dbg(ipu->dev, "IDMAC_CHA_PRI2 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_CHA_PRI(32)));
+	dev_dbg(ipu->dev, "IDMAC_BAND_EN1 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_BAND_EN(0)));
+	dev_dbg(ipu->dev, "IDMAC_BAND_EN2 = \t0x%08X\n",
+		ipu_idmac_read(ipu, IDMAC_BAND_EN(32)));
+	dev_dbg(ipu->dev, "IPU_CHA_DB_MODE_SEL0 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_CHA_DB_MODE_SEL(0)));
+	dev_dbg(ipu->dev, "IPU_CHA_DB_MODE_SEL1 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_CHA_DB_MODE_SEL(32)));
+	dev_dbg(ipu->dev, "IPU_FS_PROC_FLOW1 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_FS_PROC_FLOW1));
+	dev_dbg(ipu->dev, "IPU_FS_PROC_FLOW2 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_FS_PROC_FLOW2));
+	dev_dbg(ipu->dev, "IPU_FS_PROC_FLOW3 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_FS_PROC_FLOW3));
+	dev_dbg(ipu->dev, "IPU_FS_DISP_FLOW1 = \t0x%08X\n",
+		ipu_cm_read(ipu, IPU_FS_DISP_FLOW1));
+	for (i = 0; i < 15; i++)
+		dev_dbg(ipu->dev, "IPU_INT_CTRL(%d) = \t%08X\n", i,
+			ipu_cm_read(ipu, IPU_INT_CTRL(i)));
+}
+EXPORT_SYMBOL_GPL(ipu_dump);
+
+static int ipu_probe(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct ipu_soc *ipu;
+	struct resource *res;
+	unsigned long ipu_base;
+	int ret, irq_sync, irq_err;
+	const struct ipu_devtype *devtype;
+
+	devtype = of_device_get_match_data(&pdev->dev);
+	if (!devtype)
+		return -EINVAL;
+
+	irq_sync = platform_get_irq(pdev, 0);
+	irq_err = platform_get_irq(pdev, 1);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+
+	dev_dbg(&pdev->dev, "irq_sync: %d irq_err: %d\n",
+			irq_sync, irq_err);
+
+	if (!res || irq_sync < 0 || irq_err < 0)
+		return -ENODEV;
+
+	ipu_base = res->start;
+
+	ipu = devm_kzalloc(&pdev->dev, sizeof(*ipu), GFP_KERNEL);
+	if (!ipu)
+		return -ENODEV;
+
+	ipu->id = of_alias_get_id(np, "ipu");
+	if (ipu->id < 0)
+		ipu->id = 0;
+
+	if (of_device_is_compatible(np, "fsl,imx6qp-ipu") &&
+	    IS_ENABLED(CONFIG_DRM)) {
+		ipu->prg_priv = ipu_prg_lookup_by_phandle(&pdev->dev,
+							  "fsl,prg", ipu->id);
+		if (!ipu->prg_priv)
+			return -EPROBE_DEFER;
+	}
+
+	ipu->devtype = devtype;
+	ipu->ipu_type = devtype->type;
+
+	spin_lock_init(&ipu->lock);
+	mutex_init(&ipu->channel_lock);
+	INIT_LIST_HEAD(&ipu->channels);
+
+	dev_dbg(&pdev->dev, "cm_reg:   0x%08lx\n",
+			ipu_base + devtype->cm_ofs);
+	dev_dbg(&pdev->dev, "idmac:    0x%08lx\n",
+			ipu_base + devtype->cm_ofs + IPU_CM_IDMAC_REG_OFS);
+	dev_dbg(&pdev->dev, "cpmem:    0x%08lx\n",
+			ipu_base + devtype->cpmem_ofs);
+	dev_dbg(&pdev->dev, "csi0:    0x%08lx\n",
+			ipu_base + devtype->csi0_ofs);
+	dev_dbg(&pdev->dev, "csi1:    0x%08lx\n",
+			ipu_base + devtype->csi1_ofs);
+	dev_dbg(&pdev->dev, "ic:      0x%08lx\n",
+			ipu_base + devtype->ic_ofs);
+	dev_dbg(&pdev->dev, "disp0:    0x%08lx\n",
+			ipu_base + devtype->disp0_ofs);
+	dev_dbg(&pdev->dev, "disp1:    0x%08lx\n",
+			ipu_base + devtype->disp1_ofs);
+	dev_dbg(&pdev->dev, "srm:      0x%08lx\n",
+			ipu_base + devtype->srm_ofs);
+	dev_dbg(&pdev->dev, "tpm:      0x%08lx\n",
+			ipu_base + devtype->tpm_ofs);
+	dev_dbg(&pdev->dev, "dc:       0x%08lx\n",
+			ipu_base + devtype->cm_ofs + IPU_CM_DC_REG_OFS);
+	dev_dbg(&pdev->dev, "ic:       0x%08lx\n",
+			ipu_base + devtype->cm_ofs + IPU_CM_IC_REG_OFS);
+	dev_dbg(&pdev->dev, "dmfc:     0x%08lx\n",
+			ipu_base + devtype->cm_ofs + IPU_CM_DMFC_REG_OFS);
+	dev_dbg(&pdev->dev, "vdi:      0x%08lx\n",
+			ipu_base + devtype->vdi_ofs);
+
+	ipu->cm_reg = devm_ioremap(&pdev->dev,
+			ipu_base + devtype->cm_ofs, PAGE_SIZE);
+	ipu->idmac_reg = devm_ioremap(&pdev->dev,
+			ipu_base + devtype->cm_ofs + IPU_CM_IDMAC_REG_OFS,
+			PAGE_SIZE);
+
+	if (!ipu->cm_reg || !ipu->idmac_reg)
+		return -ENOMEM;
+
+	ipu->clk = devm_clk_get(&pdev->dev, "bus");
+	if (IS_ERR(ipu->clk)) {
+		ret = PTR_ERR(ipu->clk);
+		dev_err(&pdev->dev, "clk_get failed with %d", ret);
+		return ret;
+	}
+
+	platform_set_drvdata(pdev, ipu);
+
+	ret = clk_prepare_enable(ipu->clk);
+	if (ret) {
+		dev_err(&pdev->dev, "clk_prepare_enable failed: %d\n", ret);
+		return ret;
+	}
+
+	ipu->dev = &pdev->dev;
+	ipu->irq_sync = irq_sync;
+	ipu->irq_err = irq_err;
+
+	ret = device_reset(&pdev->dev);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to reset: %d\n", ret);
+		goto out_failed_reset;
+	}
+	ret = ipu_memory_reset(ipu);
+	if (ret)
+		goto out_failed_reset;
+
+	ret = ipu_irq_init(ipu);
+	if (ret)
+		goto out_failed_irq;
+
+	/* Set MCU_T to divide MCU access window into 2 */
+	ipu_cm_write(ipu, 0x00400000L | (IPU_MCU_T_DEFAULT << 18),
+			IPU_DISP_GEN);
+
+	ret = ipu_submodules_init(ipu, pdev, ipu_base, ipu->clk);
+	if (ret)
+		goto failed_submodules_init;
+
+	ret = ipu_add_client_devices(ipu, ipu_base);
+	if (ret) {
+		dev_err(&pdev->dev, "adding client devices failed with %d\n",
+				ret);
+		goto failed_add_clients;
+	}
+
+	dev_info(&pdev->dev, "%s probed\n", devtype->name);
+
+	return 0;
+
+failed_add_clients:
+	ipu_submodules_exit(ipu);
+failed_submodules_init:
+	ipu_irq_exit(ipu);
+out_failed_irq:
+out_failed_reset:
+	clk_disable_unprepare(ipu->clk);
+	return ret;
+}
+
+static int ipu_remove(struct platform_device *pdev)
+{
+	struct ipu_soc *ipu = platform_get_drvdata(pdev);
+
+	platform_device_unregister_children(pdev);
+	ipu_submodules_exit(ipu);
+	ipu_irq_exit(ipu);
+
+	clk_disable_unprepare(ipu->clk);
+
+	return 0;
+}
+
+static struct platform_driver imx_ipu_driver = {
+	.driver = {
+		.name = "imx-ipuv3",
+		.of_match_table = imx_ipu_dt_ids,
+	},
+	.probe = ipu_probe,
+	.remove = ipu_remove,
+};
+
+static struct platform_driver * const drivers[] = {
+#if IS_ENABLED(CONFIG_DRM)
+	&ipu_pre_drv,
+	&ipu_prg_drv,
+#endif
+	&imx_ipu_driver,
+};
+
+static int __init imx_ipu_init(void)
+{
+	return platform_register_drivers(drivers, ARRAY_SIZE(drivers));
+}
+module_init(imx_ipu_init);
+
+static void __exit imx_ipu_exit(void)
+{
+	platform_unregister_drivers(drivers, ARRAY_SIZE(drivers));
+}
+module_exit(imx_ipu_exit);
+
+MODULE_ALIAS("platform:imx-ipuv3");
+MODULE_DESCRIPTION("i.MX IPU v3 driver");
+MODULE_AUTHOR("Sascha Hauer <s.hauer@pengutronix.de>");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/ipu-v3/ipu-cpmem.c b/drivers/gpu/imx/ipu-v3/ipu-cpmem.c
new file mode 100644
index 000000000..82b244cb3
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-cpmem.c
@@ -0,0 +1,976 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (C) 2012 Mentor Graphics Inc.
+ * Copyright 2005-2012 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+#include <linux/types.h>
+#include <linux/bitrev.h>
+#include <linux/io.h>
+#include <linux/sizes.h>
+#include <drm/drm_fourcc.h>
+#include "ipu-prv.h"
+
+struct ipu_cpmem_word {
+	u32 data[5];
+	u32 res[3];
+};
+
+struct ipu_ch_param {
+	struct ipu_cpmem_word word[2];
+};
+
+struct ipu_cpmem {
+	struct ipu_ch_param __iomem *base;
+	u32 module;
+	spinlock_t lock;
+	int use_count;
+	struct ipu_soc *ipu;
+};
+
+#define IPU_CPMEM_WORD(word, ofs, size) ((((word) * 160 + (ofs)) << 8) | (size))
+
+#define IPU_FIELD_UBO		IPU_CPMEM_WORD(0, 46, 22)
+#define IPU_FIELD_VBO		IPU_CPMEM_WORD(0, 68, 22)
+#define IPU_FIELD_IOX		IPU_CPMEM_WORD(0, 90, 4)
+#define IPU_FIELD_RDRW		IPU_CPMEM_WORD(0, 94, 1)
+#define IPU_FIELD_SO		IPU_CPMEM_WORD(0, 113, 1)
+#define IPU_FIELD_SLY		IPU_CPMEM_WORD(1, 102, 14)
+#define IPU_FIELD_SLUV		IPU_CPMEM_WORD(1, 128, 14)
+
+#define IPU_FIELD_XV		IPU_CPMEM_WORD(0, 0, 10)
+#define IPU_FIELD_YV		IPU_CPMEM_WORD(0, 10, 9)
+#define IPU_FIELD_XB		IPU_CPMEM_WORD(0, 19, 13)
+#define IPU_FIELD_YB		IPU_CPMEM_WORD(0, 32, 12)
+#define IPU_FIELD_NSB_B		IPU_CPMEM_WORD(0, 44, 1)
+#define IPU_FIELD_CF		IPU_CPMEM_WORD(0, 45, 1)
+#define IPU_FIELD_SX		IPU_CPMEM_WORD(0, 46, 12)
+#define IPU_FIELD_SY		IPU_CPMEM_WORD(0, 58, 11)
+#define IPU_FIELD_NS		IPU_CPMEM_WORD(0, 69, 10)
+#define IPU_FIELD_SDX		IPU_CPMEM_WORD(0, 79, 7)
+#define IPU_FIELD_SM		IPU_CPMEM_WORD(0, 86, 10)
+#define IPU_FIELD_SCC		IPU_CPMEM_WORD(0, 96, 1)
+#define IPU_FIELD_SCE		IPU_CPMEM_WORD(0, 97, 1)
+#define IPU_FIELD_SDY		IPU_CPMEM_WORD(0, 98, 7)
+#define IPU_FIELD_SDRX		IPU_CPMEM_WORD(0, 105, 1)
+#define IPU_FIELD_SDRY		IPU_CPMEM_WORD(0, 106, 1)
+#define IPU_FIELD_BPP		IPU_CPMEM_WORD(0, 107, 3)
+#define IPU_FIELD_DEC_SEL	IPU_CPMEM_WORD(0, 110, 2)
+#define IPU_FIELD_DIM		IPU_CPMEM_WORD(0, 112, 1)
+#define IPU_FIELD_BNDM		IPU_CPMEM_WORD(0, 114, 3)
+#define IPU_FIELD_BM		IPU_CPMEM_WORD(0, 117, 2)
+#define IPU_FIELD_ROT		IPU_CPMEM_WORD(0, 119, 1)
+#define IPU_FIELD_ROT_HF_VF	IPU_CPMEM_WORD(0, 119, 3)
+#define IPU_FIELD_HF		IPU_CPMEM_WORD(0, 120, 1)
+#define IPU_FIELD_VF		IPU_CPMEM_WORD(0, 121, 1)
+#define IPU_FIELD_THE		IPU_CPMEM_WORD(0, 122, 1)
+#define IPU_FIELD_CAP		IPU_CPMEM_WORD(0, 123, 1)
+#define IPU_FIELD_CAE		IPU_CPMEM_WORD(0, 124, 1)
+#define IPU_FIELD_FW		IPU_CPMEM_WORD(0, 125, 13)
+#define IPU_FIELD_FH		IPU_CPMEM_WORD(0, 138, 12)
+#define IPU_FIELD_EBA0		IPU_CPMEM_WORD(1, 0, 29)
+#define IPU_FIELD_EBA1		IPU_CPMEM_WORD(1, 29, 29)
+#define IPU_FIELD_ILO		IPU_CPMEM_WORD(1, 58, 20)
+#define IPU_FIELD_NPB		IPU_CPMEM_WORD(1, 78, 7)
+#define IPU_FIELD_PFS		IPU_CPMEM_WORD(1, 85, 4)
+#define IPU_FIELD_ALU		IPU_CPMEM_WORD(1, 89, 1)
+#define IPU_FIELD_ALBM		IPU_CPMEM_WORD(1, 90, 3)
+#define IPU_FIELD_ID		IPU_CPMEM_WORD(1, 93, 2)
+#define IPU_FIELD_TH		IPU_CPMEM_WORD(1, 95, 7)
+#define IPU_FIELD_SL		IPU_CPMEM_WORD(1, 102, 14)
+#define IPU_FIELD_WID0		IPU_CPMEM_WORD(1, 116, 3)
+#define IPU_FIELD_WID1		IPU_CPMEM_WORD(1, 119, 3)
+#define IPU_FIELD_WID2		IPU_CPMEM_WORD(1, 122, 3)
+#define IPU_FIELD_WID3		IPU_CPMEM_WORD(1, 125, 3)
+#define IPU_FIELD_OFS0		IPU_CPMEM_WORD(1, 128, 5)
+#define IPU_FIELD_OFS1		IPU_CPMEM_WORD(1, 133, 5)
+#define IPU_FIELD_OFS2		IPU_CPMEM_WORD(1, 138, 5)
+#define IPU_FIELD_OFS3		IPU_CPMEM_WORD(1, 143, 5)
+#define IPU_FIELD_SXYS		IPU_CPMEM_WORD(1, 148, 1)
+#define IPU_FIELD_CRE		IPU_CPMEM_WORD(1, 149, 1)
+#define IPU_FIELD_DEC_SEL2	IPU_CPMEM_WORD(1, 150, 1)
+
+static inline struct ipu_ch_param __iomem *
+ipu_get_cpmem(struct ipuv3_channel *ch)
+{
+	struct ipu_cpmem *cpmem = ch->ipu->cpmem_priv;
+
+	return cpmem->base + ch->num;
+}
+
+static void ipu_ch_param_write_field(struct ipuv3_channel *ch, u32 wbs, u32 v)
+{
+	struct ipu_ch_param __iomem *base = ipu_get_cpmem(ch);
+	u32 bit = (wbs >> 8) % 160;
+	u32 size = wbs & 0xff;
+	u32 word = (wbs >> 8) / 160;
+	u32 i = bit / 32;
+	u32 ofs = bit % 32;
+	u32 mask = (1 << size) - 1;
+	u32 val;
+
+	pr_debug("%s %d %d %d\n", __func__, word, bit , size);
+
+	val = readl(&base->word[word].data[i]);
+	val &= ~(mask << ofs);
+	val |= v << ofs;
+	writel(val, &base->word[word].data[i]);
+
+	if ((bit + size - 1) / 32 > i) {
+		val = readl(&base->word[word].data[i + 1]);
+		val &= ~(mask >> (ofs ? (32 - ofs) : 0));
+		val |= v >> (ofs ? (32 - ofs) : 0);
+		writel(val, &base->word[word].data[i + 1]);
+	}
+}
+
+static u32 ipu_ch_param_read_field(struct ipuv3_channel *ch, u32 wbs)
+{
+	struct ipu_ch_param __iomem *base = ipu_get_cpmem(ch);
+	u32 bit = (wbs >> 8) % 160;
+	u32 size = wbs & 0xff;
+	u32 word = (wbs >> 8) / 160;
+	u32 i = bit / 32;
+	u32 ofs = bit % 32;
+	u32 mask = (1 << size) - 1;
+	u32 val = 0;
+
+	pr_debug("%s %d %d %d\n", __func__, word, bit , size);
+
+	val = (readl(&base->word[word].data[i]) >> ofs) & mask;
+
+	if ((bit + size - 1) / 32 > i) {
+		u32 tmp;
+
+		tmp = readl(&base->word[word].data[i + 1]);
+		tmp &= mask >> (ofs ? (32 - ofs) : 0);
+		val |= tmp << (ofs ? (32 - ofs) : 0);
+	}
+
+	return val;
+}
+
+/*
+ * The V4L2 spec defines packed RGB formats in memory byte order, which from
+ * point of view of the IPU corresponds to little-endian words with the first
+ * component in the least significant bits.
+ * The DRM pixel formats and IPU internal representation are ordered the other
+ * way around, with the first named component ordered at the most significant
+ * bits. Further, V4L2 formats are not well defined:
+ *     https://linuxtv.org/downloads/v4l-dvb-apis/packed-rgb.html
+ * We choose the interpretation which matches GStreamer behavior.
+ */
+static int v4l2_pix_fmt_to_drm_fourcc(u32 pixelformat)
+{
+	switch (pixelformat) {
+	case V4L2_PIX_FMT_RGB565:
+		/*
+		 * Here we choose the 'corrected' interpretation of RGBP, a
+		 * little-endian 16-bit word with the red component at the most
+		 * significant bits:
+		 * g[2:0]b[4:0] r[4:0]g[5:3] <=> [16:0] R:G:B
+		 */
+		return DRM_FORMAT_RGB565;
+	case V4L2_PIX_FMT_BGR24:
+		/* B G R <=> [24:0] R:G:B */
+		return DRM_FORMAT_RGB888;
+	case V4L2_PIX_FMT_RGB24:
+		/* R G B <=> [24:0] B:G:R */
+		return DRM_FORMAT_BGR888;
+	case V4L2_PIX_FMT_BGR32:
+		/* B G R A <=> [32:0] A:B:G:R */
+		return DRM_FORMAT_XRGB8888;
+	case V4L2_PIX_FMT_RGB32:
+		/* R G B A <=> [32:0] A:B:G:R */
+		return DRM_FORMAT_XBGR8888;
+	case V4L2_PIX_FMT_ABGR32:
+		/* B G R A <=> [32:0] A:R:G:B */
+		return DRM_FORMAT_ARGB8888;
+	case V4L2_PIX_FMT_XBGR32:
+		/* B G R X <=> [32:0] X:R:G:B */
+		return DRM_FORMAT_XRGB8888;
+	case V4L2_PIX_FMT_BGRA32:
+		/* A B G R <=> [32:0] R:G:B:A */
+		return DRM_FORMAT_RGBA8888;
+	case V4L2_PIX_FMT_BGRX32:
+		/* X B G R <=> [32:0] R:G:B:X */
+		return DRM_FORMAT_RGBX8888;
+	case V4L2_PIX_FMT_RGBA32:
+		/* R G B A <=> [32:0] A:B:G:R */
+		return DRM_FORMAT_ABGR8888;
+	case V4L2_PIX_FMT_RGBX32:
+		/* R G B X <=> [32:0] X:B:G:R */
+		return DRM_FORMAT_XBGR8888;
+	case V4L2_PIX_FMT_ARGB32:
+		/* A R G B <=> [32:0] B:G:R:A */
+		return DRM_FORMAT_BGRA8888;
+	case V4L2_PIX_FMT_XRGB32:
+		/* X R G B <=> [32:0] B:G:R:X */
+		return DRM_FORMAT_BGRX8888;
+	case V4L2_PIX_FMT_UYVY:
+		return DRM_FORMAT_UYVY;
+	case V4L2_PIX_FMT_YUYV:
+		return DRM_FORMAT_YUYV;
+	case V4L2_PIX_FMT_YUV420:
+		return DRM_FORMAT_YUV420;
+	case V4L2_PIX_FMT_YUV422P:
+		return DRM_FORMAT_YUV422;
+	case V4L2_PIX_FMT_YVU420:
+		return DRM_FORMAT_YVU420;
+	case V4L2_PIX_FMT_NV12:
+		return DRM_FORMAT_NV12;
+	case V4L2_PIX_FMT_NV16:
+		return DRM_FORMAT_NV16;
+	}
+
+	return -EINVAL;
+}
+
+void ipu_cpmem_zero(struct ipuv3_channel *ch)
+{
+	struct ipu_ch_param __iomem *p = ipu_get_cpmem(ch);
+	void __iomem *base = p;
+	int i;
+
+	for (i = 0; i < sizeof(*p) / sizeof(u32); i++)
+		writel(0, base + i * sizeof(u32));
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_zero);
+
+void ipu_cpmem_set_resolution(struct ipuv3_channel *ch, int xres, int yres)
+{
+	ipu_ch_param_write_field(ch, IPU_FIELD_FW, xres - 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_FH, yres - 1);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_resolution);
+
+void ipu_cpmem_skip_odd_chroma_rows(struct ipuv3_channel *ch)
+{
+	ipu_ch_param_write_field(ch, IPU_FIELD_RDRW, 1);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_skip_odd_chroma_rows);
+
+void ipu_cpmem_set_stride(struct ipuv3_channel *ch, int stride)
+{
+	ipu_ch_param_write_field(ch, IPU_FIELD_SLY, stride - 1);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_stride);
+
+void ipu_cpmem_set_high_priority(struct ipuv3_channel *ch)
+{
+	struct ipu_soc *ipu = ch->ipu;
+	u32 val;
+
+	if (ipu->ipu_type == IPUV3EX)
+		ipu_ch_param_write_field(ch, IPU_FIELD_ID, 1);
+
+	val = ipu_idmac_read(ipu, IDMAC_CHA_PRI(ch->num));
+	val |= 1 << (ch->num % 32);
+	ipu_idmac_write(ipu, val, IDMAC_CHA_PRI(ch->num));
+};
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_high_priority);
+
+void ipu_cpmem_set_buffer(struct ipuv3_channel *ch, int bufnum, dma_addr_t buf)
+{
+	WARN_ON_ONCE(buf & 0x7);
+
+	if (bufnum)
+		ipu_ch_param_write_field(ch, IPU_FIELD_EBA1, buf >> 3);
+	else
+		ipu_ch_param_write_field(ch, IPU_FIELD_EBA0, buf >> 3);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_buffer);
+
+void ipu_cpmem_set_uv_offset(struct ipuv3_channel *ch, u32 u_off, u32 v_off)
+{
+	WARN_ON_ONCE((u_off & 0x7) || (v_off & 0x7));
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_UBO, u_off / 8);
+	ipu_ch_param_write_field(ch, IPU_FIELD_VBO, v_off / 8);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_uv_offset);
+
+void ipu_cpmem_interlaced_scan(struct ipuv3_channel *ch, int stride,
+			       u32 pixelformat)
+{
+	u32 ilo, sly, sluv;
+
+	if (stride < 0) {
+		stride = -stride;
+		ilo = 0x100000 - (stride / 8);
+	} else {
+		ilo = stride / 8;
+	}
+
+	sly = (stride * 2) - 1;
+
+	switch (pixelformat) {
+	case V4L2_PIX_FMT_YUV420:
+	case V4L2_PIX_FMT_YVU420:
+		sluv = stride / 2 - 1;
+		break;
+	case V4L2_PIX_FMT_NV12:
+		sluv = stride - 1;
+		break;
+	case V4L2_PIX_FMT_YUV422P:
+		sluv = stride - 1;
+		break;
+	case V4L2_PIX_FMT_NV16:
+		sluv = stride * 2 - 1;
+		break;
+	default:
+		sluv = 0;
+		break;
+	}
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_SO, 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_ILO, ilo);
+	ipu_ch_param_write_field(ch, IPU_FIELD_SLY, sly);
+	if (sluv)
+		ipu_ch_param_write_field(ch, IPU_FIELD_SLUV, sluv);
+};
+EXPORT_SYMBOL_GPL(ipu_cpmem_interlaced_scan);
+
+void ipu_cpmem_set_axi_id(struct ipuv3_channel *ch, u32 id)
+{
+	id &= 0x3;
+	ipu_ch_param_write_field(ch, IPU_FIELD_ID, id);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_axi_id);
+
+int ipu_cpmem_get_burstsize(struct ipuv3_channel *ch)
+{
+	return ipu_ch_param_read_field(ch, IPU_FIELD_NPB) + 1;
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_get_burstsize);
+
+void ipu_cpmem_set_burstsize(struct ipuv3_channel *ch, int burstsize)
+{
+	ipu_ch_param_write_field(ch, IPU_FIELD_NPB, burstsize - 1);
+};
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_burstsize);
+
+void ipu_cpmem_set_block_mode(struct ipuv3_channel *ch)
+{
+	ipu_ch_param_write_field(ch, IPU_FIELD_BM, 1);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_block_mode);
+
+void ipu_cpmem_set_rotation(struct ipuv3_channel *ch,
+			    enum ipu_rotate_mode rot)
+{
+	u32 temp_rot = bitrev8(rot) >> 5;
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_ROT_HF_VF, temp_rot);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_rotation);
+
+int ipu_cpmem_set_format_rgb(struct ipuv3_channel *ch,
+			     const struct ipu_rgb *rgb)
+{
+	int bpp = 0, npb = 0, ro, go, bo, to;
+
+	ro = rgb->bits_per_pixel - rgb->red.length - rgb->red.offset;
+	go = rgb->bits_per_pixel - rgb->green.length - rgb->green.offset;
+	bo = rgb->bits_per_pixel - rgb->blue.length - rgb->blue.offset;
+	to = rgb->bits_per_pixel - rgb->transp.length - rgb->transp.offset;
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_WID0, rgb->red.length - 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_OFS0, ro);
+	ipu_ch_param_write_field(ch, IPU_FIELD_WID1, rgb->green.length - 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_OFS1, go);
+	ipu_ch_param_write_field(ch, IPU_FIELD_WID2, rgb->blue.length - 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_OFS2, bo);
+
+	if (rgb->transp.length) {
+		ipu_ch_param_write_field(ch, IPU_FIELD_WID3,
+				rgb->transp.length - 1);
+		ipu_ch_param_write_field(ch, IPU_FIELD_OFS3, to);
+	} else {
+		ipu_ch_param_write_field(ch, IPU_FIELD_WID3, 7);
+		ipu_ch_param_write_field(ch, IPU_FIELD_OFS3,
+				rgb->bits_per_pixel);
+	}
+
+	switch (rgb->bits_per_pixel) {
+	case 32:
+		bpp = 0;
+		npb = 15;
+		break;
+	case 24:
+		bpp = 1;
+		npb = 19;
+		break;
+	case 16:
+		bpp = 3;
+		npb = 31;
+		break;
+	case 8:
+		bpp = 5;
+		npb = 63;
+		break;
+	default:
+		return -EINVAL;
+	}
+	ipu_ch_param_write_field(ch, IPU_FIELD_BPP, bpp);
+	ipu_ch_param_write_field(ch, IPU_FIELD_NPB, npb);
+	ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 7); /* rgb mode */
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_format_rgb);
+
+int ipu_cpmem_set_format_passthrough(struct ipuv3_channel *ch, int width)
+{
+	int bpp = 0, npb = 0;
+
+	switch (width) {
+	case 32:
+		bpp = 0;
+		npb = 15;
+		break;
+	case 24:
+		bpp = 1;
+		npb = 19;
+		break;
+	case 16:
+		bpp = 3;
+		npb = 31;
+		break;
+	case 8:
+		bpp = 5;
+		npb = 63;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_BPP, bpp);
+	ipu_ch_param_write_field(ch, IPU_FIELD_NPB, npb);
+	ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 6); /* raw mode */
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_format_passthrough);
+
+void ipu_cpmem_set_yuv_interleaved(struct ipuv3_channel *ch, u32 pixel_format)
+{
+	switch (pixel_format) {
+	case V4L2_PIX_FMT_UYVY:
+		ipu_ch_param_write_field(ch, IPU_FIELD_BPP, 3); /* bits/pixel */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 0xA);/* pix fmt */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);/* burst size */
+		break;
+	case V4L2_PIX_FMT_YUYV:
+		ipu_ch_param_write_field(ch, IPU_FIELD_BPP, 3); /* bits/pixel */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 0x8);/* pix fmt */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);/* burst size */
+		break;
+	}
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_yuv_interleaved);
+
+void ipu_cpmem_set_yuv_planar_full(struct ipuv3_channel *ch,
+				   unsigned int uv_stride,
+				   unsigned int u_offset, unsigned int v_offset)
+{
+	WARN_ON_ONCE((u_offset & 0x7) || (v_offset & 0x7));
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_SLUV, uv_stride - 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_UBO, u_offset / 8);
+	ipu_ch_param_write_field(ch, IPU_FIELD_VBO, v_offset / 8);
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_yuv_planar_full);
+
+static const struct ipu_rgb def_xrgb_32 = {
+	.red	= { .offset = 16, .length = 8, },
+	.green	= { .offset =  8, .length = 8, },
+	.blue	= { .offset =  0, .length = 8, },
+	.transp = { .offset = 24, .length = 8, },
+	.bits_per_pixel = 32,
+};
+
+static const struct ipu_rgb def_xbgr_32 = {
+	.red	= { .offset =  0, .length = 8, },
+	.green	= { .offset =  8, .length = 8, },
+	.blue	= { .offset = 16, .length = 8, },
+	.transp = { .offset = 24, .length = 8, },
+	.bits_per_pixel = 32,
+};
+
+static const struct ipu_rgb def_rgbx_32 = {
+	.red	= { .offset = 24, .length = 8, },
+	.green	= { .offset = 16, .length = 8, },
+	.blue	= { .offset =  8, .length = 8, },
+	.transp = { .offset =  0, .length = 8, },
+	.bits_per_pixel = 32,
+};
+
+static const struct ipu_rgb def_bgrx_32 = {
+	.red	= { .offset =  8, .length = 8, },
+	.green	= { .offset = 16, .length = 8, },
+	.blue	= { .offset = 24, .length = 8, },
+	.transp = { .offset =  0, .length = 8, },
+	.bits_per_pixel = 32,
+};
+
+static const struct ipu_rgb def_rgb_24 = {
+	.red	= { .offset = 16, .length = 8, },
+	.green	= { .offset =  8, .length = 8, },
+	.blue	= { .offset =  0, .length = 8, },
+	.transp = { .offset =  0, .length = 0, },
+	.bits_per_pixel = 24,
+};
+
+static const struct ipu_rgb def_bgr_24 = {
+	.red	= { .offset =  0, .length = 8, },
+	.green	= { .offset =  8, .length = 8, },
+	.blue	= { .offset = 16, .length = 8, },
+	.transp = { .offset =  0, .length = 0, },
+	.bits_per_pixel = 24,
+};
+
+static const struct ipu_rgb def_rgb_16 = {
+	.red	= { .offset = 11, .length = 5, },
+	.green	= { .offset =  5, .length = 6, },
+	.blue	= { .offset =  0, .length = 5, },
+	.transp = { .offset =  0, .length = 0, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_bgr_16 = {
+	.red	= { .offset =  0, .length = 5, },
+	.green	= { .offset =  5, .length = 6, },
+	.blue	= { .offset = 11, .length = 5, },
+	.transp = { .offset =  0, .length = 0, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_argb_16 = {
+	.red	= { .offset = 10, .length = 5, },
+	.green	= { .offset =  5, .length = 5, },
+	.blue	= { .offset =  0, .length = 5, },
+	.transp = { .offset = 15, .length = 1, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_argb_16_4444 = {
+	.red	= { .offset =  8, .length = 4, },
+	.green	= { .offset =  4, .length = 4, },
+	.blue	= { .offset =  0, .length = 4, },
+	.transp = { .offset = 12, .length = 4, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_abgr_16 = {
+	.red	= { .offset =  0, .length = 5, },
+	.green	= { .offset =  5, .length = 5, },
+	.blue	= { .offset = 10, .length = 5, },
+	.transp = { .offset = 15, .length = 1, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_rgba_16 = {
+	.red	= { .offset = 11, .length = 5, },
+	.green	= { .offset =  6, .length = 5, },
+	.blue	= { .offset =  1, .length = 5, },
+	.transp = { .offset =  0, .length = 1, },
+	.bits_per_pixel = 16,
+};
+
+static const struct ipu_rgb def_bgra_16 = {
+	.red	= { .offset =  1, .length = 5, },
+	.green	= { .offset =  6, .length = 5, },
+	.blue	= { .offset = 11, .length = 5, },
+	.transp = { .offset =  0, .length = 1, },
+	.bits_per_pixel = 16,
+};
+
+#define Y_OFFSET(pix, x, y)	((x) + pix->bytesperline * (y))
+#define U_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * ((y) / 2) / 2) + (x) / 2)
+#define V_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * pix->height / 4) + \
+				 (pix->bytesperline * ((y) / 2) / 2) + (x) / 2)
+#define U2_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * (y) / 2) + (x) / 2)
+#define V2_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * pix->height / 2) + \
+				 (pix->bytesperline * (y) / 2) + (x) / 2)
+#define UV_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * ((y) / 2)) + (x))
+#define UV2_OFFSET(pix, x, y)	((pix->bytesperline * pix->height) +	 \
+				 (pix->bytesperline * y) + (x))
+
+#define NUM_ALPHA_CHANNELS	7
+
+/* See Table 37-12. Alpha channels mapping. */
+static int ipu_channel_albm(int ch_num)
+{
+	switch (ch_num) {
+	case IPUV3_CHANNEL_G_MEM_IC_PRP_VF:	return 0;
+	case IPUV3_CHANNEL_G_MEM_IC_PP:		return 1;
+	case IPUV3_CHANNEL_MEM_FG_SYNC:		return 2;
+	case IPUV3_CHANNEL_MEM_FG_ASYNC:	return 3;
+	case IPUV3_CHANNEL_MEM_BG_SYNC:		return 4;
+	case IPUV3_CHANNEL_MEM_BG_ASYNC:	return 5;
+	case IPUV3_CHANNEL_MEM_VDI_PLANE1_COMB: return 6;
+	default:
+		return -EINVAL;
+	}
+}
+
+static void ipu_cpmem_set_separate_alpha(struct ipuv3_channel *ch)
+{
+	struct ipu_soc *ipu = ch->ipu;
+	int albm;
+	u32 val;
+
+	albm = ipu_channel_albm(ch->num);
+	if (albm < 0)
+		return;
+
+	ipu_ch_param_write_field(ch, IPU_FIELD_ALU, 1);
+	ipu_ch_param_write_field(ch, IPU_FIELD_ALBM, albm);
+	ipu_ch_param_write_field(ch, IPU_FIELD_CRE, 1);
+
+	val = ipu_idmac_read(ipu, IDMAC_SEP_ALPHA);
+	val |= BIT(ch->num);
+	ipu_idmac_write(ipu, val, IDMAC_SEP_ALPHA);
+}
+
+int ipu_cpmem_set_fmt(struct ipuv3_channel *ch, u32 drm_fourcc)
+{
+	switch (drm_fourcc) {
+	case DRM_FORMAT_YUV420:
+	case DRM_FORMAT_YVU420:
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 2);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_YUV422:
+	case DRM_FORMAT_YVU422:
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 1);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_YUV444:
+	case DRM_FORMAT_YVU444:
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 0);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_NV12:
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 4);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_NV16:
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 3);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_UYVY:
+		/* bits/pixel */
+		ipu_ch_param_write_field(ch, IPU_FIELD_BPP, 3);
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 0xA);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_YUYV:
+		/* bits/pixel */
+		ipu_ch_param_write_field(ch, IPU_FIELD_BPP, 3);
+		/* pix format */
+		ipu_ch_param_write_field(ch, IPU_FIELD_PFS, 0x8);
+		/* burst size */
+		ipu_ch_param_write_field(ch, IPU_FIELD_NPB, 31);
+		break;
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+		ipu_cpmem_set_format_rgb(ch, &def_xbgr_32);
+		break;
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+		ipu_cpmem_set_format_rgb(ch, &def_xrgb_32);
+		break;
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+	case DRM_FORMAT_RGBX8888_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_rgbx_32);
+		break;
+	case DRM_FORMAT_BGRA8888:
+	case DRM_FORMAT_BGRX8888:
+	case DRM_FORMAT_BGRX8888_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_bgrx_32);
+		break;
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_BGR888_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_bgr_24);
+		break;
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_RGB888_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_rgb_24);
+		break;
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_RGB565_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_rgb_16);
+		break;
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_BGR565_A8:
+		ipu_cpmem_set_format_rgb(ch, &def_bgr_16);
+		break;
+	case DRM_FORMAT_ARGB1555:
+		ipu_cpmem_set_format_rgb(ch, &def_argb_16);
+		break;
+	case DRM_FORMAT_ABGR1555:
+		ipu_cpmem_set_format_rgb(ch, &def_abgr_16);
+		break;
+	case DRM_FORMAT_RGBA5551:
+		ipu_cpmem_set_format_rgb(ch, &def_rgba_16);
+		break;
+	case DRM_FORMAT_BGRA5551:
+		ipu_cpmem_set_format_rgb(ch, &def_bgra_16);
+		break;
+	case DRM_FORMAT_ARGB4444:
+		ipu_cpmem_set_format_rgb(ch, &def_argb_16_4444);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	switch (drm_fourcc) {
+	case DRM_FORMAT_RGB565_A8:
+	case DRM_FORMAT_BGR565_A8:
+	case DRM_FORMAT_RGB888_A8:
+	case DRM_FORMAT_BGR888_A8:
+	case DRM_FORMAT_RGBX8888_A8:
+	case DRM_FORMAT_BGRX8888_A8:
+		ipu_ch_param_write_field(ch, IPU_FIELD_WID3, 7);
+		ipu_cpmem_set_separate_alpha(ch);
+		break;
+	default:
+		break;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_fmt);
+
+int ipu_cpmem_set_image(struct ipuv3_channel *ch, struct ipu_image *image)
+{
+	struct v4l2_pix_format *pix = &image->pix;
+	int offset, u_offset, v_offset;
+	int ret = 0;
+
+	pr_debug("%s: resolution: %dx%d stride: %d\n",
+		 __func__, pix->width, pix->height,
+		 pix->bytesperline);
+
+	ipu_cpmem_set_resolution(ch, image->rect.width, image->rect.height);
+	ipu_cpmem_set_stride(ch, pix->bytesperline);
+
+	ipu_cpmem_set_fmt(ch, v4l2_pix_fmt_to_drm_fourcc(pix->pixelformat));
+
+	switch (pix->pixelformat) {
+	case V4L2_PIX_FMT_YUV420:
+		offset = Y_OFFSET(pix, image->rect.left, image->rect.top);
+		u_offset = image->u_offset ?
+			image->u_offset : U_OFFSET(pix, image->rect.left,
+						   image->rect.top) - offset;
+		v_offset = image->v_offset ?
+			image->v_offset : V_OFFSET(pix, image->rect.left,
+						   image->rect.top) - offset;
+
+		ipu_cpmem_set_yuv_planar_full(ch, pix->bytesperline / 2,
+					      u_offset, v_offset);
+		break;
+	case V4L2_PIX_FMT_YVU420:
+		offset = Y_OFFSET(pix, image->rect.left, image->rect.top);
+		u_offset = image->u_offset ?
+			image->u_offset : V_OFFSET(pix, image->rect.left,
+						   image->rect.top) - offset;
+		v_offset = image->v_offset ?
+			image->v_offset : U_OFFSET(pix, image->rect.left,
+						   image->rect.top) - offset;
+
+		ipu_cpmem_set_yuv_planar_full(ch, pix->bytesperline / 2,
+					      u_offset, v_offset);
+		break;
+	case V4L2_PIX_FMT_YUV422P:
+		offset = Y_OFFSET(pix, image->rect.left, image->rect.top);
+		u_offset = image->u_offset ?
+			image->u_offset : U2_OFFSET(pix, image->rect.left,
+						    image->rect.top) - offset;
+		v_offset = image->v_offset ?
+			image->v_offset : V2_OFFSET(pix, image->rect.left,
+						    image->rect.top) - offset;
+
+		ipu_cpmem_set_yuv_planar_full(ch, pix->bytesperline / 2,
+					      u_offset, v_offset);
+		break;
+	case V4L2_PIX_FMT_NV12:
+		offset = Y_OFFSET(pix, image->rect.left, image->rect.top);
+		u_offset = image->u_offset ?
+			image->u_offset : UV_OFFSET(pix, image->rect.left,
+						    image->rect.top) - offset;
+		v_offset = image->v_offset ? image->v_offset : 0;
+
+		ipu_cpmem_set_yuv_planar_full(ch, pix->bytesperline,
+					      u_offset, v_offset);
+		break;
+	case V4L2_PIX_FMT_NV16:
+		offset = Y_OFFSET(pix, image->rect.left, image->rect.top);
+		u_offset = image->u_offset ?
+			image->u_offset : UV2_OFFSET(pix, image->rect.left,
+						     image->rect.top) - offset;
+		v_offset = image->v_offset ? image->v_offset : 0;
+
+		ipu_cpmem_set_yuv_planar_full(ch, pix->bytesperline,
+					      u_offset, v_offset);
+		break;
+	case V4L2_PIX_FMT_UYVY:
+	case V4L2_PIX_FMT_YUYV:
+	case V4L2_PIX_FMT_RGB565:
+		offset = image->rect.left * 2 +
+			image->rect.top * pix->bytesperline;
+		break;
+	case V4L2_PIX_FMT_RGB32:
+	case V4L2_PIX_FMT_BGR32:
+	case V4L2_PIX_FMT_ABGR32:
+	case V4L2_PIX_FMT_XBGR32:
+	case V4L2_PIX_FMT_BGRA32:
+	case V4L2_PIX_FMT_BGRX32:
+	case V4L2_PIX_FMT_RGBA32:
+	case V4L2_PIX_FMT_RGBX32:
+	case V4L2_PIX_FMT_ARGB32:
+	case V4L2_PIX_FMT_XRGB32:
+		offset = image->rect.left * 4 +
+			image->rect.top * pix->bytesperline;
+		break;
+	case V4L2_PIX_FMT_RGB24:
+	case V4L2_PIX_FMT_BGR24:
+		offset = image->rect.left * 3 +
+			image->rect.top * pix->bytesperline;
+		break;
+	case V4L2_PIX_FMT_SBGGR8:
+	case V4L2_PIX_FMT_SGBRG8:
+	case V4L2_PIX_FMT_SGRBG8:
+	case V4L2_PIX_FMT_SRGGB8:
+	case V4L2_PIX_FMT_GREY:
+		offset = image->rect.left + image->rect.top * pix->bytesperline;
+		break;
+	case V4L2_PIX_FMT_SBGGR16:
+	case V4L2_PIX_FMT_SGBRG16:
+	case V4L2_PIX_FMT_SGRBG16:
+	case V4L2_PIX_FMT_SRGGB16:
+	case V4L2_PIX_FMT_Y16:
+		offset = image->rect.left * 2 +
+			 image->rect.top * pix->bytesperline;
+		break;
+	default:
+		/* This should not happen */
+		WARN_ON(1);
+		offset = 0;
+		ret = -EINVAL;
+	}
+
+	ipu_cpmem_set_buffer(ch, 0, image->phys0 + offset);
+	ipu_cpmem_set_buffer(ch, 1, image->phys1 + offset);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_set_image);
+
+void ipu_cpmem_dump(struct ipuv3_channel *ch)
+{
+	struct ipu_ch_param __iomem *p = ipu_get_cpmem(ch);
+	struct ipu_soc *ipu = ch->ipu;
+	int chno = ch->num;
+
+	dev_dbg(ipu->dev, "ch %d word 0 - %08X %08X %08X %08X %08X\n", chno,
+		readl(&p->word[0].data[0]),
+		readl(&p->word[0].data[1]),
+		readl(&p->word[0].data[2]),
+		readl(&p->word[0].data[3]),
+		readl(&p->word[0].data[4]));
+	dev_dbg(ipu->dev, "ch %d word 1 - %08X %08X %08X %08X %08X\n", chno,
+		readl(&p->word[1].data[0]),
+		readl(&p->word[1].data[1]),
+		readl(&p->word[1].data[2]),
+		readl(&p->word[1].data[3]),
+		readl(&p->word[1].data[4]));
+	dev_dbg(ipu->dev, "PFS 0x%x, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_PFS));
+	dev_dbg(ipu->dev, "BPP 0x%x, ",
+		ipu_ch_param_read_field(ch, IPU_FIELD_BPP));
+	dev_dbg(ipu->dev, "NPB 0x%x\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_NPB));
+
+	dev_dbg(ipu->dev, "FW %d, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_FW));
+	dev_dbg(ipu->dev, "FH %d, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_FH));
+	dev_dbg(ipu->dev, "EBA0 0x%x\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_EBA0) << 3);
+	dev_dbg(ipu->dev, "EBA1 0x%x\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_EBA1) << 3);
+	dev_dbg(ipu->dev, "Stride %d\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_SL));
+	dev_dbg(ipu->dev, "scan_order %d\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_SO));
+	dev_dbg(ipu->dev, "uv_stride %d\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_SLUV));
+	dev_dbg(ipu->dev, "u_offset 0x%x\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_UBO) << 3);
+	dev_dbg(ipu->dev, "v_offset 0x%x\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_VBO) << 3);
+
+	dev_dbg(ipu->dev, "Width0 %d+1, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_WID0));
+	dev_dbg(ipu->dev, "Width1 %d+1, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_WID1));
+	dev_dbg(ipu->dev, "Width2 %d+1, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_WID2));
+	dev_dbg(ipu->dev, "Width3 %d+1, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_WID3));
+	dev_dbg(ipu->dev, "Offset0 %d, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_OFS0));
+	dev_dbg(ipu->dev, "Offset1 %d, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_OFS1));
+	dev_dbg(ipu->dev, "Offset2 %d, ",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_OFS2));
+	dev_dbg(ipu->dev, "Offset3 %d\n",
+		 ipu_ch_param_read_field(ch, IPU_FIELD_OFS3));
+}
+EXPORT_SYMBOL_GPL(ipu_cpmem_dump);
+
+int ipu_cpmem_init(struct ipu_soc *ipu, struct device *dev, unsigned long base)
+{
+	struct ipu_cpmem *cpmem;
+
+	cpmem = devm_kzalloc(dev, sizeof(*cpmem), GFP_KERNEL);
+	if (!cpmem)
+		return -ENOMEM;
+
+	ipu->cpmem_priv = cpmem;
+
+	spin_lock_init(&cpmem->lock);
+	cpmem->base = devm_ioremap(dev, base, SZ_128K);
+	if (!cpmem->base)
+		return -ENOMEM;
+
+	dev_dbg(dev, "CPMEM base: 0x%08lx remapped to %p\n",
+		base, cpmem->base);
+	cpmem->ipu = ipu;
+
+	return 0;
+}
+
+void ipu_cpmem_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-csi.c b/drivers/gpu/imx/ipu-v3/ipu-csi.c
new file mode 100644
index 000000000..8ae301eef
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-csi.c
@@ -0,0 +1,821 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (C) 2012-2014 Mentor Graphics Inc.
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/export.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/videodev2.h>
+#include <uapi/linux/v4l2-mediabus.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/clkdev.h>
+
+#include "ipu-prv.h"
+
+struct ipu_csi {
+	void __iomem *base;
+	int id;
+	u32 module;
+	struct clk *clk_ipu;	/* IPU bus clock */
+	spinlock_t lock;
+	bool inuse;
+	struct ipu_soc *ipu;
+};
+
+/* CSI Register Offsets */
+#define CSI_SENS_CONF		0x0000
+#define CSI_SENS_FRM_SIZE	0x0004
+#define CSI_ACT_FRM_SIZE	0x0008
+#define CSI_OUT_FRM_CTRL	0x000c
+#define CSI_TST_CTRL		0x0010
+#define CSI_CCIR_CODE_1		0x0014
+#define CSI_CCIR_CODE_2		0x0018
+#define CSI_CCIR_CODE_3		0x001c
+#define CSI_MIPI_DI		0x0020
+#define CSI_SKIP		0x0024
+#define CSI_CPD_CTRL		0x0028
+#define CSI_CPD_RC(n)		(0x002c + ((n)*4))
+#define CSI_CPD_RS(n)		(0x004c + ((n)*4))
+#define CSI_CPD_GRC(n)		(0x005c + ((n)*4))
+#define CSI_CPD_GRS(n)		(0x007c + ((n)*4))
+#define CSI_CPD_GBC(n)		(0x008c + ((n)*4))
+#define CSI_CPD_GBS(n)		(0x00Ac + ((n)*4))
+#define CSI_CPD_BC(n)		(0x00Bc + ((n)*4))
+#define CSI_CPD_BS(n)		(0x00Dc + ((n)*4))
+#define CSI_CPD_OFFSET1		0x00ec
+#define CSI_CPD_OFFSET2		0x00f0
+
+/* CSI Register Fields */
+#define CSI_SENS_CONF_DATA_FMT_SHIFT		8
+#define CSI_SENS_CONF_DATA_FMT_MASK		0x00000700
+#define CSI_SENS_CONF_DATA_FMT_RGB_YUV444	0L
+#define CSI_SENS_CONF_DATA_FMT_YUV422_YUYV	1L
+#define CSI_SENS_CONF_DATA_FMT_YUV422_UYVY	2L
+#define CSI_SENS_CONF_DATA_FMT_BAYER		3L
+#define CSI_SENS_CONF_DATA_FMT_RGB565		4L
+#define CSI_SENS_CONF_DATA_FMT_RGB555		5L
+#define CSI_SENS_CONF_DATA_FMT_RGB444		6L
+#define CSI_SENS_CONF_DATA_FMT_JPEG		7L
+
+#define CSI_SENS_CONF_VSYNC_POL_SHIFT		0
+#define CSI_SENS_CONF_HSYNC_POL_SHIFT		1
+#define CSI_SENS_CONF_DATA_POL_SHIFT		2
+#define CSI_SENS_CONF_PIX_CLK_POL_SHIFT		3
+#define CSI_SENS_CONF_SENS_PRTCL_MASK		0x00000070
+#define CSI_SENS_CONF_SENS_PRTCL_SHIFT		4
+#define CSI_SENS_CONF_PACK_TIGHT_SHIFT		7
+#define CSI_SENS_CONF_DATA_WIDTH_SHIFT		11
+#define CSI_SENS_CONF_EXT_VSYNC_SHIFT		15
+#define CSI_SENS_CONF_DIVRATIO_SHIFT		16
+
+#define CSI_SENS_CONF_DIVRATIO_MASK		0x00ff0000
+#define CSI_SENS_CONF_DATA_DEST_SHIFT		24
+#define CSI_SENS_CONF_DATA_DEST_MASK		0x07000000
+#define CSI_SENS_CONF_JPEG8_EN_SHIFT		27
+#define CSI_SENS_CONF_JPEG_EN_SHIFT		28
+#define CSI_SENS_CONF_FORCE_EOF_SHIFT		29
+#define CSI_SENS_CONF_DATA_EN_POL_SHIFT		31
+
+#define CSI_DATA_DEST_IC			2
+#define CSI_DATA_DEST_IDMAC			4
+
+#define CSI_CCIR_ERR_DET_EN			0x01000000
+#define CSI_HORI_DOWNSIZE_EN			0x80000000
+#define CSI_VERT_DOWNSIZE_EN			0x40000000
+#define CSI_TEST_GEN_MODE_EN			0x01000000
+
+#define CSI_HSC_MASK				0x1fff0000
+#define CSI_HSC_SHIFT				16
+#define CSI_VSC_MASK				0x00000fff
+#define CSI_VSC_SHIFT				0
+
+#define CSI_TEST_GEN_R_MASK			0x000000ff
+#define CSI_TEST_GEN_R_SHIFT			0
+#define CSI_TEST_GEN_G_MASK			0x0000ff00
+#define CSI_TEST_GEN_G_SHIFT			8
+#define CSI_TEST_GEN_B_MASK			0x00ff0000
+#define CSI_TEST_GEN_B_SHIFT			16
+
+#define CSI_MAX_RATIO_SKIP_SMFC_MASK		0x00000007
+#define CSI_MAX_RATIO_SKIP_SMFC_SHIFT		0
+#define CSI_SKIP_SMFC_MASK			0x000000f8
+#define CSI_SKIP_SMFC_SHIFT			3
+#define CSI_ID_2_SKIP_MASK			0x00000300
+#define CSI_ID_2_SKIP_SHIFT			8
+
+#define CSI_COLOR_FIRST_ROW_MASK		0x00000002
+#define CSI_COLOR_FIRST_COMP_MASK		0x00000001
+
+/* MIPI CSI-2 data types */
+#define MIPI_DT_YUV420		0x18 /* YYY.../UYVY.... */
+#define MIPI_DT_YUV420_LEGACY	0x1a /* UYY.../VYY...   */
+#define MIPI_DT_YUV422		0x1e /* UYVY...         */
+#define MIPI_DT_RGB444		0x20
+#define MIPI_DT_RGB555		0x21
+#define MIPI_DT_RGB565		0x22
+#define MIPI_DT_RGB666		0x23
+#define MIPI_DT_RGB888		0x24
+#define MIPI_DT_RAW6		0x28
+#define MIPI_DT_RAW7		0x29
+#define MIPI_DT_RAW8		0x2a
+#define MIPI_DT_RAW10		0x2b
+#define MIPI_DT_RAW12		0x2c
+#define MIPI_DT_RAW14		0x2d
+
+/*
+ * Bitfield of CSI bus signal polarities and modes.
+ */
+struct ipu_csi_bus_config {
+	unsigned data_width:4;
+	unsigned clk_mode:3;
+	unsigned ext_vsync:1;
+	unsigned vsync_pol:1;
+	unsigned hsync_pol:1;
+	unsigned pixclk_pol:1;
+	unsigned data_pol:1;
+	unsigned sens_clksrc:1;
+	unsigned pack_tight:1;
+	unsigned force_eof:1;
+	unsigned data_en_pol:1;
+
+	unsigned data_fmt;
+	unsigned mipi_dt;
+};
+
+/*
+ * Enumeration of CSI data bus widths.
+ */
+enum ipu_csi_data_width {
+	IPU_CSI_DATA_WIDTH_4   = 0,
+	IPU_CSI_DATA_WIDTH_8   = 1,
+	IPU_CSI_DATA_WIDTH_10  = 3,
+	IPU_CSI_DATA_WIDTH_12  = 5,
+	IPU_CSI_DATA_WIDTH_16  = 9,
+};
+
+/*
+ * Enumeration of CSI clock modes.
+ */
+enum ipu_csi_clk_mode {
+	IPU_CSI_CLK_MODE_GATED_CLK,
+	IPU_CSI_CLK_MODE_NONGATED_CLK,
+	IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE,
+	IPU_CSI_CLK_MODE_CCIR656_INTERLACED,
+	IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_DDR,
+	IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_SDR,
+	IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_DDR,
+	IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_SDR,
+};
+
+static inline u32 ipu_csi_read(struct ipu_csi *csi, unsigned offset)
+{
+	return readl(csi->base + offset);
+}
+
+static inline void ipu_csi_write(struct ipu_csi *csi, u32 value,
+				 unsigned offset)
+{
+	writel(value, csi->base + offset);
+}
+
+/*
+ * Set mclk division ratio for generating test mode mclk. Only used
+ * for test generator.
+ */
+static int ipu_csi_set_testgen_mclk(struct ipu_csi *csi, u32 pixel_clk,
+					u32 ipu_clk)
+{
+	u32 temp;
+	int div_ratio;
+
+	div_ratio = (ipu_clk / pixel_clk) - 1;
+
+	if (div_ratio > 0xFF || div_ratio < 0) {
+		dev_err(csi->ipu->dev,
+			"value of pixel_clk extends normal range\n");
+		return -EINVAL;
+	}
+
+	temp = ipu_csi_read(csi, CSI_SENS_CONF);
+	temp &= ~CSI_SENS_CONF_DIVRATIO_MASK;
+	ipu_csi_write(csi, temp | (div_ratio << CSI_SENS_CONF_DIVRATIO_SHIFT),
+			  CSI_SENS_CONF);
+
+	return 0;
+}
+
+/*
+ * Find the CSI data format and data width for the given V4L2 media
+ * bus pixel format code.
+ */
+static int mbus_code_to_bus_cfg(struct ipu_csi_bus_config *cfg, u32 mbus_code,
+				enum v4l2_mbus_type mbus_type)
+{
+	switch (mbus_code) {
+	case MEDIA_BUS_FMT_BGR565_2X8_BE:
+	case MEDIA_BUS_FMT_BGR565_2X8_LE:
+	case MEDIA_BUS_FMT_RGB565_2X8_BE:
+	case MEDIA_BUS_FMT_RGB565_2X8_LE:
+		if (mbus_type == V4L2_MBUS_CSI2_DPHY)
+			cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_RGB565;
+		else
+			cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_RGB565;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_RGB444_2X8_PADHI_BE:
+	case MEDIA_BUS_FMT_RGB444_2X8_PADHI_LE:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_RGB444;
+		cfg->mipi_dt = MIPI_DT_RGB444;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_RGB555_2X8_PADHI_BE:
+	case MEDIA_BUS_FMT_RGB555_2X8_PADHI_LE:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_RGB555;
+		cfg->mipi_dt = MIPI_DT_RGB555;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+	case MEDIA_BUS_FMT_BGR888_1X24:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_RGB_YUV444;
+		cfg->mipi_dt = MIPI_DT_RGB888;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_UYVY8_2X8:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_YUV422_UYVY;
+		cfg->mipi_dt = MIPI_DT_YUV422;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_YUYV8_2X8:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_YUV422_YUYV;
+		cfg->mipi_dt = MIPI_DT_YUV422;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+	case MEDIA_BUS_FMT_YUYV8_1X16:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_YUV422;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_16;
+		break;
+	case MEDIA_BUS_FMT_SBGGR8_1X8:
+	case MEDIA_BUS_FMT_SGBRG8_1X8:
+	case MEDIA_BUS_FMT_SGRBG8_1X8:
+	case MEDIA_BUS_FMT_SRGGB8_1X8:
+	case MEDIA_BUS_FMT_Y8_1X8:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_RAW8;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_SBGGR10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SGBRG10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SGRBG10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SRGGB10_DPCM8_1X8:
+	case MEDIA_BUS_FMT_SBGGR10_2X8_PADHI_BE:
+	case MEDIA_BUS_FMT_SBGGR10_2X8_PADHI_LE:
+	case MEDIA_BUS_FMT_SBGGR10_2X8_PADLO_BE:
+	case MEDIA_BUS_FMT_SBGGR10_2X8_PADLO_LE:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_RAW10;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	case MEDIA_BUS_FMT_SBGGR10_1X10:
+	case MEDIA_BUS_FMT_SGBRG10_1X10:
+	case MEDIA_BUS_FMT_SGRBG10_1X10:
+	case MEDIA_BUS_FMT_SRGGB10_1X10:
+	case MEDIA_BUS_FMT_Y10_1X10:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_RAW10;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_10;
+		break;
+	case MEDIA_BUS_FMT_SBGGR12_1X12:
+	case MEDIA_BUS_FMT_SGBRG12_1X12:
+	case MEDIA_BUS_FMT_SGRBG12_1X12:
+	case MEDIA_BUS_FMT_SRGGB12_1X12:
+	case MEDIA_BUS_FMT_Y12_1X12:
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_BAYER;
+		cfg->mipi_dt = MIPI_DT_RAW12;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_12;
+		break;
+	case MEDIA_BUS_FMT_JPEG_1X8:
+		/* TODO */
+		cfg->data_fmt = CSI_SENS_CONF_DATA_FMT_JPEG;
+		cfg->mipi_dt = MIPI_DT_RAW8;
+		cfg->data_width = IPU_CSI_DATA_WIDTH_8;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/* translate alternate field mode based on given standard */
+static inline enum v4l2_field
+ipu_csi_translate_field(enum v4l2_field field, v4l2_std_id std)
+{
+	return (field != V4L2_FIELD_ALTERNATE) ? field :
+		((std & V4L2_STD_525_60) ?
+		 V4L2_FIELD_SEQ_BT : V4L2_FIELD_SEQ_TB);
+}
+
+/*
+ * Fill a CSI bus config struct from mbus_config and mbus_framefmt.
+ */
+static int fill_csi_bus_cfg(struct ipu_csi_bus_config *csicfg,
+			    const struct v4l2_mbus_config *mbus_cfg,
+			    const struct v4l2_mbus_framefmt *mbus_fmt)
+{
+	int ret;
+
+	memset(csicfg, 0, sizeof(*csicfg));
+
+	ret = mbus_code_to_bus_cfg(csicfg, mbus_fmt->code, mbus_cfg->type);
+	if (ret < 0)
+		return ret;
+
+	switch (mbus_cfg->type) {
+	case V4L2_MBUS_PARALLEL:
+		csicfg->ext_vsync = 1;
+		csicfg->vsync_pol = (mbus_cfg->flags &
+				     V4L2_MBUS_VSYNC_ACTIVE_LOW) ? 1 : 0;
+		csicfg->hsync_pol = (mbus_cfg->flags &
+				     V4L2_MBUS_HSYNC_ACTIVE_LOW) ? 1 : 0;
+		csicfg->pixclk_pol = (mbus_cfg->flags &
+				      V4L2_MBUS_PCLK_SAMPLE_FALLING) ? 1 : 0;
+		csicfg->clk_mode = IPU_CSI_CLK_MODE_GATED_CLK;
+		break;
+	case V4L2_MBUS_BT656:
+		csicfg->ext_vsync = 0;
+		if (V4L2_FIELD_HAS_BOTH(mbus_fmt->field) ||
+		    mbus_fmt->field == V4L2_FIELD_ALTERNATE)
+			csicfg->clk_mode = IPU_CSI_CLK_MODE_CCIR656_INTERLACED;
+		else
+			csicfg->clk_mode = IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE;
+		break;
+	case V4L2_MBUS_CSI2_DPHY:
+		/*
+		 * MIPI CSI-2 requires non gated clock mode, all other
+		 * parameters are not applicable for MIPI CSI-2 bus.
+		 */
+		csicfg->clk_mode = IPU_CSI_CLK_MODE_NONGATED_CLK;
+		break;
+	default:
+		/* will never get here, keep compiler quiet */
+		break;
+	}
+
+	return 0;
+}
+
+static int
+ipu_csi_set_bt_interlaced_codes(struct ipu_csi *csi,
+				const struct v4l2_mbus_framefmt *infmt,
+				const struct v4l2_mbus_framefmt *outfmt,
+				v4l2_std_id std)
+{
+	enum v4l2_field infield, outfield;
+	bool swap_fields;
+
+	/* get translated field type of input and output */
+	infield = ipu_csi_translate_field(infmt->field, std);
+	outfield = ipu_csi_translate_field(outfmt->field, std);
+
+	/*
+	 * Write the H-V-F codes the CSI will match against the
+	 * incoming data for start/end of active and blanking
+	 * field intervals. If input and output field types are
+	 * sequential but not the same (one is SEQ_BT and the other
+	 * is SEQ_TB), swap the F-bit so that the CSI will capture
+	 * field 1 lines before field 0 lines.
+	 */
+	swap_fields = (V4L2_FIELD_IS_SEQUENTIAL(infield) &&
+		       V4L2_FIELD_IS_SEQUENTIAL(outfield) &&
+		       infield != outfield);
+
+	if (!swap_fields) {
+		/*
+		 * Field0BlankEnd  = 110, Field0BlankStart  = 010
+		 * Field0ActiveEnd = 100, Field0ActiveStart = 000
+		 * Field1BlankEnd  = 111, Field1BlankStart  = 011
+		 * Field1ActiveEnd = 101, Field1ActiveStart = 001
+		 */
+		ipu_csi_write(csi, 0x40596 | CSI_CCIR_ERR_DET_EN,
+			      CSI_CCIR_CODE_1);
+		ipu_csi_write(csi, 0xD07DF, CSI_CCIR_CODE_2);
+	} else {
+		dev_dbg(csi->ipu->dev, "capture field swap\n");
+
+		/* same as above but with F-bit inverted */
+		ipu_csi_write(csi, 0xD07DF | CSI_CCIR_ERR_DET_EN,
+			      CSI_CCIR_CODE_1);
+		ipu_csi_write(csi, 0x40596, CSI_CCIR_CODE_2);
+	}
+
+	ipu_csi_write(csi, 0xFF0000, CSI_CCIR_CODE_3);
+
+	return 0;
+}
+
+
+int ipu_csi_init_interface(struct ipu_csi *csi,
+			   const struct v4l2_mbus_config *mbus_cfg,
+			   const struct v4l2_mbus_framefmt *infmt,
+			   const struct v4l2_mbus_framefmt *outfmt)
+{
+	struct ipu_csi_bus_config cfg;
+	unsigned long flags;
+	u32 width, height, data = 0;
+	v4l2_std_id std;
+	int ret;
+
+	ret = fill_csi_bus_cfg(&cfg, mbus_cfg, infmt);
+	if (ret < 0)
+		return ret;
+
+	/* set default sensor frame width and height */
+	width = infmt->width;
+	height = infmt->height;
+	if (infmt->field == V4L2_FIELD_ALTERNATE)
+		height *= 2;
+
+	/* Set the CSI_SENS_CONF register remaining fields */
+	data |= cfg.data_width << CSI_SENS_CONF_DATA_WIDTH_SHIFT |
+		cfg.data_fmt << CSI_SENS_CONF_DATA_FMT_SHIFT |
+		cfg.data_pol << CSI_SENS_CONF_DATA_POL_SHIFT |
+		cfg.vsync_pol << CSI_SENS_CONF_VSYNC_POL_SHIFT |
+		cfg.hsync_pol << CSI_SENS_CONF_HSYNC_POL_SHIFT |
+		cfg.pixclk_pol << CSI_SENS_CONF_PIX_CLK_POL_SHIFT |
+		cfg.ext_vsync << CSI_SENS_CONF_EXT_VSYNC_SHIFT |
+		cfg.clk_mode << CSI_SENS_CONF_SENS_PRTCL_SHIFT |
+		cfg.pack_tight << CSI_SENS_CONF_PACK_TIGHT_SHIFT |
+		cfg.force_eof << CSI_SENS_CONF_FORCE_EOF_SHIFT |
+		cfg.data_en_pol << CSI_SENS_CONF_DATA_EN_POL_SHIFT;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	ipu_csi_write(csi, data, CSI_SENS_CONF);
+
+	/* Set CCIR registers */
+
+	switch (cfg.clk_mode) {
+	case IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE:
+		ipu_csi_write(csi, 0x40030, CSI_CCIR_CODE_1);
+		ipu_csi_write(csi, 0xFF0000, CSI_CCIR_CODE_3);
+		break;
+	case IPU_CSI_CLK_MODE_CCIR656_INTERLACED:
+		if (width == 720 && height == 480) {
+			std = V4L2_STD_NTSC;
+			height = 525;
+		} else if (width == 720 && height == 576) {
+			std = V4L2_STD_PAL;
+			height = 625;
+		} else {
+			dev_err(csi->ipu->dev,
+				"Unsupported interlaced video mode\n");
+			ret = -EINVAL;
+			goto out_unlock;
+		}
+
+		ret = ipu_csi_set_bt_interlaced_codes(csi, infmt, outfmt, std);
+		if (ret)
+			goto out_unlock;
+		break;
+	case IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_DDR:
+	case IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_SDR:
+	case IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_DDR:
+	case IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_SDR:
+		ipu_csi_write(csi, 0x40030 | CSI_CCIR_ERR_DET_EN,
+				   CSI_CCIR_CODE_1);
+		ipu_csi_write(csi, 0xFF0000, CSI_CCIR_CODE_3);
+		break;
+	case IPU_CSI_CLK_MODE_GATED_CLK:
+	case IPU_CSI_CLK_MODE_NONGATED_CLK:
+		ipu_csi_write(csi, 0, CSI_CCIR_CODE_1);
+		break;
+	}
+
+	/* Setup sensor frame size */
+	ipu_csi_write(csi, (width - 1) | ((height - 1) << 16),
+		      CSI_SENS_FRM_SIZE);
+
+	dev_dbg(csi->ipu->dev, "CSI_SENS_CONF = 0x%08X\n",
+		ipu_csi_read(csi, CSI_SENS_CONF));
+	dev_dbg(csi->ipu->dev, "CSI_ACT_FRM_SIZE = 0x%08X\n",
+		ipu_csi_read(csi, CSI_ACT_FRM_SIZE));
+
+out_unlock:
+	spin_unlock_irqrestore(&csi->lock, flags);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_init_interface);
+
+bool ipu_csi_is_interlaced(struct ipu_csi *csi)
+{
+	unsigned long flags;
+	u32 sensor_protocol;
+
+	spin_lock_irqsave(&csi->lock, flags);
+	sensor_protocol =
+		(ipu_csi_read(csi, CSI_SENS_CONF) &
+		 CSI_SENS_CONF_SENS_PRTCL_MASK) >>
+		CSI_SENS_CONF_SENS_PRTCL_SHIFT;
+	spin_unlock_irqrestore(&csi->lock, flags);
+
+	switch (sensor_protocol) {
+	case IPU_CSI_CLK_MODE_GATED_CLK:
+	case IPU_CSI_CLK_MODE_NONGATED_CLK:
+	case IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE:
+	case IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_DDR:
+	case IPU_CSI_CLK_MODE_CCIR1120_PROGRESSIVE_SDR:
+		return false;
+	case IPU_CSI_CLK_MODE_CCIR656_INTERLACED:
+	case IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_DDR:
+	case IPU_CSI_CLK_MODE_CCIR1120_INTERLACED_SDR:
+		return true;
+	default:
+		dev_err(csi->ipu->dev,
+			"CSI %d sensor protocol unsupported\n", csi->id);
+		return false;
+	}
+}
+EXPORT_SYMBOL_GPL(ipu_csi_is_interlaced);
+
+void ipu_csi_get_window(struct ipu_csi *csi, struct v4l2_rect *w)
+{
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	reg = ipu_csi_read(csi, CSI_ACT_FRM_SIZE);
+	w->width = (reg & 0xFFFF) + 1;
+	w->height = (reg >> 16 & 0xFFFF) + 1;
+
+	reg = ipu_csi_read(csi, CSI_OUT_FRM_CTRL);
+	w->left = (reg & CSI_HSC_MASK) >> CSI_HSC_SHIFT;
+	w->top = (reg & CSI_VSC_MASK) >> CSI_VSC_SHIFT;
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_csi_get_window);
+
+void ipu_csi_set_window(struct ipu_csi *csi, struct v4l2_rect *w)
+{
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	ipu_csi_write(csi, (w->width - 1) | ((w->height - 1) << 16),
+			  CSI_ACT_FRM_SIZE);
+
+	reg = ipu_csi_read(csi, CSI_OUT_FRM_CTRL);
+	reg &= ~(CSI_HSC_MASK | CSI_VSC_MASK);
+	reg |= ((w->top << CSI_VSC_SHIFT) | (w->left << CSI_HSC_SHIFT));
+	ipu_csi_write(csi, reg, CSI_OUT_FRM_CTRL);
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_window);
+
+void ipu_csi_set_downsize(struct ipu_csi *csi, bool horiz, bool vert)
+{
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	reg = ipu_csi_read(csi, CSI_OUT_FRM_CTRL);
+	reg &= ~(CSI_HORI_DOWNSIZE_EN | CSI_VERT_DOWNSIZE_EN);
+	reg |= (horiz ? CSI_HORI_DOWNSIZE_EN : 0) |
+	       (vert ? CSI_VERT_DOWNSIZE_EN : 0);
+	ipu_csi_write(csi, reg, CSI_OUT_FRM_CTRL);
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_downsize);
+
+void ipu_csi_set_test_generator(struct ipu_csi *csi, bool active,
+				u32 r_value, u32 g_value, u32 b_value,
+				u32 pix_clk)
+{
+	unsigned long flags;
+	u32 ipu_clk = clk_get_rate(csi->clk_ipu);
+	u32 temp;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	temp = ipu_csi_read(csi, CSI_TST_CTRL);
+
+	if (!active) {
+		temp &= ~CSI_TEST_GEN_MODE_EN;
+		ipu_csi_write(csi, temp, CSI_TST_CTRL);
+	} else {
+		/* Set sensb_mclk div_ratio */
+		ipu_csi_set_testgen_mclk(csi, pix_clk, ipu_clk);
+
+		temp &= ~(CSI_TEST_GEN_R_MASK | CSI_TEST_GEN_G_MASK |
+			  CSI_TEST_GEN_B_MASK);
+		temp |= CSI_TEST_GEN_MODE_EN;
+		temp |= (r_value << CSI_TEST_GEN_R_SHIFT) |
+			(g_value << CSI_TEST_GEN_G_SHIFT) |
+			(b_value << CSI_TEST_GEN_B_SHIFT);
+		ipu_csi_write(csi, temp, CSI_TST_CTRL);
+	}
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_test_generator);
+
+int ipu_csi_set_mipi_datatype(struct ipu_csi *csi, u32 vc,
+			      struct v4l2_mbus_framefmt *mbus_fmt)
+{
+	struct ipu_csi_bus_config cfg;
+	unsigned long flags;
+	u32 temp;
+	int ret;
+
+	if (vc > 3)
+		return -EINVAL;
+
+	ret = mbus_code_to_bus_cfg(&cfg, mbus_fmt->code, V4L2_MBUS_CSI2_DPHY);
+	if (ret < 0)
+		return ret;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	temp = ipu_csi_read(csi, CSI_MIPI_DI);
+	temp &= ~(0xff << (vc * 8));
+	temp |= (cfg.mipi_dt << (vc * 8));
+	ipu_csi_write(csi, temp, CSI_MIPI_DI);
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_mipi_datatype);
+
+int ipu_csi_set_skip_smfc(struct ipu_csi *csi, u32 skip,
+			  u32 max_ratio, u32 id)
+{
+	unsigned long flags;
+	u32 temp;
+
+	if (max_ratio > 5 || id > 3)
+		return -EINVAL;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	temp = ipu_csi_read(csi, CSI_SKIP);
+	temp &= ~(CSI_MAX_RATIO_SKIP_SMFC_MASK | CSI_ID_2_SKIP_MASK |
+		  CSI_SKIP_SMFC_MASK);
+	temp |= (max_ratio << CSI_MAX_RATIO_SKIP_SMFC_SHIFT) |
+		(id << CSI_ID_2_SKIP_SHIFT) |
+		(skip << CSI_SKIP_SMFC_SHIFT);
+	ipu_csi_write(csi, temp, CSI_SKIP);
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_skip_smfc);
+
+int ipu_csi_set_dest(struct ipu_csi *csi, enum ipu_csi_dest csi_dest)
+{
+	unsigned long flags;
+	u32 csi_sens_conf, dest;
+
+	if (csi_dest == IPU_CSI_DEST_IDMAC)
+		dest = CSI_DATA_DEST_IDMAC;
+	else
+		dest = CSI_DATA_DEST_IC; /* IC or VDIC */
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	csi_sens_conf = ipu_csi_read(csi, CSI_SENS_CONF);
+	csi_sens_conf &= ~CSI_SENS_CONF_DATA_DEST_MASK;
+	csi_sens_conf |= (dest << CSI_SENS_CONF_DATA_DEST_SHIFT);
+	ipu_csi_write(csi, csi_sens_conf, CSI_SENS_CONF);
+
+	spin_unlock_irqrestore(&csi->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_set_dest);
+
+int ipu_csi_enable(struct ipu_csi *csi)
+{
+	ipu_module_enable(csi->ipu, csi->module);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_enable);
+
+int ipu_csi_disable(struct ipu_csi *csi)
+{
+	ipu_module_disable(csi->ipu, csi->module);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_disable);
+
+struct ipu_csi *ipu_csi_get(struct ipu_soc *ipu, int id)
+{
+	unsigned long flags;
+	struct ipu_csi *csi, *ret;
+
+	if (id > 1)
+		return ERR_PTR(-EINVAL);
+
+	csi = ipu->csi_priv[id];
+	ret = csi;
+
+	spin_lock_irqsave(&csi->lock, flags);
+
+	if (csi->inuse) {
+		ret = ERR_PTR(-EBUSY);
+		goto unlock;
+	}
+
+	csi->inuse = true;
+unlock:
+	spin_unlock_irqrestore(&csi->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_csi_get);
+
+void ipu_csi_put(struct ipu_csi *csi)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&csi->lock, flags);
+	csi->inuse = false;
+	spin_unlock_irqrestore(&csi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_csi_put);
+
+int ipu_csi_init(struct ipu_soc *ipu, struct device *dev, int id,
+		 unsigned long base, u32 module, struct clk *clk_ipu)
+{
+	struct ipu_csi *csi;
+
+	if (id > 1)
+		return -ENODEV;
+
+	csi = devm_kzalloc(dev, sizeof(*csi), GFP_KERNEL);
+	if (!csi)
+		return -ENOMEM;
+
+	ipu->csi_priv[id] = csi;
+
+	spin_lock_init(&csi->lock);
+	csi->module = module;
+	csi->id = id;
+	csi->clk_ipu = clk_ipu;
+	csi->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!csi->base)
+		return -ENOMEM;
+
+	dev_dbg(dev, "CSI%d base: 0x%08lx remapped to %p\n",
+		id, base, csi->base);
+	csi->ipu = ipu;
+
+	return 0;
+}
+
+void ipu_csi_exit(struct ipu_soc *ipu, int id)
+{
+}
+
+void ipu_csi_dump(struct ipu_csi *csi)
+{
+	dev_dbg(csi->ipu->dev, "CSI_SENS_CONF:     %08x\n",
+		ipu_csi_read(csi, CSI_SENS_CONF));
+	dev_dbg(csi->ipu->dev, "CSI_SENS_FRM_SIZE: %08x\n",
+		ipu_csi_read(csi, CSI_SENS_FRM_SIZE));
+	dev_dbg(csi->ipu->dev, "CSI_ACT_FRM_SIZE:  %08x\n",
+		ipu_csi_read(csi, CSI_ACT_FRM_SIZE));
+	dev_dbg(csi->ipu->dev, "CSI_OUT_FRM_CTRL:  %08x\n",
+		ipu_csi_read(csi, CSI_OUT_FRM_CTRL));
+	dev_dbg(csi->ipu->dev, "CSI_TST_CTRL:      %08x\n",
+		ipu_csi_read(csi, CSI_TST_CTRL));
+	dev_dbg(csi->ipu->dev, "CSI_CCIR_CODE_1:   %08x\n",
+		ipu_csi_read(csi, CSI_CCIR_CODE_1));
+	dev_dbg(csi->ipu->dev, "CSI_CCIR_CODE_2:   %08x\n",
+		ipu_csi_read(csi, CSI_CCIR_CODE_2));
+	dev_dbg(csi->ipu->dev, "CSI_CCIR_CODE_3:   %08x\n",
+		ipu_csi_read(csi, CSI_CCIR_CODE_3));
+	dev_dbg(csi->ipu->dev, "CSI_MIPI_DI:       %08x\n",
+		ipu_csi_read(csi, CSI_MIPI_DI));
+	dev_dbg(csi->ipu->dev, "CSI_SKIP:          %08x\n",
+		ipu_csi_read(csi, CSI_SKIP));
+}
+EXPORT_SYMBOL_GPL(ipu_csi_dump);
diff --git a/drivers/gpu/imx/ipu-v3/ipu-dc.c b/drivers/gpu/imx/ipu-v3/ipu-dc.c
new file mode 100644
index 000000000..ca96b2354
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-dc.c
@@ -0,0 +1,425 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+
+#include <linux/export.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+
+#include <video/imx-ipu-v3.h>
+#include "ipu-prv.h"
+
+#define DC_MAP_CONF_PTR(n)	(0x108 + ((n) & ~0x1) * 2)
+#define DC_MAP_CONF_VAL(n)	(0x144 + ((n) & ~0x1) * 2)
+
+#define DC_EVT_NF		0
+#define DC_EVT_NL		1
+#define DC_EVT_EOF		2
+#define DC_EVT_NFIELD		3
+#define DC_EVT_EOL		4
+#define DC_EVT_EOFIELD		5
+#define DC_EVT_NEW_ADDR		6
+#define DC_EVT_NEW_CHAN		7
+#define DC_EVT_NEW_DATA		8
+
+#define DC_EVT_NEW_ADDR_W_0	0
+#define DC_EVT_NEW_ADDR_W_1	1
+#define DC_EVT_NEW_CHAN_W_0	2
+#define DC_EVT_NEW_CHAN_W_1	3
+#define DC_EVT_NEW_DATA_W_0	4
+#define DC_EVT_NEW_DATA_W_1	5
+#define DC_EVT_NEW_ADDR_R_0	6
+#define DC_EVT_NEW_ADDR_R_1	7
+#define DC_EVT_NEW_CHAN_R_0	8
+#define DC_EVT_NEW_CHAN_R_1	9
+#define DC_EVT_NEW_DATA_R_0	10
+#define DC_EVT_NEW_DATA_R_1	11
+
+#define DC_WR_CH_CONF		0x0
+#define DC_WR_CH_ADDR		0x4
+#define DC_RL_CH(evt)		(8 + ((evt) & ~0x1) * 2)
+
+#define DC_GEN			0xd4
+#define DC_DISP_CONF1(disp)	(0xd8 + (disp) * 4)
+#define DC_DISP_CONF2(disp)	(0xe8 + (disp) * 4)
+#define DC_STAT			0x1c8
+
+#define WROD(lf)		(0x18 | ((lf) << 1))
+#define WRG			0x01
+#define WCLK			0xc9
+
+#define SYNC_WAVE 0
+#define NULL_WAVE (-1)
+
+#define DC_GEN_SYNC_1_6_SYNC	(2 << 1)
+#define DC_GEN_SYNC_PRIORITY_1	(1 << 7)
+
+#define DC_WR_CH_CONF_WORD_SIZE_8		(0 << 0)
+#define DC_WR_CH_CONF_WORD_SIZE_16		(1 << 0)
+#define DC_WR_CH_CONF_WORD_SIZE_24		(2 << 0)
+#define DC_WR_CH_CONF_WORD_SIZE_32		(3 << 0)
+#define DC_WR_CH_CONF_DISP_ID_PARALLEL(i)	(((i) & 0x1) << 3)
+#define DC_WR_CH_CONF_DISP_ID_SERIAL		(2 << 3)
+#define DC_WR_CH_CONF_DISP_ID_ASYNC		(3 << 4)
+#define DC_WR_CH_CONF_FIELD_MODE		(1 << 9)
+#define DC_WR_CH_CONF_PROG_TYPE_NORMAL		(4 << 5)
+#define DC_WR_CH_CONF_PROG_TYPE_MASK		(7 << 5)
+#define DC_WR_CH_CONF_PROG_DI_ID		(1 << 2)
+#define DC_WR_CH_CONF_PROG_DISP_ID(i)		(((i) & 0x1) << 3)
+
+#define IPU_DC_NUM_CHANNELS	10
+
+struct ipu_dc_priv;
+
+enum ipu_dc_map {
+	IPU_DC_MAP_RGB24,
+	IPU_DC_MAP_RGB565,
+	IPU_DC_MAP_GBR24, /* TVEv2 */
+	IPU_DC_MAP_BGR666,
+	IPU_DC_MAP_LVDS666,
+	IPU_DC_MAP_BGR24,
+};
+
+struct ipu_dc {
+	/* The display interface number assigned to this dc channel */
+	unsigned int		di;
+	void __iomem		*base;
+	struct ipu_dc_priv	*priv;
+	int			chno;
+	bool			in_use;
+};
+
+struct ipu_dc_priv {
+	void __iomem		*dc_reg;
+	void __iomem		*dc_tmpl_reg;
+	struct ipu_soc		*ipu;
+	struct device		*dev;
+	struct ipu_dc		channels[IPU_DC_NUM_CHANNELS];
+	struct mutex		mutex;
+	struct completion	comp;
+	int			use_count;
+};
+
+static void dc_link_event(struct ipu_dc *dc, int event, int addr, int priority)
+{
+	u32 reg;
+
+	reg = readl(dc->base + DC_RL_CH(event));
+	reg &= ~(0xffff << (16 * (event & 0x1)));
+	reg |= ((addr << 8) | priority) << (16 * (event & 0x1));
+	writel(reg, dc->base + DC_RL_CH(event));
+}
+
+static void dc_write_tmpl(struct ipu_dc *dc, int word, u32 opcode, u32 operand,
+		int map, int wave, int glue, int sync, int stop)
+{
+	struct ipu_dc_priv *priv = dc->priv;
+	u32 reg1, reg2;
+
+	if (opcode == WCLK) {
+		reg1 = (operand << 20) & 0xfff00000;
+		reg2 = operand >> 12 | opcode << 1 | stop << 9;
+	} else if (opcode == WRG) {
+		reg1 = sync | glue << 4 | ++wave << 11 | ((operand << 15) & 0xffff8000);
+		reg2 = operand >> 17 | opcode << 7 | stop << 9;
+	} else {
+		reg1 = sync | glue << 4 | ++wave << 11 | ++map << 15 | ((operand << 20) & 0xfff00000);
+		reg2 = operand >> 12 | opcode << 4 | stop << 9;
+	}
+	writel(reg1, priv->dc_tmpl_reg + word * 8);
+	writel(reg2, priv->dc_tmpl_reg + word * 8 + 4);
+}
+
+static int ipu_bus_format_to_map(u32 fmt)
+{
+	switch (fmt) {
+	default:
+		WARN_ON(1);
+		fallthrough;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		return IPU_DC_MAP_RGB24;
+	case MEDIA_BUS_FMT_RGB565_1X16:
+		return IPU_DC_MAP_RGB565;
+	case MEDIA_BUS_FMT_GBR888_1X24:
+		return IPU_DC_MAP_GBR24;
+	case MEDIA_BUS_FMT_RGB666_1X18:
+		return IPU_DC_MAP_BGR666;
+	case MEDIA_BUS_FMT_RGB666_1X24_CPADHI:
+		return IPU_DC_MAP_LVDS666;
+	case MEDIA_BUS_FMT_BGR888_1X24:
+		return IPU_DC_MAP_BGR24;
+	}
+}
+
+int ipu_dc_init_sync(struct ipu_dc *dc, struct ipu_di *di, bool interlaced,
+		u32 bus_format, u32 width)
+{
+	struct ipu_dc_priv *priv = dc->priv;
+	int addr, sync;
+	u32 reg = 0;
+	int map;
+
+	dc->di = ipu_di_get_num(di);
+
+	if (!IS_ALIGNED(width, 8)) {
+		dev_warn(priv->dev,
+			 "%s: hactive does not align to 8 byte\n", __func__);
+	}
+
+	map = ipu_bus_format_to_map(bus_format);
+
+	/*
+	 * In interlaced mode we need more counters to create the asymmetric
+	 * per-field VSYNC signals. The pixel active signal synchronising DC
+	 * to DI moves to signal generator #6 (see ipu-di.c). In progressive
+	 * mode counter #5 is used.
+	 */
+	sync = interlaced ? 6 : 5;
+
+	/* Reserve 5 microcode template words for each DI */
+	if (dc->di)
+		addr = 5;
+	else
+		addr = 0;
+
+	if (interlaced) {
+		dc_link_event(dc, DC_EVT_NL, addr, 3);
+		dc_link_event(dc, DC_EVT_EOL, addr, 2);
+		dc_link_event(dc, DC_EVT_NEW_DATA, addr, 1);
+
+		/* Init template microcode */
+		dc_write_tmpl(dc, addr, WROD(0), 0, map, SYNC_WAVE, 0, sync, 1);
+	} else {
+		dc_link_event(dc, DC_EVT_NL, addr + 2, 3);
+		dc_link_event(dc, DC_EVT_EOL, addr + 3, 2);
+		dc_link_event(dc, DC_EVT_NEW_DATA, addr + 1, 1);
+
+		/* Init template microcode */
+		dc_write_tmpl(dc, addr + 2, WROD(0), 0, map, SYNC_WAVE, 8, sync, 1);
+		dc_write_tmpl(dc, addr + 3, WROD(0), 0, map, SYNC_WAVE, 4, sync, 0);
+		dc_write_tmpl(dc, addr + 4, WRG, 0, map, NULL_WAVE, 0, 0, 1);
+		dc_write_tmpl(dc, addr + 1, WROD(0), 0, map, SYNC_WAVE, 0, sync, 1);
+	}
+
+	dc_link_event(dc, DC_EVT_NF, 0, 0);
+	dc_link_event(dc, DC_EVT_NFIELD, 0, 0);
+	dc_link_event(dc, DC_EVT_EOF, 0, 0);
+	dc_link_event(dc, DC_EVT_EOFIELD, 0, 0);
+	dc_link_event(dc, DC_EVT_NEW_CHAN, 0, 0);
+	dc_link_event(dc, DC_EVT_NEW_ADDR, 0, 0);
+
+	reg = readl(dc->base + DC_WR_CH_CONF);
+	if (interlaced)
+		reg |= DC_WR_CH_CONF_FIELD_MODE;
+	else
+		reg &= ~DC_WR_CH_CONF_FIELD_MODE;
+	writel(reg, dc->base + DC_WR_CH_CONF);
+
+	writel(0x0, dc->base + DC_WR_CH_ADDR);
+	writel(width, priv->dc_reg + DC_DISP_CONF2(dc->di));
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dc_init_sync);
+
+void ipu_dc_enable(struct ipu_soc *ipu)
+{
+	struct ipu_dc_priv *priv = ipu->dc_priv;
+
+	mutex_lock(&priv->mutex);
+
+	if (!priv->use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_DC_EN);
+
+	priv->use_count++;
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dc_enable);
+
+void ipu_dc_enable_channel(struct ipu_dc *dc)
+{
+	u32 reg;
+
+	reg = readl(dc->base + DC_WR_CH_CONF);
+	reg |= DC_WR_CH_CONF_PROG_TYPE_NORMAL;
+	writel(reg, dc->base + DC_WR_CH_CONF);
+}
+EXPORT_SYMBOL_GPL(ipu_dc_enable_channel);
+
+void ipu_dc_disable_channel(struct ipu_dc *dc)
+{
+	u32 val;
+
+	val = readl(dc->base + DC_WR_CH_CONF);
+	val &= ~DC_WR_CH_CONF_PROG_TYPE_MASK;
+	writel(val, dc->base + DC_WR_CH_CONF);
+}
+EXPORT_SYMBOL_GPL(ipu_dc_disable_channel);
+
+void ipu_dc_disable(struct ipu_soc *ipu)
+{
+	struct ipu_dc_priv *priv = ipu->dc_priv;
+
+	mutex_lock(&priv->mutex);
+
+	priv->use_count--;
+	if (!priv->use_count)
+		ipu_module_disable(priv->ipu, IPU_CONF_DC_EN);
+
+	if (priv->use_count < 0)
+		priv->use_count = 0;
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dc_disable);
+
+static void ipu_dc_map_config(struct ipu_dc_priv *priv, enum ipu_dc_map map,
+		int byte_num, int offset, int mask)
+{
+	int ptr = map * 3 + byte_num;
+	u32 reg;
+
+	reg = readl(priv->dc_reg + DC_MAP_CONF_VAL(ptr));
+	reg &= ~(0xffff << (16 * (ptr & 0x1)));
+	reg |= ((offset << 8) | mask) << (16 * (ptr & 0x1));
+	writel(reg, priv->dc_reg + DC_MAP_CONF_VAL(ptr));
+
+	reg = readl(priv->dc_reg + DC_MAP_CONF_PTR(map));
+	reg &= ~(0x1f << ((16 * (map & 0x1)) + (5 * byte_num)));
+	reg |= ptr << ((16 * (map & 0x1)) + (5 * byte_num));
+	writel(reg, priv->dc_reg + DC_MAP_CONF_PTR(map));
+}
+
+static void ipu_dc_map_clear(struct ipu_dc_priv *priv, int map)
+{
+	u32 reg = readl(priv->dc_reg + DC_MAP_CONF_PTR(map));
+
+	writel(reg & ~(0xffff << (16 * (map & 0x1))),
+		     priv->dc_reg + DC_MAP_CONF_PTR(map));
+}
+
+struct ipu_dc *ipu_dc_get(struct ipu_soc *ipu, int channel)
+{
+	struct ipu_dc_priv *priv = ipu->dc_priv;
+	struct ipu_dc *dc;
+
+	if (channel >= IPU_DC_NUM_CHANNELS)
+		return ERR_PTR(-ENODEV);
+
+	dc = &priv->channels[channel];
+
+	mutex_lock(&priv->mutex);
+
+	if (dc->in_use) {
+		mutex_unlock(&priv->mutex);
+		return ERR_PTR(-EBUSY);
+	}
+
+	dc->in_use = true;
+
+	mutex_unlock(&priv->mutex);
+
+	return dc;
+}
+EXPORT_SYMBOL_GPL(ipu_dc_get);
+
+void ipu_dc_put(struct ipu_dc *dc)
+{
+	struct ipu_dc_priv *priv = dc->priv;
+
+	mutex_lock(&priv->mutex);
+	dc->in_use = false;
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dc_put);
+
+int ipu_dc_init(struct ipu_soc *ipu, struct device *dev,
+		unsigned long base, unsigned long template_base)
+{
+	struct ipu_dc_priv *priv;
+	static int channel_offsets[] = { 0, 0x1c, 0x38, 0x54, 0x58, 0x5c,
+		0x78, 0, 0x94, 0xb4};
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	mutex_init(&priv->mutex);
+
+	priv->dev = dev;
+	priv->ipu = ipu;
+	priv->dc_reg = devm_ioremap(dev, base, PAGE_SIZE);
+	priv->dc_tmpl_reg = devm_ioremap(dev, template_base, PAGE_SIZE);
+	if (!priv->dc_reg || !priv->dc_tmpl_reg)
+		return -ENOMEM;
+
+	for (i = 0; i < IPU_DC_NUM_CHANNELS; i++) {
+		priv->channels[i].chno = i;
+		priv->channels[i].priv = priv;
+		priv->channels[i].base = priv->dc_reg + channel_offsets[i];
+	}
+
+	writel(DC_WR_CH_CONF_WORD_SIZE_24 | DC_WR_CH_CONF_DISP_ID_PARALLEL(1) |
+			DC_WR_CH_CONF_PROG_DI_ID,
+			priv->channels[1].base + DC_WR_CH_CONF);
+	writel(DC_WR_CH_CONF_WORD_SIZE_24 | DC_WR_CH_CONF_DISP_ID_PARALLEL(0),
+			priv->channels[5].base + DC_WR_CH_CONF);
+
+	writel(DC_GEN_SYNC_1_6_SYNC | DC_GEN_SYNC_PRIORITY_1,
+		priv->dc_reg + DC_GEN);
+
+	ipu->dc_priv = priv;
+
+	dev_dbg(dev, "DC base: 0x%08lx template base: 0x%08lx\n",
+			base, template_base);
+
+	/* rgb24 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_RGB24);
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB24, 0, 7, 0xff); /* blue */
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB24, 1, 15, 0xff); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB24, 2, 23, 0xff); /* red */
+
+	/* rgb565 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_RGB565);
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB565, 0, 4, 0xf8); /* blue */
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB565, 1, 10, 0xfc); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_RGB565, 2, 15, 0xf8); /* red */
+
+	/* gbr24 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_GBR24);
+	ipu_dc_map_config(priv, IPU_DC_MAP_GBR24, 2, 15, 0xff); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_GBR24, 1, 7, 0xff); /* blue */
+	ipu_dc_map_config(priv, IPU_DC_MAP_GBR24, 0, 23, 0xff); /* red */
+
+	/* bgr666 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_BGR666);
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR666, 0, 5, 0xfc); /* blue */
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR666, 1, 11, 0xfc); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR666, 2, 17, 0xfc); /* red */
+
+	/* lvds666 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_LVDS666);
+	ipu_dc_map_config(priv, IPU_DC_MAP_LVDS666, 0, 5, 0xfc); /* blue */
+	ipu_dc_map_config(priv, IPU_DC_MAP_LVDS666, 1, 13, 0xfc); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_LVDS666, 2, 21, 0xfc); /* red */
+
+	/* bgr24 */
+	ipu_dc_map_clear(priv, IPU_DC_MAP_BGR24);
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR24, 2, 7, 0xff); /* red */
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR24, 1, 15, 0xff); /* green */
+	ipu_dc_map_config(priv, IPU_DC_MAP_BGR24, 0, 23, 0xff); /* blue */
+
+	return 0;
+}
+
+void ipu_dc_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-di.c b/drivers/gpu/imx/ipu-v3/ipu-di.c
new file mode 100644
index 000000000..666223c6b
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-di.c
@@ -0,0 +1,748 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/export.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/io.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+
+#include <video/imx-ipu-v3.h>
+#include "ipu-prv.h"
+
+struct ipu_di {
+	void __iomem *base;
+	int id;
+	u32 module;
+	struct clk *clk_di;	/* display input clock */
+	struct clk *clk_ipu;	/* IPU bus clock */
+	struct clk *clk_di_pixel; /* resulting pixel clock */
+	bool inuse;
+	struct ipu_soc *ipu;
+};
+
+static DEFINE_MUTEX(di_mutex);
+
+struct di_sync_config {
+	int run_count;
+	int run_src;
+	int offset_count;
+	int offset_src;
+	int repeat_count;
+	int cnt_clr_src;
+	int cnt_polarity_gen_en;
+	int cnt_polarity_clr_src;
+	int cnt_polarity_trigger_src;
+	int cnt_up;
+	int cnt_down;
+};
+
+enum di_pins {
+	DI_PIN11 = 0,
+	DI_PIN12 = 1,
+	DI_PIN13 = 2,
+	DI_PIN14 = 3,
+	DI_PIN15 = 4,
+	DI_PIN16 = 5,
+	DI_PIN17 = 6,
+	DI_PIN_CS = 7,
+
+	DI_PIN_SER_CLK = 0,
+	DI_PIN_SER_RS = 1,
+};
+
+enum di_sync_wave {
+	DI_SYNC_NONE = 0,
+	DI_SYNC_CLK = 1,
+	DI_SYNC_INT_HSYNC = 2,
+	DI_SYNC_HSYNC = 3,
+	DI_SYNC_VSYNC = 4,
+	DI_SYNC_DE = 6,
+
+	DI_SYNC_CNT1 = 2,	/* counter >= 2 only */
+	DI_SYNC_CNT4 = 5,	/* counter >= 5 only */
+	DI_SYNC_CNT5 = 6,	/* counter >= 6 only */
+};
+
+#define SYNC_WAVE 0
+
+#define DI_GENERAL		0x0000
+#define DI_BS_CLKGEN0		0x0004
+#define DI_BS_CLKGEN1		0x0008
+#define DI_SW_GEN0(gen)		(0x000c + 4 * ((gen) - 1))
+#define DI_SW_GEN1(gen)		(0x0030 + 4 * ((gen) - 1))
+#define DI_STP_REP(gen)		(0x0148 + 4 * (((gen) - 1)/2))
+#define DI_SYNC_AS_GEN		0x0054
+#define DI_DW_GEN(gen)		(0x0058 + 4 * (gen))
+#define DI_DW_SET(gen, set)	(0x0088 + 4 * ((gen) + 0xc * (set)))
+#define DI_SER_CONF		0x015c
+#define DI_SSC			0x0160
+#define DI_POL			0x0164
+#define DI_AW0			0x0168
+#define DI_AW1			0x016c
+#define DI_SCR_CONF		0x0170
+#define DI_STAT			0x0174
+
+#define DI_SW_GEN0_RUN_COUNT(x)			((x) << 19)
+#define DI_SW_GEN0_RUN_SRC(x)			((x) << 16)
+#define DI_SW_GEN0_OFFSET_COUNT(x)		((x) << 3)
+#define DI_SW_GEN0_OFFSET_SRC(x)		((x) << 0)
+
+#define DI_SW_GEN1_CNT_POL_GEN_EN(x)		((x) << 29)
+#define DI_SW_GEN1_CNT_CLR_SRC(x)		((x) << 25)
+#define DI_SW_GEN1_CNT_POL_TRIGGER_SRC(x)	((x) << 12)
+#define DI_SW_GEN1_CNT_POL_CLR_SRC(x)		((x) << 9)
+#define DI_SW_GEN1_CNT_DOWN(x)			((x) << 16)
+#define DI_SW_GEN1_CNT_UP(x)			(x)
+#define DI_SW_GEN1_AUTO_RELOAD			(0x10000000)
+
+#define DI_DW_GEN_ACCESS_SIZE_OFFSET		24
+#define DI_DW_GEN_COMPONENT_SIZE_OFFSET		16
+
+#define DI_GEN_POLARITY_1			(1 << 0)
+#define DI_GEN_POLARITY_2			(1 << 1)
+#define DI_GEN_POLARITY_3			(1 << 2)
+#define DI_GEN_POLARITY_4			(1 << 3)
+#define DI_GEN_POLARITY_5			(1 << 4)
+#define DI_GEN_POLARITY_6			(1 << 5)
+#define DI_GEN_POLARITY_7			(1 << 6)
+#define DI_GEN_POLARITY_8			(1 << 7)
+#define DI_GEN_POLARITY_DISP_CLK		(1 << 17)
+#define DI_GEN_DI_CLK_EXT			(1 << 20)
+#define DI_GEN_DI_VSYNC_EXT			(1 << 21)
+
+#define DI_POL_DRDY_DATA_POLARITY		(1 << 7)
+#define DI_POL_DRDY_POLARITY_15			(1 << 4)
+
+#define DI_VSYNC_SEL_OFFSET			13
+
+static inline u32 ipu_di_read(struct ipu_di *di, unsigned offset)
+{
+	return readl(di->base + offset);
+}
+
+static inline void ipu_di_write(struct ipu_di *di, u32 value, unsigned offset)
+{
+	writel(value, di->base + offset);
+}
+
+static void ipu_di_data_wave_config(struct ipu_di *di,
+				     int wave_gen,
+				     int access_size, int component_size)
+{
+	u32 reg;
+	reg = (access_size << DI_DW_GEN_ACCESS_SIZE_OFFSET) |
+	    (component_size << DI_DW_GEN_COMPONENT_SIZE_OFFSET);
+	ipu_di_write(di, reg, DI_DW_GEN(wave_gen));
+}
+
+static void ipu_di_data_pin_config(struct ipu_di *di, int wave_gen, int di_pin,
+		int set, int up, int down)
+{
+	u32 reg;
+
+	reg = ipu_di_read(di, DI_DW_GEN(wave_gen));
+	reg &= ~(0x3 << (di_pin * 2));
+	reg |= set << (di_pin * 2);
+	ipu_di_write(di, reg, DI_DW_GEN(wave_gen));
+
+	ipu_di_write(di, (down << 16) | up, DI_DW_SET(wave_gen, set));
+}
+
+static void ipu_di_sync_config(struct ipu_di *di, struct di_sync_config *config,
+		int start, int count)
+{
+	u32 reg;
+	int i;
+
+	for (i = 0; i < count; i++) {
+		struct di_sync_config *c = &config[i];
+		int wave_gen = start + i + 1;
+
+		if ((c->run_count >= 0x1000) || (c->offset_count >= 0x1000) ||
+				(c->repeat_count >= 0x1000) ||
+				(c->cnt_up >= 0x400) ||
+				(c->cnt_down >= 0x400)) {
+			dev_err(di->ipu->dev, "DI%d counters out of range.\n",
+					di->id);
+			return;
+		}
+
+		reg = DI_SW_GEN0_RUN_COUNT(c->run_count) |
+			DI_SW_GEN0_RUN_SRC(c->run_src) |
+			DI_SW_GEN0_OFFSET_COUNT(c->offset_count) |
+			DI_SW_GEN0_OFFSET_SRC(c->offset_src);
+		ipu_di_write(di, reg, DI_SW_GEN0(wave_gen));
+
+		reg = DI_SW_GEN1_CNT_POL_GEN_EN(c->cnt_polarity_gen_en) |
+			DI_SW_GEN1_CNT_CLR_SRC(c->cnt_clr_src) |
+			DI_SW_GEN1_CNT_POL_TRIGGER_SRC(
+					c->cnt_polarity_trigger_src) |
+			DI_SW_GEN1_CNT_POL_CLR_SRC(c->cnt_polarity_clr_src) |
+			DI_SW_GEN1_CNT_DOWN(c->cnt_down) |
+			DI_SW_GEN1_CNT_UP(c->cnt_up);
+
+		/* Enable auto reload */
+		if (c->repeat_count == 0)
+			reg |= DI_SW_GEN1_AUTO_RELOAD;
+
+		ipu_di_write(di, reg, DI_SW_GEN1(wave_gen));
+
+		reg = ipu_di_read(di, DI_STP_REP(wave_gen));
+		reg &= ~(0xffff << (16 * ((wave_gen - 1) & 0x1)));
+		reg |= c->repeat_count << (16 * ((wave_gen - 1) & 0x1));
+		ipu_di_write(di, reg, DI_STP_REP(wave_gen));
+	}
+}
+
+static void ipu_di_sync_config_interlaced(struct ipu_di *di,
+		struct ipu_di_signal_cfg *sig)
+{
+	u32 h_total = sig->mode.hactive + sig->mode.hsync_len +
+		sig->mode.hback_porch + sig->mode.hfront_porch;
+	u32 v_total = sig->mode.vactive + sig->mode.vsync_len +
+		sig->mode.vback_porch + sig->mode.vfront_porch;
+	struct di_sync_config cfg[] = {
+		{
+			/* 1: internal VSYNC for each frame */
+			.run_count = v_total * 2 - 1,
+			.run_src = 3,			/* == counter 7 */
+		}, {
+			/* PIN2: HSYNC waveform */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_CLK,
+			.cnt_down = sig->mode.hsync_len * 2,
+		}, {
+			/* PIN3: VSYNC waveform */
+			.run_count = v_total - 1,
+			.run_src = 4,			/* == counter 7 */
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = 4,	/* == counter 7 */
+			.cnt_down = sig->mode.vsync_len * 2,
+			.cnt_clr_src = DI_SYNC_CNT1,
+		}, {
+			/* 4: Field */
+			.run_count = v_total / 2,
+			.run_src = DI_SYNC_HSYNC,
+			.offset_count = h_total / 2,
+			.offset_src = DI_SYNC_CLK,
+			.repeat_count = 2,
+			.cnt_clr_src = DI_SYNC_CNT1,
+		}, {
+			/* 5: Active lines */
+			.run_src = DI_SYNC_HSYNC,
+			.offset_count = (sig->mode.vsync_len +
+					 sig->mode.vback_porch) / 2,
+			.offset_src = DI_SYNC_HSYNC,
+			.repeat_count = sig->mode.vactive / 2,
+			.cnt_clr_src = DI_SYNC_CNT4,
+		}, {
+			/* 6: Active pixel, referenced by DC */
+			.run_src = DI_SYNC_CLK,
+			.offset_count = sig->mode.hsync_len +
+					sig->mode.hback_porch,
+			.offset_src = DI_SYNC_CLK,
+			.repeat_count = sig->mode.hactive,
+			.cnt_clr_src = DI_SYNC_CNT5,
+		}, {
+			/* 7: Half line HSYNC */
+			.run_count = h_total / 2 - 1,
+			.run_src = DI_SYNC_CLK,
+		}
+	};
+
+	ipu_di_sync_config(di, cfg, 0, ARRAY_SIZE(cfg));
+
+	ipu_di_write(di, v_total / 2 - 1, DI_SCR_CONF);
+}
+
+static void ipu_di_sync_config_noninterlaced(struct ipu_di *di,
+		struct ipu_di_signal_cfg *sig, int div)
+{
+	u32 h_total = sig->mode.hactive + sig->mode.hsync_len +
+		sig->mode.hback_porch + sig->mode.hfront_porch;
+	u32 v_total = sig->mode.vactive + sig->mode.vsync_len +
+		sig->mode.vback_porch + sig->mode.vfront_porch;
+	struct di_sync_config cfg[] = {
+		{
+			/* 1: INT_HSYNC */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+		} , {
+			/* PIN2: HSYNC */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+			.offset_count = div * sig->v_to_h_sync,
+			.offset_src = DI_SYNC_CLK,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_CLK,
+			.cnt_down = sig->mode.hsync_len * 2,
+		} , {
+			/* PIN3: VSYNC */
+			.run_count = v_total - 1,
+			.run_src = DI_SYNC_INT_HSYNC,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_INT_HSYNC,
+			.cnt_down = sig->mode.vsync_len * 2,
+		} , {
+			/* 4: Line Active */
+			.run_src = DI_SYNC_HSYNC,
+			.offset_count = sig->mode.vsync_len +
+					sig->mode.vback_porch,
+			.offset_src = DI_SYNC_HSYNC,
+			.repeat_count = sig->mode.vactive,
+			.cnt_clr_src = DI_SYNC_VSYNC,
+		} , {
+			/* 5: Pixel Active, referenced by DC */
+			.run_src = DI_SYNC_CLK,
+			.offset_count = sig->mode.hsync_len +
+					sig->mode.hback_porch,
+			.offset_src = DI_SYNC_CLK,
+			.repeat_count = sig->mode.hactive,
+			.cnt_clr_src = 5, /* Line Active */
+		} , {
+			/* unused */
+		} , {
+			/* unused */
+		},
+	};
+	/* can't use #7 and #8 for line active and pixel active counters */
+	struct di_sync_config cfg_vga[] = {
+		{
+			/* 1: INT_HSYNC */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+		} , {
+			/* 2: VSYNC */
+			.run_count = v_total - 1,
+			.run_src = DI_SYNC_INT_HSYNC,
+		} , {
+			/* 3: Line Active */
+			.run_src = DI_SYNC_INT_HSYNC,
+			.offset_count = sig->mode.vsync_len +
+					sig->mode.vback_porch,
+			.offset_src = DI_SYNC_INT_HSYNC,
+			.repeat_count = sig->mode.vactive,
+			.cnt_clr_src = 3 /* VSYNC */,
+		} , {
+			/* PIN4: HSYNC for VGA via TVEv2 on TQ MBa53 */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+			.offset_count = div * sig->v_to_h_sync + 18, /* magic value from Freescale TVE driver */
+			.offset_src = DI_SYNC_CLK,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_CLK,
+			.cnt_down = sig->mode.hsync_len * 2,
+		} , {
+			/* 5: Pixel Active signal to DC */
+			.run_src = DI_SYNC_CLK,
+			.offset_count = sig->mode.hsync_len +
+					sig->mode.hback_porch,
+			.offset_src = DI_SYNC_CLK,
+			.repeat_count = sig->mode.hactive,
+			.cnt_clr_src = 4, /* Line Active */
+		} , {
+			/* PIN6: VSYNC for VGA via TVEv2 on TQ MBa53 */
+			.run_count = v_total - 1,
+			.run_src = DI_SYNC_INT_HSYNC,
+			.offset_count = 1, /* magic value from Freescale TVE driver */
+			.offset_src = DI_SYNC_INT_HSYNC,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_INT_HSYNC,
+			.cnt_down = sig->mode.vsync_len * 2,
+		} , {
+			/* PIN4: HSYNC for VGA via TVEv2 on i.MX53-QSB */
+			.run_count = h_total - 1,
+			.run_src = DI_SYNC_CLK,
+			.offset_count = div * sig->v_to_h_sync + 18, /* magic value from Freescale TVE driver */
+			.offset_src = DI_SYNC_CLK,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_CLK,
+			.cnt_down = sig->mode.hsync_len * 2,
+		} , {
+			/* PIN6: VSYNC for VGA via TVEv2 on i.MX53-QSB */
+			.run_count = v_total - 1,
+			.run_src = DI_SYNC_INT_HSYNC,
+			.offset_count = 1, /* magic value from Freescale TVE driver */
+			.offset_src = DI_SYNC_INT_HSYNC,
+			.cnt_polarity_gen_en = 1,
+			.cnt_polarity_trigger_src = DI_SYNC_INT_HSYNC,
+			.cnt_down = sig->mode.vsync_len * 2,
+		} , {
+			/* unused */
+		},
+	};
+
+	ipu_di_write(di, v_total - 1, DI_SCR_CONF);
+	if (sig->hsync_pin == 2 && sig->vsync_pin == 3)
+		ipu_di_sync_config(di, cfg, 0, ARRAY_SIZE(cfg));
+	else
+		ipu_di_sync_config(di, cfg_vga, 0, ARRAY_SIZE(cfg_vga));
+}
+
+static void ipu_di_config_clock(struct ipu_di *di,
+	const struct ipu_di_signal_cfg *sig)
+{
+	struct clk *clk;
+	unsigned clkgen0;
+	uint32_t val;
+
+	if (sig->clkflags & IPU_DI_CLKMODE_EXT) {
+		/*
+		 * CLKMODE_EXT means we must use the DI clock: this is
+		 * needed for things like LVDS which needs to feed the
+		 * DI and LDB with the same pixel clock.
+		 */
+		clk = di->clk_di;
+
+		if (sig->clkflags & IPU_DI_CLKMODE_SYNC) {
+			/*
+			 * CLKMODE_SYNC means that we want the DI to be
+			 * clocked at the same rate as the parent clock.
+			 * This is needed (eg) for LDB which needs to be
+			 * fed with the same pixel clock.  We assume that
+			 * the LDB clock has already been set correctly.
+			 */
+			clkgen0 = 1 << 4;
+		} else {
+			/*
+			 * We can use the divider.  We should really have
+			 * a flag here indicating whether the bridge can
+			 * cope with a fractional divider or not.  For the
+			 * time being, let's go for simplicitly and
+			 * reliability.
+			 */
+			unsigned long in_rate;
+			unsigned div;
+
+			clk_set_rate(clk, sig->mode.pixelclock);
+
+			in_rate = clk_get_rate(clk);
+			div = DIV_ROUND_CLOSEST(in_rate, sig->mode.pixelclock);
+			div = clamp(div, 1U, 255U);
+
+			clkgen0 = div << 4;
+		}
+	} else {
+		/*
+		 * For other interfaces, we can arbitarily select between
+		 * the DI specific clock and the internal IPU clock.  See
+		 * DI_GENERAL bit 20.  We select the IPU clock if it can
+		 * give us a clock rate within 1% of the requested frequency,
+		 * otherwise we use the DI clock.
+		 */
+		unsigned long rate, clkrate;
+		unsigned div, error;
+
+		clkrate = clk_get_rate(di->clk_ipu);
+		div = DIV_ROUND_CLOSEST(clkrate, sig->mode.pixelclock);
+		div = clamp(div, 1U, 255U);
+		rate = clkrate / div;
+
+		error = rate / (sig->mode.pixelclock / 1000);
+
+		dev_dbg(di->ipu->dev, "  IPU clock can give %lu with divider %u, error %d.%u%%\n",
+			rate, div, (signed)(error - 1000) / 10, error % 10);
+
+		/* Allow a 1% error */
+		if (error < 1010 && error >= 990) {
+			clk = di->clk_ipu;
+
+			clkgen0 = div << 4;
+		} else {
+			unsigned long in_rate;
+			unsigned div;
+
+			clk = di->clk_di;
+
+			clk_set_rate(clk, sig->mode.pixelclock);
+
+			in_rate = clk_get_rate(clk);
+			div = DIV_ROUND_CLOSEST(in_rate, sig->mode.pixelclock);
+			div = clamp(div, 1U, 255U);
+
+			clkgen0 = div << 4;
+		}
+	}
+
+	di->clk_di_pixel = clk;
+
+	/* Set the divider */
+	ipu_di_write(di, clkgen0, DI_BS_CLKGEN0);
+
+	/*
+	 * Set the high/low periods.  Bits 24:16 give us the falling edge,
+	 * and bits 8:0 give the rising edge.  LSB is fraction, and is
+	 * based on the divider above.  We want a 50% duty cycle, so set
+	 * the falling edge to be half the divider.
+	 */
+	ipu_di_write(di, (clkgen0 >> 4) << 16, DI_BS_CLKGEN1);
+
+	/* Finally select the input clock */
+	val = ipu_di_read(di, DI_GENERAL) & ~DI_GEN_DI_CLK_EXT;
+	if (clk == di->clk_di)
+		val |= DI_GEN_DI_CLK_EXT;
+	ipu_di_write(di, val, DI_GENERAL);
+
+	dev_dbg(di->ipu->dev, "Want %luHz IPU %luHz DI %luHz using %s, %luHz\n",
+		sig->mode.pixelclock,
+		clk_get_rate(di->clk_ipu),
+		clk_get_rate(di->clk_di),
+		clk == di->clk_di ? "DI" : "IPU",
+		clk_get_rate(di->clk_di_pixel) / (clkgen0 >> 4));
+}
+
+/*
+ * This function is called to adjust a video mode to IPU restrictions.
+ * It is meant to be called from drm crtc mode_fixup() methods.
+ */
+int ipu_di_adjust_videomode(struct ipu_di *di, struct videomode *mode)
+{
+	u32 diff;
+
+	if (!IS_ALIGNED(mode->hactive, 8) &&
+	    mode->hfront_porch < ALIGN(mode->hactive, 8) - mode->hactive) {
+		dev_err(di->ipu->dev, "hactive %d is not aligned to 8 and front porch is too small to compensate\n",
+			mode->hactive);
+		return -EINVAL;
+	}
+
+	if (mode->vfront_porch >= 2)
+		return 0;
+
+	diff = 2 - mode->vfront_porch;
+
+	if (mode->vback_porch >= diff) {
+		mode->vfront_porch = 2;
+		mode->vback_porch -= diff;
+	} else if (mode->vsync_len > diff) {
+		mode->vfront_porch = 2;
+		mode->vsync_len = mode->vsync_len - diff;
+	} else {
+		dev_warn(di->ipu->dev, "failed to adjust videomode\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(di->ipu->dev, "videomode adapted for IPU restrictions\n");
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_di_adjust_videomode);
+
+static u32 ipu_di_gen_polarity(int pin)
+{
+	switch (pin) {
+	case 1:
+		return DI_GEN_POLARITY_1;
+	case 2:
+		return DI_GEN_POLARITY_2;
+	case 3:
+		return DI_GEN_POLARITY_3;
+	case 4:
+		return DI_GEN_POLARITY_4;
+	case 5:
+		return DI_GEN_POLARITY_5;
+	case 6:
+		return DI_GEN_POLARITY_6;
+	case 7:
+		return DI_GEN_POLARITY_7;
+	case 8:
+		return DI_GEN_POLARITY_8;
+	}
+	return 0;
+}
+
+int ipu_di_init_sync_panel(struct ipu_di *di, struct ipu_di_signal_cfg *sig)
+{
+	u32 reg;
+	u32 di_gen, vsync_cnt;
+	u32 div;
+
+	dev_dbg(di->ipu->dev, "disp %d: panel size = %d x %d\n",
+		di->id, sig->mode.hactive, sig->mode.vactive);
+
+	dev_dbg(di->ipu->dev, "Clocks: IPU %luHz DI %luHz Needed %luHz\n",
+		clk_get_rate(di->clk_ipu),
+		clk_get_rate(di->clk_di),
+		sig->mode.pixelclock);
+
+	mutex_lock(&di_mutex);
+
+	ipu_di_config_clock(di, sig);
+
+	div = ipu_di_read(di, DI_BS_CLKGEN0) & 0xfff;
+	div = div / 16;		/* Now divider is integer portion */
+
+	/* Setup pixel clock timing */
+	/* Down time is half of period */
+	ipu_di_write(di, (div << 16), DI_BS_CLKGEN1);
+
+	ipu_di_data_wave_config(di, SYNC_WAVE, div - 1, div - 1);
+	ipu_di_data_pin_config(di, SYNC_WAVE, DI_PIN15, 3, 0, div * 2);
+
+	di_gen = ipu_di_read(di, DI_GENERAL) & DI_GEN_DI_CLK_EXT;
+	di_gen |= DI_GEN_DI_VSYNC_EXT;
+
+	if (sig->mode.flags & DISPLAY_FLAGS_INTERLACED) {
+		ipu_di_sync_config_interlaced(di, sig);
+
+		/* set y_sel = 1 */
+		di_gen |= 0x10000000;
+
+		vsync_cnt = 3;
+	} else {
+		ipu_di_sync_config_noninterlaced(di, sig, div);
+
+		vsync_cnt = 3;
+		if (di->id == 1)
+			/*
+			 * TODO: change only for TVEv2, parallel display
+			 * uses pin 2 / 3
+			 */
+			if (!(sig->hsync_pin == 2 && sig->vsync_pin == 3))
+				vsync_cnt = 6;
+	}
+
+	if (sig->mode.flags & DISPLAY_FLAGS_HSYNC_HIGH)
+		di_gen |= ipu_di_gen_polarity(sig->hsync_pin);
+	if (sig->mode.flags & DISPLAY_FLAGS_VSYNC_HIGH)
+		di_gen |= ipu_di_gen_polarity(sig->vsync_pin);
+
+	if (sig->clk_pol)
+		di_gen |= DI_GEN_POLARITY_DISP_CLK;
+
+	ipu_di_write(di, di_gen, DI_GENERAL);
+
+	ipu_di_write(di, (--vsync_cnt << DI_VSYNC_SEL_OFFSET) | 0x00000002,
+		     DI_SYNC_AS_GEN);
+
+	reg = ipu_di_read(di, DI_POL);
+	reg &= ~(DI_POL_DRDY_DATA_POLARITY | DI_POL_DRDY_POLARITY_15);
+
+	if (sig->enable_pol)
+		reg |= DI_POL_DRDY_POLARITY_15;
+	if (sig->data_pol)
+		reg |= DI_POL_DRDY_DATA_POLARITY;
+
+	ipu_di_write(di, reg, DI_POL);
+
+	mutex_unlock(&di_mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_di_init_sync_panel);
+
+int ipu_di_enable(struct ipu_di *di)
+{
+	int ret;
+
+	WARN_ON(IS_ERR(di->clk_di_pixel));
+
+	ret = clk_prepare_enable(di->clk_di_pixel);
+	if (ret)
+		return ret;
+
+	ipu_module_enable(di->ipu, di->module);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_di_enable);
+
+int ipu_di_disable(struct ipu_di *di)
+{
+	WARN_ON(IS_ERR(di->clk_di_pixel));
+
+	ipu_module_disable(di->ipu, di->module);
+
+	clk_disable_unprepare(di->clk_di_pixel);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_di_disable);
+
+int ipu_di_get_num(struct ipu_di *di)
+{
+	return di->id;
+}
+EXPORT_SYMBOL_GPL(ipu_di_get_num);
+
+static DEFINE_MUTEX(ipu_di_lock);
+
+struct ipu_di *ipu_di_get(struct ipu_soc *ipu, int disp)
+{
+	struct ipu_di *di;
+
+	if (disp > 1)
+		return ERR_PTR(-EINVAL);
+
+	di = ipu->di_priv[disp];
+
+	mutex_lock(&ipu_di_lock);
+
+	if (di->inuse) {
+		di = ERR_PTR(-EBUSY);
+		goto out;
+	}
+
+	di->inuse = true;
+out:
+	mutex_unlock(&ipu_di_lock);
+
+	return di;
+}
+EXPORT_SYMBOL_GPL(ipu_di_get);
+
+void ipu_di_put(struct ipu_di *di)
+{
+	mutex_lock(&ipu_di_lock);
+
+	di->inuse = false;
+
+	mutex_unlock(&ipu_di_lock);
+}
+EXPORT_SYMBOL_GPL(ipu_di_put);
+
+int ipu_di_init(struct ipu_soc *ipu, struct device *dev, int id,
+		unsigned long base,
+		u32 module, struct clk *clk_ipu)
+{
+	struct ipu_di *di;
+
+	if (id > 1)
+		return -ENODEV;
+
+	di = devm_kzalloc(dev, sizeof(*di), GFP_KERNEL);
+	if (!di)
+		return -ENOMEM;
+
+	ipu->di_priv[id] = di;
+
+	di->clk_di = devm_clk_get(dev, id ? "di1" : "di0");
+	if (IS_ERR(di->clk_di))
+		return PTR_ERR(di->clk_di);
+
+	di->module = module;
+	di->id = id;
+	di->clk_ipu = clk_ipu;
+	di->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!di->base)
+		return -ENOMEM;
+
+	ipu_di_write(di, 0x10, DI_BS_CLKGEN0);
+
+	dev_dbg(dev, "DI%d base: 0x%08lx remapped to %p\n",
+			id, base, di->base);
+	di->inuse = false;
+	di->ipu = ipu;
+
+	return 0;
+}
+
+void ipu_di_exit(struct ipu_soc *ipu, int id)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-dmfc.c b/drivers/gpu/imx/ipu-v3/ipu-dmfc.c
new file mode 100644
index 000000000..ae682084a
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-dmfc.c
@@ -0,0 +1,214 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/export.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/io.h>
+
+#include <video/imx-ipu-v3.h>
+#include "ipu-prv.h"
+
+#define DMFC_RD_CHAN		0x0000
+#define DMFC_WR_CHAN		0x0004
+#define DMFC_WR_CHAN_DEF	0x0008
+#define DMFC_DP_CHAN		0x000c
+#define DMFC_DP_CHAN_DEF	0x0010
+#define DMFC_GENERAL1		0x0014
+#define DMFC_GENERAL2		0x0018
+#define DMFC_IC_CTRL		0x001c
+#define DMFC_WR_CHAN_ALT	0x0020
+#define DMFC_WR_CHAN_DEF_ALT	0x0024
+#define DMFC_DP_CHAN_ALT	0x0028
+#define DMFC_DP_CHAN_DEF_ALT	0x002c
+#define DMFC_GENERAL1_ALT	0x0030
+#define DMFC_STAT		0x0034
+
+#define DMFC_WR_CHAN_1_28		0
+#define DMFC_WR_CHAN_2_41		8
+#define DMFC_WR_CHAN_1C_42		16
+#define DMFC_WR_CHAN_2C_43		24
+
+#define DMFC_DP_CHAN_5B_23		0
+#define DMFC_DP_CHAN_5F_27		8
+#define DMFC_DP_CHAN_6B_24		16
+#define DMFC_DP_CHAN_6F_29		24
+
+struct dmfc_channel_data {
+	int		ipu_channel;
+	unsigned long	channel_reg;
+	unsigned long	shift;
+	unsigned	eot_shift;
+	unsigned	max_fifo_lines;
+};
+
+static const struct dmfc_channel_data dmfcdata[] = {
+	{
+		.ipu_channel	= IPUV3_CHANNEL_MEM_BG_SYNC,
+		.channel_reg	= DMFC_DP_CHAN,
+		.shift		= DMFC_DP_CHAN_5B_23,
+		.eot_shift	= 20,
+		.max_fifo_lines	= 3,
+	}, {
+		.ipu_channel	= 24,
+		.channel_reg	= DMFC_DP_CHAN,
+		.shift		= DMFC_DP_CHAN_6B_24,
+		.eot_shift	= 22,
+		.max_fifo_lines	= 1,
+	}, {
+		.ipu_channel	= IPUV3_CHANNEL_MEM_FG_SYNC,
+		.channel_reg	= DMFC_DP_CHAN,
+		.shift		= DMFC_DP_CHAN_5F_27,
+		.eot_shift	= 21,
+		.max_fifo_lines	= 2,
+	}, {
+		.ipu_channel	= IPUV3_CHANNEL_MEM_DC_SYNC,
+		.channel_reg	= DMFC_WR_CHAN,
+		.shift		= DMFC_WR_CHAN_1_28,
+		.eot_shift	= 16,
+		.max_fifo_lines	= 2,
+	}, {
+		.ipu_channel	= 29,
+		.channel_reg	= DMFC_DP_CHAN,
+		.shift		= DMFC_DP_CHAN_6F_29,
+		.eot_shift	= 23,
+		.max_fifo_lines	= 1,
+	},
+};
+
+#define DMFC_NUM_CHANNELS	ARRAY_SIZE(dmfcdata)
+
+struct ipu_dmfc_priv;
+
+struct dmfc_channel {
+	unsigned			slots;
+	struct ipu_soc			*ipu;
+	struct ipu_dmfc_priv		*priv;
+	const struct dmfc_channel_data	*data;
+};
+
+struct ipu_dmfc_priv {
+	struct ipu_soc *ipu;
+	struct device *dev;
+	struct dmfc_channel channels[DMFC_NUM_CHANNELS];
+	struct mutex mutex;
+	void __iomem *base;
+	int use_count;
+};
+
+int ipu_dmfc_enable_channel(struct dmfc_channel *dmfc)
+{
+	struct ipu_dmfc_priv *priv = dmfc->priv;
+	mutex_lock(&priv->mutex);
+
+	if (!priv->use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_DMFC_EN);
+
+	priv->use_count++;
+
+	mutex_unlock(&priv->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dmfc_enable_channel);
+
+void ipu_dmfc_disable_channel(struct dmfc_channel *dmfc)
+{
+	struct ipu_dmfc_priv *priv = dmfc->priv;
+
+	mutex_lock(&priv->mutex);
+
+	priv->use_count--;
+
+	if (!priv->use_count)
+		ipu_module_disable(priv->ipu, IPU_CONF_DMFC_EN);
+
+	if (priv->use_count < 0)
+		priv->use_count = 0;
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dmfc_disable_channel);
+
+void ipu_dmfc_config_wait4eot(struct dmfc_channel *dmfc, int width)
+{
+	struct ipu_dmfc_priv *priv = dmfc->priv;
+	u32 dmfc_gen1;
+
+	mutex_lock(&priv->mutex);
+
+	dmfc_gen1 = readl(priv->base + DMFC_GENERAL1);
+
+	if ((dmfc->slots * 64 * 4) / width > dmfc->data->max_fifo_lines)
+		dmfc_gen1 |= 1 << dmfc->data->eot_shift;
+	else
+		dmfc_gen1 &= ~(1 << dmfc->data->eot_shift);
+
+	writel(dmfc_gen1, priv->base + DMFC_GENERAL1);
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dmfc_config_wait4eot);
+
+struct dmfc_channel *ipu_dmfc_get(struct ipu_soc *ipu, int ipu_channel)
+{
+	struct ipu_dmfc_priv *priv = ipu->dmfc_priv;
+	int i;
+
+	for (i = 0; i < DMFC_NUM_CHANNELS; i++)
+		if (dmfcdata[i].ipu_channel == ipu_channel)
+			return &priv->channels[i];
+	return ERR_PTR(-ENODEV);
+}
+EXPORT_SYMBOL_GPL(ipu_dmfc_get);
+
+void ipu_dmfc_put(struct dmfc_channel *dmfc)
+{
+}
+EXPORT_SYMBOL_GPL(ipu_dmfc_put);
+
+int ipu_dmfc_init(struct ipu_soc *ipu, struct device *dev, unsigned long base,
+		struct clk *ipu_clk)
+{
+	struct ipu_dmfc_priv *priv;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	priv->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!priv->base)
+		return -ENOMEM;
+
+	priv->dev = dev;
+	priv->ipu = ipu;
+	mutex_init(&priv->mutex);
+
+	ipu->dmfc_priv = priv;
+
+	for (i = 0; i < DMFC_NUM_CHANNELS; i++) {
+		priv->channels[i].priv = priv;
+		priv->channels[i].ipu = ipu;
+		priv->channels[i].data = &dmfcdata[i];
+
+		if (dmfcdata[i].ipu_channel == IPUV3_CHANNEL_MEM_BG_SYNC ||
+		    dmfcdata[i].ipu_channel == IPUV3_CHANNEL_MEM_FG_SYNC ||
+		    dmfcdata[i].ipu_channel == IPUV3_CHANNEL_MEM_DC_SYNC)
+			priv->channels[i].slots = 2;
+	}
+
+	writel(0x00000050, priv->base + DMFC_WR_CHAN);
+	writel(0x00005654, priv->base + DMFC_DP_CHAN);
+	writel(0x202020f6, priv->base + DMFC_WR_CHAN_DEF);
+	writel(0x2020f6f6, priv->base + DMFC_DP_CHAN_DEF);
+	writel(0x00000003, priv->base + DMFC_GENERAL1);
+
+	return 0;
+}
+
+void ipu_dmfc_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-dp.c b/drivers/gpu/imx/ipu-v3/ipu-dp.c
new file mode 100644
index 000000000..6a558205d
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-dp.c
@@ -0,0 +1,376 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/export.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/io.h>
+#include <linux/err.h>
+
+#include <drm/drm_color_mgmt.h>
+#include <video/imx-ipu-v3.h>
+#include "ipu-prv.h"
+
+#define DP_SYNC 0
+#define DP_ASYNC0 0x60
+#define DP_ASYNC1 0xBC
+
+#define DP_COM_CONF		0x0
+#define DP_GRAPH_WIND_CTRL	0x0004
+#define DP_FG_POS		0x0008
+#define DP_CSC_A_0		0x0044
+#define DP_CSC_A_1		0x0048
+#define DP_CSC_A_2		0x004C
+#define DP_CSC_A_3		0x0050
+#define DP_CSC_0		0x0054
+#define DP_CSC_1		0x0058
+
+#define DP_COM_CONF_FG_EN		(1 << 0)
+#define DP_COM_CONF_GWSEL		(1 << 1)
+#define DP_COM_CONF_GWAM		(1 << 2)
+#define DP_COM_CONF_GWCKE		(1 << 3)
+#define DP_COM_CONF_CSC_DEF_MASK	(3 << 8)
+#define DP_COM_CONF_CSC_DEF_OFFSET	8
+#define DP_COM_CONF_CSC_DEF_FG		(3 << 8)
+#define DP_COM_CONF_CSC_DEF_BG		(2 << 8)
+#define DP_COM_CONF_CSC_DEF_BOTH	(1 << 8)
+
+#define IPUV3_NUM_FLOWS		3
+
+struct ipu_dp_priv;
+
+struct ipu_dp {
+	u32 flow;
+	bool in_use;
+	bool foreground;
+	enum ipu_color_space in_cs;
+};
+
+struct ipu_flow {
+	struct ipu_dp foreground;
+	struct ipu_dp background;
+	enum ipu_color_space out_cs;
+	void __iomem *base;
+	struct ipu_dp_priv *priv;
+};
+
+struct ipu_dp_priv {
+	struct ipu_soc *ipu;
+	struct device *dev;
+	void __iomem *base;
+	struct ipu_flow flow[IPUV3_NUM_FLOWS];
+	struct mutex mutex;
+	int use_count;
+};
+
+static u32 ipu_dp_flow_base[] = {DP_SYNC, DP_ASYNC0, DP_ASYNC1};
+
+static inline struct ipu_flow *to_flow(struct ipu_dp *dp)
+{
+	if (dp->foreground)
+		return container_of(dp, struct ipu_flow, foreground);
+	else
+		return container_of(dp, struct ipu_flow, background);
+}
+
+int ipu_dp_set_global_alpha(struct ipu_dp *dp, bool enable,
+		u8 alpha, bool bg_chan)
+{
+	struct ipu_flow *flow = to_flow(dp);
+	struct ipu_dp_priv *priv = flow->priv;
+	u32 reg;
+
+	mutex_lock(&priv->mutex);
+
+	reg = readl(flow->base + DP_COM_CONF);
+	if (bg_chan)
+		reg &= ~DP_COM_CONF_GWSEL;
+	else
+		reg |= DP_COM_CONF_GWSEL;
+	writel(reg, flow->base + DP_COM_CONF);
+
+	if (enable) {
+		reg = readl(flow->base + DP_GRAPH_WIND_CTRL) & 0x00FFFFFFL;
+		writel(reg | ((u32) alpha << 24),
+			     flow->base + DP_GRAPH_WIND_CTRL);
+
+		reg = readl(flow->base + DP_COM_CONF);
+		writel(reg | DP_COM_CONF_GWAM, flow->base + DP_COM_CONF);
+	} else {
+		reg = readl(flow->base + DP_COM_CONF);
+		writel(reg & ~DP_COM_CONF_GWAM, flow->base + DP_COM_CONF);
+	}
+
+	ipu_srm_dp_update(priv->ipu, true);
+
+	mutex_unlock(&priv->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_set_global_alpha);
+
+int ipu_dp_set_window_pos(struct ipu_dp *dp, u16 x_pos, u16 y_pos)
+{
+	struct ipu_flow *flow = to_flow(dp);
+	struct ipu_dp_priv *priv = flow->priv;
+
+	writel((x_pos << 16) | y_pos, flow->base + DP_FG_POS);
+
+	ipu_srm_dp_update(priv->ipu, true);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_set_window_pos);
+
+static void ipu_dp_csc_init(struct ipu_flow *flow,
+		enum drm_color_encoding ycbcr_enc,
+		enum drm_color_range range,
+		enum ipu_color_space in,
+		enum ipu_color_space out,
+		u32 place)
+{
+	u32 reg;
+
+	reg = readl(flow->base + DP_COM_CONF);
+	reg &= ~DP_COM_CONF_CSC_DEF_MASK;
+
+	if (in == out) {
+		writel(reg, flow->base + DP_COM_CONF);
+		return;
+	}
+
+	if (in == IPUV3_COLORSPACE_RGB && out == IPUV3_COLORSPACE_YUV) {
+		writel(0x099 | (0x12d << 16), flow->base + DP_CSC_A_0);
+		writel(0x03a | (0x3a9 << 16), flow->base + DP_CSC_A_1);
+		writel(0x356 | (0x100 << 16), flow->base + DP_CSC_A_2);
+		writel(0x100 | (0x329 << 16), flow->base + DP_CSC_A_3);
+		writel(0x3d6 | (0x0000 << 16) | (2 << 30),
+				flow->base + DP_CSC_0);
+		writel(0x200 | (2 << 14) | (0x200 << 16) | (2 << 30),
+				flow->base + DP_CSC_1);
+	} else if (ycbcr_enc == DRM_COLOR_YCBCR_BT709) {
+		/* Rec.709 limited range */
+		writel(0x095 | (0x000 << 16), flow->base + DP_CSC_A_0);
+		writel(0x0e5 | (0x095 << 16), flow->base + DP_CSC_A_1);
+		writel(0x3e5 | (0x3bc << 16), flow->base + DP_CSC_A_2);
+		writel(0x095 | (0x10e << 16), flow->base + DP_CSC_A_3);
+		writel(0x000 | (0x3e10 << 16) | (1 << 30),
+				flow->base + DP_CSC_0);
+		writel(0x09a | (1 << 14) | (0x3dbe << 16) | (1 << 30),
+				flow->base + DP_CSC_1);
+	} else {
+		/* BT.601 limited range */
+		writel(0x095 | (0x000 << 16), flow->base + DP_CSC_A_0);
+		writel(0x0cc | (0x095 << 16), flow->base + DP_CSC_A_1);
+		writel(0x3ce | (0x398 << 16), flow->base + DP_CSC_A_2);
+		writel(0x095 | (0x0ff << 16), flow->base + DP_CSC_A_3);
+		writel(0x000 | (0x3e42 << 16) | (1 << 30),
+				flow->base + DP_CSC_0);
+		writel(0x10a | (1 << 14) | (0x3dd6 << 16) | (1 << 30),
+				flow->base + DP_CSC_1);
+	}
+
+	reg |= place;
+
+	writel(reg, flow->base + DP_COM_CONF);
+}
+
+int ipu_dp_setup_channel(struct ipu_dp *dp,
+		enum drm_color_encoding ycbcr_enc,
+		enum drm_color_range range,
+		enum ipu_color_space in,
+		enum ipu_color_space out)
+{
+	struct ipu_flow *flow = to_flow(dp);
+	struct ipu_dp_priv *priv = flow->priv;
+
+	mutex_lock(&priv->mutex);
+
+	dp->in_cs = in;
+
+	if (!dp->foreground)
+		flow->out_cs = out;
+
+	if (flow->foreground.in_cs == flow->background.in_cs) {
+		/*
+		 * foreground and background are of same colorspace, put
+		 * colorspace converter after combining unit.
+		 */
+		ipu_dp_csc_init(flow, ycbcr_enc, range,
+				flow->foreground.in_cs, flow->out_cs,
+				DP_COM_CONF_CSC_DEF_BOTH);
+	} else {
+		if (flow->foreground.in_cs == IPUV3_COLORSPACE_UNKNOWN ||
+		    flow->foreground.in_cs == flow->out_cs)
+			/*
+			 * foreground identical to output, apply color
+			 * conversion on background
+			 */
+			ipu_dp_csc_init(flow, ycbcr_enc, range,
+					flow->background.in_cs,
+					flow->out_cs, DP_COM_CONF_CSC_DEF_BG);
+		else
+			ipu_dp_csc_init(flow, ycbcr_enc, range,
+					flow->foreground.in_cs,
+					flow->out_cs, DP_COM_CONF_CSC_DEF_FG);
+	}
+
+	ipu_srm_dp_update(priv->ipu, true);
+
+	mutex_unlock(&priv->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_setup_channel);
+
+int ipu_dp_enable(struct ipu_soc *ipu)
+{
+	struct ipu_dp_priv *priv = ipu->dp_priv;
+
+	mutex_lock(&priv->mutex);
+
+	if (!priv->use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_DP_EN);
+
+	priv->use_count++;
+
+	mutex_unlock(&priv->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_enable);
+
+int ipu_dp_enable_channel(struct ipu_dp *dp)
+{
+	struct ipu_flow *flow = to_flow(dp);
+	struct ipu_dp_priv *priv = flow->priv;
+	u32 reg;
+
+	if (!dp->foreground)
+		return 0;
+
+	mutex_lock(&priv->mutex);
+
+	reg = readl(flow->base + DP_COM_CONF);
+	reg |= DP_COM_CONF_FG_EN;
+	writel(reg, flow->base + DP_COM_CONF);
+
+	ipu_srm_dp_update(priv->ipu, true);
+
+	mutex_unlock(&priv->mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_enable_channel);
+
+void ipu_dp_disable_channel(struct ipu_dp *dp, bool sync)
+{
+	struct ipu_flow *flow = to_flow(dp);
+	struct ipu_dp_priv *priv = flow->priv;
+	u32 reg, csc;
+
+	dp->in_cs = IPUV3_COLORSPACE_UNKNOWN;
+
+	if (!dp->foreground)
+		return;
+
+	mutex_lock(&priv->mutex);
+
+	reg = readl(flow->base + DP_COM_CONF);
+	csc = reg & DP_COM_CONF_CSC_DEF_MASK;
+	reg &= ~DP_COM_CONF_CSC_DEF_MASK;
+	if (csc == DP_COM_CONF_CSC_DEF_BOTH || csc == DP_COM_CONF_CSC_DEF_BG)
+		reg |= DP_COM_CONF_CSC_DEF_BG;
+
+	reg &= ~DP_COM_CONF_FG_EN;
+	writel(reg, flow->base + DP_COM_CONF);
+
+	writel(0, flow->base + DP_FG_POS);
+	ipu_srm_dp_update(priv->ipu, sync);
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dp_disable_channel);
+
+void ipu_dp_disable(struct ipu_soc *ipu)
+{
+	struct ipu_dp_priv *priv = ipu->dp_priv;
+
+	mutex_lock(&priv->mutex);
+
+	priv->use_count--;
+
+	if (!priv->use_count)
+		ipu_module_disable(priv->ipu, IPU_CONF_DP_EN);
+
+	if (priv->use_count < 0)
+		priv->use_count = 0;
+
+	mutex_unlock(&priv->mutex);
+}
+EXPORT_SYMBOL_GPL(ipu_dp_disable);
+
+struct ipu_dp *ipu_dp_get(struct ipu_soc *ipu, unsigned int flow)
+{
+	struct ipu_dp_priv *priv = ipu->dp_priv;
+	struct ipu_dp *dp;
+
+	if ((flow >> 1) >= IPUV3_NUM_FLOWS)
+		return ERR_PTR(-EINVAL);
+
+	if (flow & 1)
+		dp = &priv->flow[flow >> 1].foreground;
+	else
+		dp = &priv->flow[flow >> 1].background;
+
+	if (dp->in_use)
+		return ERR_PTR(-EBUSY);
+
+	dp->in_use = true;
+
+	return dp;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_get);
+
+void ipu_dp_put(struct ipu_dp *dp)
+{
+	dp->in_use = false;
+}
+EXPORT_SYMBOL_GPL(ipu_dp_put);
+
+int ipu_dp_init(struct ipu_soc *ipu, struct device *dev, unsigned long base)
+{
+	struct ipu_dp_priv *priv;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+	priv->dev = dev;
+	priv->ipu = ipu;
+
+	ipu->dp_priv = priv;
+
+	priv->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!priv->base)
+		return -ENOMEM;
+
+	mutex_init(&priv->mutex);
+
+	for (i = 0; i < IPUV3_NUM_FLOWS; i++) {
+		priv->flow[i].background.in_cs = IPUV3_COLORSPACE_UNKNOWN;
+		priv->flow[i].foreground.in_cs = IPUV3_COLORSPACE_UNKNOWN;
+		priv->flow[i].foreground.foreground = true;
+		priv->flow[i].base = priv->base + ipu_dp_flow_base[i];
+		priv->flow[i].priv = priv;
+	}
+
+	return 0;
+}
+
+void ipu_dp_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-ic-csc.c b/drivers/gpu/imx/ipu-v3/ipu-ic-csc.c
new file mode 100644
index 000000000..d1ca7ba94
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-ic-csc.c
@@ -0,0 +1,409 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright (C) 2019 Mentor Graphics Inc.
+ */
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/sizes.h>
+#include "ipu-prv.h"
+
+#define QUANT_MAP(q)					\
+	((q) == V4L2_QUANTIZATION_FULL_RANGE ||		\
+	 (q) == V4L2_QUANTIZATION_DEFAULT ? 0 : 1)
+
+/* identity matrix */
+static const struct ipu_ic_csc_params identity = {
+	.coeff = {
+		{  128,    0,    0, },
+		{    0,  128,    0, },
+		{    0,    0,  128, },
+	},
+	.offset = { 0, 0, 0, },
+	.scale = 2,
+};
+
+/*
+ * RGB full-range to RGB limited-range
+ *
+ * R_lim = 0.8588 * R_full + 16
+ * G_lim = 0.8588 * G_full + 16
+ * B_lim = 0.8588 * B_full + 16
+ */
+static const struct ipu_ic_csc_params rgbf2rgbl = {
+	.coeff = {
+		{  220,    0,    0, },
+		{    0,  220,    0, },
+		{    0,    0,  220, },
+	},
+	.offset = { 64, 64, 64, },
+	.scale = 1,
+};
+
+/*
+ * RGB limited-range to RGB full-range
+ *
+ * R_full = 1.1644 * (R_lim - 16)
+ * G_full = 1.1644 * (G_lim - 16)
+ * B_full = 1.1644 * (B_lim - 16)
+ */
+static const struct ipu_ic_csc_params rgbl2rgbf = {
+	.coeff = {
+		{  149,    0,    0, },
+		{    0,  149,    0, },
+		{    0,    0,  149, },
+	},
+	.offset = { -37, -37, -37, },
+	.scale = 2,
+};
+
+/*
+ * YUV full-range to YUV limited-range
+ *
+ * Y_lim  = 0.8588 * Y_full + 16
+ * Cb_lim = 0.8784 * (Cb_full - 128) + 128
+ * Cr_lim = 0.8784 * (Cr_full - 128) + 128
+ */
+static const struct ipu_ic_csc_params yuvf2yuvl = {
+	.coeff = {
+		{  220,    0,    0, },
+		{    0,  225,    0, },
+		{    0,    0,  225, },
+	},
+	.offset = { 64, 62, 62, },
+	.scale = 1,
+	.sat = true,
+};
+
+/*
+ * YUV limited-range to YUV full-range
+ *
+ * Y_full  = 1.1644 * (Y_lim - 16)
+ * Cb_full = 1.1384 * (Cb_lim - 128) + 128
+ * Cr_full = 1.1384 * (Cr_lim - 128) + 128
+ */
+static const struct ipu_ic_csc_params yuvl2yuvf = {
+	.coeff = {
+		{  149,    0,    0, },
+		{    0,  146,    0, },
+		{    0,    0,  146, },
+	},
+	.offset = { -37, -35, -35, },
+	.scale = 2,
+};
+
+static const struct ipu_ic_csc_params *rgb2rgb[] = {
+	&identity,
+	&rgbf2rgbl,
+	&rgbl2rgbf,
+	&identity,
+};
+
+static const struct ipu_ic_csc_params *yuv2yuv[] = {
+	&identity,
+	&yuvf2yuvl,
+	&yuvl2yuvf,
+	&identity,
+};
+
+/*
+ * BT.601 RGB full-range to YUV full-range
+ *
+ * Y =  .2990 * R + .5870 * G + .1140 * B
+ * U = -.1687 * R - .3313 * G + .5000 * B + 128
+ * V =  .5000 * R - .4187 * G - .0813 * B + 128
+ */
+static const struct ipu_ic_csc_params rgbf2yuvf_601 = {
+	.coeff = {
+		{   77,  150,   29, },
+		{  -43,  -85,  128, },
+		{  128, -107,  -21, },
+	},
+	.offset = { 0, 512, 512, },
+	.scale = 1,
+};
+
+/* BT.601 RGB full-range to YUV limited-range */
+static const struct ipu_ic_csc_params rgbf2yuvl_601 = {
+	.coeff = {
+		{   66,  129,   25, },
+		{  -38,  -74,  112, },
+		{  112,  -94,  -18, },
+	},
+	.offset = { 64, 512, 512, },
+	.scale = 1,
+	.sat = true,
+};
+
+/* BT.601 RGB limited-range to YUV full-range */
+static const struct ipu_ic_csc_params rgbl2yuvf_601 = {
+	.coeff = {
+		{   89,  175,   34, },
+		{  -50,  -99,  149, },
+		{  149, -125,  -24, },
+	},
+	.offset = { -75, 512, 512, },
+	.scale = 1,
+};
+
+/* BT.601 RGB limited-range to YUV limited-range */
+static const struct ipu_ic_csc_params rgbl2yuvl_601 = {
+	.coeff = {
+		{   77,  150,   29, },
+		{  -44,  -87,  131, },
+		{  131, -110,  -21, },
+	},
+	.offset = { 0, 512, 512, },
+	.scale = 1,
+	.sat = true,
+};
+
+/*
+ * BT.601 YUV full-range to RGB full-range
+ *
+ * R = 1. * Y +      0 * (Cb - 128) + 1.4020 * (Cr - 128)
+ * G = 1. * Y -  .3441 * (Cb - 128) -  .7141 * (Cr - 128)
+ * B = 1. * Y + 1.7720 * (Cb - 128) +      0 * (Cr - 128)
+ *
+ * equivalently (factoring out the offsets):
+ *
+ * R = 1. * Y  +      0 * Cb + 1.4020 * Cr - 179.456
+ * G = 1. * Y  -  .3441 * Cb -  .7141 * Cr + 135.450
+ * B = 1. * Y  + 1.7720 * Cb +      0 * Cr - 226.816
+ */
+static const struct ipu_ic_csc_params yuvf2rgbf_601 = {
+	.coeff = {
+		{  128,    0,  179, },
+		{  128,  -44,  -91, },
+		{  128,  227,    0, },
+	},
+	.offset = { -359, 271, -454, },
+	.scale = 2,
+};
+
+/* BT.601 YUV full-range to RGB limited-range */
+static const struct ipu_ic_csc_params yuvf2rgbl_601 = {
+	.coeff = {
+		{  110,    0,  154, },
+		{  110,  -38,  -78, },
+		{  110,  195,    0, },
+	},
+	.offset = { -276, 265, -358, },
+	.scale = 2,
+};
+
+/* BT.601 YUV limited-range to RGB full-range */
+static const struct ipu_ic_csc_params yuvl2rgbf_601 = {
+	.coeff = {
+		{   75,    0,  102, },
+		{   75,  -25,  -52, },
+		{   75,  129,    0, },
+	},
+	.offset = { -223, 136, -277, },
+	.scale = 3,
+};
+
+/* BT.601 YUV limited-range to RGB limited-range */
+static const struct ipu_ic_csc_params yuvl2rgbl_601 = {
+	.coeff = {
+		{  128,    0,  175, },
+		{  128,  -43,  -89, },
+		{  128,  222,    0, },
+	},
+	.offset = { -351, 265, -443, },
+	.scale = 2,
+};
+
+static const struct ipu_ic_csc_params *rgb2yuv_601[] = {
+	&rgbf2yuvf_601,
+	&rgbf2yuvl_601,
+	&rgbl2yuvf_601,
+	&rgbl2yuvl_601,
+};
+
+static const struct ipu_ic_csc_params *yuv2rgb_601[] = {
+	&yuvf2rgbf_601,
+	&yuvf2rgbl_601,
+	&yuvl2rgbf_601,
+	&yuvl2rgbl_601,
+};
+
+/*
+ * REC.709 encoding from RGB full range to YUV full range:
+ *
+ * Y =  .2126 * R + .7152 * G + .0722 * B
+ * U = -.1146 * R - .3854 * G + .5000 * B + 128
+ * V =  .5000 * R - .4542 * G - .0458 * B + 128
+ */
+static const struct ipu_ic_csc_params rgbf2yuvf_709 = {
+	.coeff = {
+		{  54,  183,  19 },
+		{ -29,  -99, 128 },
+		{ 128, -116, -12 },
+	},
+	.offset = { 0, 512, 512 },
+	.scale = 1,
+};
+
+/* Rec.709 RGB full-range to YUV limited-range */
+static const struct ipu_ic_csc_params rgbf2yuvl_709 = {
+	.coeff = {
+		{   47,  157,   16, },
+		{  -26,  -87,  112, },
+		{  112, -102,  -10, },
+	},
+	.offset = { 64, 512, 512, },
+	.scale = 1,
+	.sat = true,
+};
+
+/* Rec.709 RGB limited-range to YUV full-range */
+static const struct ipu_ic_csc_params rgbl2yuvf_709 = {
+	.coeff = {
+		{   63,  213,   22, },
+		{  -34, -115,  149, },
+		{  149, -135,  -14, },
+	},
+	.offset = { -75, 512, 512, },
+	.scale = 1,
+};
+
+/* Rec.709 RGB limited-range to YUV limited-range */
+static const struct ipu_ic_csc_params rgbl2yuvl_709 = {
+	.coeff = {
+		{   54,  183,   18, },
+		{  -30, -101,  131, },
+		{  131, -119,  -12, },
+	},
+	.offset = { 0, 512, 512, },
+	.scale = 1,
+	.sat = true,
+};
+
+/*
+ * Inverse REC.709 encoding from YUV full range to RGB full range:
+ *
+ * R = 1. * Y +      0 * (Cb - 128) + 1.5748 * (Cr - 128)
+ * G = 1. * Y -  .1873 * (Cb - 128) -  .4681 * (Cr - 128)
+ * B = 1. * Y + 1.8556 * (Cb - 128) +      0 * (Cr - 128)
+ *
+ * equivalently (factoring out the offsets):
+ *
+ * R = 1. * Y  +      0 * Cb + 1.5748 * Cr - 201.574
+ * G = 1. * Y  -  .1873 * Cb -  .4681 * Cr +  83.891
+ * B = 1. * Y  + 1.8556 * Cb +      0 * Cr - 237.517
+ */
+static const struct ipu_ic_csc_params yuvf2rgbf_709 = {
+	.coeff = {
+		{  128,   0, 202 },
+		{  128, -24, -60 },
+		{  128, 238,   0 },
+	},
+	.offset = { -403, 168, -475 },
+	.scale = 2,
+};
+
+/* Rec.709 YUV full-range to RGB limited-range */
+static const struct ipu_ic_csc_params yuvf2rgbl_709 = {
+	.coeff = {
+		{  110,    0,  173, },
+		{  110,  -21,  -51, },
+		{  110,  204,    0, },
+	},
+	.offset = { -314, 176, -376, },
+	.scale = 2,
+};
+
+/* Rec.709 YUV limited-range to RGB full-range */
+static const struct ipu_ic_csc_params yuvl2rgbf_709 = {
+	.coeff = {
+		{   75,    0,  115, },
+		{   75,  -14,  -34, },
+		{   75,  135,    0, },
+	},
+	.offset = { -248, 77, -289, },
+	.scale = 3,
+};
+
+/* Rec.709 YUV limited-range to RGB limited-range */
+static const struct ipu_ic_csc_params yuvl2rgbl_709 = {
+	.coeff = {
+		{  128,    0,  197, },
+		{  128,  -23,  -59, },
+		{  128,  232,    0, },
+	},
+	.offset = { -394, 164, -464, },
+	.scale = 2,
+};
+
+static const struct ipu_ic_csc_params *rgb2yuv_709[] = {
+	&rgbf2yuvf_709,
+	&rgbf2yuvl_709,
+	&rgbl2yuvf_709,
+	&rgbl2yuvl_709,
+};
+
+static const struct ipu_ic_csc_params *yuv2rgb_709[] = {
+	&yuvf2rgbf_709,
+	&yuvf2rgbl_709,
+	&yuvl2rgbf_709,
+	&yuvl2rgbl_709,
+};
+
+static int calc_csc_coeffs(struct ipu_ic_csc *csc)
+{
+	const struct ipu_ic_csc_params **params_tbl;
+	int tbl_idx;
+
+	tbl_idx = (QUANT_MAP(csc->in_cs.quant) << 1) |
+		QUANT_MAP(csc->out_cs.quant);
+
+	if (csc->in_cs.cs == csc->out_cs.cs) {
+		csc->params = (csc->in_cs.cs == IPUV3_COLORSPACE_YUV) ?
+			*yuv2yuv[tbl_idx] : *rgb2rgb[tbl_idx];
+
+		return 0;
+	}
+
+	/* YUV <-> RGB encoding is required */
+
+	switch (csc->out_cs.enc) {
+	case V4L2_YCBCR_ENC_601:
+		params_tbl = (csc->in_cs.cs == IPUV3_COLORSPACE_YUV) ?
+			yuv2rgb_601 : rgb2yuv_601;
+		break;
+	case V4L2_YCBCR_ENC_709:
+		params_tbl = (csc->in_cs.cs == IPUV3_COLORSPACE_YUV) ?
+			yuv2rgb_709 : rgb2yuv_709;
+		break;
+	default:
+		return -ENOTSUPP;
+	}
+
+	csc->params = *params_tbl[tbl_idx];
+
+	return 0;
+}
+
+int __ipu_ic_calc_csc(struct ipu_ic_csc *csc)
+{
+	return calc_csc_coeffs(csc);
+}
+EXPORT_SYMBOL_GPL(__ipu_ic_calc_csc);
+
+int ipu_ic_calc_csc(struct ipu_ic_csc *csc,
+		    enum v4l2_ycbcr_encoding in_enc,
+		    enum v4l2_quantization in_quant,
+		    enum ipu_color_space in_cs,
+		    enum v4l2_ycbcr_encoding out_enc,
+		    enum v4l2_quantization out_quant,
+		    enum ipu_color_space out_cs)
+{
+	ipu_ic_fill_colorspace(&csc->in_cs, in_enc, in_quant, in_cs);
+	ipu_ic_fill_colorspace(&csc->out_cs, out_enc, out_quant, out_cs);
+
+	return __ipu_ic_calc_csc(csc);
+}
+EXPORT_SYMBOL_GPL(ipu_ic_calc_csc);
diff --git a/drivers/gpu/imx/ipu-v3/ipu-ic.c b/drivers/gpu/imx/ipu-v3/ipu-ic.c
new file mode 100644
index 000000000..846461bac
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-ic.c
@@ -0,0 +1,761 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (C) 2012-2014 Mentor Graphics Inc.
+ * Copyright 2005-2012 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/spinlock.h>
+#include <linux/bitrev.h>
+#include <linux/io.h>
+#include <linux/err.h>
+#include <linux/sizes.h>
+#include "ipu-prv.h"
+
+/* IC Register Offsets */
+#define IC_CONF                 0x0000
+#define IC_PRP_ENC_RSC          0x0004
+#define IC_PRP_VF_RSC           0x0008
+#define IC_PP_RSC               0x000C
+#define IC_CMBP_1               0x0010
+#define IC_CMBP_2               0x0014
+#define IC_IDMAC_1              0x0018
+#define IC_IDMAC_2              0x001C
+#define IC_IDMAC_3              0x0020
+#define IC_IDMAC_4              0x0024
+
+/* IC Register Fields */
+#define IC_CONF_PRPENC_EN       (1 << 0)
+#define IC_CONF_PRPENC_CSC1     (1 << 1)
+#define IC_CONF_PRPENC_ROT_EN   (1 << 2)
+#define IC_CONF_PRPVF_EN        (1 << 8)
+#define IC_CONF_PRPVF_CSC1      (1 << 9)
+#define IC_CONF_PRPVF_CSC2      (1 << 10)
+#define IC_CONF_PRPVF_CMB       (1 << 11)
+#define IC_CONF_PRPVF_ROT_EN    (1 << 12)
+#define IC_CONF_PP_EN           (1 << 16)
+#define IC_CONF_PP_CSC1         (1 << 17)
+#define IC_CONF_PP_CSC2         (1 << 18)
+#define IC_CONF_PP_CMB          (1 << 19)
+#define IC_CONF_PP_ROT_EN       (1 << 20)
+#define IC_CONF_IC_GLB_LOC_A    (1 << 28)
+#define IC_CONF_KEY_COLOR_EN    (1 << 29)
+#define IC_CONF_RWS_EN          (1 << 30)
+#define IC_CONF_CSI_MEM_WR_EN   (1 << 31)
+
+#define IC_IDMAC_1_CB0_BURST_16         (1 << 0)
+#define IC_IDMAC_1_CB1_BURST_16         (1 << 1)
+#define IC_IDMAC_1_CB2_BURST_16         (1 << 2)
+#define IC_IDMAC_1_CB3_BURST_16         (1 << 3)
+#define IC_IDMAC_1_CB4_BURST_16         (1 << 4)
+#define IC_IDMAC_1_CB5_BURST_16         (1 << 5)
+#define IC_IDMAC_1_CB6_BURST_16         (1 << 6)
+#define IC_IDMAC_1_CB7_BURST_16         (1 << 7)
+#define IC_IDMAC_1_PRPENC_ROT_MASK      (0x7 << 11)
+#define IC_IDMAC_1_PRPENC_ROT_OFFSET    11
+#define IC_IDMAC_1_PRPVF_ROT_MASK       (0x7 << 14)
+#define IC_IDMAC_1_PRPVF_ROT_OFFSET     14
+#define IC_IDMAC_1_PP_ROT_MASK          (0x7 << 17)
+#define IC_IDMAC_1_PP_ROT_OFFSET        17
+#define IC_IDMAC_1_PP_FLIP_RS           (1 << 22)
+#define IC_IDMAC_1_PRPVF_FLIP_RS        (1 << 21)
+#define IC_IDMAC_1_PRPENC_FLIP_RS       (1 << 20)
+
+#define IC_IDMAC_2_PRPENC_HEIGHT_MASK   (0x3ff << 0)
+#define IC_IDMAC_2_PRPENC_HEIGHT_OFFSET 0
+#define IC_IDMAC_2_PRPVF_HEIGHT_MASK    (0x3ff << 10)
+#define IC_IDMAC_2_PRPVF_HEIGHT_OFFSET  10
+#define IC_IDMAC_2_PP_HEIGHT_MASK       (0x3ff << 20)
+#define IC_IDMAC_2_PP_HEIGHT_OFFSET     20
+
+#define IC_IDMAC_3_PRPENC_WIDTH_MASK    (0x3ff << 0)
+#define IC_IDMAC_3_PRPENC_WIDTH_OFFSET  0
+#define IC_IDMAC_3_PRPVF_WIDTH_MASK     (0x3ff << 10)
+#define IC_IDMAC_3_PRPVF_WIDTH_OFFSET   10
+#define IC_IDMAC_3_PP_WIDTH_MASK        (0x3ff << 20)
+#define IC_IDMAC_3_PP_WIDTH_OFFSET      20
+
+struct ic_task_regoffs {
+	u32 rsc;
+	u32 tpmem_csc[2];
+};
+
+struct ic_task_bitfields {
+	u32 ic_conf_en;
+	u32 ic_conf_rot_en;
+	u32 ic_conf_cmb_en;
+	u32 ic_conf_csc1_en;
+	u32 ic_conf_csc2_en;
+	u32 ic_cmb_galpha_bit;
+};
+
+static const struct ic_task_regoffs ic_task_reg[IC_NUM_TASKS] = {
+	[IC_TASK_ENCODER] = {
+		.rsc = IC_PRP_ENC_RSC,
+		.tpmem_csc = {0x2008, 0},
+	},
+	[IC_TASK_VIEWFINDER] = {
+		.rsc = IC_PRP_VF_RSC,
+		.tpmem_csc = {0x4028, 0x4040},
+	},
+	[IC_TASK_POST_PROCESSOR] = {
+		.rsc = IC_PP_RSC,
+		.tpmem_csc = {0x6060, 0x6078},
+	},
+};
+
+static const struct ic_task_bitfields ic_task_bit[IC_NUM_TASKS] = {
+	[IC_TASK_ENCODER] = {
+		.ic_conf_en = IC_CONF_PRPENC_EN,
+		.ic_conf_rot_en = IC_CONF_PRPENC_ROT_EN,
+		.ic_conf_cmb_en = 0,    /* NA */
+		.ic_conf_csc1_en = IC_CONF_PRPENC_CSC1,
+		.ic_conf_csc2_en = 0,   /* NA */
+		.ic_cmb_galpha_bit = 0, /* NA */
+	},
+	[IC_TASK_VIEWFINDER] = {
+		.ic_conf_en = IC_CONF_PRPVF_EN,
+		.ic_conf_rot_en = IC_CONF_PRPVF_ROT_EN,
+		.ic_conf_cmb_en = IC_CONF_PRPVF_CMB,
+		.ic_conf_csc1_en = IC_CONF_PRPVF_CSC1,
+		.ic_conf_csc2_en = IC_CONF_PRPVF_CSC2,
+		.ic_cmb_galpha_bit = 0,
+	},
+	[IC_TASK_POST_PROCESSOR] = {
+		.ic_conf_en = IC_CONF_PP_EN,
+		.ic_conf_rot_en = IC_CONF_PP_ROT_EN,
+		.ic_conf_cmb_en = IC_CONF_PP_CMB,
+		.ic_conf_csc1_en = IC_CONF_PP_CSC1,
+		.ic_conf_csc2_en = IC_CONF_PP_CSC2,
+		.ic_cmb_galpha_bit = 8,
+	},
+};
+
+struct ipu_ic_priv;
+
+struct ipu_ic {
+	enum ipu_ic_task task;
+	const struct ic_task_regoffs *reg;
+	const struct ic_task_bitfields *bit;
+
+	struct ipu_ic_colorspace in_cs;
+	struct ipu_ic_colorspace g_in_cs;
+	struct ipu_ic_colorspace out_cs;
+
+	bool graphics;
+	bool rotation;
+	bool in_use;
+
+	struct ipu_ic_priv *priv;
+};
+
+struct ipu_ic_priv {
+	void __iomem *base;
+	void __iomem *tpmem_base;
+	spinlock_t lock;
+	struct ipu_soc *ipu;
+	int use_count;
+	int irt_use_count;
+	struct ipu_ic task[IC_NUM_TASKS];
+};
+
+static inline u32 ipu_ic_read(struct ipu_ic *ic, unsigned offset)
+{
+	return readl(ic->priv->base + offset);
+}
+
+static inline void ipu_ic_write(struct ipu_ic *ic, u32 value, unsigned offset)
+{
+	writel(value, ic->priv->base + offset);
+}
+
+static int init_csc(struct ipu_ic *ic,
+		    const struct ipu_ic_csc *csc,
+		    int csc_index)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	u32 __iomem *base;
+	const u16 (*c)[3];
+	const u16 *a;
+	u32 param;
+
+	base = (u32 __iomem *)
+		(priv->tpmem_base + ic->reg->tpmem_csc[csc_index]);
+
+	/* Cast to unsigned */
+	c = (const u16 (*)[3])csc->params.coeff;
+	a = (const u16 *)csc->params.offset;
+
+	param = ((a[0] & 0x1f) << 27) | ((c[0][0] & 0x1ff) << 18) |
+		((c[1][1] & 0x1ff) << 9) | (c[2][2] & 0x1ff);
+	writel(param, base++);
+
+	param = ((a[0] & 0x1fe0) >> 5) | (csc->params.scale << 8) |
+		(csc->params.sat << 10);
+	writel(param, base++);
+
+	param = ((a[1] & 0x1f) << 27) | ((c[0][1] & 0x1ff) << 18) |
+		((c[1][0] & 0x1ff) << 9) | (c[2][0] & 0x1ff);
+	writel(param, base++);
+
+	param = ((a[1] & 0x1fe0) >> 5);
+	writel(param, base++);
+
+	param = ((a[2] & 0x1f) << 27) | ((c[0][2] & 0x1ff) << 18) |
+		((c[1][2] & 0x1ff) << 9) | (c[2][1] & 0x1ff);
+	writel(param, base++);
+
+	param = ((a[2] & 0x1fe0) >> 5);
+	writel(param, base++);
+
+	return 0;
+}
+
+static int calc_resize_coeffs(struct ipu_ic *ic,
+			      u32 in_size, u32 out_size,
+			      u32 *resize_coeff,
+			      u32 *downsize_coeff)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	struct ipu_soc *ipu = priv->ipu;
+	u32 temp_size, temp_downsize;
+
+	/*
+	 * Input size cannot be more than 4096, and output size cannot
+	 * be more than 1024
+	 */
+	if (in_size > 4096) {
+		dev_err(ipu->dev, "Unsupported resize (in_size > 4096)\n");
+		return -EINVAL;
+	}
+	if (out_size > 1024) {
+		dev_err(ipu->dev, "Unsupported resize (out_size > 1024)\n");
+		return -EINVAL;
+	}
+
+	/* Cannot downsize more than 4:1 */
+	if ((out_size << 2) < in_size) {
+		dev_err(ipu->dev, "Unsupported downsize\n");
+		return -EINVAL;
+	}
+
+	/* Compute downsizing coefficient */
+	temp_downsize = 0;
+	temp_size = in_size;
+	while (((temp_size > 1024) || (temp_size >= out_size * 2)) &&
+	       (temp_downsize < 2)) {
+		temp_size >>= 1;
+		temp_downsize++;
+	}
+	*downsize_coeff = temp_downsize;
+
+	/*
+	 * compute resizing coefficient using the following equation:
+	 * resize_coeff = M * (SI - 1) / (SO - 1)
+	 * where M = 2^13, SI = input size, SO = output size
+	 */
+	*resize_coeff = (8192L * (temp_size - 1)) / (out_size - 1);
+	if (*resize_coeff >= 16384L) {
+		dev_err(ipu->dev, "Warning! Overflow on resize coeff.\n");
+		*resize_coeff = 0x3FFF;
+	}
+
+	return 0;
+}
+
+void ipu_ic_task_enable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	unsigned long flags;
+	u32 ic_conf;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ic_conf = ipu_ic_read(ic, IC_CONF);
+
+	ic_conf |= ic->bit->ic_conf_en;
+
+	if (ic->rotation)
+		ic_conf |= ic->bit->ic_conf_rot_en;
+
+	if (ic->in_cs.cs != ic->out_cs.cs)
+		ic_conf |= ic->bit->ic_conf_csc1_en;
+
+	if (ic->graphics) {
+		ic_conf |= ic->bit->ic_conf_cmb_en;
+		ic_conf |= ic->bit->ic_conf_csc1_en;
+
+		if (ic->g_in_cs.cs != ic->out_cs.cs)
+			ic_conf |= ic->bit->ic_conf_csc2_en;
+	}
+
+	ipu_ic_write(ic, ic_conf, IC_CONF);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_ic_task_enable);
+
+void ipu_ic_task_disable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	unsigned long flags;
+	u32 ic_conf;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ic_conf = ipu_ic_read(ic, IC_CONF);
+
+	ic_conf &= ~(ic->bit->ic_conf_en |
+		     ic->bit->ic_conf_csc1_en |
+		     ic->bit->ic_conf_rot_en);
+	if (ic->bit->ic_conf_csc2_en)
+		ic_conf &= ~ic->bit->ic_conf_csc2_en;
+	if (ic->bit->ic_conf_cmb_en)
+		ic_conf &= ~ic->bit->ic_conf_cmb_en;
+
+	ipu_ic_write(ic, ic_conf, IC_CONF);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_ic_task_disable);
+
+int ipu_ic_task_graphics_init(struct ipu_ic *ic,
+			      const struct ipu_ic_colorspace *g_in_cs,
+			      bool galpha_en, u32 galpha,
+			      bool colorkey_en, u32 colorkey)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	struct ipu_ic_csc csc2;
+	unsigned long flags;
+	u32 reg, ic_conf;
+	int ret = 0;
+
+	if (ic->task == IC_TASK_ENCODER)
+		return -EINVAL;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ic_conf = ipu_ic_read(ic, IC_CONF);
+
+	if (!(ic_conf & ic->bit->ic_conf_csc1_en)) {
+		struct ipu_ic_csc csc1;
+
+		ret = ipu_ic_calc_csc(&csc1,
+				      V4L2_YCBCR_ENC_601,
+				      V4L2_QUANTIZATION_FULL_RANGE,
+				      IPUV3_COLORSPACE_RGB,
+				      V4L2_YCBCR_ENC_601,
+				      V4L2_QUANTIZATION_FULL_RANGE,
+				      IPUV3_COLORSPACE_RGB);
+		if (ret)
+			goto unlock;
+
+		/* need transparent CSC1 conversion */
+		ret = init_csc(ic, &csc1, 0);
+		if (ret)
+			goto unlock;
+	}
+
+	ic->g_in_cs = *g_in_cs;
+	csc2.in_cs = ic->g_in_cs;
+	csc2.out_cs = ic->out_cs;
+
+	ret = __ipu_ic_calc_csc(&csc2);
+	if (ret)
+		goto unlock;
+
+	ret = init_csc(ic, &csc2, 1);
+	if (ret)
+		goto unlock;
+
+	if (galpha_en) {
+		ic_conf |= IC_CONF_IC_GLB_LOC_A;
+		reg = ipu_ic_read(ic, IC_CMBP_1);
+		reg &= ~(0xff << ic->bit->ic_cmb_galpha_bit);
+		reg |= (galpha << ic->bit->ic_cmb_galpha_bit);
+		ipu_ic_write(ic, reg, IC_CMBP_1);
+	} else
+		ic_conf &= ~IC_CONF_IC_GLB_LOC_A;
+
+	if (colorkey_en) {
+		ic_conf |= IC_CONF_KEY_COLOR_EN;
+		ipu_ic_write(ic, colorkey, IC_CMBP_2);
+	} else
+		ic_conf &= ~IC_CONF_KEY_COLOR_EN;
+
+	ipu_ic_write(ic, ic_conf, IC_CONF);
+
+	ic->graphics = true;
+unlock:
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_ic_task_graphics_init);
+
+int ipu_ic_task_init_rsc(struct ipu_ic *ic,
+			 const struct ipu_ic_csc *csc,
+			 int in_width, int in_height,
+			 int out_width, int out_height,
+			 u32 rsc)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	u32 downsize_coeff, resize_coeff;
+	unsigned long flags;
+	int ret = 0;
+
+	if (!rsc) {
+		/* Setup vertical resizing */
+
+		ret = calc_resize_coeffs(ic, in_height, out_height,
+					 &resize_coeff, &downsize_coeff);
+		if (ret)
+			return ret;
+
+		rsc = (downsize_coeff << 30) | (resize_coeff << 16);
+
+		/* Setup horizontal resizing */
+		ret = calc_resize_coeffs(ic, in_width, out_width,
+					 &resize_coeff, &downsize_coeff);
+		if (ret)
+			return ret;
+
+		rsc |= (downsize_coeff << 14) | resize_coeff;
+	}
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ipu_ic_write(ic, rsc, ic->reg->rsc);
+
+	/* Setup color space conversion */
+	ic->in_cs = csc->in_cs;
+	ic->out_cs = csc->out_cs;
+
+	ret = init_csc(ic, csc, 0);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+
+int ipu_ic_task_init(struct ipu_ic *ic,
+		     const struct ipu_ic_csc *csc,
+		     int in_width, int in_height,
+		     int out_width, int out_height)
+{
+	return ipu_ic_task_init_rsc(ic, csc,
+				    in_width, in_height,
+				    out_width, out_height, 0);
+}
+EXPORT_SYMBOL_GPL(ipu_ic_task_init);
+
+int ipu_ic_task_idma_init(struct ipu_ic *ic, struct ipuv3_channel *channel,
+			  u32 width, u32 height, int burst_size,
+			  enum ipu_rotate_mode rot)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	struct ipu_soc *ipu = priv->ipu;
+	u32 ic_idmac_1, ic_idmac_2, ic_idmac_3;
+	u32 temp_rot = bitrev8(rot) >> 5;
+	bool need_hor_flip = false;
+	unsigned long flags;
+	int ret = 0;
+
+	if ((burst_size != 8) && (burst_size != 16)) {
+		dev_err(ipu->dev, "Illegal burst length for IC\n");
+		return -EINVAL;
+	}
+
+	width--;
+	height--;
+
+	if (temp_rot & 0x2)	/* Need horizontal flip */
+		need_hor_flip = true;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ic_idmac_1 = ipu_ic_read(ic, IC_IDMAC_1);
+	ic_idmac_2 = ipu_ic_read(ic, IC_IDMAC_2);
+	ic_idmac_3 = ipu_ic_read(ic, IC_IDMAC_3);
+
+	switch (channel->num) {
+	case IPUV3_CHANNEL_IC_PP_MEM:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB2_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB2_BURST_16;
+
+		if (need_hor_flip)
+			ic_idmac_1 |= IC_IDMAC_1_PP_FLIP_RS;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_PP_FLIP_RS;
+
+		ic_idmac_2 &= ~IC_IDMAC_2_PP_HEIGHT_MASK;
+		ic_idmac_2 |= height << IC_IDMAC_2_PP_HEIGHT_OFFSET;
+
+		ic_idmac_3 &= ~IC_IDMAC_3_PP_WIDTH_MASK;
+		ic_idmac_3 |= width << IC_IDMAC_3_PP_WIDTH_OFFSET;
+		break;
+	case IPUV3_CHANNEL_MEM_IC_PP:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB5_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB5_BURST_16;
+		break;
+	case IPUV3_CHANNEL_MEM_ROT_PP:
+		ic_idmac_1 &= ~IC_IDMAC_1_PP_ROT_MASK;
+		ic_idmac_1 |= temp_rot << IC_IDMAC_1_PP_ROT_OFFSET;
+		break;
+	case IPUV3_CHANNEL_MEM_IC_PRP_VF:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB6_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB6_BURST_16;
+		break;
+	case IPUV3_CHANNEL_IC_PRP_ENC_MEM:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB0_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB0_BURST_16;
+
+		if (need_hor_flip)
+			ic_idmac_1 |= IC_IDMAC_1_PRPENC_FLIP_RS;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_PRPENC_FLIP_RS;
+
+		ic_idmac_2 &= ~IC_IDMAC_2_PRPENC_HEIGHT_MASK;
+		ic_idmac_2 |= height << IC_IDMAC_2_PRPENC_HEIGHT_OFFSET;
+
+		ic_idmac_3 &= ~IC_IDMAC_3_PRPENC_WIDTH_MASK;
+		ic_idmac_3 |= width << IC_IDMAC_3_PRPENC_WIDTH_OFFSET;
+		break;
+	case IPUV3_CHANNEL_MEM_ROT_ENC:
+		ic_idmac_1 &= ~IC_IDMAC_1_PRPENC_ROT_MASK;
+		ic_idmac_1 |= temp_rot << IC_IDMAC_1_PRPENC_ROT_OFFSET;
+		break;
+	case IPUV3_CHANNEL_IC_PRP_VF_MEM:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB1_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB1_BURST_16;
+
+		if (need_hor_flip)
+			ic_idmac_1 |= IC_IDMAC_1_PRPVF_FLIP_RS;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_PRPVF_FLIP_RS;
+
+		ic_idmac_2 &= ~IC_IDMAC_2_PRPVF_HEIGHT_MASK;
+		ic_idmac_2 |= height << IC_IDMAC_2_PRPVF_HEIGHT_OFFSET;
+
+		ic_idmac_3 &= ~IC_IDMAC_3_PRPVF_WIDTH_MASK;
+		ic_idmac_3 |= width << IC_IDMAC_3_PRPVF_WIDTH_OFFSET;
+		break;
+	case IPUV3_CHANNEL_MEM_ROT_VF:
+		ic_idmac_1 &= ~IC_IDMAC_1_PRPVF_ROT_MASK;
+		ic_idmac_1 |= temp_rot << IC_IDMAC_1_PRPVF_ROT_OFFSET;
+		break;
+	case IPUV3_CHANNEL_G_MEM_IC_PRP_VF:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB3_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB3_BURST_16;
+		break;
+	case IPUV3_CHANNEL_G_MEM_IC_PP:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB4_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB4_BURST_16;
+		break;
+	case IPUV3_CHANNEL_VDI_MEM_IC_VF:
+		if (burst_size == 16)
+			ic_idmac_1 |= IC_IDMAC_1_CB7_BURST_16;
+		else
+			ic_idmac_1 &= ~IC_IDMAC_1_CB7_BURST_16;
+		break;
+	default:
+		goto unlock;
+	}
+
+	ipu_ic_write(ic, ic_idmac_1, IC_IDMAC_1);
+	ipu_ic_write(ic, ic_idmac_2, IC_IDMAC_2);
+	ipu_ic_write(ic, ic_idmac_3, IC_IDMAC_3);
+
+	if (ipu_rot_mode_is_irt(rot))
+		ic->rotation = true;
+
+unlock:
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_ic_task_idma_init);
+
+static void ipu_irt_enable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+
+	if (!priv->irt_use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_ROT_EN);
+
+	priv->irt_use_count++;
+}
+
+static void ipu_irt_disable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+
+	if (priv->irt_use_count) {
+		if (!--priv->irt_use_count)
+			ipu_module_disable(priv->ipu, IPU_CONF_ROT_EN);
+	}
+}
+
+int ipu_ic_enable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	if (!priv->use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_IC_EN);
+
+	priv->use_count++;
+
+	if (ic->rotation)
+		ipu_irt_enable(ic);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_ic_enable);
+
+int ipu_ic_disable(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	priv->use_count--;
+
+	if (!priv->use_count)
+		ipu_module_disable(priv->ipu, IPU_CONF_IC_EN);
+
+	if (priv->use_count < 0)
+		priv->use_count = 0;
+
+	if (ic->rotation)
+		ipu_irt_disable(ic);
+
+	ic->rotation = ic->graphics = false;
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_ic_disable);
+
+struct ipu_ic *ipu_ic_get(struct ipu_soc *ipu, enum ipu_ic_task task)
+{
+	struct ipu_ic_priv *priv = ipu->ic_priv;
+	unsigned long flags;
+	struct ipu_ic *ic, *ret;
+
+	if (task >= IC_NUM_TASKS)
+		return ERR_PTR(-EINVAL);
+
+	ic = &priv->task[task];
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	if (ic->in_use) {
+		ret = ERR_PTR(-EBUSY);
+		goto unlock;
+	}
+
+	ic->in_use = true;
+	ret = ic;
+
+unlock:
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_ic_get);
+
+void ipu_ic_put(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	ic->in_use = false;
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_ic_put);
+
+int ipu_ic_init(struct ipu_soc *ipu, struct device *dev,
+		unsigned long base, unsigned long tpmem_base)
+{
+	struct ipu_ic_priv *priv;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	ipu->ic_priv = priv;
+
+	spin_lock_init(&priv->lock);
+	priv->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!priv->base)
+		return -ENOMEM;
+	priv->tpmem_base = devm_ioremap(dev, tpmem_base, SZ_64K);
+	if (!priv->tpmem_base)
+		return -ENOMEM;
+
+	dev_dbg(dev, "IC base: 0x%08lx remapped to %p\n", base, priv->base);
+
+	priv->ipu = ipu;
+
+	for (i = 0; i < IC_NUM_TASKS; i++) {
+		priv->task[i].task = i;
+		priv->task[i].priv = priv;
+		priv->task[i].reg = &ic_task_reg[i];
+		priv->task[i].bit = &ic_task_bit[i];
+	}
+
+	return 0;
+}
+
+void ipu_ic_exit(struct ipu_soc *ipu)
+{
+}
+
+void ipu_ic_dump(struct ipu_ic *ic)
+{
+	struct ipu_ic_priv *priv = ic->priv;
+	struct ipu_soc *ipu = priv->ipu;
+
+	dev_dbg(ipu->dev, "IC_CONF = \t0x%08X\n",
+		ipu_ic_read(ic, IC_CONF));
+	dev_dbg(ipu->dev, "IC_PRP_ENC_RSC = \t0x%08X\n",
+		ipu_ic_read(ic, IC_PRP_ENC_RSC));
+	dev_dbg(ipu->dev, "IC_PRP_VF_RSC = \t0x%08X\n",
+		ipu_ic_read(ic, IC_PRP_VF_RSC));
+	dev_dbg(ipu->dev, "IC_PP_RSC = \t0x%08X\n",
+		ipu_ic_read(ic, IC_PP_RSC));
+	dev_dbg(ipu->dev, "IC_CMBP_1 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_CMBP_1));
+	dev_dbg(ipu->dev, "IC_CMBP_2 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_CMBP_2));
+	dev_dbg(ipu->dev, "IC_IDMAC_1 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_IDMAC_1));
+	dev_dbg(ipu->dev, "IC_IDMAC_2 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_IDMAC_2));
+	dev_dbg(ipu->dev, "IC_IDMAC_3 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_IDMAC_3));
+	dev_dbg(ipu->dev, "IC_IDMAC_4 = \t0x%08X\n",
+		ipu_ic_read(ic, IC_IDMAC_4));
+}
+EXPORT_SYMBOL_GPL(ipu_ic_dump);
diff --git a/drivers/gpu/imx/ipu-v3/ipu-image-convert.c b/drivers/gpu/imx/ipu-v3/ipu-image-convert.c
new file mode 100644
index 000000000..aa1d4b6d2
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-image-convert.c
@@ -0,0 +1,2512 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (C) 2012-2016 Mentor Graphics Inc.
+ *
+ * Queued image conversion support, with tiling and rotation.
+ */
+
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <video/imx-ipu-image-convert.h>
+#include "ipu-prv.h"
+
+/*
+ * The IC Resizer has a restriction that the output frame from the
+ * resizer must be 1024 or less in both width (pixels) and height
+ * (lines).
+ *
+ * The image converter attempts to split up a conversion when
+ * the desired output (converted) frame resolution exceeds the
+ * IC resizer limit of 1024 in either dimension.
+ *
+ * If either dimension of the output frame exceeds the limit, the
+ * dimension is split into 1, 2, or 4 equal stripes, for a maximum
+ * of 4*4 or 16 tiles. A conversion is then carried out for each
+ * tile (but taking care to pass the full frame stride length to
+ * the DMA channel's parameter memory!). IDMA double-buffering is used
+ * to convert each tile back-to-back when possible (see note below
+ * when double_buffering boolean is set).
+ *
+ * Note that the input frame must be split up into the same number
+ * of tiles as the output frame:
+ *
+ *                       +---------+-----+
+ *   +-----+---+         |  A      | B   |
+ *   | A   | B |         |         |     |
+ *   +-----+---+   -->   +---------+-----+
+ *   | C   | D |         |  C      | D   |
+ *   +-----+---+         |         |     |
+ *                       +---------+-----+
+ *
+ * Clockwise 90° rotations are handled by first rescaling into a
+ * reusable temporary tile buffer and then rotating with the 8x8
+ * block rotator, writing to the correct destination:
+ *
+ *                                         +-----+-----+
+ *                                         |     |     |
+ *   +-----+---+         +---------+       | C   | A   |
+ *   | A   | B |         | A,B, |  |       |     |     |
+ *   +-----+---+   -->   | C,D  |  |  -->  |     |     |
+ *   | C   | D |         +---------+       +-----+-----+
+ *   +-----+---+                           | D   | B   |
+ *                                         |     |     |
+ *                                         +-----+-----+
+ *
+ * If the 8x8 block rotator is used, horizontal or vertical flipping
+ * is done during the rotation step, otherwise flipping is done
+ * during the scaling step.
+ * With rotation or flipping, tile order changes between input and
+ * output image. Tiles are numbered row major from top left to bottom
+ * right for both input and output image.
+ */
+
+#define MAX_STRIPES_W    4
+#define MAX_STRIPES_H    4
+#define MAX_TILES (MAX_STRIPES_W * MAX_STRIPES_H)
+
+#define MIN_W     16
+#define MIN_H     8
+#define MAX_W     4096
+#define MAX_H     4096
+
+enum ipu_image_convert_type {
+	IMAGE_CONVERT_IN = 0,
+	IMAGE_CONVERT_OUT,
+};
+
+struct ipu_image_convert_dma_buf {
+	void          *virt;
+	dma_addr_t    phys;
+	unsigned long len;
+};
+
+struct ipu_image_convert_dma_chan {
+	int in;
+	int out;
+	int rot_in;
+	int rot_out;
+	int vdi_in_p;
+	int vdi_in;
+	int vdi_in_n;
+};
+
+/* dimensions of one tile */
+struct ipu_image_tile {
+	u32 width;
+	u32 height;
+	u32 left;
+	u32 top;
+	/* size and strides are in bytes */
+	u32 size;
+	u32 stride;
+	u32 rot_stride;
+	/* start Y or packed offset of this tile */
+	u32 offset;
+	/* offset from start to tile in U plane, for planar formats */
+	u32 u_off;
+	/* offset from start to tile in V plane, for planar formats */
+	u32 v_off;
+};
+
+struct ipu_image_convert_image {
+	struct ipu_image base;
+	enum ipu_image_convert_type type;
+
+	const struct ipu_image_pixfmt *fmt;
+	unsigned int stride;
+
+	/* # of rows (horizontal stripes) if dest height is > 1024 */
+	unsigned int num_rows;
+	/* # of columns (vertical stripes) if dest width is > 1024 */
+	unsigned int num_cols;
+
+	struct ipu_image_tile tile[MAX_TILES];
+};
+
+struct ipu_image_pixfmt {
+	u32	fourcc;        /* V4L2 fourcc */
+	int     bpp;           /* total bpp */
+	int     uv_width_dec;  /* decimation in width for U/V planes */
+	int     uv_height_dec; /* decimation in height for U/V planes */
+	bool    planar;        /* planar format */
+	bool    uv_swapped;    /* U and V planes are swapped */
+	bool    uv_packed;     /* partial planar (U and V in same plane) */
+};
+
+struct ipu_image_convert_ctx;
+struct ipu_image_convert_chan;
+struct ipu_image_convert_priv;
+
+enum eof_irq_mask {
+	EOF_IRQ_IN      = BIT(0),
+	EOF_IRQ_ROT_IN  = BIT(1),
+	EOF_IRQ_OUT     = BIT(2),
+	EOF_IRQ_ROT_OUT = BIT(3),
+};
+
+#define EOF_IRQ_COMPLETE (EOF_IRQ_IN | EOF_IRQ_OUT)
+#define EOF_IRQ_ROT_COMPLETE (EOF_IRQ_IN | EOF_IRQ_OUT |	\
+			      EOF_IRQ_ROT_IN | EOF_IRQ_ROT_OUT)
+
+struct ipu_image_convert_ctx {
+	struct ipu_image_convert_chan *chan;
+
+	ipu_image_convert_cb_t complete;
+	void *complete_context;
+
+	/* Source/destination image data and rotation mode */
+	struct ipu_image_convert_image in;
+	struct ipu_image_convert_image out;
+	struct ipu_ic_csc csc;
+	enum ipu_rotate_mode rot_mode;
+	u32 downsize_coeff_h;
+	u32 downsize_coeff_v;
+	u32 image_resize_coeff_h;
+	u32 image_resize_coeff_v;
+	u32 resize_coeffs_h[MAX_STRIPES_W];
+	u32 resize_coeffs_v[MAX_STRIPES_H];
+
+	/* intermediate buffer for rotation */
+	struct ipu_image_convert_dma_buf rot_intermediate[2];
+
+	/* current buffer number for double buffering */
+	int cur_buf_num;
+
+	bool aborting;
+	struct completion aborted;
+
+	/* can we use double-buffering for this conversion operation? */
+	bool double_buffering;
+	/* num_rows * num_cols */
+	unsigned int num_tiles;
+	/* next tile to process */
+	unsigned int next_tile;
+	/* where to place converted tile in dest image */
+	unsigned int out_tile_map[MAX_TILES];
+
+	/* mask of completed EOF irqs at every tile conversion */
+	enum eof_irq_mask eof_mask;
+
+	struct list_head list;
+};
+
+struct ipu_image_convert_chan {
+	struct ipu_image_convert_priv *priv;
+
+	enum ipu_ic_task ic_task;
+	const struct ipu_image_convert_dma_chan *dma_ch;
+
+	struct ipu_ic *ic;
+	struct ipuv3_channel *in_chan;
+	struct ipuv3_channel *out_chan;
+	struct ipuv3_channel *rotation_in_chan;
+	struct ipuv3_channel *rotation_out_chan;
+
+	/* the IPU end-of-frame irqs */
+	int in_eof_irq;
+	int rot_in_eof_irq;
+	int out_eof_irq;
+	int rot_out_eof_irq;
+
+	spinlock_t irqlock;
+
+	/* list of convert contexts */
+	struct list_head ctx_list;
+	/* queue of conversion runs */
+	struct list_head pending_q;
+	/* queue of completed runs */
+	struct list_head done_q;
+
+	/* the current conversion run */
+	struct ipu_image_convert_run *current_run;
+};
+
+struct ipu_image_convert_priv {
+	struct ipu_image_convert_chan chan[IC_NUM_TASKS];
+	struct ipu_soc *ipu;
+};
+
+static const struct ipu_image_convert_dma_chan
+image_convert_dma_chan[IC_NUM_TASKS] = {
+	[IC_TASK_VIEWFINDER] = {
+		.in = IPUV3_CHANNEL_MEM_IC_PRP_VF,
+		.out = IPUV3_CHANNEL_IC_PRP_VF_MEM,
+		.rot_in = IPUV3_CHANNEL_MEM_ROT_VF,
+		.rot_out = IPUV3_CHANNEL_ROT_VF_MEM,
+		.vdi_in_p = IPUV3_CHANNEL_MEM_VDI_PREV,
+		.vdi_in = IPUV3_CHANNEL_MEM_VDI_CUR,
+		.vdi_in_n = IPUV3_CHANNEL_MEM_VDI_NEXT,
+	},
+	[IC_TASK_POST_PROCESSOR] = {
+		.in = IPUV3_CHANNEL_MEM_IC_PP,
+		.out = IPUV3_CHANNEL_IC_PP_MEM,
+		.rot_in = IPUV3_CHANNEL_MEM_ROT_PP,
+		.rot_out = IPUV3_CHANNEL_ROT_PP_MEM,
+	},
+};
+
+static const struct ipu_image_pixfmt image_convert_formats[] = {
+	{
+		.fourcc	= V4L2_PIX_FMT_RGB565,
+		.bpp    = 16,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_RGB24,
+		.bpp    = 24,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_BGR24,
+		.bpp    = 24,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_RGB32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_BGR32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_XRGB32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_XBGR32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_BGRX32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_RGBX32,
+		.bpp    = 32,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_YUYV,
+		.bpp    = 16,
+		.uv_width_dec = 2,
+		.uv_height_dec = 1,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_UYVY,
+		.bpp    = 16,
+		.uv_width_dec = 2,
+		.uv_height_dec = 1,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_YUV420,
+		.bpp    = 12,
+		.planar = true,
+		.uv_width_dec = 2,
+		.uv_height_dec = 2,
+	}, {
+		.fourcc	= V4L2_PIX_FMT_YVU420,
+		.bpp    = 12,
+		.planar = true,
+		.uv_width_dec = 2,
+		.uv_height_dec = 2,
+		.uv_swapped = true,
+	}, {
+		.fourcc = V4L2_PIX_FMT_NV12,
+		.bpp    = 12,
+		.planar = true,
+		.uv_width_dec = 2,
+		.uv_height_dec = 2,
+		.uv_packed = true,
+	}, {
+		.fourcc = V4L2_PIX_FMT_YUV422P,
+		.bpp    = 16,
+		.planar = true,
+		.uv_width_dec = 2,
+		.uv_height_dec = 1,
+	}, {
+		.fourcc = V4L2_PIX_FMT_NV16,
+		.bpp    = 16,
+		.planar = true,
+		.uv_width_dec = 2,
+		.uv_height_dec = 1,
+		.uv_packed = true,
+	},
+};
+
+static const struct ipu_image_pixfmt *get_format(u32 fourcc)
+{
+	const struct ipu_image_pixfmt *ret = NULL;
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(image_convert_formats); i++) {
+		if (image_convert_formats[i].fourcc == fourcc) {
+			ret = &image_convert_formats[i];
+			break;
+		}
+	}
+
+	return ret;
+}
+
+static void dump_format(struct ipu_image_convert_ctx *ctx,
+			struct ipu_image_convert_image *ic_image)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+
+	dev_dbg(priv->ipu->dev,
+		"task %u: ctx %p: %s format: %dx%d (%dx%d tiles), %c%c%c%c\n",
+		chan->ic_task, ctx,
+		ic_image->type == IMAGE_CONVERT_OUT ? "Output" : "Input",
+		ic_image->base.pix.width, ic_image->base.pix.height,
+		ic_image->num_cols, ic_image->num_rows,
+		ic_image->fmt->fourcc & 0xff,
+		(ic_image->fmt->fourcc >> 8) & 0xff,
+		(ic_image->fmt->fourcc >> 16) & 0xff,
+		(ic_image->fmt->fourcc >> 24) & 0xff);
+}
+
+int ipu_image_convert_enum_format(int index, u32 *fourcc)
+{
+	const struct ipu_image_pixfmt *fmt;
+
+	if (index >= (int)ARRAY_SIZE(image_convert_formats))
+		return -EINVAL;
+
+	/* Format found */
+	fmt = &image_convert_formats[index];
+	*fourcc = fmt->fourcc;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_enum_format);
+
+static void free_dma_buf(struct ipu_image_convert_priv *priv,
+			 struct ipu_image_convert_dma_buf *buf)
+{
+	if (buf->virt)
+		dma_free_coherent(priv->ipu->dev,
+				  buf->len, buf->virt, buf->phys);
+	buf->virt = NULL;
+	buf->phys = 0;
+}
+
+static int alloc_dma_buf(struct ipu_image_convert_priv *priv,
+			 struct ipu_image_convert_dma_buf *buf,
+			 int size)
+{
+	buf->len = PAGE_ALIGN(size);
+	buf->virt = dma_alloc_coherent(priv->ipu->dev, buf->len, &buf->phys,
+				       GFP_DMA | GFP_KERNEL);
+	if (!buf->virt) {
+		dev_err(priv->ipu->dev, "failed to alloc dma buffer\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static inline int num_stripes(int dim)
+{
+	return (dim - 1) / 1024 + 1;
+}
+
+/*
+ * Calculate downsizing coefficients, which are the same for all tiles,
+ * and initial bilinear resizing coefficients, which are used to find the
+ * best seam positions.
+ * Also determine the number of tiles necessary to guarantee that no tile
+ * is larger than 1024 pixels in either dimension at the output and between
+ * IC downsizing and main processing sections.
+ */
+static int calc_image_resize_coefficients(struct ipu_image_convert_ctx *ctx,
+					  struct ipu_image *in,
+					  struct ipu_image *out)
+{
+	u32 downsized_width = in->rect.width;
+	u32 downsized_height = in->rect.height;
+	u32 downsize_coeff_v = 0;
+	u32 downsize_coeff_h = 0;
+	u32 resized_width = out->rect.width;
+	u32 resized_height = out->rect.height;
+	u32 resize_coeff_h;
+	u32 resize_coeff_v;
+	u32 cols;
+	u32 rows;
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		resized_width = out->rect.height;
+		resized_height = out->rect.width;
+	}
+
+	/* Do not let invalid input lead to an endless loop below */
+	if (WARN_ON(resized_width == 0 || resized_height == 0))
+		return -EINVAL;
+
+	while (downsized_width >= resized_width * 2) {
+		downsized_width >>= 1;
+		downsize_coeff_h++;
+	}
+
+	while (downsized_height >= resized_height * 2) {
+		downsized_height >>= 1;
+		downsize_coeff_v++;
+	}
+
+	/*
+	 * Calculate the bilinear resizing coefficients that could be used if
+	 * we were converting with a single tile. The bottom right output pixel
+	 * should sample as close as possible to the bottom right input pixel
+	 * out of the decimator, but not overshoot it:
+	 */
+	resize_coeff_h = 8192 * (downsized_width - 1) / (resized_width - 1);
+	resize_coeff_v = 8192 * (downsized_height - 1) / (resized_height - 1);
+
+	/*
+	 * Both the output of the IC downsizing section before being passed to
+	 * the IC main processing section and the final output of the IC main
+	 * processing section must be <= 1024 pixels in both dimensions.
+	 */
+	cols = num_stripes(max_t(u32, downsized_width, resized_width));
+	rows = num_stripes(max_t(u32, downsized_height, resized_height));
+
+	dev_dbg(ctx->chan->priv->ipu->dev,
+		"%s: hscale: >>%u, *8192/%u vscale: >>%u, *8192/%u, %ux%u tiles\n",
+		__func__, downsize_coeff_h, resize_coeff_h, downsize_coeff_v,
+		resize_coeff_v, cols, rows);
+
+	if (downsize_coeff_h > 2 || downsize_coeff_v  > 2 ||
+	    resize_coeff_h > 0x3fff || resize_coeff_v > 0x3fff)
+		return -EINVAL;
+
+	ctx->downsize_coeff_h = downsize_coeff_h;
+	ctx->downsize_coeff_v = downsize_coeff_v;
+	ctx->image_resize_coeff_h = resize_coeff_h;
+	ctx->image_resize_coeff_v = resize_coeff_v;
+	ctx->in.num_cols = cols;
+	ctx->in.num_rows = rows;
+
+	return 0;
+}
+
+#define round_closest(x, y) round_down((x) + (y)/2, (y))
+
+/*
+ * Find the best aligned seam position for the given column / row index.
+ * Rotation and image offsets are out of scope.
+ *
+ * @index: column / row index, used to calculate valid interval
+ * @in_edge: input right / bottom edge
+ * @out_edge: output right / bottom edge
+ * @in_align: input alignment, either horizontal 8-byte line start address
+ *            alignment, or pixel alignment due to image format
+ * @out_align: output alignment, either horizontal 8-byte line start address
+ *             alignment, or pixel alignment due to image format or rotator
+ *             block size
+ * @in_burst: horizontal input burst size in case of horizontal flip
+ * @out_burst: horizontal output burst size or rotator block size
+ * @downsize_coeff: downsizing section coefficient
+ * @resize_coeff: main processing section resizing coefficient
+ * @_in_seam: aligned input seam position return value
+ * @_out_seam: aligned output seam position return value
+ */
+static void find_best_seam(struct ipu_image_convert_ctx *ctx,
+			   unsigned int index,
+			   unsigned int in_edge,
+			   unsigned int out_edge,
+			   unsigned int in_align,
+			   unsigned int out_align,
+			   unsigned int in_burst,
+			   unsigned int out_burst,
+			   unsigned int downsize_coeff,
+			   unsigned int resize_coeff,
+			   u32 *_in_seam,
+			   u32 *_out_seam)
+{
+	struct device *dev = ctx->chan->priv->ipu->dev;
+	unsigned int out_pos;
+	/* Input / output seam position candidates */
+	unsigned int out_seam = 0;
+	unsigned int in_seam = 0;
+	unsigned int min_diff = UINT_MAX;
+	unsigned int out_start;
+	unsigned int out_end;
+	unsigned int in_start;
+	unsigned int in_end;
+
+	/* Start within 1024 pixels of the right / bottom edge */
+	out_start = max_t(int, index * out_align, out_edge - 1024);
+	/* End before having to add more columns to the left / rows above */
+	out_end = min_t(unsigned int, out_edge, index * 1024 + 1);
+
+	/*
+	 * Limit input seam position to make sure that the downsized input tile
+	 * to the right or bottom does not exceed 1024 pixels.
+	 */
+	in_start = max_t(int, index * in_align,
+			 in_edge - (1024 << downsize_coeff));
+	in_end = min_t(unsigned int, in_edge,
+		       index * (1024 << downsize_coeff) + 1);
+
+	/*
+	 * Output tiles must start at a multiple of 8 bytes horizontally and
+	 * possibly at an even line horizontally depending on the pixel format.
+	 * Only consider output aligned positions for the seam.
+	 */
+	out_start = round_up(out_start, out_align);
+	for (out_pos = out_start; out_pos < out_end; out_pos += out_align) {
+		unsigned int in_pos;
+		unsigned int in_pos_aligned;
+		unsigned int in_pos_rounded;
+		unsigned int abs_diff;
+
+		/*
+		 * Tiles in the right row / bottom column may not be allowed to
+		 * overshoot horizontally / vertically. out_burst may be the
+		 * actual DMA burst size, or the rotator block size.
+		 */
+		if ((out_burst > 1) && (out_edge - out_pos) % out_burst)
+			continue;
+
+		/*
+		 * Input sample position, corresponding to out_pos, 19.13 fixed
+		 * point.
+		 */
+		in_pos = (out_pos * resize_coeff) << downsize_coeff;
+		/*
+		 * The closest input sample position that we could actually
+		 * start the input tile at, 19.13 fixed point.
+		 */
+		in_pos_aligned = round_closest(in_pos, 8192U * in_align);
+		/* Convert 19.13 fixed point to integer */
+		in_pos_rounded = in_pos_aligned / 8192U;
+
+		if (in_pos_rounded < in_start)
+			continue;
+		if (in_pos_rounded >= in_end)
+			break;
+
+		if ((in_burst > 1) &&
+		    (in_edge - in_pos_rounded) % in_burst)
+			continue;
+
+		if (in_pos < in_pos_aligned)
+			abs_diff = in_pos_aligned - in_pos;
+		else
+			abs_diff = in_pos - in_pos_aligned;
+
+		if (abs_diff < min_diff) {
+			in_seam = in_pos_rounded;
+			out_seam = out_pos;
+			min_diff = abs_diff;
+		}
+	}
+
+	*_out_seam = out_seam;
+	*_in_seam = in_seam;
+
+	dev_dbg(dev, "%s: out_seam %u(%u) in [%u, %u], in_seam %u(%u) in [%u, %u] diff %u.%03u\n",
+		__func__, out_seam, out_align, out_start, out_end,
+		in_seam, in_align, in_start, in_end, min_diff / 8192,
+		DIV_ROUND_CLOSEST(min_diff % 8192 * 1000, 8192));
+}
+
+/*
+ * Tile left edges are required to be aligned to multiples of 8 bytes
+ * by the IDMAC.
+ */
+static inline u32 tile_left_align(const struct ipu_image_pixfmt *fmt)
+{
+	if (fmt->planar)
+		return fmt->uv_packed ? 8 : 8 * fmt->uv_width_dec;
+	else
+		return fmt->bpp == 32 ? 2 : fmt->bpp == 16 ? 4 : 8;
+}
+
+/*
+ * Tile top edge alignment is only limited by chroma subsampling.
+ */
+static inline u32 tile_top_align(const struct ipu_image_pixfmt *fmt)
+{
+	return fmt->uv_height_dec > 1 ? 2 : 1;
+}
+
+static inline u32 tile_width_align(enum ipu_image_convert_type type,
+				   const struct ipu_image_pixfmt *fmt,
+				   enum ipu_rotate_mode rot_mode)
+{
+	if (type == IMAGE_CONVERT_IN) {
+		/*
+		 * The IC burst reads 8 pixels at a time. Reading beyond the
+		 * end of the line is usually acceptable. Those pixels are
+		 * ignored, unless the IC has to write the scaled line in
+		 * reverse.
+		 */
+		return (!ipu_rot_mode_is_irt(rot_mode) &&
+			(rot_mode & IPU_ROT_BIT_HFLIP)) ? 8 : 2;
+	}
+
+	/*
+	 * Align to 16x16 pixel blocks for planar 4:2:0 chroma subsampled
+	 * formats to guarantee 8-byte aligned line start addresses in the
+	 * chroma planes when IRT is used. Align to 8x8 pixel IRT block size
+	 * for all other formats.
+	 */
+	return (ipu_rot_mode_is_irt(rot_mode) &&
+		fmt->planar && !fmt->uv_packed) ?
+		8 * fmt->uv_width_dec : 8;
+}
+
+static inline u32 tile_height_align(enum ipu_image_convert_type type,
+				    const struct ipu_image_pixfmt *fmt,
+				    enum ipu_rotate_mode rot_mode)
+{
+	if (type == IMAGE_CONVERT_IN || !ipu_rot_mode_is_irt(rot_mode))
+		return 2;
+
+	/*
+	 * Align to 16x16 pixel blocks for planar 4:2:0 chroma subsampled
+	 * formats to guarantee 8-byte aligned line start addresses in the
+	 * chroma planes when IRT is used. Align to 8x8 pixel IRT block size
+	 * for all other formats.
+	 */
+	return (fmt->planar && !fmt->uv_packed) ? 8 * fmt->uv_width_dec : 8;
+}
+
+/*
+ * Fill in left position and width and for all tiles in an input column, and
+ * for all corresponding output tiles. If the 90° rotator is used, the output
+ * tiles are in a row, and output tile top position and height are set.
+ */
+static void fill_tile_column(struct ipu_image_convert_ctx *ctx,
+			     unsigned int col,
+			     struct ipu_image_convert_image *in,
+			     unsigned int in_left, unsigned int in_width,
+			     struct ipu_image_convert_image *out,
+			     unsigned int out_left, unsigned int out_width)
+{
+	unsigned int row, tile_idx;
+	struct ipu_image_tile *in_tile, *out_tile;
+
+	for (row = 0; row < in->num_rows; row++) {
+		tile_idx = in->num_cols * row + col;
+		in_tile = &in->tile[tile_idx];
+		out_tile = &out->tile[ctx->out_tile_map[tile_idx]];
+
+		in_tile->left = in_left;
+		in_tile->width = in_width;
+
+		if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+			out_tile->top = out_left;
+			out_tile->height = out_width;
+		} else {
+			out_tile->left = out_left;
+			out_tile->width = out_width;
+		}
+	}
+}
+
+/*
+ * Fill in top position and height and for all tiles in an input row, and
+ * for all corresponding output tiles. If the 90° rotator is used, the output
+ * tiles are in a column, and output tile left position and width are set.
+ */
+static void fill_tile_row(struct ipu_image_convert_ctx *ctx, unsigned int row,
+			  struct ipu_image_convert_image *in,
+			  unsigned int in_top, unsigned int in_height,
+			  struct ipu_image_convert_image *out,
+			  unsigned int out_top, unsigned int out_height)
+{
+	unsigned int col, tile_idx;
+	struct ipu_image_tile *in_tile, *out_tile;
+
+	for (col = 0; col < in->num_cols; col++) {
+		tile_idx = in->num_cols * row + col;
+		in_tile = &in->tile[tile_idx];
+		out_tile = &out->tile[ctx->out_tile_map[tile_idx]];
+
+		in_tile->top = in_top;
+		in_tile->height = in_height;
+
+		if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+			out_tile->left = out_top;
+			out_tile->width = out_height;
+		} else {
+			out_tile->top = out_top;
+			out_tile->height = out_height;
+		}
+	}
+}
+
+/*
+ * Find the best horizontal and vertical seam positions to split into tiles.
+ * Minimize the fractional part of the input sampling position for the
+ * top / left pixels of each tile.
+ */
+static void find_seams(struct ipu_image_convert_ctx *ctx,
+		       struct ipu_image_convert_image *in,
+		       struct ipu_image_convert_image *out)
+{
+	struct device *dev = ctx->chan->priv->ipu->dev;
+	unsigned int resized_width = out->base.rect.width;
+	unsigned int resized_height = out->base.rect.height;
+	unsigned int col;
+	unsigned int row;
+	unsigned int in_left_align = tile_left_align(in->fmt);
+	unsigned int in_top_align = tile_top_align(in->fmt);
+	unsigned int out_left_align = tile_left_align(out->fmt);
+	unsigned int out_top_align = tile_top_align(out->fmt);
+	unsigned int out_width_align = tile_width_align(out->type, out->fmt,
+							ctx->rot_mode);
+	unsigned int out_height_align = tile_height_align(out->type, out->fmt,
+							  ctx->rot_mode);
+	unsigned int in_right = in->base.rect.width;
+	unsigned int in_bottom = in->base.rect.height;
+	unsigned int out_right = out->base.rect.width;
+	unsigned int out_bottom = out->base.rect.height;
+	unsigned int flipped_out_left;
+	unsigned int flipped_out_top;
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		/* Switch width/height and align top left to IRT block size */
+		resized_width = out->base.rect.height;
+		resized_height = out->base.rect.width;
+		out_left_align = out_height_align;
+		out_top_align = out_width_align;
+		out_width_align = out_left_align;
+		out_height_align = out_top_align;
+		out_right = out->base.rect.height;
+		out_bottom = out->base.rect.width;
+	}
+
+	for (col = in->num_cols - 1; col > 0; col--) {
+		bool allow_in_overshoot = ipu_rot_mode_is_irt(ctx->rot_mode) ||
+					  !(ctx->rot_mode & IPU_ROT_BIT_HFLIP);
+		bool allow_out_overshoot = (col < in->num_cols - 1) &&
+					   !(ctx->rot_mode & IPU_ROT_BIT_HFLIP);
+		unsigned int in_left;
+		unsigned int out_left;
+
+		/*
+		 * Align input width to burst length if the scaling step flips
+		 * horizontally.
+		 */
+
+		find_best_seam(ctx, col,
+			       in_right, out_right,
+			       in_left_align, out_left_align,
+			       allow_in_overshoot ? 1 : 8 /* burst length */,
+			       allow_out_overshoot ? 1 : out_width_align,
+			       ctx->downsize_coeff_h, ctx->image_resize_coeff_h,
+			       &in_left, &out_left);
+
+		if (ctx->rot_mode & IPU_ROT_BIT_HFLIP)
+			flipped_out_left = resized_width - out_right;
+		else
+			flipped_out_left = out_left;
+
+		fill_tile_column(ctx, col, in, in_left, in_right - in_left,
+				 out, flipped_out_left, out_right - out_left);
+
+		dev_dbg(dev, "%s: col %u: %u, %u -> %u, %u\n", __func__, col,
+			in_left, in_right - in_left,
+			flipped_out_left, out_right - out_left);
+
+		in_right = in_left;
+		out_right = out_left;
+	}
+
+	flipped_out_left = (ctx->rot_mode & IPU_ROT_BIT_HFLIP) ?
+			   resized_width - out_right : 0;
+
+	fill_tile_column(ctx, 0, in, 0, in_right,
+			 out, flipped_out_left, out_right);
+
+	dev_dbg(dev, "%s: col 0: 0, %u -> %u, %u\n", __func__,
+		in_right, flipped_out_left, out_right);
+
+	for (row = in->num_rows - 1; row > 0; row--) {
+		bool allow_overshoot = row < in->num_rows - 1;
+		unsigned int in_top;
+		unsigned int out_top;
+
+		find_best_seam(ctx, row,
+			       in_bottom, out_bottom,
+			       in_top_align, out_top_align,
+			       1, allow_overshoot ? 1 : out_height_align,
+			       ctx->downsize_coeff_v, ctx->image_resize_coeff_v,
+			       &in_top, &out_top);
+
+		if ((ctx->rot_mode & IPU_ROT_BIT_VFLIP) ^
+		    ipu_rot_mode_is_irt(ctx->rot_mode))
+			flipped_out_top = resized_height - out_bottom;
+		else
+			flipped_out_top = out_top;
+
+		fill_tile_row(ctx, row, in, in_top, in_bottom - in_top,
+			      out, flipped_out_top, out_bottom - out_top);
+
+		dev_dbg(dev, "%s: row %u: %u, %u -> %u, %u\n", __func__, row,
+			in_top, in_bottom - in_top,
+			flipped_out_top, out_bottom - out_top);
+
+		in_bottom = in_top;
+		out_bottom = out_top;
+	}
+
+	if ((ctx->rot_mode & IPU_ROT_BIT_VFLIP) ^
+	    ipu_rot_mode_is_irt(ctx->rot_mode))
+		flipped_out_top = resized_height - out_bottom;
+	else
+		flipped_out_top = 0;
+
+	fill_tile_row(ctx, 0, in, 0, in_bottom,
+		      out, flipped_out_top, out_bottom);
+
+	dev_dbg(dev, "%s: row 0: 0, %u -> %u, %u\n", __func__,
+		in_bottom, flipped_out_top, out_bottom);
+}
+
+static int calc_tile_dimensions(struct ipu_image_convert_ctx *ctx,
+				struct ipu_image_convert_image *image)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	unsigned int max_width = 1024;
+	unsigned int max_height = 1024;
+	unsigned int i;
+
+	if (image->type == IMAGE_CONVERT_IN) {
+		/* Up to 4096x4096 input tile size */
+		max_width <<= ctx->downsize_coeff_h;
+		max_height <<= ctx->downsize_coeff_v;
+	}
+
+	for (i = 0; i < ctx->num_tiles; i++) {
+		struct ipu_image_tile *tile;
+		const unsigned int row = i / image->num_cols;
+		const unsigned int col = i % image->num_cols;
+
+		if (image->type == IMAGE_CONVERT_OUT)
+			tile = &image->tile[ctx->out_tile_map[i]];
+		else
+			tile = &image->tile[i];
+
+		tile->size = ((tile->height * image->fmt->bpp) >> 3) *
+			tile->width;
+
+		if (image->fmt->planar) {
+			tile->stride = tile->width;
+			tile->rot_stride = tile->height;
+		} else {
+			tile->stride =
+				(image->fmt->bpp * tile->width) >> 3;
+			tile->rot_stride =
+				(image->fmt->bpp * tile->height) >> 3;
+		}
+
+		dev_dbg(priv->ipu->dev,
+			"task %u: ctx %p: %s@[%u,%u]: %ux%u@%u,%u\n",
+			chan->ic_task, ctx,
+			image->type == IMAGE_CONVERT_IN ? "Input" : "Output",
+			row, col,
+			tile->width, tile->height, tile->left, tile->top);
+
+		if (!tile->width || tile->width > max_width ||
+		    !tile->height || tile->height > max_height) {
+			dev_err(priv->ipu->dev, "invalid %s tile size: %ux%u\n",
+				image->type == IMAGE_CONVERT_IN ? "input" :
+				"output", tile->width, tile->height);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * Use the rotation transformation to find the tile coordinates
+ * (row, col) of a tile in the destination frame that corresponds
+ * to the given tile coordinates of a source frame. The destination
+ * coordinate is then converted to a tile index.
+ */
+static int transform_tile_index(struct ipu_image_convert_ctx *ctx,
+				int src_row, int src_col)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_image *s_image = &ctx->in;
+	struct ipu_image_convert_image *d_image = &ctx->out;
+	int dst_row, dst_col;
+
+	/* with no rotation it's a 1:1 mapping */
+	if (ctx->rot_mode == IPU_ROTATE_NONE)
+		return src_row * s_image->num_cols + src_col;
+
+	/*
+	 * before doing the transform, first we have to translate
+	 * source row,col for an origin in the center of s_image
+	 */
+	src_row = src_row * 2 - (s_image->num_rows - 1);
+	src_col = src_col * 2 - (s_image->num_cols - 1);
+
+	/* do the rotation transform */
+	if (ctx->rot_mode & IPU_ROT_BIT_90) {
+		dst_col = -src_row;
+		dst_row = src_col;
+	} else {
+		dst_col = src_col;
+		dst_row = src_row;
+	}
+
+	/* apply flip */
+	if (ctx->rot_mode & IPU_ROT_BIT_HFLIP)
+		dst_col = -dst_col;
+	if (ctx->rot_mode & IPU_ROT_BIT_VFLIP)
+		dst_row = -dst_row;
+
+	dev_dbg(priv->ipu->dev, "task %u: ctx %p: [%d,%d] --> [%d,%d]\n",
+		chan->ic_task, ctx, src_col, src_row, dst_col, dst_row);
+
+	/*
+	 * finally translate dest row,col using an origin in upper
+	 * left of d_image
+	 */
+	dst_row += d_image->num_rows - 1;
+	dst_col += d_image->num_cols - 1;
+	dst_row /= 2;
+	dst_col /= 2;
+
+	return dst_row * d_image->num_cols + dst_col;
+}
+
+/*
+ * Fill the out_tile_map[] with transformed destination tile indeces.
+ */
+static void calc_out_tile_map(struct ipu_image_convert_ctx *ctx)
+{
+	struct ipu_image_convert_image *s_image = &ctx->in;
+	unsigned int row, col, tile = 0;
+
+	for (row = 0; row < s_image->num_rows; row++) {
+		for (col = 0; col < s_image->num_cols; col++) {
+			ctx->out_tile_map[tile] =
+				transform_tile_index(ctx, row, col);
+			tile++;
+		}
+	}
+}
+
+static int calc_tile_offsets_planar(struct ipu_image_convert_ctx *ctx,
+				    struct ipu_image_convert_image *image)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	const struct ipu_image_pixfmt *fmt = image->fmt;
+	unsigned int row, col, tile = 0;
+	u32 H, top, y_stride, uv_stride;
+	u32 uv_row_off, uv_col_off, uv_off, u_off, v_off, tmp;
+	u32 y_row_off, y_col_off, y_off;
+	u32 y_size, uv_size;
+
+	/* setup some convenience vars */
+	H = image->base.pix.height;
+
+	y_stride = image->stride;
+	uv_stride = y_stride / fmt->uv_width_dec;
+	if (fmt->uv_packed)
+		uv_stride *= 2;
+
+	y_size = H * y_stride;
+	uv_size = y_size / (fmt->uv_width_dec * fmt->uv_height_dec);
+
+	for (row = 0; row < image->num_rows; row++) {
+		top = image->tile[tile].top;
+		y_row_off = top * y_stride;
+		uv_row_off = (top * uv_stride) / fmt->uv_height_dec;
+
+		for (col = 0; col < image->num_cols; col++) {
+			y_col_off = image->tile[tile].left;
+			uv_col_off = y_col_off / fmt->uv_width_dec;
+			if (fmt->uv_packed)
+				uv_col_off *= 2;
+
+			y_off = y_row_off + y_col_off;
+			uv_off = uv_row_off + uv_col_off;
+
+			u_off = y_size - y_off + uv_off;
+			v_off = (fmt->uv_packed) ? 0 : u_off + uv_size;
+			if (fmt->uv_swapped) {
+				tmp = u_off;
+				u_off = v_off;
+				v_off = tmp;
+			}
+
+			image->tile[tile].offset = y_off;
+			image->tile[tile].u_off = u_off;
+			image->tile[tile++].v_off = v_off;
+
+			if ((y_off & 0x7) || (u_off & 0x7) || (v_off & 0x7)) {
+				dev_err(priv->ipu->dev,
+					"task %u: ctx %p: %s@[%d,%d]: "
+					"y_off %08x, u_off %08x, v_off %08x\n",
+					chan->ic_task, ctx,
+					image->type == IMAGE_CONVERT_IN ?
+					"Input" : "Output", row, col,
+					y_off, u_off, v_off);
+				return -EINVAL;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int calc_tile_offsets_packed(struct ipu_image_convert_ctx *ctx,
+				    struct ipu_image_convert_image *image)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	const struct ipu_image_pixfmt *fmt = image->fmt;
+	unsigned int row, col, tile = 0;
+	u32 bpp, stride, offset;
+	u32 row_off, col_off;
+
+	/* setup some convenience vars */
+	stride = image->stride;
+	bpp = fmt->bpp;
+
+	for (row = 0; row < image->num_rows; row++) {
+		row_off = image->tile[tile].top * stride;
+
+		for (col = 0; col < image->num_cols; col++) {
+			col_off = (image->tile[tile].left * bpp) >> 3;
+
+			offset = row_off + col_off;
+
+			image->tile[tile].offset = offset;
+			image->tile[tile].u_off = 0;
+			image->tile[tile++].v_off = 0;
+
+			if (offset & 0x7) {
+				dev_err(priv->ipu->dev,
+					"task %u: ctx %p: %s@[%d,%d]: "
+					"phys %08x\n",
+					chan->ic_task, ctx,
+					image->type == IMAGE_CONVERT_IN ?
+					"Input" : "Output", row, col,
+					row_off + col_off);
+				return -EINVAL;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int calc_tile_offsets(struct ipu_image_convert_ctx *ctx,
+			      struct ipu_image_convert_image *image)
+{
+	if (image->fmt->planar)
+		return calc_tile_offsets_planar(ctx, image);
+
+	return calc_tile_offsets_packed(ctx, image);
+}
+
+/*
+ * Calculate the resizing ratio for the IC main processing section given input
+ * size, fixed downsizing coefficient, and output size.
+ * Either round to closest for the next tile's first pixel to minimize seams
+ * and distortion (for all but right column / bottom row), or round down to
+ * avoid sampling beyond the edges of the input image for this tile's last
+ * pixel.
+ * Returns the resizing coefficient, resizing ratio is 8192.0 / resize_coeff.
+ */
+static u32 calc_resize_coeff(u32 input_size, u32 downsize_coeff,
+			     u32 output_size, bool allow_overshoot)
+{
+	u32 downsized = input_size >> downsize_coeff;
+
+	if (allow_overshoot)
+		return DIV_ROUND_CLOSEST(8192 * downsized, output_size);
+	else
+		return 8192 * (downsized - 1) / (output_size - 1);
+}
+
+/*
+ * Slightly modify resize coefficients per tile to hide the bilinear
+ * interpolator reset at tile borders, shifting the right / bottom edge
+ * by up to a half input pixel. This removes noticeable seams between
+ * tiles at higher upscaling factors.
+ */
+static void calc_tile_resize_coefficients(struct ipu_image_convert_ctx *ctx)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_tile *in_tile, *out_tile;
+	unsigned int col, row, tile_idx;
+	unsigned int last_output;
+
+	for (col = 0; col < ctx->in.num_cols; col++) {
+		bool closest = (col < ctx->in.num_cols - 1) &&
+			       !(ctx->rot_mode & IPU_ROT_BIT_HFLIP);
+		u32 resized_width;
+		u32 resize_coeff_h;
+		u32 in_width;
+
+		tile_idx = col;
+		in_tile = &ctx->in.tile[tile_idx];
+		out_tile = &ctx->out.tile[ctx->out_tile_map[tile_idx]];
+
+		if (ipu_rot_mode_is_irt(ctx->rot_mode))
+			resized_width = out_tile->height;
+		else
+			resized_width = out_tile->width;
+
+		resize_coeff_h = calc_resize_coeff(in_tile->width,
+						   ctx->downsize_coeff_h,
+						   resized_width, closest);
+
+		dev_dbg(priv->ipu->dev, "%s: column %u hscale: *8192/%u\n",
+			__func__, col, resize_coeff_h);
+
+		/*
+		 * With the horizontal scaling factor known, round up resized
+		 * width (output width or height) to burst size.
+		 */
+		resized_width = round_up(resized_width, 8);
+
+		/*
+		 * Calculate input width from the last accessed input pixel
+		 * given resized width and scaling coefficients. Round up to
+		 * burst size.
+		 */
+		last_output = resized_width - 1;
+		if (closest && ((last_output * resize_coeff_h) % 8192))
+			last_output++;
+		in_width = round_up(
+			(DIV_ROUND_UP(last_output * resize_coeff_h, 8192) + 1)
+			<< ctx->downsize_coeff_h, 8);
+
+		for (row = 0; row < ctx->in.num_rows; row++) {
+			tile_idx = row * ctx->in.num_cols + col;
+			in_tile = &ctx->in.tile[tile_idx];
+			out_tile = &ctx->out.tile[ctx->out_tile_map[tile_idx]];
+
+			if (ipu_rot_mode_is_irt(ctx->rot_mode))
+				out_tile->height = resized_width;
+			else
+				out_tile->width = resized_width;
+
+			in_tile->width = in_width;
+		}
+
+		ctx->resize_coeffs_h[col] = resize_coeff_h;
+	}
+
+	for (row = 0; row < ctx->in.num_rows; row++) {
+		bool closest = (row < ctx->in.num_rows - 1) &&
+			       !(ctx->rot_mode & IPU_ROT_BIT_VFLIP);
+		u32 resized_height;
+		u32 resize_coeff_v;
+		u32 in_height;
+
+		tile_idx = row * ctx->in.num_cols;
+		in_tile = &ctx->in.tile[tile_idx];
+		out_tile = &ctx->out.tile[ctx->out_tile_map[tile_idx]];
+
+		if (ipu_rot_mode_is_irt(ctx->rot_mode))
+			resized_height = out_tile->width;
+		else
+			resized_height = out_tile->height;
+
+		resize_coeff_v = calc_resize_coeff(in_tile->height,
+						   ctx->downsize_coeff_v,
+						   resized_height, closest);
+
+		dev_dbg(priv->ipu->dev, "%s: row %u vscale: *8192/%u\n",
+			__func__, row, resize_coeff_v);
+
+		/*
+		 * With the vertical scaling factor known, round up resized
+		 * height (output width or height) to IDMAC limitations.
+		 */
+		resized_height = round_up(resized_height, 2);
+
+		/*
+		 * Calculate input width from the last accessed input pixel
+		 * given resized height and scaling coefficients. Align to
+		 * IDMAC restrictions.
+		 */
+		last_output = resized_height - 1;
+		if (closest && ((last_output * resize_coeff_v) % 8192))
+			last_output++;
+		in_height = round_up(
+			(DIV_ROUND_UP(last_output * resize_coeff_v, 8192) + 1)
+			<< ctx->downsize_coeff_v, 2);
+
+		for (col = 0; col < ctx->in.num_cols; col++) {
+			tile_idx = row * ctx->in.num_cols + col;
+			in_tile = &ctx->in.tile[tile_idx];
+			out_tile = &ctx->out.tile[ctx->out_tile_map[tile_idx]];
+
+			if (ipu_rot_mode_is_irt(ctx->rot_mode))
+				out_tile->width = resized_height;
+			else
+				out_tile->height = resized_height;
+
+			in_tile->height = in_height;
+		}
+
+		ctx->resize_coeffs_v[row] = resize_coeff_v;
+	}
+}
+
+/*
+ * return the number of runs in given queue (pending_q or done_q)
+ * for this context. hold irqlock when calling.
+ */
+static int get_run_count(struct ipu_image_convert_ctx *ctx,
+			 struct list_head *q)
+{
+	struct ipu_image_convert_run *run;
+	int count = 0;
+
+	lockdep_assert_held(&ctx->chan->irqlock);
+
+	list_for_each_entry(run, q, list) {
+		if (run->ctx == ctx)
+			count++;
+	}
+
+	return count;
+}
+
+static void convert_stop(struct ipu_image_convert_run *run)
+{
+	struct ipu_image_convert_ctx *ctx = run->ctx;
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: stopping ctx %p run %p\n",
+		__func__, chan->ic_task, ctx, run);
+
+	/* disable IC tasks and the channels */
+	ipu_ic_task_disable(chan->ic);
+	ipu_idmac_disable_channel(chan->in_chan);
+	ipu_idmac_disable_channel(chan->out_chan);
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		ipu_idmac_disable_channel(chan->rotation_in_chan);
+		ipu_idmac_disable_channel(chan->rotation_out_chan);
+		ipu_idmac_unlink(chan->out_chan, chan->rotation_in_chan);
+	}
+
+	ipu_ic_disable(chan->ic);
+}
+
+static void init_idmac_channel(struct ipu_image_convert_ctx *ctx,
+			       struct ipuv3_channel *channel,
+			       struct ipu_image_convert_image *image,
+			       enum ipu_rotate_mode rot_mode,
+			       bool rot_swap_width_height,
+			       unsigned int tile)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	unsigned int burst_size;
+	u32 width, height, stride;
+	dma_addr_t addr0, addr1 = 0;
+	struct ipu_image tile_image;
+	unsigned int tile_idx[2];
+
+	if (image->type == IMAGE_CONVERT_OUT) {
+		tile_idx[0] = ctx->out_tile_map[tile];
+		tile_idx[1] = ctx->out_tile_map[1];
+	} else {
+		tile_idx[0] = tile;
+		tile_idx[1] = 1;
+	}
+
+	if (rot_swap_width_height) {
+		width = image->tile[tile_idx[0]].height;
+		height = image->tile[tile_idx[0]].width;
+		stride = image->tile[tile_idx[0]].rot_stride;
+		addr0 = ctx->rot_intermediate[0].phys;
+		if (ctx->double_buffering)
+			addr1 = ctx->rot_intermediate[1].phys;
+	} else {
+		width = image->tile[tile_idx[0]].width;
+		height = image->tile[tile_idx[0]].height;
+		stride = image->stride;
+		addr0 = image->base.phys0 +
+			image->tile[tile_idx[0]].offset;
+		if (ctx->double_buffering)
+			addr1 = image->base.phys0 +
+				image->tile[tile_idx[1]].offset;
+	}
+
+	ipu_cpmem_zero(channel);
+
+	memset(&tile_image, 0, sizeof(tile_image));
+	tile_image.pix.width = tile_image.rect.width = width;
+	tile_image.pix.height = tile_image.rect.height = height;
+	tile_image.pix.bytesperline = stride;
+	tile_image.pix.pixelformat =  image->fmt->fourcc;
+	tile_image.phys0 = addr0;
+	tile_image.phys1 = addr1;
+	if (image->fmt->planar && !rot_swap_width_height) {
+		tile_image.u_offset = image->tile[tile_idx[0]].u_off;
+		tile_image.v_offset = image->tile[tile_idx[0]].v_off;
+	}
+
+	ipu_cpmem_set_image(channel, &tile_image);
+
+	if (rot_mode)
+		ipu_cpmem_set_rotation(channel, rot_mode);
+
+	/*
+	 * Skip writing U and V components to odd rows in the output
+	 * channels for planar 4:2:0.
+	 */
+	if ((channel == chan->out_chan ||
+	     channel == chan->rotation_out_chan) &&
+	    image->fmt->planar && image->fmt->uv_height_dec == 2)
+		ipu_cpmem_skip_odd_chroma_rows(channel);
+
+	if (channel == chan->rotation_in_chan ||
+	    channel == chan->rotation_out_chan) {
+		burst_size = 8;
+		ipu_cpmem_set_block_mode(channel);
+	} else
+		burst_size = (width % 16) ? 8 : 16;
+
+	ipu_cpmem_set_burstsize(channel, burst_size);
+
+	ipu_ic_task_idma_init(chan->ic, channel, width, height,
+			      burst_size, rot_mode);
+
+	/*
+	 * Setting a non-zero AXI ID collides with the PRG AXI snooping, so
+	 * only do this when there is no PRG present.
+	 */
+	if (!channel->ipu->prg_priv)
+		ipu_cpmem_set_axi_id(channel, 1);
+
+	ipu_idmac_set_double_buffer(channel, ctx->double_buffering);
+}
+
+static int convert_start(struct ipu_image_convert_run *run, unsigned int tile)
+{
+	struct ipu_image_convert_ctx *ctx = run->ctx;
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_image *s_image = &ctx->in;
+	struct ipu_image_convert_image *d_image = &ctx->out;
+	unsigned int dst_tile = ctx->out_tile_map[tile];
+	unsigned int dest_width, dest_height;
+	unsigned int col, row;
+	u32 rsc;
+	int ret;
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: starting ctx %p run %p tile %u -> %u\n",
+		__func__, chan->ic_task, ctx, run, tile, dst_tile);
+
+	/* clear EOF irq mask */
+	ctx->eof_mask = 0;
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		/* swap width/height for resizer */
+		dest_width = d_image->tile[dst_tile].height;
+		dest_height = d_image->tile[dst_tile].width;
+	} else {
+		dest_width = d_image->tile[dst_tile].width;
+		dest_height = d_image->tile[dst_tile].height;
+	}
+
+	row = tile / s_image->num_cols;
+	col = tile % s_image->num_cols;
+
+	rsc =  (ctx->downsize_coeff_v << 30) |
+	       (ctx->resize_coeffs_v[row] << 16) |
+	       (ctx->downsize_coeff_h << 14) |
+	       (ctx->resize_coeffs_h[col]);
+
+	dev_dbg(priv->ipu->dev, "%s: %ux%u -> %ux%u (rsc = 0x%x)\n",
+		__func__, s_image->tile[tile].width,
+		s_image->tile[tile].height, dest_width, dest_height, rsc);
+
+	/* setup the IC resizer and CSC */
+	ret = ipu_ic_task_init_rsc(chan->ic, &ctx->csc,
+				   s_image->tile[tile].width,
+				   s_image->tile[tile].height,
+				   dest_width,
+				   dest_height,
+				   rsc);
+	if (ret) {
+		dev_err(priv->ipu->dev, "ipu_ic_task_init failed, %d\n", ret);
+		return ret;
+	}
+
+	/* init the source MEM-->IC PP IDMAC channel */
+	init_idmac_channel(ctx, chan->in_chan, s_image,
+			   IPU_ROTATE_NONE, false, tile);
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		/* init the IC PP-->MEM IDMAC channel */
+		init_idmac_channel(ctx, chan->out_chan, d_image,
+				   IPU_ROTATE_NONE, true, tile);
+
+		/* init the MEM-->IC PP ROT IDMAC channel */
+		init_idmac_channel(ctx, chan->rotation_in_chan, d_image,
+				   ctx->rot_mode, true, tile);
+
+		/* init the destination IC PP ROT-->MEM IDMAC channel */
+		init_idmac_channel(ctx, chan->rotation_out_chan, d_image,
+				   IPU_ROTATE_NONE, false, tile);
+
+		/* now link IC PP-->MEM to MEM-->IC PP ROT */
+		ipu_idmac_link(chan->out_chan, chan->rotation_in_chan);
+	} else {
+		/* init the destination IC PP-->MEM IDMAC channel */
+		init_idmac_channel(ctx, chan->out_chan, d_image,
+				   ctx->rot_mode, false, tile);
+	}
+
+	/* enable the IC */
+	ipu_ic_enable(chan->ic);
+
+	/* set buffers ready */
+	ipu_idmac_select_buffer(chan->in_chan, 0);
+	ipu_idmac_select_buffer(chan->out_chan, 0);
+	if (ipu_rot_mode_is_irt(ctx->rot_mode))
+		ipu_idmac_select_buffer(chan->rotation_out_chan, 0);
+	if (ctx->double_buffering) {
+		ipu_idmac_select_buffer(chan->in_chan, 1);
+		ipu_idmac_select_buffer(chan->out_chan, 1);
+		if (ipu_rot_mode_is_irt(ctx->rot_mode))
+			ipu_idmac_select_buffer(chan->rotation_out_chan, 1);
+	}
+
+	/* enable the channels! */
+	ipu_idmac_enable_channel(chan->in_chan);
+	ipu_idmac_enable_channel(chan->out_chan);
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		ipu_idmac_enable_channel(chan->rotation_in_chan);
+		ipu_idmac_enable_channel(chan->rotation_out_chan);
+	}
+
+	ipu_ic_task_enable(chan->ic);
+
+	ipu_cpmem_dump(chan->in_chan);
+	ipu_cpmem_dump(chan->out_chan);
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		ipu_cpmem_dump(chan->rotation_in_chan);
+		ipu_cpmem_dump(chan->rotation_out_chan);
+	}
+
+	ipu_dump(priv->ipu);
+
+	return 0;
+}
+
+/* hold irqlock when calling */
+static int do_run(struct ipu_image_convert_run *run)
+{
+	struct ipu_image_convert_ctx *ctx = run->ctx;
+	struct ipu_image_convert_chan *chan = ctx->chan;
+
+	lockdep_assert_held(&chan->irqlock);
+
+	ctx->in.base.phys0 = run->in_phys;
+	ctx->out.base.phys0 = run->out_phys;
+
+	ctx->cur_buf_num = 0;
+	ctx->next_tile = 1;
+
+	/* remove run from pending_q and set as current */
+	list_del(&run->list);
+	chan->current_run = run;
+
+	return convert_start(run, 0);
+}
+
+/* hold irqlock when calling */
+static void run_next(struct ipu_image_convert_chan *chan)
+{
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_run *run, *tmp;
+	int ret;
+
+	lockdep_assert_held(&chan->irqlock);
+
+	list_for_each_entry_safe(run, tmp, &chan->pending_q, list) {
+		/* skip contexts that are aborting */
+		if (run->ctx->aborting) {
+			dev_dbg(priv->ipu->dev,
+				"%s: task %u: skipping aborting ctx %p run %p\n",
+				__func__, chan->ic_task, run->ctx, run);
+			continue;
+		}
+
+		ret = do_run(run);
+		if (!ret)
+			break;
+
+		/*
+		 * something went wrong with start, add the run
+		 * to done q and continue to the next run in the
+		 * pending q.
+		 */
+		run->status = ret;
+		list_add_tail(&run->list, &chan->done_q);
+		chan->current_run = NULL;
+	}
+}
+
+static void empty_done_q(struct ipu_image_convert_chan *chan)
+{
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_run *run;
+	unsigned long flags;
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	while (!list_empty(&chan->done_q)) {
+		run = list_entry(chan->done_q.next,
+				 struct ipu_image_convert_run,
+				 list);
+
+		list_del(&run->list);
+
+		dev_dbg(priv->ipu->dev,
+			"%s: task %u: completing ctx %p run %p with %d\n",
+			__func__, chan->ic_task, run->ctx, run, run->status);
+
+		/* call the completion callback and free the run */
+		spin_unlock_irqrestore(&chan->irqlock, flags);
+		run->ctx->complete(run, run->ctx->complete_context);
+		spin_lock_irqsave(&chan->irqlock, flags);
+	}
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+}
+
+/*
+ * the bottom half thread clears out the done_q, calling the
+ * completion handler for each.
+ */
+static irqreturn_t do_bh(int irq, void *dev_id)
+{
+	struct ipu_image_convert_chan *chan = dev_id;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_ctx *ctx;
+	unsigned long flags;
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: enter\n", __func__,
+		chan->ic_task);
+
+	empty_done_q(chan);
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	/*
+	 * the done_q is cleared out, signal any contexts
+	 * that are aborting that abort can complete.
+	 */
+	list_for_each_entry(ctx, &chan->ctx_list, list) {
+		if (ctx->aborting) {
+			dev_dbg(priv->ipu->dev,
+				"%s: task %u: signaling abort for ctx %p\n",
+				__func__, chan->ic_task, ctx);
+			complete_all(&ctx->aborted);
+		}
+	}
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: exit\n", __func__,
+		chan->ic_task);
+
+	return IRQ_HANDLED;
+}
+
+static bool ic_settings_changed(struct ipu_image_convert_ctx *ctx)
+{
+	unsigned int cur_tile = ctx->next_tile - 1;
+	unsigned int next_tile = ctx->next_tile;
+
+	if (ctx->resize_coeffs_h[cur_tile % ctx->in.num_cols] !=
+	    ctx->resize_coeffs_h[next_tile % ctx->in.num_cols] ||
+	    ctx->resize_coeffs_v[cur_tile / ctx->in.num_cols] !=
+	    ctx->resize_coeffs_v[next_tile / ctx->in.num_cols] ||
+	    ctx->in.tile[cur_tile].width != ctx->in.tile[next_tile].width ||
+	    ctx->in.tile[cur_tile].height != ctx->in.tile[next_tile].height ||
+	    ctx->out.tile[cur_tile].width != ctx->out.tile[next_tile].width ||
+	    ctx->out.tile[cur_tile].height != ctx->out.tile[next_tile].height)
+		return true;
+
+	return false;
+}
+
+/* hold irqlock when calling */
+static irqreturn_t do_tile_complete(struct ipu_image_convert_run *run)
+{
+	struct ipu_image_convert_ctx *ctx = run->ctx;
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_tile *src_tile, *dst_tile;
+	struct ipu_image_convert_image *s_image = &ctx->in;
+	struct ipu_image_convert_image *d_image = &ctx->out;
+	struct ipuv3_channel *outch;
+	unsigned int dst_idx;
+
+	lockdep_assert_held(&chan->irqlock);
+
+	outch = ipu_rot_mode_is_irt(ctx->rot_mode) ?
+		chan->rotation_out_chan : chan->out_chan;
+
+	/*
+	 * It is difficult to stop the channel DMA before the channels
+	 * enter the paused state. Without double-buffering the channels
+	 * are always in a paused state when the EOF irq occurs, so it
+	 * is safe to stop the channels now. For double-buffering we
+	 * just ignore the abort until the operation completes, when it
+	 * is safe to shut down.
+	 */
+	if (ctx->aborting && !ctx->double_buffering) {
+		convert_stop(run);
+		run->status = -EIO;
+		goto done;
+	}
+
+	if (ctx->next_tile == ctx->num_tiles) {
+		/*
+		 * the conversion is complete
+		 */
+		convert_stop(run);
+		run->status = 0;
+		goto done;
+	}
+
+	/*
+	 * not done, place the next tile buffers.
+	 */
+	if (!ctx->double_buffering) {
+		if (ic_settings_changed(ctx)) {
+			convert_stop(run);
+			convert_start(run, ctx->next_tile);
+		} else {
+			src_tile = &s_image->tile[ctx->next_tile];
+			dst_idx = ctx->out_tile_map[ctx->next_tile];
+			dst_tile = &d_image->tile[dst_idx];
+
+			ipu_cpmem_set_buffer(chan->in_chan, 0,
+					     s_image->base.phys0 +
+					     src_tile->offset);
+			ipu_cpmem_set_buffer(outch, 0,
+					     d_image->base.phys0 +
+					     dst_tile->offset);
+			if (s_image->fmt->planar)
+				ipu_cpmem_set_uv_offset(chan->in_chan,
+							src_tile->u_off,
+							src_tile->v_off);
+			if (d_image->fmt->planar)
+				ipu_cpmem_set_uv_offset(outch,
+							dst_tile->u_off,
+							dst_tile->v_off);
+
+			ipu_idmac_select_buffer(chan->in_chan, 0);
+			ipu_idmac_select_buffer(outch, 0);
+		}
+	} else if (ctx->next_tile < ctx->num_tiles - 1) {
+
+		src_tile = &s_image->tile[ctx->next_tile + 1];
+		dst_idx = ctx->out_tile_map[ctx->next_tile + 1];
+		dst_tile = &d_image->tile[dst_idx];
+
+		ipu_cpmem_set_buffer(chan->in_chan, ctx->cur_buf_num,
+				     s_image->base.phys0 + src_tile->offset);
+		ipu_cpmem_set_buffer(outch, ctx->cur_buf_num,
+				     d_image->base.phys0 + dst_tile->offset);
+
+		ipu_idmac_select_buffer(chan->in_chan, ctx->cur_buf_num);
+		ipu_idmac_select_buffer(outch, ctx->cur_buf_num);
+
+		ctx->cur_buf_num ^= 1;
+	}
+
+	ctx->eof_mask = 0; /* clear EOF irq mask for next tile */
+	ctx->next_tile++;
+	return IRQ_HANDLED;
+done:
+	list_add_tail(&run->list, &chan->done_q);
+	chan->current_run = NULL;
+	run_next(chan);
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t eof_irq(int irq, void *data)
+{
+	struct ipu_image_convert_chan *chan = data;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_ctx *ctx;
+	struct ipu_image_convert_run *run;
+	irqreturn_t ret = IRQ_HANDLED;
+	bool tile_complete = false;
+	unsigned long flags;
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	/* get current run and its context */
+	run = chan->current_run;
+	if (!run) {
+		ret = IRQ_NONE;
+		goto out;
+	}
+
+	ctx = run->ctx;
+
+	if (irq == chan->in_eof_irq) {
+		ctx->eof_mask |= EOF_IRQ_IN;
+	} else if (irq == chan->out_eof_irq) {
+		ctx->eof_mask |= EOF_IRQ_OUT;
+	} else if (irq == chan->rot_in_eof_irq ||
+		   irq == chan->rot_out_eof_irq) {
+		if (!ipu_rot_mode_is_irt(ctx->rot_mode)) {
+			/* this was NOT a rotation op, shouldn't happen */
+			dev_err(priv->ipu->dev,
+				"Unexpected rotation interrupt\n");
+			goto out;
+		}
+		ctx->eof_mask |= (irq == chan->rot_in_eof_irq) ?
+			EOF_IRQ_ROT_IN : EOF_IRQ_ROT_OUT;
+	} else {
+		dev_err(priv->ipu->dev, "Received unknown irq %d\n", irq);
+		ret = IRQ_NONE;
+		goto out;
+	}
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode))
+		tile_complete =	(ctx->eof_mask == EOF_IRQ_ROT_COMPLETE);
+	else
+		tile_complete = (ctx->eof_mask == EOF_IRQ_COMPLETE);
+
+	if (tile_complete)
+		ret = do_tile_complete(run);
+out:
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+	return ret;
+}
+
+/*
+ * try to force the completion of runs for this ctx. Called when
+ * abort wait times out in ipu_image_convert_abort().
+ */
+static void force_abort(struct ipu_image_convert_ctx *ctx)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_run *run;
+	unsigned long flags;
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	run = chan->current_run;
+	if (run && run->ctx == ctx) {
+		convert_stop(run);
+		run->status = -EIO;
+		list_add_tail(&run->list, &chan->done_q);
+		chan->current_run = NULL;
+		run_next(chan);
+	}
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+
+	empty_done_q(chan);
+}
+
+static void release_ipu_resources(struct ipu_image_convert_chan *chan)
+{
+	if (chan->in_eof_irq >= 0)
+		free_irq(chan->in_eof_irq, chan);
+	if (chan->rot_in_eof_irq >= 0)
+		free_irq(chan->rot_in_eof_irq, chan);
+	if (chan->out_eof_irq >= 0)
+		free_irq(chan->out_eof_irq, chan);
+	if (chan->rot_out_eof_irq >= 0)
+		free_irq(chan->rot_out_eof_irq, chan);
+
+	if (!IS_ERR_OR_NULL(chan->in_chan))
+		ipu_idmac_put(chan->in_chan);
+	if (!IS_ERR_OR_NULL(chan->out_chan))
+		ipu_idmac_put(chan->out_chan);
+	if (!IS_ERR_OR_NULL(chan->rotation_in_chan))
+		ipu_idmac_put(chan->rotation_in_chan);
+	if (!IS_ERR_OR_NULL(chan->rotation_out_chan))
+		ipu_idmac_put(chan->rotation_out_chan);
+	if (!IS_ERR_OR_NULL(chan->ic))
+		ipu_ic_put(chan->ic);
+
+	chan->in_chan = chan->out_chan = chan->rotation_in_chan =
+		chan->rotation_out_chan = NULL;
+	chan->in_eof_irq = -1;
+	chan->rot_in_eof_irq = -1;
+	chan->out_eof_irq = -1;
+	chan->rot_out_eof_irq = -1;
+}
+
+static int get_eof_irq(struct ipu_image_convert_chan *chan,
+		       struct ipuv3_channel *channel)
+{
+	struct ipu_image_convert_priv *priv = chan->priv;
+	int ret, irq;
+
+	irq = ipu_idmac_channel_irq(priv->ipu, channel, IPU_IRQ_EOF);
+
+	ret = request_threaded_irq(irq, eof_irq, do_bh, 0, "ipu-ic", chan);
+	if (ret < 0) {
+		dev_err(priv->ipu->dev, "could not acquire irq %d\n", irq);
+		return ret;
+	}
+
+	return irq;
+}
+
+static int get_ipu_resources(struct ipu_image_convert_chan *chan)
+{
+	const struct ipu_image_convert_dma_chan *dma = chan->dma_ch;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	int ret;
+
+	/* get IC */
+	chan->ic = ipu_ic_get(priv->ipu, chan->ic_task);
+	if (IS_ERR(chan->ic)) {
+		dev_err(priv->ipu->dev, "could not acquire IC\n");
+		ret = PTR_ERR(chan->ic);
+		goto err;
+	}
+
+	/* get IDMAC channels */
+	chan->in_chan = ipu_idmac_get(priv->ipu, dma->in);
+	chan->out_chan = ipu_idmac_get(priv->ipu, dma->out);
+	if (IS_ERR(chan->in_chan) || IS_ERR(chan->out_chan)) {
+		dev_err(priv->ipu->dev, "could not acquire idmac channels\n");
+		ret = -EBUSY;
+		goto err;
+	}
+
+	chan->rotation_in_chan = ipu_idmac_get(priv->ipu, dma->rot_in);
+	chan->rotation_out_chan = ipu_idmac_get(priv->ipu, dma->rot_out);
+	if (IS_ERR(chan->rotation_in_chan) || IS_ERR(chan->rotation_out_chan)) {
+		dev_err(priv->ipu->dev,
+			"could not acquire idmac rotation channels\n");
+		ret = -EBUSY;
+		goto err;
+	}
+
+	/* acquire the EOF interrupts */
+	ret = get_eof_irq(chan, chan->in_chan);
+	if (ret < 0) {
+		chan->in_eof_irq = -1;
+		goto err;
+	}
+	chan->in_eof_irq = ret;
+
+	ret = get_eof_irq(chan, chan->rotation_in_chan);
+	if (ret < 0) {
+		chan->rot_in_eof_irq = -1;
+		goto err;
+	}
+	chan->rot_in_eof_irq = ret;
+
+	ret = get_eof_irq(chan, chan->out_chan);
+	if (ret < 0) {
+		chan->out_eof_irq = -1;
+		goto err;
+	}
+	chan->out_eof_irq = ret;
+
+	ret = get_eof_irq(chan, chan->rotation_out_chan);
+	if (ret < 0) {
+		chan->rot_out_eof_irq = -1;
+		goto err;
+	}
+	chan->rot_out_eof_irq = ret;
+
+	return 0;
+err:
+	release_ipu_resources(chan);
+	return ret;
+}
+
+static int fill_image(struct ipu_image_convert_ctx *ctx,
+		      struct ipu_image_convert_image *ic_image,
+		      struct ipu_image *image,
+		      enum ipu_image_convert_type type)
+{
+	struct ipu_image_convert_priv *priv = ctx->chan->priv;
+
+	ic_image->base = *image;
+	ic_image->type = type;
+
+	ic_image->fmt = get_format(image->pix.pixelformat);
+	if (!ic_image->fmt) {
+		dev_err(priv->ipu->dev, "pixelformat not supported for %s\n",
+			type == IMAGE_CONVERT_OUT ? "Output" : "Input");
+		return -EINVAL;
+	}
+
+	if (ic_image->fmt->planar)
+		ic_image->stride = ic_image->base.pix.width;
+	else
+		ic_image->stride  = ic_image->base.pix.bytesperline;
+
+	return 0;
+}
+
+/* borrowed from drivers/media/v4l2-core/v4l2-common.c */
+static unsigned int clamp_align(unsigned int x, unsigned int min,
+				unsigned int max, unsigned int align)
+{
+	/* Bits that must be zero to be aligned */
+	unsigned int mask = ~((1 << align) - 1);
+
+	/* Clamp to aligned min and max */
+	x = clamp(x, (min + ~mask) & mask, max & mask);
+
+	/* Round to nearest aligned value */
+	if (align)
+		x = (x + (1 << (align - 1))) & mask;
+
+	return x;
+}
+
+/* Adjusts input/output images to IPU restrictions */
+void ipu_image_convert_adjust(struct ipu_image *in, struct ipu_image *out,
+			      enum ipu_rotate_mode rot_mode)
+{
+	const struct ipu_image_pixfmt *infmt, *outfmt;
+	u32 w_align_out, h_align_out;
+	u32 w_align_in, h_align_in;
+
+	infmt = get_format(in->pix.pixelformat);
+	outfmt = get_format(out->pix.pixelformat);
+
+	/* set some default pixel formats if needed */
+	if (!infmt) {
+		in->pix.pixelformat = V4L2_PIX_FMT_RGB24;
+		infmt = get_format(V4L2_PIX_FMT_RGB24);
+	}
+	if (!outfmt) {
+		out->pix.pixelformat = V4L2_PIX_FMT_RGB24;
+		outfmt = get_format(V4L2_PIX_FMT_RGB24);
+	}
+
+	/* image converter does not handle fields */
+	in->pix.field = out->pix.field = V4L2_FIELD_NONE;
+
+	/* resizer cannot downsize more than 4:1 */
+	if (ipu_rot_mode_is_irt(rot_mode)) {
+		out->pix.height = max_t(__u32, out->pix.height,
+					in->pix.width / 4);
+		out->pix.width = max_t(__u32, out->pix.width,
+				       in->pix.height / 4);
+	} else {
+		out->pix.width = max_t(__u32, out->pix.width,
+				       in->pix.width / 4);
+		out->pix.height = max_t(__u32, out->pix.height,
+					in->pix.height / 4);
+	}
+
+	/* align input width/height */
+	w_align_in = ilog2(tile_width_align(IMAGE_CONVERT_IN, infmt,
+					    rot_mode));
+	h_align_in = ilog2(tile_height_align(IMAGE_CONVERT_IN, infmt,
+					     rot_mode));
+	in->pix.width = clamp_align(in->pix.width, MIN_W, MAX_W,
+				    w_align_in);
+	in->pix.height = clamp_align(in->pix.height, MIN_H, MAX_H,
+				     h_align_in);
+
+	/* align output width/height */
+	w_align_out = ilog2(tile_width_align(IMAGE_CONVERT_OUT, outfmt,
+					     rot_mode));
+	h_align_out = ilog2(tile_height_align(IMAGE_CONVERT_OUT, outfmt,
+					      rot_mode));
+	out->pix.width = clamp_align(out->pix.width, MIN_W, MAX_W,
+				     w_align_out);
+	out->pix.height = clamp_align(out->pix.height, MIN_H, MAX_H,
+				      h_align_out);
+
+	/* set input/output strides and image sizes */
+	in->pix.bytesperline = infmt->planar ?
+		clamp_align(in->pix.width, 2 << w_align_in, MAX_W,
+			    w_align_in) :
+		clamp_align((in->pix.width * infmt->bpp) >> 3,
+			    ((2 << w_align_in) * infmt->bpp) >> 3,
+			    (MAX_W * infmt->bpp) >> 3,
+			    w_align_in);
+	in->pix.sizeimage = infmt->planar ?
+		(in->pix.height * in->pix.bytesperline * infmt->bpp) >> 3 :
+		in->pix.height * in->pix.bytesperline;
+	out->pix.bytesperline = outfmt->planar ? out->pix.width :
+		(out->pix.width * outfmt->bpp) >> 3;
+	out->pix.sizeimage = outfmt->planar ?
+		(out->pix.height * out->pix.bytesperline * outfmt->bpp) >> 3 :
+		out->pix.height * out->pix.bytesperline;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_adjust);
+
+/*
+ * this is used by ipu_image_convert_prepare() to verify set input and
+ * output images are valid before starting the conversion. Clients can
+ * also call it before calling ipu_image_convert_prepare().
+ */
+int ipu_image_convert_verify(struct ipu_image *in, struct ipu_image *out,
+			     enum ipu_rotate_mode rot_mode)
+{
+	struct ipu_image testin, testout;
+
+	testin = *in;
+	testout = *out;
+
+	ipu_image_convert_adjust(&testin, &testout, rot_mode);
+
+	if (testin.pix.width != in->pix.width ||
+	    testin.pix.height != in->pix.height ||
+	    testout.pix.width != out->pix.width ||
+	    testout.pix.height != out->pix.height)
+		return -EINVAL;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_verify);
+
+/*
+ * Call ipu_image_convert_prepare() to prepare for the conversion of
+ * given images and rotation mode. Returns a new conversion context.
+ */
+struct ipu_image_convert_ctx *
+ipu_image_convert_prepare(struct ipu_soc *ipu, enum ipu_ic_task ic_task,
+			  struct ipu_image *in, struct ipu_image *out,
+			  enum ipu_rotate_mode rot_mode,
+			  ipu_image_convert_cb_t complete,
+			  void *complete_context)
+{
+	struct ipu_image_convert_priv *priv = ipu->image_convert_priv;
+	struct ipu_image_convert_image *s_image, *d_image;
+	struct ipu_image_convert_chan *chan;
+	struct ipu_image_convert_ctx *ctx;
+	unsigned long flags;
+	unsigned int i;
+	bool get_res;
+	int ret;
+
+	if (!in || !out || !complete ||
+	    (ic_task != IC_TASK_VIEWFINDER &&
+	     ic_task != IC_TASK_POST_PROCESSOR))
+		return ERR_PTR(-EINVAL);
+
+	/* verify the in/out images before continuing */
+	ret = ipu_image_convert_verify(in, out, rot_mode);
+	if (ret) {
+		dev_err(priv->ipu->dev, "%s: in/out formats invalid\n",
+			__func__);
+		return ERR_PTR(ret);
+	}
+
+	chan = &priv->chan[ic_task];
+
+	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
+	if (!ctx)
+		return ERR_PTR(-ENOMEM);
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: ctx %p\n", __func__,
+		chan->ic_task, ctx);
+
+	ctx->chan = chan;
+	init_completion(&ctx->aborted);
+
+	ctx->rot_mode = rot_mode;
+
+	/* Sets ctx->in.num_rows/cols as well */
+	ret = calc_image_resize_coefficients(ctx, in, out);
+	if (ret)
+		goto out_free;
+
+	s_image = &ctx->in;
+	d_image = &ctx->out;
+
+	/* set tiling and rotation */
+	if (ipu_rot_mode_is_irt(rot_mode)) {
+		d_image->num_rows = s_image->num_cols;
+		d_image->num_cols = s_image->num_rows;
+	} else {
+		d_image->num_rows = s_image->num_rows;
+		d_image->num_cols = s_image->num_cols;
+	}
+
+	ctx->num_tiles = d_image->num_cols * d_image->num_rows;
+
+	ret = fill_image(ctx, s_image, in, IMAGE_CONVERT_IN);
+	if (ret)
+		goto out_free;
+	ret = fill_image(ctx, d_image, out, IMAGE_CONVERT_OUT);
+	if (ret)
+		goto out_free;
+
+	calc_out_tile_map(ctx);
+
+	find_seams(ctx, s_image, d_image);
+
+	ret = calc_tile_dimensions(ctx, s_image);
+	if (ret)
+		goto out_free;
+
+	ret = calc_tile_offsets(ctx, s_image);
+	if (ret)
+		goto out_free;
+
+	calc_tile_dimensions(ctx, d_image);
+	ret = calc_tile_offsets(ctx, d_image);
+	if (ret)
+		goto out_free;
+
+	calc_tile_resize_coefficients(ctx);
+
+	ret = ipu_ic_calc_csc(&ctx->csc,
+			s_image->base.pix.ycbcr_enc,
+			s_image->base.pix.quantization,
+			ipu_pixelformat_to_colorspace(s_image->fmt->fourcc),
+			d_image->base.pix.ycbcr_enc,
+			d_image->base.pix.quantization,
+			ipu_pixelformat_to_colorspace(d_image->fmt->fourcc));
+	if (ret)
+		goto out_free;
+
+	dump_format(ctx, s_image);
+	dump_format(ctx, d_image);
+
+	ctx->complete = complete;
+	ctx->complete_context = complete_context;
+
+	/*
+	 * Can we use double-buffering for this operation? If there is
+	 * only one tile (the whole image can be converted in a single
+	 * operation) there's no point in using double-buffering. Also,
+	 * the IPU's IDMAC channels allow only a single U and V plane
+	 * offset shared between both buffers, but these offsets change
+	 * for every tile, and therefore would have to be updated for
+	 * each buffer which is not possible. So double-buffering is
+	 * impossible when either the source or destination images are
+	 * a planar format (YUV420, YUV422P, etc.). Further, differently
+	 * sized tiles or different resizing coefficients per tile
+	 * prevent double-buffering as well.
+	 */
+	ctx->double_buffering = (ctx->num_tiles > 1 &&
+				 !s_image->fmt->planar &&
+				 !d_image->fmt->planar);
+	for (i = 1; i < ctx->num_tiles; i++) {
+		if (ctx->in.tile[i].width != ctx->in.tile[0].width ||
+		    ctx->in.tile[i].height != ctx->in.tile[0].height ||
+		    ctx->out.tile[i].width != ctx->out.tile[0].width ||
+		    ctx->out.tile[i].height != ctx->out.tile[0].height) {
+			ctx->double_buffering = false;
+			break;
+		}
+	}
+	for (i = 1; i < ctx->in.num_cols; i++) {
+		if (ctx->resize_coeffs_h[i] != ctx->resize_coeffs_h[0]) {
+			ctx->double_buffering = false;
+			break;
+		}
+	}
+	for (i = 1; i < ctx->in.num_rows; i++) {
+		if (ctx->resize_coeffs_v[i] != ctx->resize_coeffs_v[0]) {
+			ctx->double_buffering = false;
+			break;
+		}
+	}
+
+	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
+		unsigned long intermediate_size = d_image->tile[0].size;
+
+		for (i = 1; i < ctx->num_tiles; i++) {
+			if (d_image->tile[i].size > intermediate_size)
+				intermediate_size = d_image->tile[i].size;
+		}
+
+		ret = alloc_dma_buf(priv, &ctx->rot_intermediate[0],
+				    intermediate_size);
+		if (ret)
+			goto out_free;
+		if (ctx->double_buffering) {
+			ret = alloc_dma_buf(priv,
+					    &ctx->rot_intermediate[1],
+					    intermediate_size);
+			if (ret)
+				goto out_free_dmabuf0;
+		}
+	}
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	get_res = list_empty(&chan->ctx_list);
+
+	list_add_tail(&ctx->list, &chan->ctx_list);
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+
+	if (get_res) {
+		ret = get_ipu_resources(chan);
+		if (ret)
+			goto out_free_dmabuf1;
+	}
+
+	return ctx;
+
+out_free_dmabuf1:
+	free_dma_buf(priv, &ctx->rot_intermediate[1]);
+	spin_lock_irqsave(&chan->irqlock, flags);
+	list_del(&ctx->list);
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+out_free_dmabuf0:
+	free_dma_buf(priv, &ctx->rot_intermediate[0]);
+out_free:
+	kfree(ctx);
+	return ERR_PTR(ret);
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_prepare);
+
+/*
+ * Carry out a single image conversion run. Only the physaddr's of the input
+ * and output image buffers are needed. The conversion context must have
+ * been created previously with ipu_image_convert_prepare().
+ */
+int ipu_image_convert_queue(struct ipu_image_convert_run *run)
+{
+	struct ipu_image_convert_chan *chan;
+	struct ipu_image_convert_priv *priv;
+	struct ipu_image_convert_ctx *ctx;
+	unsigned long flags;
+	int ret = 0;
+
+	if (!run || !run->ctx || !run->in_phys || !run->out_phys)
+		return -EINVAL;
+
+	ctx = run->ctx;
+	chan = ctx->chan;
+	priv = chan->priv;
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: ctx %p run %p\n", __func__,
+		chan->ic_task, ctx, run);
+
+	INIT_LIST_HEAD(&run->list);
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	if (ctx->aborting) {
+		ret = -EIO;
+		goto unlock;
+	}
+
+	list_add_tail(&run->list, &chan->pending_q);
+
+	if (!chan->current_run) {
+		ret = do_run(run);
+		if (ret)
+			chan->current_run = NULL;
+	}
+unlock:
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_queue);
+
+/* Abort any active or pending conversions for this context */
+static void __ipu_image_convert_abort(struct ipu_image_convert_ctx *ctx)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	struct ipu_image_convert_run *run, *active_run, *tmp;
+	unsigned long flags;
+	int run_count, ret;
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	/* move all remaining pending runs in this context to done_q */
+	list_for_each_entry_safe(run, tmp, &chan->pending_q, list) {
+		if (run->ctx != ctx)
+			continue;
+		run->status = -EIO;
+		list_move_tail(&run->list, &chan->done_q);
+	}
+
+	run_count = get_run_count(ctx, &chan->done_q);
+	active_run = (chan->current_run && chan->current_run->ctx == ctx) ?
+		chan->current_run : NULL;
+
+	if (active_run)
+		reinit_completion(&ctx->aborted);
+
+	ctx->aborting = true;
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+
+	if (!run_count && !active_run) {
+		dev_dbg(priv->ipu->dev,
+			"%s: task %u: no abort needed for ctx %p\n",
+			__func__, chan->ic_task, ctx);
+		return;
+	}
+
+	if (!active_run) {
+		empty_done_q(chan);
+		return;
+	}
+
+	dev_dbg(priv->ipu->dev,
+		"%s: task %u: wait for completion: %d runs\n",
+		__func__, chan->ic_task, run_count);
+
+	ret = wait_for_completion_timeout(&ctx->aborted,
+					  msecs_to_jiffies(10000));
+	if (ret == 0) {
+		dev_warn(priv->ipu->dev, "%s: timeout\n", __func__);
+		force_abort(ctx);
+	}
+}
+
+void ipu_image_convert_abort(struct ipu_image_convert_ctx *ctx)
+{
+	__ipu_image_convert_abort(ctx);
+	ctx->aborting = false;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_abort);
+
+/* Unprepare image conversion context */
+void ipu_image_convert_unprepare(struct ipu_image_convert_ctx *ctx)
+{
+	struct ipu_image_convert_chan *chan = ctx->chan;
+	struct ipu_image_convert_priv *priv = chan->priv;
+	unsigned long flags;
+	bool put_res;
+
+	/* make sure no runs are hanging around */
+	__ipu_image_convert_abort(ctx);
+
+	dev_dbg(priv->ipu->dev, "%s: task %u: removing ctx %p\n", __func__,
+		chan->ic_task, ctx);
+
+	spin_lock_irqsave(&chan->irqlock, flags);
+
+	list_del(&ctx->list);
+
+	put_res = list_empty(&chan->ctx_list);
+
+	spin_unlock_irqrestore(&chan->irqlock, flags);
+
+	if (put_res)
+		release_ipu_resources(chan);
+
+	free_dma_buf(priv, &ctx->rot_intermediate[1]);
+	free_dma_buf(priv, &ctx->rot_intermediate[0]);
+
+	kfree(ctx);
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_unprepare);
+
+/*
+ * "Canned" asynchronous single image conversion. Allocates and returns
+ * a new conversion run.  On successful return the caller must free the
+ * run and call ipu_image_convert_unprepare() after conversion completes.
+ */
+struct ipu_image_convert_run *
+ipu_image_convert(struct ipu_soc *ipu, enum ipu_ic_task ic_task,
+		  struct ipu_image *in, struct ipu_image *out,
+		  enum ipu_rotate_mode rot_mode,
+		  ipu_image_convert_cb_t complete,
+		  void *complete_context)
+{
+	struct ipu_image_convert_ctx *ctx;
+	struct ipu_image_convert_run *run;
+	int ret;
+
+	ctx = ipu_image_convert_prepare(ipu, ic_task, in, out, rot_mode,
+					complete, complete_context);
+	if (IS_ERR(ctx))
+		return ERR_CAST(ctx);
+
+	run = kzalloc(sizeof(*run), GFP_KERNEL);
+	if (!run) {
+		ipu_image_convert_unprepare(ctx);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	run->ctx = ctx;
+	run->in_phys = in->phys0;
+	run->out_phys = out->phys0;
+
+	ret = ipu_image_convert_queue(run);
+	if (ret) {
+		ipu_image_convert_unprepare(ctx);
+		kfree(run);
+		return ERR_PTR(ret);
+	}
+
+	return run;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert);
+
+/* "Canned" synchronous single image conversion */
+static void image_convert_sync_complete(struct ipu_image_convert_run *run,
+					void *data)
+{
+	struct completion *comp = data;
+
+	complete(comp);
+}
+
+int ipu_image_convert_sync(struct ipu_soc *ipu, enum ipu_ic_task ic_task,
+			   struct ipu_image *in, struct ipu_image *out,
+			   enum ipu_rotate_mode rot_mode)
+{
+	struct ipu_image_convert_run *run;
+	struct completion comp;
+	int ret;
+
+	init_completion(&comp);
+
+	run = ipu_image_convert(ipu, ic_task, in, out, rot_mode,
+				image_convert_sync_complete, &comp);
+	if (IS_ERR(run))
+		return PTR_ERR(run);
+
+	ret = wait_for_completion_timeout(&comp, msecs_to_jiffies(10000));
+	ret = (ret == 0) ? -ETIMEDOUT : 0;
+
+	ipu_image_convert_unprepare(run->ctx);
+	kfree(run);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_image_convert_sync);
+
+int ipu_image_convert_init(struct ipu_soc *ipu, struct device *dev)
+{
+	struct ipu_image_convert_priv *priv;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	ipu->image_convert_priv = priv;
+	priv->ipu = ipu;
+
+	for (i = 0; i < IC_NUM_TASKS; i++) {
+		struct ipu_image_convert_chan *chan = &priv->chan[i];
+
+		chan->ic_task = i;
+		chan->priv = priv;
+		chan->dma_ch = &image_convert_dma_chan[i];
+		chan->in_eof_irq = -1;
+		chan->rot_in_eof_irq = -1;
+		chan->out_eof_irq = -1;
+		chan->rot_out_eof_irq = -1;
+
+		spin_lock_init(&chan->irqlock);
+		INIT_LIST_HEAD(&chan->ctx_list);
+		INIT_LIST_HEAD(&chan->pending_q);
+		INIT_LIST_HEAD(&chan->done_q);
+	}
+
+	return 0;
+}
+
+void ipu_image_convert_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-pre.c b/drivers/gpu/imx/ipu-v3/ipu-pre.c
new file mode 100644
index 000000000..ad82c9e02
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-pre.c
@@ -0,0 +1,346 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2017 Lucas Stach, Pengutronix
+ */
+
+#include <drm/drm_fourcc.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/genalloc.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <video/imx-ipu-v3.h>
+
+#include "ipu-prv.h"
+
+#define IPU_PRE_MAX_WIDTH	2048
+#define IPU_PRE_NUM_SCANLINES	8
+
+#define IPU_PRE_CTRL					0x000
+#define IPU_PRE_CTRL_SET				0x004
+#define  IPU_PRE_CTRL_ENABLE				(1 << 0)
+#define  IPU_PRE_CTRL_BLOCK_EN				(1 << 1)
+#define  IPU_PRE_CTRL_BLOCK_16				(1 << 2)
+#define  IPU_PRE_CTRL_SDW_UPDATE			(1 << 4)
+#define  IPU_PRE_CTRL_VFLIP				(1 << 5)
+#define  IPU_PRE_CTRL_SO				(1 << 6)
+#define  IPU_PRE_CTRL_INTERLACED_FIELD			(1 << 7)
+#define  IPU_PRE_CTRL_HANDSHAKE_EN			(1 << 8)
+#define  IPU_PRE_CTRL_HANDSHAKE_LINE_NUM(v)		((v & 0x3) << 9)
+#define  IPU_PRE_CTRL_HANDSHAKE_ABORT_SKIP_EN		(1 << 11)
+#define  IPU_PRE_CTRL_EN_REPEAT				(1 << 28)
+#define  IPU_PRE_CTRL_TPR_REST_SEL			(1 << 29)
+#define  IPU_PRE_CTRL_CLKGATE				(1 << 30)
+#define  IPU_PRE_CTRL_SFTRST				(1 << 31)
+
+#define IPU_PRE_CUR_BUF					0x030
+
+#define IPU_PRE_NEXT_BUF				0x040
+
+#define IPU_PRE_TPR_CTRL				0x070
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT(v)		((v & 0xff) << 0)
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT_MASK		0xff
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT_16_BIT		(1 << 0)
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT_SPLIT_BUF		(1 << 4)
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT_SINGLE_BUF	(1 << 5)
+#define  IPU_PRE_TPR_CTRL_TILE_FORMAT_SUPER_TILED	(1 << 6)
+
+#define IPU_PRE_PREFETCH_ENG_CTRL			0x080
+#define  IPU_PRE_PREF_ENG_CTRL_PREFETCH_EN		(1 << 0)
+#define  IPU_PRE_PREF_ENG_CTRL_RD_NUM_BYTES(v)		((v & 0x7) << 1)
+#define  IPU_PRE_PREF_ENG_CTRL_INPUT_ACTIVE_BPP(v)	((v & 0x3) << 4)
+#define  IPU_PRE_PREF_ENG_CTRL_INPUT_PIXEL_FORMAT(v)	((v & 0x7) << 8)
+#define  IPU_PRE_PREF_ENG_CTRL_SHIFT_BYPASS		(1 << 11)
+#define  IPU_PRE_PREF_ENG_CTRL_FIELD_INVERSE		(1 << 12)
+#define  IPU_PRE_PREF_ENG_CTRL_PARTIAL_UV_SWAP		(1 << 14)
+#define  IPU_PRE_PREF_ENG_CTRL_TPR_COOR_OFFSET_EN	(1 << 15)
+
+#define IPU_PRE_PREFETCH_ENG_INPUT_SIZE			0x0a0
+#define  IPU_PRE_PREFETCH_ENG_INPUT_SIZE_WIDTH(v)	((v & 0xffff) << 0)
+#define  IPU_PRE_PREFETCH_ENG_INPUT_SIZE_HEIGHT(v)	((v & 0xffff) << 16)
+
+#define IPU_PRE_PREFETCH_ENG_PITCH			0x0d0
+#define  IPU_PRE_PREFETCH_ENG_PITCH_Y(v)		((v & 0xffff) << 0)
+#define  IPU_PRE_PREFETCH_ENG_PITCH_UV(v)		((v & 0xffff) << 16)
+
+#define IPU_PRE_STORE_ENG_CTRL				0x110
+#define  IPU_PRE_STORE_ENG_CTRL_STORE_EN		(1 << 0)
+#define  IPU_PRE_STORE_ENG_CTRL_WR_NUM_BYTES(v)		((v & 0x7) << 1)
+#define  IPU_PRE_STORE_ENG_CTRL_OUTPUT_ACTIVE_BPP(v)	((v & 0x3) << 4)
+
+#define IPU_PRE_STORE_ENG_STATUS			0x120
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_X_MASK	0xffff
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_X_SHIFT	0
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_Y_MASK	0x3fff
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_Y_SHIFT	16
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_FIFO_FULL	(1 << 30)
+#define  IPU_PRE_STORE_ENG_STATUS_STORE_FIELD		(1 << 31)
+
+#define IPU_PRE_STORE_ENG_SIZE				0x130
+#define  IPU_PRE_STORE_ENG_SIZE_INPUT_WIDTH(v)		((v & 0xffff) << 0)
+#define  IPU_PRE_STORE_ENG_SIZE_INPUT_HEIGHT(v)		((v & 0xffff) << 16)
+
+#define IPU_PRE_STORE_ENG_PITCH				0x140
+#define  IPU_PRE_STORE_ENG_PITCH_OUT_PITCH(v)		((v & 0xffff) << 0)
+
+#define IPU_PRE_STORE_ENG_ADDR				0x150
+
+struct ipu_pre {
+	struct list_head	list;
+	struct device		*dev;
+
+	void __iomem		*regs;
+	struct clk		*clk_axi;
+	struct gen_pool		*iram;
+
+	dma_addr_t		buffer_paddr;
+	void			*buffer_virt;
+	bool			in_use;
+	unsigned int		safe_window_end;
+	unsigned int		last_bufaddr;
+};
+
+static DEFINE_MUTEX(ipu_pre_list_mutex);
+static LIST_HEAD(ipu_pre_list);
+static int available_pres;
+
+int ipu_pre_get_available_count(void)
+{
+	return available_pres;
+}
+
+struct ipu_pre *
+ipu_pre_lookup_by_phandle(struct device *dev, const char *name, int index)
+{
+	struct device_node *pre_node = of_parse_phandle(dev->of_node,
+							name, index);
+	struct ipu_pre *pre;
+
+	mutex_lock(&ipu_pre_list_mutex);
+	list_for_each_entry(pre, &ipu_pre_list, list) {
+		if (pre_node == pre->dev->of_node) {
+			mutex_unlock(&ipu_pre_list_mutex);
+			device_link_add(dev, pre->dev,
+					DL_FLAG_AUTOREMOVE_CONSUMER);
+			of_node_put(pre_node);
+			return pre;
+		}
+	}
+	mutex_unlock(&ipu_pre_list_mutex);
+
+	of_node_put(pre_node);
+
+	return NULL;
+}
+
+int ipu_pre_get(struct ipu_pre *pre)
+{
+	u32 val;
+
+	if (pre->in_use)
+		return -EBUSY;
+
+	/* first get the engine out of reset and remove clock gating */
+	writel(0, pre->regs + IPU_PRE_CTRL);
+
+	/* init defaults that should be applied to all streams */
+	val = IPU_PRE_CTRL_HANDSHAKE_ABORT_SKIP_EN |
+	      IPU_PRE_CTRL_HANDSHAKE_EN |
+	      IPU_PRE_CTRL_TPR_REST_SEL |
+	      IPU_PRE_CTRL_SDW_UPDATE;
+	writel(val, pre->regs + IPU_PRE_CTRL);
+
+	pre->in_use = true;
+	return 0;
+}
+
+void ipu_pre_put(struct ipu_pre *pre)
+{
+	writel(IPU_PRE_CTRL_SFTRST, pre->regs + IPU_PRE_CTRL);
+
+	pre->in_use = false;
+}
+
+void ipu_pre_configure(struct ipu_pre *pre, unsigned int width,
+		       unsigned int height, unsigned int stride, u32 format,
+		       uint64_t modifier, unsigned int bufaddr)
+{
+	const struct drm_format_info *info = drm_format_info(format);
+	u32 active_bpp = info->cpp[0] >> 1;
+	u32 val;
+
+	/* calculate safe window for ctrl register updates */
+	if (modifier == DRM_FORMAT_MOD_LINEAR)
+		pre->safe_window_end = height - 2;
+	else
+		pre->safe_window_end = DIV_ROUND_UP(height, 4) - 1;
+
+	writel(bufaddr, pre->regs + IPU_PRE_CUR_BUF);
+	writel(bufaddr, pre->regs + IPU_PRE_NEXT_BUF);
+	pre->last_bufaddr = bufaddr;
+
+	val = IPU_PRE_PREF_ENG_CTRL_INPUT_PIXEL_FORMAT(0) |
+	      IPU_PRE_PREF_ENG_CTRL_INPUT_ACTIVE_BPP(active_bpp) |
+	      IPU_PRE_PREF_ENG_CTRL_RD_NUM_BYTES(4) |
+	      IPU_PRE_PREF_ENG_CTRL_SHIFT_BYPASS |
+	      IPU_PRE_PREF_ENG_CTRL_PREFETCH_EN;
+	writel(val, pre->regs + IPU_PRE_PREFETCH_ENG_CTRL);
+
+	val = IPU_PRE_PREFETCH_ENG_INPUT_SIZE_WIDTH(width) |
+	      IPU_PRE_PREFETCH_ENG_INPUT_SIZE_HEIGHT(height);
+	writel(val, pre->regs + IPU_PRE_PREFETCH_ENG_INPUT_SIZE);
+
+	val = IPU_PRE_PREFETCH_ENG_PITCH_Y(stride);
+	writel(val, pre->regs + IPU_PRE_PREFETCH_ENG_PITCH);
+
+	val = IPU_PRE_STORE_ENG_CTRL_OUTPUT_ACTIVE_BPP(active_bpp) |
+	      IPU_PRE_STORE_ENG_CTRL_WR_NUM_BYTES(4) |
+	      IPU_PRE_STORE_ENG_CTRL_STORE_EN;
+	writel(val, pre->regs + IPU_PRE_STORE_ENG_CTRL);
+
+	val = IPU_PRE_STORE_ENG_SIZE_INPUT_WIDTH(width) |
+	      IPU_PRE_STORE_ENG_SIZE_INPUT_HEIGHT(height);
+	writel(val, pre->regs + IPU_PRE_STORE_ENG_SIZE);
+
+	val = IPU_PRE_STORE_ENG_PITCH_OUT_PITCH(stride);
+	writel(val, pre->regs + IPU_PRE_STORE_ENG_PITCH);
+
+	writel(pre->buffer_paddr, pre->regs + IPU_PRE_STORE_ENG_ADDR);
+
+	val = readl(pre->regs + IPU_PRE_TPR_CTRL);
+	val &= ~IPU_PRE_TPR_CTRL_TILE_FORMAT_MASK;
+	if (modifier != DRM_FORMAT_MOD_LINEAR) {
+		/* only support single buffer formats for now */
+		val |= IPU_PRE_TPR_CTRL_TILE_FORMAT_SINGLE_BUF;
+		if (modifier == DRM_FORMAT_MOD_VIVANTE_SUPER_TILED)
+			val |= IPU_PRE_TPR_CTRL_TILE_FORMAT_SUPER_TILED;
+		if (info->cpp[0] == 2)
+			val |= IPU_PRE_TPR_CTRL_TILE_FORMAT_16_BIT;
+	}
+	writel(val, pre->regs + IPU_PRE_TPR_CTRL);
+
+	val = readl(pre->regs + IPU_PRE_CTRL);
+	val |= IPU_PRE_CTRL_EN_REPEAT | IPU_PRE_CTRL_ENABLE |
+	       IPU_PRE_CTRL_SDW_UPDATE;
+	if (modifier == DRM_FORMAT_MOD_LINEAR)
+		val &= ~IPU_PRE_CTRL_BLOCK_EN;
+	else
+		val |= IPU_PRE_CTRL_BLOCK_EN;
+	writel(val, pre->regs + IPU_PRE_CTRL);
+}
+
+void ipu_pre_update(struct ipu_pre *pre, unsigned int bufaddr)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(5);
+	unsigned short current_yblock;
+	u32 val;
+
+	if (bufaddr == pre->last_bufaddr)
+		return;
+
+	writel(bufaddr, pre->regs + IPU_PRE_NEXT_BUF);
+	pre->last_bufaddr = bufaddr;
+
+	do {
+		if (time_after(jiffies, timeout)) {
+			dev_warn(pre->dev, "timeout waiting for PRE safe window\n");
+			return;
+		}
+
+		val = readl(pre->regs + IPU_PRE_STORE_ENG_STATUS);
+		current_yblock =
+			(val >> IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_Y_SHIFT) &
+			IPU_PRE_STORE_ENG_STATUS_STORE_BLOCK_Y_MASK;
+	} while (current_yblock == 0 || current_yblock >= pre->safe_window_end);
+
+	writel(IPU_PRE_CTRL_SDW_UPDATE, pre->regs + IPU_PRE_CTRL_SET);
+}
+
+bool ipu_pre_update_pending(struct ipu_pre *pre)
+{
+	return !!(readl_relaxed(pre->regs + IPU_PRE_CTRL) &
+		  IPU_PRE_CTRL_SDW_UPDATE);
+}
+
+u32 ipu_pre_get_baddr(struct ipu_pre *pre)
+{
+	return (u32)pre->buffer_paddr;
+}
+
+static int ipu_pre_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct ipu_pre *pre;
+
+	pre = devm_kzalloc(dev, sizeof(*pre), GFP_KERNEL);
+	if (!pre)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	pre->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(pre->regs))
+		return PTR_ERR(pre->regs);
+
+	pre->clk_axi = devm_clk_get(dev, "axi");
+	if (IS_ERR(pre->clk_axi))
+		return PTR_ERR(pre->clk_axi);
+
+	pre->iram = of_gen_pool_get(dev->of_node, "fsl,iram", 0);
+	if (!pre->iram)
+		return -EPROBE_DEFER;
+
+	/*
+	 * Allocate IRAM buffer with maximum size. This could be made dynamic,
+	 * but as there is no other user of this IRAM region and we can fit all
+	 * max sized buffers into it, there is no need yet.
+	 */
+	pre->buffer_virt = gen_pool_dma_alloc(pre->iram, IPU_PRE_MAX_WIDTH *
+					      IPU_PRE_NUM_SCANLINES * 4,
+					      &pre->buffer_paddr);
+	if (!pre->buffer_virt)
+		return -ENOMEM;
+
+	clk_prepare_enable(pre->clk_axi);
+
+	pre->dev = dev;
+	platform_set_drvdata(pdev, pre);
+	mutex_lock(&ipu_pre_list_mutex);
+	list_add(&pre->list, &ipu_pre_list);
+	available_pres++;
+	mutex_unlock(&ipu_pre_list_mutex);
+
+	return 0;
+}
+
+static int ipu_pre_remove(struct platform_device *pdev)
+{
+	struct ipu_pre *pre = platform_get_drvdata(pdev);
+
+	mutex_lock(&ipu_pre_list_mutex);
+	list_del(&pre->list);
+	available_pres--;
+	mutex_unlock(&ipu_pre_list_mutex);
+
+	clk_disable_unprepare(pre->clk_axi);
+
+	if (pre->buffer_virt)
+		gen_pool_free(pre->iram, (unsigned long)pre->buffer_virt,
+			      IPU_PRE_MAX_WIDTH * IPU_PRE_NUM_SCANLINES * 4);
+	return 0;
+}
+
+static const struct of_device_id ipu_pre_dt_ids[] = {
+	{ .compatible = "fsl,imx6qp-pre", },
+	{ /* sentinel */ },
+};
+
+struct platform_driver ipu_pre_drv = {
+	.probe		= ipu_pre_probe,
+	.remove		= ipu_pre_remove,
+	.driver		= {
+		.name	= "imx-ipu-pre",
+		.of_match_table = ipu_pre_dt_ids,
+	},
+};
diff --git a/drivers/gpu/imx/ipu-v3/ipu-prg.c b/drivers/gpu/imx/ipu-v3/ipu-prg.c
new file mode 100644
index 000000000..196797c1b
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-prg.c
@@ -0,0 +1,483 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2016-2017 Lucas Stach, Pengutronix
+ */
+
+#include <drm/drm_fourcc.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/iopoll.h>
+#include <linux/mfd/syscon.h>
+#include <linux/mfd/syscon/imx6q-iomuxc-gpr.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/regmap.h>
+#include <video/imx-ipu-v3.h>
+
+#include "ipu-prv.h"
+
+#define IPU_PRG_CTL				0x00
+#define  IPU_PRG_CTL_BYPASS(i)			(1 << (0 + i))
+#define  IPU_PRG_CTL_SOFT_ARID_MASK		0x3
+#define  IPU_PRG_CTL_SOFT_ARID_SHIFT(i)		(8 + i * 2)
+#define  IPU_PRG_CTL_SOFT_ARID(i, v)		((v & 0x3) << (8 + 2 * i))
+#define  IPU_PRG_CTL_SO(i)			(1 << (16 + i))
+#define  IPU_PRG_CTL_VFLIP(i)			(1 << (19 + i))
+#define  IPU_PRG_CTL_BLOCK_MODE(i)		(1 << (22 + i))
+#define  IPU_PRG_CTL_CNT_LOAD_EN(i)		(1 << (25 + i))
+#define  IPU_PRG_CTL_SOFTRST			(1 << 30)
+#define  IPU_PRG_CTL_SHADOW_EN			(1 << 31)
+
+#define IPU_PRG_STATUS				0x04
+#define  IPU_PRG_STATUS_BUFFER0_READY(i)	(1 << (0 + i * 2))
+#define  IPU_PRG_STATUS_BUFFER1_READY(i)	(1 << (1 + i * 2))
+
+#define IPU_PRG_QOS				0x08
+#define  IPU_PRG_QOS_ARID_MASK			0xf
+#define  IPU_PRG_QOS_ARID_SHIFT(i)		(0 + i * 4)
+
+#define IPU_PRG_REG_UPDATE			0x0c
+#define  IPU_PRG_REG_UPDATE_REG_UPDATE		(1 << 0)
+
+#define IPU_PRG_STRIDE(i)			(0x10 + i * 0x4)
+#define  IPU_PRG_STRIDE_STRIDE_MASK		0x3fff
+
+#define IPU_PRG_CROP_LINE			0x1c
+
+#define IPU_PRG_THD				0x20
+
+#define IPU_PRG_BADDR(i)			(0x24 + i * 0x4)
+
+#define IPU_PRG_OFFSET(i)			(0x30 + i * 0x4)
+
+#define IPU_PRG_ILO(i)				(0x3c + i * 0x4)
+
+#define IPU_PRG_HEIGHT(i)			(0x48 + i * 0x4)
+#define  IPU_PRG_HEIGHT_PRE_HEIGHT_MASK		0xfff
+#define  IPU_PRG_HEIGHT_PRE_HEIGHT_SHIFT	0
+#define  IPU_PRG_HEIGHT_IPU_HEIGHT_MASK		0xfff
+#define  IPU_PRG_HEIGHT_IPU_HEIGHT_SHIFT	16
+
+struct ipu_prg_channel {
+	bool			enabled;
+	int			used_pre;
+};
+
+struct ipu_prg {
+	struct list_head	list;
+	struct device		*dev;
+	int			id;
+
+	void __iomem		*regs;
+	struct clk		*clk_ipg, *clk_axi;
+	struct regmap		*iomuxc_gpr;
+	struct ipu_pre		*pres[3];
+
+	struct ipu_prg_channel	chan[3];
+};
+
+static DEFINE_MUTEX(ipu_prg_list_mutex);
+static LIST_HEAD(ipu_prg_list);
+
+struct ipu_prg *
+ipu_prg_lookup_by_phandle(struct device *dev, const char *name, int ipu_id)
+{
+	struct device_node *prg_node = of_parse_phandle(dev->of_node,
+							name, 0);
+	struct ipu_prg *prg;
+
+	mutex_lock(&ipu_prg_list_mutex);
+	list_for_each_entry(prg, &ipu_prg_list, list) {
+		if (prg_node == prg->dev->of_node) {
+			mutex_unlock(&ipu_prg_list_mutex);
+			device_link_add(dev, prg->dev,
+					DL_FLAG_AUTOREMOVE_CONSUMER);
+			prg->id = ipu_id;
+			of_node_put(prg_node);
+			return prg;
+		}
+	}
+	mutex_unlock(&ipu_prg_list_mutex);
+
+	of_node_put(prg_node);
+
+	return NULL;
+}
+
+int ipu_prg_max_active_channels(void)
+{
+	return ipu_pre_get_available_count();
+}
+EXPORT_SYMBOL_GPL(ipu_prg_max_active_channels);
+
+bool ipu_prg_present(struct ipu_soc *ipu)
+{
+	if (ipu->prg_priv)
+		return true;
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(ipu_prg_present);
+
+bool ipu_prg_format_supported(struct ipu_soc *ipu, uint32_t format,
+			      uint64_t modifier)
+{
+	const struct drm_format_info *info = drm_format_info(format);
+
+	if (info->num_planes != 1)
+		return false;
+
+	switch (modifier) {
+	case DRM_FORMAT_MOD_LINEAR:
+	case DRM_FORMAT_MOD_VIVANTE_TILED:
+	case DRM_FORMAT_MOD_VIVANTE_SUPER_TILED:
+		return true;
+	default:
+		return false;
+	}
+}
+EXPORT_SYMBOL_GPL(ipu_prg_format_supported);
+
+int ipu_prg_enable(struct ipu_soc *ipu)
+{
+	struct ipu_prg *prg = ipu->prg_priv;
+
+	if (!prg)
+		return 0;
+
+	return pm_runtime_get_sync(prg->dev);
+}
+EXPORT_SYMBOL_GPL(ipu_prg_enable);
+
+void ipu_prg_disable(struct ipu_soc *ipu)
+{
+	struct ipu_prg *prg = ipu->prg_priv;
+
+	if (!prg)
+		return;
+
+	pm_runtime_put(prg->dev);
+}
+EXPORT_SYMBOL_GPL(ipu_prg_disable);
+
+/*
+ * The channel configuartion functions below are not thread safe, as they
+ * must be only called from the atomic commit path in the DRM driver, which
+ * is properly serialized.
+ */
+static int ipu_prg_ipu_to_prg_chan(int ipu_chan)
+{
+	/*
+	 * This isn't clearly documented in the RM, but IPU to PRG channel
+	 * assignment is fixed, as only with this mapping the control signals
+	 * match up.
+	 */
+	switch (ipu_chan) {
+	case IPUV3_CHANNEL_MEM_BG_SYNC:
+		return 0;
+	case IPUV3_CHANNEL_MEM_FG_SYNC:
+		return 1;
+	case IPUV3_CHANNEL_MEM_DC_SYNC:
+		return 2;
+	default:
+		return -EINVAL;
+	}
+}
+
+static int ipu_prg_get_pre(struct ipu_prg *prg, int prg_chan)
+{
+	int i, ret;
+
+	/* channel 0 is special as it is hardwired to one of the PREs */
+	if (prg_chan == 0) {
+		ret = ipu_pre_get(prg->pres[0]);
+		if (ret)
+			goto fail;
+		prg->chan[prg_chan].used_pre = 0;
+		return 0;
+	}
+
+	for (i = 1; i < 3; i++) {
+		ret = ipu_pre_get(prg->pres[i]);
+		if (!ret) {
+			u32 val, mux;
+			int shift;
+
+			prg->chan[prg_chan].used_pre = i;
+
+			/* configure the PRE to PRG channel mux */
+			shift = (i == 1) ? 12 : 14;
+			mux = (prg->id << 1) | (prg_chan - 1);
+			regmap_update_bits(prg->iomuxc_gpr, IOMUXC_GPR5,
+					   0x3 << shift, mux << shift);
+
+			/* check other mux, must not point to same channel */
+			shift = (i == 1) ? 14 : 12;
+			regmap_read(prg->iomuxc_gpr, IOMUXC_GPR5, &val);
+			if (((val >> shift) & 0x3) == mux) {
+				regmap_update_bits(prg->iomuxc_gpr, IOMUXC_GPR5,
+						   0x3 << shift,
+						   (mux ^ 0x1) << shift);
+			}
+
+			return 0;
+		}
+	}
+
+fail:
+	dev_err(prg->dev, "could not get PRE for PRG chan %d", prg_chan);
+	return ret;
+}
+
+static void ipu_prg_put_pre(struct ipu_prg *prg, int prg_chan)
+{
+	struct ipu_prg_channel *chan = &prg->chan[prg_chan];
+
+	ipu_pre_put(prg->pres[chan->used_pre]);
+	chan->used_pre = -1;
+}
+
+void ipu_prg_channel_disable(struct ipuv3_channel *ipu_chan)
+{
+	int prg_chan = ipu_prg_ipu_to_prg_chan(ipu_chan->num);
+	struct ipu_prg *prg = ipu_chan->ipu->prg_priv;
+	struct ipu_prg_channel *chan;
+	u32 val;
+
+	if (prg_chan < 0)
+		return;
+
+	chan = &prg->chan[prg_chan];
+	if (!chan->enabled)
+		return;
+
+	pm_runtime_get_sync(prg->dev);
+
+	val = readl(prg->regs + IPU_PRG_CTL);
+	val |= IPU_PRG_CTL_BYPASS(prg_chan);
+	writel(val, prg->regs + IPU_PRG_CTL);
+
+	val = IPU_PRG_REG_UPDATE_REG_UPDATE;
+	writel(val, prg->regs + IPU_PRG_REG_UPDATE);
+
+	pm_runtime_put(prg->dev);
+
+	ipu_prg_put_pre(prg, prg_chan);
+
+	chan->enabled = false;
+}
+EXPORT_SYMBOL_GPL(ipu_prg_channel_disable);
+
+int ipu_prg_channel_configure(struct ipuv3_channel *ipu_chan,
+			      unsigned int axi_id, unsigned int width,
+			      unsigned int height, unsigned int stride,
+			      u32 format, uint64_t modifier, unsigned long *eba)
+{
+	int prg_chan = ipu_prg_ipu_to_prg_chan(ipu_chan->num);
+	struct ipu_prg *prg = ipu_chan->ipu->prg_priv;
+	struct ipu_prg_channel *chan;
+	u32 val;
+	int ret;
+
+	if (prg_chan < 0)
+		return prg_chan;
+
+	chan = &prg->chan[prg_chan];
+
+	if (chan->enabled) {
+		ipu_pre_update(prg->pres[chan->used_pre], *eba);
+		return 0;
+	}
+
+	ret = ipu_prg_get_pre(prg, prg_chan);
+	if (ret)
+		return ret;
+
+	ipu_pre_configure(prg->pres[chan->used_pre],
+			  width, height, stride, format, modifier, *eba);
+
+
+	pm_runtime_get_sync(prg->dev);
+
+	val = (stride - 1) & IPU_PRG_STRIDE_STRIDE_MASK;
+	writel(val, prg->regs + IPU_PRG_STRIDE(prg_chan));
+
+	val = ((height & IPU_PRG_HEIGHT_PRE_HEIGHT_MASK) <<
+	       IPU_PRG_HEIGHT_PRE_HEIGHT_SHIFT) |
+	      ((height & IPU_PRG_HEIGHT_IPU_HEIGHT_MASK) <<
+	       IPU_PRG_HEIGHT_IPU_HEIGHT_SHIFT);
+	writel(val, prg->regs + IPU_PRG_HEIGHT(prg_chan));
+
+	val = ipu_pre_get_baddr(prg->pres[chan->used_pre]);
+	*eba = val;
+	writel(val, prg->regs + IPU_PRG_BADDR(prg_chan));
+
+	val = readl(prg->regs + IPU_PRG_CTL);
+	/* config AXI ID */
+	val &= ~(IPU_PRG_CTL_SOFT_ARID_MASK <<
+		 IPU_PRG_CTL_SOFT_ARID_SHIFT(prg_chan));
+	val |= IPU_PRG_CTL_SOFT_ARID(prg_chan, axi_id);
+	/* enable channel */
+	val &= ~IPU_PRG_CTL_BYPASS(prg_chan);
+	writel(val, prg->regs + IPU_PRG_CTL);
+
+	val = IPU_PRG_REG_UPDATE_REG_UPDATE;
+	writel(val, prg->regs + IPU_PRG_REG_UPDATE);
+
+	/* wait for both double buffers to be filled */
+	readl_poll_timeout(prg->regs + IPU_PRG_STATUS, val,
+			   (val & IPU_PRG_STATUS_BUFFER0_READY(prg_chan)) &&
+			   (val & IPU_PRG_STATUS_BUFFER1_READY(prg_chan)),
+			   5, 1000);
+
+	pm_runtime_put(prg->dev);
+
+	chan->enabled = true;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_prg_channel_configure);
+
+bool ipu_prg_channel_configure_pending(struct ipuv3_channel *ipu_chan)
+{
+	int prg_chan = ipu_prg_ipu_to_prg_chan(ipu_chan->num);
+	struct ipu_prg *prg = ipu_chan->ipu->prg_priv;
+	struct ipu_prg_channel *chan;
+
+	if (prg_chan < 0)
+		return false;
+
+	chan = &prg->chan[prg_chan];
+	WARN_ON(!chan->enabled);
+
+	return ipu_pre_update_pending(prg->pres[chan->used_pre]);
+}
+EXPORT_SYMBOL_GPL(ipu_prg_channel_configure_pending);
+
+static int ipu_prg_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct ipu_prg *prg;
+	u32 val;
+	int i, ret;
+
+	prg = devm_kzalloc(dev, sizeof(*prg), GFP_KERNEL);
+	if (!prg)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	prg->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(prg->regs))
+		return PTR_ERR(prg->regs);
+
+
+	prg->clk_ipg = devm_clk_get(dev, "ipg");
+	if (IS_ERR(prg->clk_ipg))
+		return PTR_ERR(prg->clk_ipg);
+
+	prg->clk_axi = devm_clk_get(dev, "axi");
+	if (IS_ERR(prg->clk_axi))
+		return PTR_ERR(prg->clk_axi);
+
+	prg->iomuxc_gpr =
+		syscon_regmap_lookup_by_compatible("fsl,imx6q-iomuxc-gpr");
+	if (IS_ERR(prg->iomuxc_gpr))
+		return PTR_ERR(prg->iomuxc_gpr);
+
+	for (i = 0; i < 3; i++) {
+		prg->pres[i] = ipu_pre_lookup_by_phandle(dev, "fsl,pres", i);
+		if (!prg->pres[i])
+			return -EPROBE_DEFER;
+	}
+
+	ret = clk_prepare_enable(prg->clk_ipg);
+	if (ret)
+		return ret;
+
+	ret = clk_prepare_enable(prg->clk_axi);
+	if (ret) {
+		clk_disable_unprepare(prg->clk_ipg);
+		return ret;
+	}
+
+	/* init to free running mode */
+	val = readl(prg->regs + IPU_PRG_CTL);
+	val |= IPU_PRG_CTL_SHADOW_EN;
+	writel(val, prg->regs + IPU_PRG_CTL);
+
+	/* disable address threshold */
+	writel(0xffffffff, prg->regs + IPU_PRG_THD);
+
+	pm_runtime_set_active(dev);
+	pm_runtime_enable(dev);
+
+	prg->dev = dev;
+	platform_set_drvdata(pdev, prg);
+	mutex_lock(&ipu_prg_list_mutex);
+	list_add(&prg->list, &ipu_prg_list);
+	mutex_unlock(&ipu_prg_list_mutex);
+
+	return 0;
+}
+
+static int ipu_prg_remove(struct platform_device *pdev)
+{
+	struct ipu_prg *prg = platform_get_drvdata(pdev);
+
+	mutex_lock(&ipu_prg_list_mutex);
+	list_del(&prg->list);
+	mutex_unlock(&ipu_prg_list_mutex);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int prg_suspend(struct device *dev)
+{
+	struct ipu_prg *prg = dev_get_drvdata(dev);
+
+	clk_disable_unprepare(prg->clk_axi);
+	clk_disable_unprepare(prg->clk_ipg);
+
+	return 0;
+}
+
+static int prg_resume(struct device *dev)
+{
+	struct ipu_prg *prg = dev_get_drvdata(dev);
+	int ret;
+
+	ret = clk_prepare_enable(prg->clk_ipg);
+	if (ret)
+		return ret;
+
+	ret = clk_prepare_enable(prg->clk_axi);
+	if (ret) {
+		clk_disable_unprepare(prg->clk_ipg);
+		return ret;
+	}
+
+	return 0;
+}
+#endif
+
+static const struct dev_pm_ops prg_pm_ops = {
+	SET_RUNTIME_PM_OPS(prg_suspend, prg_resume, NULL)
+};
+
+static const struct of_device_id ipu_prg_dt_ids[] = {
+	{ .compatible = "fsl,imx6qp-prg", },
+	{ /* sentinel */ },
+};
+
+struct platform_driver ipu_prg_drv = {
+	.probe		= ipu_prg_probe,
+	.remove		= ipu_prg_remove,
+	.driver		= {
+		.name	= "imx-ipu-prg",
+		.pm	= &prg_pm_ops,
+		.of_match_table = ipu_prg_dt_ids,
+	},
+};
diff --git a/drivers/gpu/imx/ipu-v3/ipu-prv.h b/drivers/gpu/imx/ipu-v3/ipu-prv.h
new file mode 100644
index 000000000..291ac1bab
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-prv.h
@@ -0,0 +1,274 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+/*
+ * Copyright (c) 2010 Sascha Hauer <s.hauer@pengutronix.de>
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#ifndef __IPU_PRV_H__
+#define __IPU_PRV_H__
+
+struct ipu_soc;
+
+#include <linux/types.h>
+#include <linux/device.h>
+#include <linux/clk.h>
+#include <linux/platform_device.h>
+
+#include <video/imx-ipu-v3.h>
+
+#define IPU_MCU_T_DEFAULT	8
+#define IPU_CM_IDMAC_REG_OFS	0x00008000
+#define IPU_CM_IC_REG_OFS	0x00020000
+#define IPU_CM_IRT_REG_OFS	0x00028000
+#define IPU_CM_CSI0_REG_OFS	0x00030000
+#define IPU_CM_CSI1_REG_OFS	0x00038000
+#define IPU_CM_SMFC_REG_OFS	0x00050000
+#define IPU_CM_DC_REG_OFS	0x00058000
+#define IPU_CM_DMFC_REG_OFS	0x00060000
+
+/* Register addresses */
+/* IPU Common registers */
+#define IPU_CM_REG(offset)	(offset)
+
+#define IPU_CONF			IPU_CM_REG(0)
+
+#define IPU_SRM_PRI1			IPU_CM_REG(0x00a0)
+#define IPU_SRM_PRI2			IPU_CM_REG(0x00a4)
+#define IPU_FS_PROC_FLOW1		IPU_CM_REG(0x00a8)
+#define IPU_FS_PROC_FLOW2		IPU_CM_REG(0x00ac)
+#define IPU_FS_PROC_FLOW3		IPU_CM_REG(0x00b0)
+#define IPU_FS_DISP_FLOW1		IPU_CM_REG(0x00b4)
+#define IPU_FS_DISP_FLOW2		IPU_CM_REG(0x00b8)
+#define IPU_SKIP			IPU_CM_REG(0x00bc)
+#define IPU_DISP_ALT_CONF		IPU_CM_REG(0x00c0)
+#define IPU_DISP_GEN			IPU_CM_REG(0x00c4)
+#define IPU_DISP_ALT1			IPU_CM_REG(0x00c8)
+#define IPU_DISP_ALT2			IPU_CM_REG(0x00cc)
+#define IPU_DISP_ALT3			IPU_CM_REG(0x00d0)
+#define IPU_DISP_ALT4			IPU_CM_REG(0x00d4)
+#define IPU_SNOOP			IPU_CM_REG(0x00d8)
+#define IPU_MEM_RST			IPU_CM_REG(0x00dc)
+#define IPU_PM				IPU_CM_REG(0x00e0)
+#define IPU_GPR				IPU_CM_REG(0x00e4)
+#define IPU_CHA_DB_MODE_SEL(ch)		IPU_CM_REG(0x0150 + 4 * ((ch) / 32))
+#define IPU_ALT_CHA_DB_MODE_SEL(ch)	IPU_CM_REG(0x0168 + 4 * ((ch) / 32))
+#define IPU_CHA_CUR_BUF(ch)		IPU_CM_REG(0x023C + 4 * ((ch) / 32))
+#define IPU_ALT_CUR_BUF0		IPU_CM_REG(0x0244)
+#define IPU_ALT_CUR_BUF1		IPU_CM_REG(0x0248)
+#define IPU_SRM_STAT			IPU_CM_REG(0x024C)
+#define IPU_PROC_TASK_STAT		IPU_CM_REG(0x0250)
+#define IPU_DISP_TASK_STAT		IPU_CM_REG(0x0254)
+#define IPU_CHA_BUF0_RDY(ch)		IPU_CM_REG(0x0268 + 4 * ((ch) / 32))
+#define IPU_CHA_BUF1_RDY(ch)		IPU_CM_REG(0x0270 + 4 * ((ch) / 32))
+#define IPU_CHA_BUF2_RDY(ch)		IPU_CM_REG(0x0288 + 4 * ((ch) / 32))
+#define IPU_ALT_CHA_BUF0_RDY(ch)	IPU_CM_REG(0x0278 + 4 * ((ch) / 32))
+#define IPU_ALT_CHA_BUF1_RDY(ch)	IPU_CM_REG(0x0280 + 4 * ((ch) / 32))
+
+#define IPU_INT_CTRL(n)		IPU_CM_REG(0x003C + 4 * (n))
+#define IPU_INT_STAT(n)		IPU_CM_REG(0x0200 + 4 * (n))
+
+/* SRM_PRI2 */
+#define DP_S_SRM_MODE_MASK		(0x3 << 3)
+#define DP_S_SRM_MODE_NOW		(0x3 << 3)
+#define DP_S_SRM_MODE_NEXT_FRAME	(0x1 << 3)
+
+/* FS_PROC_FLOW1 */
+#define FS_PRPENC_ROT_SRC_SEL_MASK	(0xf << 0)
+#define FS_PRPENC_ROT_SRC_SEL_ENC		(0x7 << 0)
+#define FS_PRPVF_ROT_SRC_SEL_MASK	(0xf << 8)
+#define FS_PRPVF_ROT_SRC_SEL_VF			(0x8 << 8)
+#define FS_PP_SRC_SEL_MASK		(0xf << 12)
+#define FS_PP_ROT_SRC_SEL_MASK		(0xf << 16)
+#define FS_PP_ROT_SRC_SEL_PP			(0x5 << 16)
+#define FS_VDI1_SRC_SEL_MASK		(0x3 << 20)
+#define FS_VDI3_SRC_SEL_MASK		(0x3 << 20)
+#define FS_PRP_SRC_SEL_MASK		(0xf << 24)
+#define FS_VDI_SRC_SEL_MASK		(0x3 << 28)
+#define FS_VDI_SRC_SEL_CSI_DIRECT		(0x1 << 28)
+#define FS_VDI_SRC_SEL_VDOA			(0x2 << 28)
+
+/* FS_PROC_FLOW2 */
+#define FS_PRP_ENC_DEST_SEL_MASK	(0xf << 0)
+#define FS_PRP_ENC_DEST_SEL_IRT_ENC		(0x1 << 0)
+#define FS_PRPVF_DEST_SEL_MASK		(0xf << 4)
+#define FS_PRPVF_DEST_SEL_IRT_VF		(0x1 << 4)
+#define FS_PRPVF_ROT_DEST_SEL_MASK	(0xf << 8)
+#define FS_PP_DEST_SEL_MASK		(0xf << 12)
+#define FS_PP_DEST_SEL_IRT_PP			(0x3 << 12)
+#define FS_PP_ROT_DEST_SEL_MASK		(0xf << 16)
+#define FS_PRPENC_ROT_DEST_SEL_MASK	(0xf << 20)
+#define FS_PRP_DEST_SEL_MASK		(0xf << 24)
+
+#define IPU_DI0_COUNTER_RELEASE			(1 << 24)
+#define IPU_DI1_COUNTER_RELEASE			(1 << 25)
+
+#define IPU_IDMAC_REG(offset)	(offset)
+
+#define IDMAC_CONF			IPU_IDMAC_REG(0x0000)
+#define IDMAC_CHA_EN(ch)		IPU_IDMAC_REG(0x0004 + 4 * ((ch) / 32))
+#define IDMAC_SEP_ALPHA			IPU_IDMAC_REG(0x000c)
+#define IDMAC_ALT_SEP_ALPHA		IPU_IDMAC_REG(0x0010)
+#define IDMAC_CHA_PRI(ch)		IPU_IDMAC_REG(0x0014 + 4 * ((ch) / 32))
+#define IDMAC_WM_EN(ch)			IPU_IDMAC_REG(0x001c + 4 * ((ch) / 32))
+#define IDMAC_CH_LOCK_EN_1		IPU_IDMAC_REG(0x0024)
+#define IDMAC_CH_LOCK_EN_2		IPU_IDMAC_REG(0x0028)
+#define IDMAC_SUB_ADDR_0		IPU_IDMAC_REG(0x002c)
+#define IDMAC_SUB_ADDR_1		IPU_IDMAC_REG(0x0030)
+#define IDMAC_SUB_ADDR_2		IPU_IDMAC_REG(0x0034)
+#define IDMAC_BAND_EN(ch)		IPU_IDMAC_REG(0x0040 + 4 * ((ch) / 32))
+#define IDMAC_CHA_BUSY(ch)		IPU_IDMAC_REG(0x0100 + 4 * ((ch) / 32))
+
+#define IPU_NUM_IRQS	(32 * 15)
+
+enum ipu_modules {
+	IPU_CONF_CSI0_EN		= (1 << 0),
+	IPU_CONF_CSI1_EN		= (1 << 1),
+	IPU_CONF_IC_EN			= (1 << 2),
+	IPU_CONF_ROT_EN			= (1 << 3),
+	IPU_CONF_ISP_EN			= (1 << 4),
+	IPU_CONF_DP_EN			= (1 << 5),
+	IPU_CONF_DI0_EN			= (1 << 6),
+	IPU_CONF_DI1_EN			= (1 << 7),
+	IPU_CONF_SMFC_EN		= (1 << 8),
+	IPU_CONF_DC_EN			= (1 << 9),
+	IPU_CONF_DMFC_EN		= (1 << 10),
+
+	IPU_CONF_VDI_EN			= (1 << 12),
+
+	IPU_CONF_IDMAC_DIS		= (1 << 22),
+
+	IPU_CONF_IC_DMFC_SEL		= (1 << 25),
+	IPU_CONF_IC_DMFC_SYNC		= (1 << 26),
+	IPU_CONF_VDI_DMFC_SYNC		= (1 << 27),
+
+	IPU_CONF_CSI0_DATA_SOURCE	= (1 << 28),
+	IPU_CONF_CSI1_DATA_SOURCE	= (1 << 29),
+	IPU_CONF_IC_INPUT		= (1 << 30),
+	IPU_CONF_CSI_SEL		= (1 << 31),
+};
+
+struct ipuv3_channel {
+	unsigned int num;
+	struct ipu_soc *ipu;
+	struct list_head list;
+};
+
+struct ipu_cpmem;
+struct ipu_csi;
+struct ipu_dc_priv;
+struct ipu_dmfc_priv;
+struct ipu_di;
+struct ipu_ic_priv;
+struct ipu_vdi;
+struct ipu_image_convert_priv;
+struct ipu_smfc_priv;
+struct ipu_pre;
+struct ipu_prg;
+
+struct ipu_devtype;
+
+struct ipu_soc {
+	struct device		*dev;
+	const struct ipu_devtype	*devtype;
+	enum ipuv3_type		ipu_type;
+	spinlock_t		lock;
+	struct mutex		channel_lock;
+	struct list_head	channels;
+
+	void __iomem		*cm_reg;
+	void __iomem		*idmac_reg;
+
+	int			id;
+	int			usecount;
+
+	struct clk		*clk;
+
+	int			irq_sync;
+	int			irq_err;
+	struct irq_domain	*domain;
+
+	struct ipu_cpmem	*cpmem_priv;
+	struct ipu_dc_priv	*dc_priv;
+	struct ipu_dp_priv	*dp_priv;
+	struct ipu_dmfc_priv	*dmfc_priv;
+	struct ipu_di		*di_priv[2];
+	struct ipu_csi		*csi_priv[2];
+	struct ipu_ic_priv	*ic_priv;
+	struct ipu_vdi          *vdi_priv;
+	struct ipu_image_convert_priv *image_convert_priv;
+	struct ipu_smfc_priv	*smfc_priv;
+	struct ipu_prg		*prg_priv;
+};
+
+static inline u32 ipu_idmac_read(struct ipu_soc *ipu, unsigned offset)
+{
+	return readl(ipu->idmac_reg + offset);
+}
+
+static inline void ipu_idmac_write(struct ipu_soc *ipu, u32 value,
+				   unsigned offset)
+{
+	writel(value, ipu->idmac_reg + offset);
+}
+
+void ipu_srm_dp_update(struct ipu_soc *ipu, bool sync);
+
+int ipu_module_enable(struct ipu_soc *ipu, u32 mask);
+int ipu_module_disable(struct ipu_soc *ipu, u32 mask);
+
+bool ipu_idmac_channel_busy(struct ipu_soc *ipu, unsigned int chno);
+
+int ipu_csi_init(struct ipu_soc *ipu, struct device *dev, int id,
+		 unsigned long base, u32 module, struct clk *clk_ipu);
+void ipu_csi_exit(struct ipu_soc *ipu, int id);
+
+int ipu_ic_init(struct ipu_soc *ipu, struct device *dev,
+		unsigned long base, unsigned long tpmem_base);
+void ipu_ic_exit(struct ipu_soc *ipu);
+
+int ipu_vdi_init(struct ipu_soc *ipu, struct device *dev,
+		 unsigned long base, u32 module);
+void ipu_vdi_exit(struct ipu_soc *ipu);
+
+int ipu_image_convert_init(struct ipu_soc *ipu, struct device *dev);
+void ipu_image_convert_exit(struct ipu_soc *ipu);
+
+int ipu_di_init(struct ipu_soc *ipu, struct device *dev, int id,
+		unsigned long base, u32 module, struct clk *ipu_clk);
+void ipu_di_exit(struct ipu_soc *ipu, int id);
+
+int ipu_dmfc_init(struct ipu_soc *ipu, struct device *dev, unsigned long base,
+		struct clk *ipu_clk);
+void ipu_dmfc_exit(struct ipu_soc *ipu);
+
+int ipu_dp_init(struct ipu_soc *ipu, struct device *dev, unsigned long base);
+void ipu_dp_exit(struct ipu_soc *ipu);
+
+int ipu_dc_init(struct ipu_soc *ipu, struct device *dev, unsigned long base,
+		unsigned long template_base);
+void ipu_dc_exit(struct ipu_soc *ipu);
+
+int ipu_cpmem_init(struct ipu_soc *ipu, struct device *dev, unsigned long base);
+void ipu_cpmem_exit(struct ipu_soc *ipu);
+
+int ipu_smfc_init(struct ipu_soc *ipu, struct device *dev, unsigned long base);
+void ipu_smfc_exit(struct ipu_soc *ipu);
+
+struct ipu_pre *ipu_pre_lookup_by_phandle(struct device *dev, const char *name,
+					  int index);
+int ipu_pre_get_available_count(void);
+int ipu_pre_get(struct ipu_pre *pre);
+void ipu_pre_put(struct ipu_pre *pre);
+u32 ipu_pre_get_baddr(struct ipu_pre *pre);
+void ipu_pre_configure(struct ipu_pre *pre, unsigned int width,
+		       unsigned int height, unsigned int stride, u32 format,
+		       uint64_t modifier, unsigned int bufaddr);
+void ipu_pre_update(struct ipu_pre *pre, unsigned int bufaddr);
+bool ipu_pre_update_pending(struct ipu_pre *pre);
+
+struct ipu_prg *ipu_prg_lookup_by_phandle(struct device *dev, const char *name,
+					  int ipu_id);
+
+extern struct platform_driver ipu_pre_drv;
+extern struct platform_driver ipu_prg_drv;
+
+#endif				/* __IPU_PRV_H__ */
diff --git a/drivers/gpu/imx/ipu-v3/ipu-smfc.c b/drivers/gpu/imx/ipu-v3/ipu-smfc.c
new file mode 100644
index 000000000..46ffc0a59
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-smfc.c
@@ -0,0 +1,202 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright 2008-2010 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+#include <linux/export.h>
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/errno.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/clk.h>
+#include <video/imx-ipu-v3.h>
+
+#include "ipu-prv.h"
+
+struct ipu_smfc {
+	struct ipu_smfc_priv *priv;
+	int chno;
+	bool inuse;
+};
+
+struct ipu_smfc_priv {
+	void __iomem *base;
+	spinlock_t lock;
+	struct ipu_soc *ipu;
+	struct ipu_smfc channel[4];
+	int use_count;
+};
+
+/*SMFC Registers */
+#define SMFC_MAP	0x0000
+#define SMFC_WMC	0x0004
+#define SMFC_BS		0x0008
+
+int ipu_smfc_set_burstsize(struct ipu_smfc *smfc, int burstsize)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+	u32 val, shift;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	shift = smfc->chno * 4;
+	val = readl(priv->base + SMFC_BS);
+	val &= ~(0xf << shift);
+	val |= burstsize << shift;
+	writel(val, priv->base + SMFC_BS);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_set_burstsize);
+
+int ipu_smfc_map_channel(struct ipu_smfc *smfc, int csi_id, int mipi_id)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+	u32 val, shift;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	shift = smfc->chno * 3;
+	val = readl(priv->base + SMFC_MAP);
+	val &= ~(0x7 << shift);
+	val |= ((csi_id << 2) | mipi_id) << shift;
+	writel(val, priv->base + SMFC_MAP);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_map_channel);
+
+int ipu_smfc_set_watermark(struct ipu_smfc *smfc, u32 set_level, u32 clr_level)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+	u32 val, shift;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	shift = smfc->chno * 6 + (smfc->chno > 1 ? 4 : 0);
+	val = readl(priv->base + SMFC_WMC);
+	val &= ~(0x3f << shift);
+	val |= ((clr_level << 3) | set_level) << shift;
+	writel(val, priv->base + SMFC_WMC);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_set_watermark);
+
+int ipu_smfc_enable(struct ipu_smfc *smfc)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	if (!priv->use_count)
+		ipu_module_enable(priv->ipu, IPU_CONF_SMFC_EN);
+
+	priv->use_count++;
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_enable);
+
+int ipu_smfc_disable(struct ipu_smfc *smfc)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	priv->use_count--;
+
+	if (!priv->use_count)
+		ipu_module_disable(priv->ipu, IPU_CONF_SMFC_EN);
+
+	if (priv->use_count < 0)
+		priv->use_count = 0;
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_disable);
+
+struct ipu_smfc *ipu_smfc_get(struct ipu_soc *ipu, unsigned int chno)
+{
+	struct ipu_smfc_priv *priv = ipu->smfc_priv;
+	struct ipu_smfc *smfc, *ret;
+	unsigned long flags;
+
+	if (chno >= 4)
+		return ERR_PTR(-EINVAL);
+
+	smfc = &priv->channel[chno];
+	ret = smfc;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	if (smfc->inuse) {
+		ret = ERR_PTR(-EBUSY);
+		goto unlock;
+	}
+
+	smfc->inuse = true;
+unlock:
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_get);
+
+void ipu_smfc_put(struct ipu_smfc *smfc)
+{
+	struct ipu_smfc_priv *priv = smfc->priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	smfc->inuse = false;
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_smfc_put);
+
+int ipu_smfc_init(struct ipu_soc *ipu, struct device *dev,
+		  unsigned long base)
+{
+	struct ipu_smfc_priv *priv;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	ipu->smfc_priv = priv;
+	spin_lock_init(&priv->lock);
+	priv->ipu = ipu;
+
+	priv->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!priv->base)
+		return -ENOMEM;
+
+	for (i = 0; i < 4; i++) {
+		priv->channel[i].priv = priv;
+		priv->channel[i].chno = i;
+	}
+
+	pr_debug("%s: ioremap 0x%08lx -> %p\n", __func__, base, priv->base);
+
+	return 0;
+}
+
+void ipu_smfc_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/ipu-v3/ipu-vdi.c b/drivers/gpu/imx/ipu-v3/ipu-vdi.c
new file mode 100644
index 000000000..a593b232b
--- /dev/null
+++ b/drivers/gpu/imx/ipu-v3/ipu-vdi.c
@@ -0,0 +1,234 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (C) 2012-2016 Mentor Graphics Inc.
+ * Copyright (C) 2005-2009 Freescale Semiconductor, Inc.
+ */
+#include <linux/io.h>
+#include "ipu-prv.h"
+
+struct ipu_vdi {
+	void __iomem *base;
+	u32 module;
+	spinlock_t lock;
+	int use_count;
+	struct ipu_soc *ipu;
+};
+
+
+/* VDI Register Offsets */
+#define VDI_FSIZE 0x0000
+#define VDI_C     0x0004
+
+/* VDI Register Fields */
+#define VDI_C_CH_420             (0 << 1)
+#define VDI_C_CH_422             (1 << 1)
+#define VDI_C_MOT_SEL_MASK       (0x3 << 2)
+#define VDI_C_MOT_SEL_FULL       (2 << 2)
+#define VDI_C_MOT_SEL_LOW        (1 << 2)
+#define VDI_C_MOT_SEL_MED        (0 << 2)
+#define VDI_C_BURST_SIZE1_4      (3 << 4)
+#define VDI_C_BURST_SIZE2_4      (3 << 8)
+#define VDI_C_BURST_SIZE3_4      (3 << 12)
+#define VDI_C_BURST_SIZE_MASK    0xF
+#define VDI_C_BURST_SIZE1_OFFSET 4
+#define VDI_C_BURST_SIZE2_OFFSET 8
+#define VDI_C_BURST_SIZE3_OFFSET 12
+#define VDI_C_VWM1_SET_1         (0 << 16)
+#define VDI_C_VWM1_SET_2         (1 << 16)
+#define VDI_C_VWM1_CLR_2         (1 << 19)
+#define VDI_C_VWM3_SET_1         (0 << 22)
+#define VDI_C_VWM3_SET_2         (1 << 22)
+#define VDI_C_VWM3_CLR_2         (1 << 25)
+#define VDI_C_TOP_FIELD_MAN_1    (1 << 30)
+#define VDI_C_TOP_FIELD_AUTO_1   (1 << 31)
+
+static inline u32 ipu_vdi_read(struct ipu_vdi *vdi, unsigned int offset)
+{
+	return readl(vdi->base + offset);
+}
+
+static inline void ipu_vdi_write(struct ipu_vdi *vdi, u32 value,
+				 unsigned int offset)
+{
+	writel(value, vdi->base + offset);
+}
+
+void ipu_vdi_set_field_order(struct ipu_vdi *vdi, v4l2_std_id std, u32 field)
+{
+	bool top_field_0 = false;
+	unsigned long flags;
+	u32 reg;
+
+	switch (field) {
+	case V4L2_FIELD_INTERLACED_TB:
+	case V4L2_FIELD_SEQ_TB:
+	case V4L2_FIELD_TOP:
+		top_field_0 = true;
+		break;
+	case V4L2_FIELD_INTERLACED_BT:
+	case V4L2_FIELD_SEQ_BT:
+	case V4L2_FIELD_BOTTOM:
+		top_field_0 = false;
+		break;
+	default:
+		top_field_0 = (std & V4L2_STD_525_60) ? true : false;
+		break;
+	}
+
+	spin_lock_irqsave(&vdi->lock, flags);
+
+	reg = ipu_vdi_read(vdi, VDI_C);
+	if (top_field_0)
+		reg &= ~(VDI_C_TOP_FIELD_MAN_1 | VDI_C_TOP_FIELD_AUTO_1);
+	else
+		reg |= VDI_C_TOP_FIELD_MAN_1 | VDI_C_TOP_FIELD_AUTO_1;
+	ipu_vdi_write(vdi, reg, VDI_C);
+
+	spin_unlock_irqrestore(&vdi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_set_field_order);
+
+void ipu_vdi_set_motion(struct ipu_vdi *vdi, enum ipu_motion_sel motion_sel)
+{
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&vdi->lock, flags);
+
+	reg = ipu_vdi_read(vdi, VDI_C);
+
+	reg &= ~VDI_C_MOT_SEL_MASK;
+
+	switch (motion_sel) {
+	case MED_MOTION:
+		reg |= VDI_C_MOT_SEL_MED;
+		break;
+	case HIGH_MOTION:
+		reg |= VDI_C_MOT_SEL_FULL;
+		break;
+	default:
+		reg |= VDI_C_MOT_SEL_LOW;
+		break;
+	}
+
+	ipu_vdi_write(vdi, reg, VDI_C);
+
+	spin_unlock_irqrestore(&vdi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_set_motion);
+
+void ipu_vdi_setup(struct ipu_vdi *vdi, u32 code, int xres, int yres)
+{
+	unsigned long flags;
+	u32 pixel_fmt, reg;
+
+	spin_lock_irqsave(&vdi->lock, flags);
+
+	reg = ((yres - 1) << 16) | (xres - 1);
+	ipu_vdi_write(vdi, reg, VDI_FSIZE);
+
+	/*
+	 * Full motion, only vertical filter is used.
+	 * Burst size is 4 accesses
+	 */
+	if (code == MEDIA_BUS_FMT_UYVY8_2X8 ||
+	    code == MEDIA_BUS_FMT_UYVY8_1X16 ||
+	    code == MEDIA_BUS_FMT_YUYV8_2X8 ||
+	    code == MEDIA_BUS_FMT_YUYV8_1X16)
+		pixel_fmt = VDI_C_CH_422;
+	else
+		pixel_fmt = VDI_C_CH_420;
+
+	reg = ipu_vdi_read(vdi, VDI_C);
+	reg |= pixel_fmt;
+	reg |= VDI_C_BURST_SIZE2_4;
+	reg |= VDI_C_BURST_SIZE1_4 | VDI_C_VWM1_CLR_2;
+	reg |= VDI_C_BURST_SIZE3_4 | VDI_C_VWM3_CLR_2;
+	ipu_vdi_write(vdi, reg, VDI_C);
+
+	spin_unlock_irqrestore(&vdi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_setup);
+
+void ipu_vdi_unsetup(struct ipu_vdi *vdi)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&vdi->lock, flags);
+	ipu_vdi_write(vdi, 0, VDI_FSIZE);
+	ipu_vdi_write(vdi, 0, VDI_C);
+	spin_unlock_irqrestore(&vdi->lock, flags);
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_unsetup);
+
+int ipu_vdi_enable(struct ipu_vdi *vdi)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&vdi->lock, flags);
+
+	if (!vdi->use_count)
+		ipu_module_enable(vdi->ipu, vdi->module);
+
+	vdi->use_count++;
+
+	spin_unlock_irqrestore(&vdi->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_enable);
+
+int ipu_vdi_disable(struct ipu_vdi *vdi)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&vdi->lock, flags);
+
+	if (vdi->use_count) {
+		if (!--vdi->use_count)
+			ipu_module_disable(vdi->ipu, vdi->module);
+	}
+
+	spin_unlock_irqrestore(&vdi->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_disable);
+
+struct ipu_vdi *ipu_vdi_get(struct ipu_soc *ipu)
+{
+	return ipu->vdi_priv;
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_get);
+
+void ipu_vdi_put(struct ipu_vdi *vdi)
+{
+}
+EXPORT_SYMBOL_GPL(ipu_vdi_put);
+
+int ipu_vdi_init(struct ipu_soc *ipu, struct device *dev,
+		 unsigned long base, u32 module)
+{
+	struct ipu_vdi *vdi;
+
+	vdi = devm_kzalloc(dev, sizeof(*vdi), GFP_KERNEL);
+	if (!vdi)
+		return -ENOMEM;
+
+	ipu->vdi_priv = vdi;
+
+	spin_lock_init(&vdi->lock);
+	vdi->module = module;
+	vdi->base = devm_ioremap(dev, base, PAGE_SIZE);
+	if (!vdi->base)
+		return -ENOMEM;
+
+	dev_dbg(dev, "VDI base: 0x%08lx remapped to %p\n", base, vdi->base);
+	vdi->ipu = ipu;
+
+	return 0;
+}
+
+void ipu_vdi_exit(struct ipu_soc *ipu)
+{
+}
diff --git a/drivers/gpu/imx/lcdif/Kconfig b/drivers/gpu/imx/lcdif/Kconfig
new file mode 100644
index 000000000..dfaea1207
--- /dev/null
+++ b/drivers/gpu/imx/lcdif/Kconfig
@@ -0,0 +1,9 @@
+config IMX_LCDIF_CORE
+	tristate "i.MX LCDIF core support"
+	depends on ARCH_MXC
+	depends on DRM && OF
+	select RESET_CONTROLLER
+	help
+	  Choose this if you have a NXP i.MX8MM platform and want to use the
+	  LCDIF display controller. This option only enables LCDIF base support.
+
diff --git a/drivers/gpu/imx/lcdif/Makefile b/drivers/gpu/imx/lcdif/Makefile
new file mode 100644
index 000000000..8c7ce5ccc
--- /dev/null
+++ b/drivers/gpu/imx/lcdif/Makefile
@@ -0,0 +1,3 @@
+obj-$(CONFIG_IMX_LCDIF_CORE) += imx-lcdif-core.o
+
+imx-lcdif-core-objs := lcdif-common.o
diff --git a/drivers/gpu/imx/lcdif/lcdif-common.c b/drivers/gpu/imx/lcdif/lcdif-common.c
new file mode 100644
index 000000000..09b07758b
--- /dev/null
+++ b/drivers/gpu/imx/lcdif/lcdif-common.c
@@ -0,0 +1,854 @@
+/*
+ * Copyright 2018,2021-2022 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/busfreq-imx.h>
+#include <linux/clk.h>
+#include <linux/iopoll.h>
+#include <linux/media-bus-format.h>
+#include <linux/mfd/syscon.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/reset.h>
+#include <linux/types.h>
+#include <drm/drm_fourcc.h>
+#include <video/imx-lcdif.h>
+#include <video/videomode.h>
+
+#include "lcdif-regs.h"
+
+#define DRIVER_NAME "imx-lcdif"
+
+struct lcdif_soc {
+	struct device *dev;
+
+	int irq;
+	void __iomem *base;
+	struct reset_control *soft_resetn;
+	struct reset_control *clk_enable;
+	atomic_t rpm_suspended;
+
+	struct clk *clk_pix;
+	struct clk *clk_disp_axi;
+	struct clk *clk_disp_apb;
+};
+
+struct lcdif_soc_pdata {
+	bool hsync_invert;
+	bool vsync_invert;
+	bool de_invert;
+};
+
+struct lcdif_platform_reg {
+	struct lcdif_client_platformdata pdata;
+	char *name;
+};
+
+struct lcdif_platform_reg client_reg[] = {
+	{
+		.pdata = { },
+		.name  = "imx-lcdif-crtc",
+	},
+};
+
+struct lcdif_soc_pdata imx8mm_pdata = {
+	.hsync_invert = true,
+	.vsync_invert = true,
+	.de_invert    = true,
+};
+
+static const struct of_device_id imx_lcdif_dt_ids[] = {
+	{ .compatible = "fsl,imx8mm-lcdif", .data = &imx8mm_pdata, },
+	{ .compatible = "fsl,imx8mn-lcdif", .data = &imx8mm_pdata, },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, imx_lcdif_dt_ids);
+
+#ifdef CONFIG_PM
+static int imx_lcdif_runtime_suspend(struct device *dev);
+static int imx_lcdif_runtime_resume(struct device *dev);
+#else
+static int imx_lcdif_runtime_suspend(struct device *dev)
+{
+	return 0;
+}
+static int imx_lcdif_runtime_resume(struct device *dev)
+{
+	return 0;
+}
+#endif
+
+static int lcdif_rstc_reset(struct reset_control *rstc, bool assert)
+{
+	int ret;
+
+	if (!rstc)
+		return 0;
+
+	ret = assert ? reset_control_assert(rstc)	:
+		       reset_control_deassert(rstc);
+
+	return ret;
+}
+
+static int lcdif_enable_clocks(struct lcdif_soc *lcdif)
+{
+	int ret;
+
+	if (lcdif->clk_disp_axi) {
+		ret = clk_prepare_enable(lcdif->clk_disp_axi);
+		if (ret)
+			return ret;
+	}
+
+	if (lcdif->clk_disp_apb) {
+		ret = clk_prepare_enable(lcdif->clk_disp_apb);
+		if (ret)
+			goto disable_disp_axi;
+	}
+
+	ret = clk_prepare_enable(lcdif->clk_pix);
+	if (ret)
+		goto disable_disp_apb;
+
+	return 0;
+
+disable_disp_apb:
+	if (lcdif->clk_disp_apb)
+		clk_disable_unprepare(lcdif->clk_disp_apb);
+disable_disp_axi:
+	if (lcdif->clk_disp_axi)
+		clk_disable_unprepare(lcdif->clk_disp_axi);
+
+	return ret;
+}
+
+static void lcdif_disable_clocks(struct lcdif_soc *lcdif)
+{
+	clk_disable_unprepare(lcdif->clk_pix);
+
+	if (lcdif->clk_disp_axi)
+		clk_disable_unprepare(lcdif->clk_disp_axi);
+
+	if (lcdif->clk_disp_apb)
+		clk_disable_unprepare(lcdif->clk_disp_apb);
+}
+
+int lcdif_vblank_irq_get(struct lcdif_soc *lcdif)
+{
+	return lcdif->irq;
+}
+EXPORT_SYMBOL(lcdif_vblank_irq_get);
+
+void lcdif_dump_registers(struct lcdif_soc *lcdif)
+{
+	pr_info("%#x	: %#x\n", LCDIF_CTRL,
+				  readl(lcdif->base + LCDIF_CTRL));
+	pr_info("%#x	: %#x\n", LCDIF_CTRL1,
+				  readl(lcdif->base + LCDIF_CTRL1));
+	pr_info("%#x	: %#x\n", LCDIF_CTRL2,
+				  readl(lcdif->base + LCDIF_CTRL2));
+	pr_info("%#x	: %#x\n", LCDIF_TRANSFER_COUNT,
+				  readl(lcdif->base + LCDIF_TRANSFER_COUNT));
+	pr_info("%#x	: %#x\n", LCDIF_CUR_BUF,
+				  readl(lcdif->base + LCDIF_CUR_BUF));
+	pr_info("%#x	: %#x\n", LCDIF_NEXT_BUF,
+				  readl(lcdif->base + LCDIF_NEXT_BUF));
+	pr_info("%#x	: %#x\n", LCDIF_VDCTRL0,
+				  readl(lcdif->base + LCDIF_VDCTRL0));
+	pr_info("%#x	: %#x\n", LCDIF_VDCTRL1,
+				  readl(lcdif->base + LCDIF_VDCTRL1));
+	pr_info("%#x	: %#x\n", LCDIF_VDCTRL2,
+				  readl(lcdif->base + LCDIF_VDCTRL2));
+	pr_info("%#x	: %#x\n", LCDIF_VDCTRL3,
+				  readl(lcdif->base + LCDIF_VDCTRL3));
+	pr_info("%#x	: %#x\n", LCDIF_VDCTRL4,
+				  readl(lcdif->base + LCDIF_VDCTRL4));
+}
+EXPORT_SYMBOL(lcdif_dump_registers);
+
+void lcdif_vblank_irq_enable(struct lcdif_soc *lcdif)
+{
+	writel(CTRL1_CUR_FRAME_DONE_IRQ, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+	writel(CTRL1_CUR_FRAME_DONE_IRQ_EN, lcdif->base + LCDIF_CTRL1 + REG_SET);
+}
+EXPORT_SYMBOL(lcdif_vblank_irq_enable);
+
+void lcdif_vblank_irq_disable(struct lcdif_soc *lcdif)
+{
+	writel(CTRL1_CUR_FRAME_DONE_IRQ_EN, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+	writel(CTRL1_CUR_FRAME_DONE_IRQ, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+}
+EXPORT_SYMBOL(lcdif_vblank_irq_disable);
+
+void lcdif_vblank_irq_clear(struct lcdif_soc *lcdif)
+{
+	writel(CTRL1_CUR_FRAME_DONE_IRQ, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+}
+EXPORT_SYMBOL(lcdif_vblank_irq_clear);
+
+static uint32_t lcdif_get_bpp_from_fmt(uint32_t format)
+{
+	/* TODO: only support RGB for now */
+
+	switch (format) {
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_ARGB1555:
+	case DRM_FORMAT_XRGB1555:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_XBGR1555:
+		return 16;
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+		return 32;
+	default:
+		/* unsupported format */
+		return 0;
+	}
+}
+
+/*
+ * Get the bus format supported by LCDIF
+ * according to drm fourcc format
+ */
+int lcdif_get_bus_fmt_from_pix_fmt(struct lcdif_soc *lcdif,
+				   uint32_t format)
+{
+	uint32_t bpp;
+
+	bpp = lcdif_get_bpp_from_fmt(format);
+	if (!bpp)
+		return -EINVAL;
+
+	switch (bpp) {
+	case 16:
+		return MEDIA_BUS_FMT_RGB565_1X16;
+	case 18:
+		return MEDIA_BUS_FMT_RGB666_1X18;
+	case 24:
+	case 32:
+		return MEDIA_BUS_FMT_RGB888_1X24;
+	default:
+		return -EINVAL;
+	}
+}
+EXPORT_SYMBOL(lcdif_get_bus_fmt_from_pix_fmt);
+
+int lcdif_set_pix_fmt(struct lcdif_soc *lcdif, u32 format)
+{
+	u32 ctrl = 0, ctrl1 = 0;
+
+	/* TODO: lcdif should be disabled to set pixel format */
+
+	ctrl  = readl(lcdif->base + LCDIF_CTRL);
+	ctrl1 = readl(lcdif->base + LCDIF_CTRL1);
+
+	/* clear pixel format related bits */
+	ctrl  &= ~(CTRL_SHIFT_NUM(0x3f)  | CTRL_INPUT_SWIZZLE(0x3) |
+		   CTRL_CSC_SWIZZLE(0x3) | CTRL_SET_WORD_LENGTH(0x3));
+
+	ctrl1 &= ~CTRL1_SET_BYTE_PACKAGING(0xf);
+
+	/* default is 'RGB' order */
+	writel(CTRL2_ODD_LINE_PATTERN(0x7) |
+	       CTRL2_EVEN_LINE_PATTERN(0x7),
+	       lcdif->base + LCDIF_CTRL2 + REG_CLR);
+
+	switch (format) {
+		/* bpp 16 */
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_ARGB1555:
+	case DRM_FORMAT_XRGB1555:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_XBGR1555:
+		/* Data format */
+		ctrl = (format == DRM_FORMAT_RGB565 ||
+			format == DRM_FORMAT_BGR565) ?
+			(ctrl & ~CTRL_DF16) : (ctrl | CTRL_DF16);
+
+		ctrl |= CTRL_SET_WORD_LENGTH(0x0);
+
+		/* Byte packing */
+		ctrl1 |= CTRL1_SET_BYTE_PACKAGING(0xf);
+
+		/* 'BGR' order */
+		if (format == DRM_FORMAT_BGR565		||
+		    format == DRM_FORMAT_ABGR1555	||
+		    format == DRM_FORMAT_XBGR1555)
+			writel(CTRL2_ODD_LINE_PATTERN(0x5) |
+			       CTRL2_EVEN_LINE_PATTERN(0x5),
+			       lcdif->base + LCDIF_CTRL2 + REG_SET);
+		break;
+		/* bpp 32 */
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+		/*Data format */
+		ctrl &= ~CTRL_DF24;
+		ctrl |= CTRL_SET_WORD_LENGTH(3);
+
+		if (format == DRM_FORMAT_RGBA8888 ||
+		    format == DRM_FORMAT_RGBX8888)
+			ctrl |= CTRL_SHIFT_DIR(1) | CTRL_SHIFT_NUM(8);
+
+		/* Byte packing */
+		ctrl1 |= CTRL1_SET_BYTE_PACKAGING(0x7);
+
+		/* 'BGR' order */
+		if (format == DRM_FORMAT_ABGR8888 ||
+		    format == DRM_FORMAT_XBGR8888)
+			writel(CTRL2_ODD_LINE_PATTERN(0x5) |
+			       CTRL2_EVEN_LINE_PATTERN(0x5),
+			       lcdif->base + LCDIF_CTRL2 + REG_SET);
+		break;
+	default:
+		dev_err(lcdif->dev, "unsupported pixel format: %p4cc\n",
+			&format);
+		return -EINVAL;
+	}
+
+	writel(ctrl,  lcdif->base + LCDIF_CTRL);
+	writel(ctrl1, lcdif->base + LCDIF_CTRL1);
+
+	return 0;
+}
+EXPORT_SYMBOL(lcdif_set_pix_fmt);
+
+void lcdif_set_bus_fmt(struct lcdif_soc *lcdif, u32 bus_format)
+{
+	u32 bus_width;
+
+	switch (bus_format) {
+	case MEDIA_BUS_FMT_RGB565_1X16:
+		bus_width = CTRL_SET_BUS_WIDTH(STMLCDIF_16BIT);
+		break;
+	case MEDIA_BUS_FMT_RGB666_1X18:
+		bus_width = CTRL_SET_BUS_WIDTH(STMLCDIF_18BIT);
+		break;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		bus_width = CTRL_SET_BUS_WIDTH(STMLCDIF_24BIT);
+		break;
+	default:
+		dev_err(lcdif->dev, "unknown bus format: %#x\n", bus_format);
+		return;
+	}
+
+	writel(CTRL_SET_BUS_WIDTH(0x3), lcdif->base + LCDIF_CTRL + REG_CLR);
+	writel(bus_width, lcdif->base + LCDIF_CTRL + REG_SET);
+}
+EXPORT_SYMBOL(lcdif_set_bus_fmt);
+
+void lcdif_set_fb_addr(struct lcdif_soc *lcdif, int id, u32 addr, bool use_i80)
+{
+	switch (id) {
+	case 0:
+		/* primary plane */
+		if (use_i80)
+			writel(addr, lcdif->base + LCDIF_CUR_BUF);
+		else
+			writel(addr, lcdif->base + LCDIF_NEXT_BUF);
+		break;
+	default:
+		/* TODO: add overlay support */
+		return;
+	}
+}
+EXPORT_SYMBOL(lcdif_set_fb_addr);
+
+void lcdif_set_fb_hcrop(struct lcdif_soc *lcdif, u32 src_w,
+			u32 fb_w, bool crop)
+{
+	u32 mask_cnt;
+	u32 vdctrl3, vdctrl4, transfer_count;
+	u32 pigeon_12_0, pigeon_12_1, pigeon_12_2;
+
+	if (!crop) {
+		writel(0x0, lcdif->base + HW_EPDC_PIGEON_12_0);
+		writel(0x0, lcdif->base + HW_EPDC_PIGEON_12_1);
+
+		return;
+	}
+
+	/*
+	 * transfer_count's hcount and vdctrl4's H_VALID_DATA_CNT
+	 * should use fb width instead of hactive when requires cropping.
+	 */
+	transfer_count = readl(lcdif->base + LCDIF_TRANSFER_COUNT);
+	transfer_count &= ~TRANSFER_COUNT_SET_HCOUNT(0xffff);
+	transfer_count |= TRANSFER_COUNT_SET_HCOUNT(fb_w);
+	writel(transfer_count, lcdif->base + LCDIF_TRANSFER_COUNT);
+
+	vdctrl4 = readl(lcdif->base + LCDIF_VDCTRL4);
+	vdctrl4 &= ~SET_DOTCLK_H_VALID_DATA_CNT(0x3ffff);
+	vdctrl4 |= SET_DOTCLK_H_VALID_DATA_CNT(fb_w);
+	writel(vdctrl4, lcdif->base + LCDIF_VDCTRL4);
+
+	/* configure related pigeon registers */
+	vdctrl3  = readl(lcdif->base + LCDIF_VDCTRL3);
+	mask_cnt = GET_HOR_WAIT_CNT(vdctrl3) - 5;
+
+	pigeon_12_0 = PIGEON_12_0_SET_STATE_MASK(0x24)		|
+		      PIGEON_12_0_SET_MASK_CNT(mask_cnt)	|
+		      PIGEON_12_0_SET_MASK_CNT_SEL(0x6)		|
+		      PIGEON_12_0_POL_ACTIVE_LOW		|
+		      PIGEON_12_0_EN;
+	writel(pigeon_12_0, lcdif->base + HW_EPDC_PIGEON_12_0);
+
+	pigeon_12_1 = PIGEON_12_1_SET_CLR_CNT(src_w) |
+		      PIGEON_12_1_SET_SET_CNT(0x0);
+	writel(pigeon_12_1, lcdif->base + HW_EPDC_PIGEON_12_1);
+
+	pigeon_12_2 = 0x0;
+	writel(pigeon_12_2, lcdif->base + HW_EPDC_PIGEON_12_2);
+}
+EXPORT_SYMBOL(lcdif_set_fb_hcrop);
+
+
+void lcdif_set_mode(struct lcdif_soc *lcdif, struct videomode *vmode,
+		    bool use_i80)
+{
+	const struct of_device_id *of_id =
+			of_match_device(imx_lcdif_dt_ids, lcdif->dev);
+	const struct lcdif_soc_pdata *soc_pdata;
+	u32 vdctrl0, vdctrl1, vdctrl2, vdctrl3, vdctrl4, htotal;
+
+	if (unlikely(!of_id))
+		return;
+	soc_pdata = of_id->data;
+
+	/* Clear the FIFO */
+	writel(CTRL1_FIFO_CLEAR, lcdif->base + LCDIF_CTRL1 + REG_SET);
+	writel(CTRL1_FIFO_CLEAR, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+
+	/* set pixel clock rate */
+	clk_disable_unprepare(lcdif->clk_pix);
+	clk_set_rate(lcdif->clk_pix, vmode->pixelclock);
+	clk_prepare_enable(lcdif->clk_pix);
+
+	/* config display timings */
+	writel(TRANSFER_COUNT_SET_VCOUNT(vmode->vactive) |
+	       TRANSFER_COUNT_SET_HCOUNT(vmode->hactive),
+	       lcdif->base + LCDIF_TRANSFER_COUNT);
+
+	if (use_i80) {
+		/* use MPU 8080 mode */
+		writel(CTRL1_MODE86, lcdif->base + LCDIF_CTRL1 + REG_CLR);
+		return;
+	}
+
+	vdctrl0 = VDCTRL0_ENABLE_PRESENT		|
+		  VDCTRL0_VSYNC_PERIOD_UNIT 		|
+		  VDCTRL0_VSYNC_PULSE_WIDTH_UNIT	|
+		  VDCTRL0_SET_VSYNC_PULSE_WIDTH(vmode->vsync_len);
+
+	/* Polarities */
+	if (soc_pdata) {
+		if ((soc_pdata->hsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_HSYNC_LOW) ||
+		    (!soc_pdata->hsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_HSYNC_HIGH))
+				vdctrl0 |= VDCTRL0_HSYNC_ACT_HIGH;
+
+		if ((soc_pdata->vsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_VSYNC_LOW) ||
+		    (!soc_pdata->vsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_VSYNC_HIGH))
+				vdctrl0 |= VDCTRL0_VSYNC_ACT_HIGH;
+
+		if ((soc_pdata->de_invert &&
+		     vmode->flags & DISPLAY_FLAGS_DE_LOW) ||
+		    (!soc_pdata->de_invert &&
+		     vmode->flags & DISPLAY_FLAGS_DE_HIGH))
+				vdctrl0 |= VDCTRL0_ENABLE_ACT_HIGH;
+	} else {
+		if (vmode->flags & DISPLAY_FLAGS_HSYNC_HIGH)
+			vdctrl0 |= VDCTRL0_HSYNC_ACT_HIGH;
+		if (vmode->flags & DISPLAY_FLAGS_VSYNC_HIGH)
+			vdctrl0 |= VDCTRL0_VSYNC_ACT_HIGH;
+		if (vmode->flags & DISPLAY_FLAGS_DE_HIGH)
+			vdctrl0 |= VDCTRL0_ENABLE_ACT_HIGH;
+	}
+
+	if (vmode->flags & DISPLAY_FLAGS_PIXDATA_POSEDGE)
+		vdctrl0 |= VDCTRL0_DOTCLK_ACT_FALLING;
+
+	writel(vdctrl0, lcdif->base + LCDIF_VDCTRL0);
+
+	vdctrl1 = vmode->vactive + vmode->vsync_len +
+		  vmode->vfront_porch + vmode->vback_porch;
+	writel(vdctrl1, lcdif->base + LCDIF_VDCTRL1);
+
+	htotal = vmode->hactive + vmode->hsync_len +
+		 vmode->hfront_porch + vmode->hback_porch;
+	vdctrl2 = VDCTRL2_SET_HSYNC_PULSE_WIDTH(vmode->hsync_len) |
+		  VDCTRL2_SET_HSYNC_PERIOD(htotal);
+	writel(vdctrl2, lcdif->base + LCDIF_VDCTRL2);
+
+	vdctrl3 = SET_HOR_WAIT_CNT(vmode->hsync_len + vmode->hback_porch) |
+		  SET_VERT_WAIT_CNT(vmode->vsync_len + vmode->vback_porch);
+	writel(vdctrl3, lcdif->base + LCDIF_VDCTRL3);
+
+	vdctrl4 = SET_DOTCLK_H_VALID_DATA_CNT(vmode->hactive);
+	writel(vdctrl4, lcdif->base + LCDIF_VDCTRL4);
+}
+EXPORT_SYMBOL(lcdif_set_mode);
+
+void lcdif_enable_controller(struct lcdif_soc *lcdif, bool use_i80)
+{
+	u32 ctrl2, vdctrl4, timing;
+
+	ctrl2	= readl(lcdif->base + LCDIF_CTRL2);
+	vdctrl4 = readl(lcdif->base + LCDIF_VDCTRL4);
+
+	ctrl2 &= ~CTRL2_OUTSTANDING_REQS(0x7);
+	ctrl2 |= CTRL2_OUTSTANDING_REQS(use_i80 ? REQ_8 : REQ_16);
+	writel(ctrl2, lcdif->base + LCDIF_CTRL2);
+
+	if (use_i80) {
+		/* MPU 8080 write mode */
+		writel(CTRL_DATA_SELECT, lcdif->base + LCDIF_CTRL + REG_SET);
+		writel(CTRL_READ_WRITEB, lcdif->base + LCDIF_CTRL + REG_CLR);
+		writel(CTRL_BYPASS_COUNT, lcdif->base + LCDIF_CTRL + REG_CLR);
+		writel(CTRL_DVI_MODE | CTRL_VSYNC_MODE | CTRL_DOTCLK_MODE,
+		       lcdif->base + LCDIF_CTRL + REG_CLR);
+
+		writel(CTRL1_COMBINE_MPU_WR_STRB,
+		       lcdif->base + LCDIF_CTRL1 + REG_CLR);
+
+		timing = TIMING_CMD_HOLD(2)  | TIMING_CMD_SETUP(1) |
+			 TIMING_DATA_HOLD(2) | TIMING_DATA_SETUP(1);
+		writel(timing, lcdif->base + LCDIF_TIMING);
+	} else {
+		/* Continuous dotclock mode */
+		writel(CTRL_BYPASS_COUNT | CTRL_DOTCLK_MODE,
+		       lcdif->base + LCDIF_CTRL + REG_SET);
+	}
+
+	/* enable the SYNC signals first, then the DMA engine */
+	vdctrl4 |= VDCTRL4_SYNC_SIGNALS_ON;
+	writel(vdctrl4, lcdif->base + LCDIF_VDCTRL4);
+
+	/* enable underflow recovery */
+	writel(CTRL1_RECOVERY_ON_UNDERFLOW,
+	       lcdif->base + LCDIF_CTRL1 + REG_SET);
+
+	/* run lcdif */
+	writel(CTRL_MASTER, lcdif->base + LCDIF_CTRL + REG_SET);
+	writel(CTRL_RUN, lcdif->base + LCDIF_CTRL + REG_SET);
+}
+EXPORT_SYMBOL(lcdif_enable_controller);
+
+void lcdif_disable_controller(struct lcdif_soc *lcdif, bool use_i80)
+{
+	int ret;
+	u32 ctrl, vdctrl4;
+
+	writel(CTRL_RUN, lcdif->base + LCDIF_CTRL + REG_CLR);
+
+	if (!use_i80) {
+		writel(CTRL_DOTCLK_MODE, lcdif->base + LCDIF_CTRL + REG_CLR);
+
+		ret = readl_poll_timeout(lcdif->base + LCDIF_CTRL, ctrl,
+					 !(ctrl & CTRL_RUN), 0, 1000);
+		if (WARN_ON(ret))
+			dev_err(lcdif->dev, "disable lcdif run timeout\n");
+	}
+
+	writel(CTRL_MASTER, lcdif->base + LCDIF_CTRL + REG_CLR);
+
+	vdctrl4 = readl(lcdif->base + LCDIF_VDCTRL4);
+	vdctrl4 &= ~VDCTRL4_SYNC_SIGNALS_ON;
+	writel(vdctrl4, lcdif->base + LCDIF_VDCTRL4);
+}
+EXPORT_SYMBOL(lcdif_disable_controller);
+
+long lcdif_pix_clk_round_rate(struct lcdif_soc *lcdif,
+			      unsigned long rate)
+{
+	if (unlikely(!rate))
+		return -EINVAL;
+
+	return clk_round_rate(lcdif->clk_pix, rate);
+}
+EXPORT_SYMBOL(lcdif_pix_clk_round_rate);
+
+static int platform_remove_device_fn(struct device *dev, void *data)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	platform_device_unregister(pdev);
+
+	return 0;
+}
+
+static void platform_device_unregister_children(struct platform_device *pdev)
+{
+	device_for_each_child(&pdev->dev, NULL, platform_remove_device_fn);
+}
+
+static int lcdif_add_client_devices(struct lcdif_soc *lcdif)
+{
+	int ret = 0, i;
+	struct device *dev = lcdif->dev;
+	struct platform_device *pdev = NULL;
+	struct device_node *of_node;
+
+	for (i = 0; i < ARRAY_SIZE(client_reg); i++) {
+		of_node = of_graph_get_port_by_id(dev->of_node, i);
+		if (!of_node) {
+			dev_info(dev, "no port@%d node in %s\n",
+				 i, dev->of_node->full_name);
+			continue;
+		}
+		of_node_put(of_node);
+
+		pdev = platform_device_alloc(client_reg[i].name, i);
+		if (!pdev) {
+			dev_err(dev, "Can't allocate port pdev\n");
+			ret = -ENOMEM;
+			goto err_register;
+		}
+
+		pdev->dev.parent = dev;
+		client_reg[i].pdata.of_node = of_node;
+
+		ret = platform_device_add_data(pdev, &client_reg[i].pdata,
+					       sizeof(client_reg[i].pdata));
+		if (!ret)
+			ret = platform_device_add(pdev);
+		if (ret) {
+			platform_device_put(pdev);
+			goto err_register;
+		}
+
+		pdev->dev.of_node = of_node;
+	}
+
+	if (!pdev)
+		return -ENODEV;
+
+	return 0;
+
+err_register:
+	platform_device_unregister_children(to_platform_device(dev));
+	return ret;
+}
+
+static int lcdif_of_parse_resets(struct lcdif_soc *lcdif)
+{
+	int ret;
+	struct device *dev = lcdif->dev;
+	struct device_node *np = dev->of_node;
+	struct device_node *parent, *child;
+	struct of_phandle_args args;
+	struct reset_control *rstc;
+	const char *compat;
+	uint32_t len, rstc_num = 0;
+
+	ret = of_parse_phandle_with_args(np, "resets", "#reset-cells",
+					 0, &args);
+	if (ret)
+		return ret;
+
+	parent = args.np;
+	for_each_child_of_node(parent, child) {
+		compat = of_get_property(child, "compatible", NULL);
+		if (!compat)
+			continue;
+
+		rstc = of_reset_control_array_get(child, false, false, true);
+		if (IS_ERR(rstc))
+			continue;
+
+		len = strlen(compat);
+		if (!of_compat_cmp("lcdif,soft-resetn", compat, len)) {
+			lcdif->soft_resetn = rstc;
+			rstc_num++;
+		} else if (!of_compat_cmp("lcdif,clk-enable", compat, len)) {
+			lcdif->clk_enable = rstc;
+			rstc_num++;
+		}
+		else
+			dev_warn(dev, "invalid lcdif reset node: %s\n", compat);
+	}
+
+	if (!rstc_num) {
+		dev_err(dev, "no invalid reset control exists\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int imx_lcdif_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct device *dev = &pdev->dev;
+	struct lcdif_soc *lcdif;
+	struct resource *res;
+
+	dev_dbg(dev, "%s: probe begin\n", __func__);
+
+	lcdif = devm_kzalloc(dev, sizeof(*lcdif), GFP_KERNEL);
+	if (!lcdif) {
+		dev_err(dev, "Can't allocate 'lcdif_soc' structure\n");
+		return -ENOMEM;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENODEV;
+
+	lcdif->irq = platform_get_irq(pdev, 0);
+	if (lcdif->irq < 0)
+		return -ENODEV;
+
+	lcdif->clk_pix = devm_clk_get(dev, "pix");
+	if (IS_ERR(lcdif->clk_pix))
+		return PTR_ERR(lcdif->clk_pix);
+
+	lcdif->clk_disp_axi = devm_clk_get(dev, "disp-axi");
+	if (IS_ERR(lcdif->clk_disp_axi))
+		lcdif->clk_disp_axi = NULL;
+
+	lcdif->clk_disp_apb = devm_clk_get(dev, "disp-apb");
+	if (IS_ERR(lcdif->clk_disp_apb))
+		lcdif->clk_disp_apb = NULL;
+
+	lcdif->base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(lcdif->base))
+		return PTR_ERR(lcdif->base);
+
+	lcdif->dev = dev;
+	ret = lcdif_of_parse_resets(lcdif);
+	if (ret)
+		return ret;
+
+	platform_set_drvdata(pdev, lcdif);
+
+	atomic_set(&lcdif->rpm_suspended, 0);
+	pm_runtime_enable(dev);
+	atomic_inc(&lcdif->rpm_suspended);
+
+	dev_dbg(dev, "%s: probe end\n", __func__);
+
+	return lcdif_add_client_devices(lcdif);
+}
+
+static int imx_lcdif_remove(struct platform_device *pdev)
+{
+	pm_runtime_disable(&pdev->dev);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int imx_lcdif_suspend(struct device *dev)
+{
+	return imx_lcdif_runtime_suspend(dev);
+}
+
+static int imx_lcdif_resume(struct device *dev)
+{
+	return imx_lcdif_runtime_resume(dev);
+}
+#endif
+
+#ifdef CONFIG_PM
+static int imx_lcdif_runtime_suspend(struct device *dev)
+{
+	struct lcdif_soc *lcdif = dev_get_drvdata(dev);
+
+	if (atomic_inc_return(&lcdif->rpm_suspended) > 1)
+		return 0;
+
+	lcdif_disable_clocks(lcdif);
+
+	release_bus_freq(BUS_FREQ_HIGH);
+
+	return 0;
+}
+
+static int imx_lcdif_runtime_resume(struct device *dev)
+{
+	int ret = 0;
+	struct lcdif_soc *lcdif = dev_get_drvdata(dev);
+
+	if (unlikely(!atomic_read(&lcdif->rpm_suspended))) {
+		dev_warn(lcdif->dev, "Unbalanced %s!\n", __func__);
+		return 0;
+	}
+
+	if (!atomic_dec_and_test(&lcdif->rpm_suspended))
+		return 0;
+
+	request_bus_freq(BUS_FREQ_HIGH);
+
+	ret = lcdif_enable_clocks(lcdif);
+	if (ret) {
+		release_bus_freq(BUS_FREQ_HIGH);
+		return ret;
+	}
+
+	ret = lcdif_rstc_reset(lcdif->soft_resetn, false);
+	if (ret) {
+		dev_err(dev, "deassert soft_resetn failed\n");
+		return ret;
+	}
+
+	ret = lcdif_rstc_reset(lcdif->clk_enable, true);
+	if (ret) {
+		dev_err(dev, "assert clk_enable failed\n");
+		return ret;
+	}
+
+	/* Pull LCDIF out of reset */
+	writel(0x0, lcdif->base + LCDIF_CTRL);
+
+	return ret;
+}
+#endif
+
+static const struct dev_pm_ops imx_lcdif_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(imx_lcdif_suspend, imx_lcdif_resume)
+	SET_RUNTIME_PM_OPS(imx_lcdif_runtime_suspend,
+			   imx_lcdif_runtime_resume, NULL)
+};
+
+struct platform_driver imx_lcdif_driver = {
+	.probe    = imx_lcdif_probe,
+	.remove   = imx_lcdif_remove,
+	.driver   = {
+		.name = DRIVER_NAME,
+		.of_match_table = imx_lcdif_dt_ids,
+		.pm = &imx_lcdif_pm_ops,
+	},
+};
+
+module_platform_driver(imx_lcdif_driver);
+
+MODULE_DESCRIPTION("NXP i.MX LCDIF Display Controller driver");
+MODULE_AUTHOR("Fancy Fang <chen.fang@nxp.com>");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/lcdif/lcdif-regs.h b/drivers/gpu/imx/lcdif/lcdif-regs.h
new file mode 100644
index 000000000..e40d5a7d5
--- /dev/null
+++ b/drivers/gpu/imx/lcdif/lcdif-regs.h
@@ -0,0 +1,153 @@
+/*
+ * Copyright 2018,2021 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __LCDIF_REGS_H
+#define __LCDIF_REGS_H
+
+#define REG_SET	4
+#define REG_CLR	8
+
+/* regs offset */
+#define LCDIF_CTRL			0x00
+#define LCDIF_CTRL1			0X10
+#define LCDIF_CTRL2			0X20
+#define LCDIF_TRANSFER_COUNT		0x30
+#define LCDIF_CUR_BUF			0x40
+#define LCDIF_NEXT_BUF			0x50
+#define LCDIF_TIMING			0x60
+#define LCDIF_VDCTRL0			0x70
+#define LCDIF_VDCTRL1			0x80
+#define LCDIF_VDCTRL2			0x90
+#define LCDIF_VDCTRL3			0xa0
+#define LCDIF_VDCTRL4			0xb0
+
+/* pigeon registers for crop */
+#define HW_EPDC_PIGEON_12_0		0xb00
+#define HW_EPDC_PIGEON_12_1		0xb10
+#define HW_EPDC_PIGEON_12_2		0xb20
+
+/* reg bit manipulation */
+#define REG_MASK(e, s) (((1 << ((e) - (s) + 1)) - 1) << (s))
+#define REG_PUT(x, e, s) (((x) << (s)) & REG_MASK(e, s))
+#define REG_GET(x, e, s) (((x) & REG_MASK(e, s)) >> (s))
+
+#define SWIZZLE_LE		0 /* Little-Endian or No swap */
+#define SWIZZLE_BE		1 /* Big-Endian or swap all */
+#define SWIZZLE_HWD		2 /* Swap half-words */
+#define SWIZZLE_HWD_BYTE	3 /* Swap bytes within each half-word */
+
+/* regs bit fields */
+#define CTRL_SFTRST			BIT(31)
+#define CTRL_CLKGATE			BIT(30)
+#define CTRL_READ_WRITEB		BIT(28)
+#define CTRL_SHIFT_DIR(x)		REG_PUT((x), 26, 26)
+#define CTRL_SHIFT_NUM(x)		REG_PUT((x), 25, 21)
+#define CTRL_DVI_MODE			BIT(20)
+#define CTRL_BYPASS_COUNT		BIT(19)
+#define CTRL_VSYNC_MODE			BIT(18)
+#define CTRL_DOTCLK_MODE		BIT(17)
+#define CTRL_DATA_SELECT		BIT(16)
+#define CTRL_INPUT_SWIZZLE(x)		REG_PUT((x), 15, 14)
+#define CTRL_CSC_SWIZZLE(x)		REG_PUT((x), 13, 12)
+#define CTRL_SET_BUS_WIDTH(x)		REG_PUT((x), 11, 10)
+#define CTRL_GET_BUS_WIDTH(x)		REG_GET((x), 11, 10)
+#define CTRL_BUS_WIDTH_MASK		REG_PUT((0x3), 11, 10)
+#define CTRL_SET_WORD_LENGTH(x)		REG_PUT((x), 9, 8)
+#define CTRL_GET_WORD_LENGTH(x)		REG_GET((x), 9, 8)
+#define CTRL_MASTER			BIT(5)
+#define CTRL_DF16			BIT(3)
+#define CTRL_DF18			BIT(2)
+#define CTRL_DF24			BIT(1)
+#define CTRL_RUN			BIT(0)
+
+#define CTRL1_COMBINE_MPU_WR_STRB	BIT(27)
+#define CTRL1_RECOVERY_ON_UNDERFLOW	BIT(24)
+#define CTRL1_FIFO_CLEAR		BIT(21)
+#define CTRL1_SET_BYTE_PACKAGING(x)	REG_PUT((x), 19, 16)
+#define CTRL1_GET_BYTE_PACKAGING(x)	REG_GET((x), 19, 16)
+#define CTRL1_CUR_FRAME_DONE_IRQ_EN	BIT(13)
+#define CTRL1_CUR_FRAME_DONE_IRQ	BIT(9)
+#define CTRL1_MODE86			BIT(1)
+
+#define REQ_1	0
+#define REQ_2	1
+#define REQ_4	2
+#define REQ_8	3
+#define REQ_16	4
+
+#define CTRL2_OUTSTANDING_REQS(x)	REG_PUT((x), 23, 21)
+#define CTRL2_ODD_LINE_PATTERN(x)	REG_PUT((x), 18, 16)
+#define CTRL2_EVEN_LINE_PATTERN(x)	REG_PUT((x), 14, 12)
+
+#define TRANSFER_COUNT_SET_VCOUNT(x)	(((x) & 0xffff) << 16)
+#define TRANSFER_COUNT_GET_VCOUNT(x)	(((x) >> 16) & 0xffff)
+#define TRANSFER_COUNT_SET_HCOUNT(x)	((x) & 0xffff)
+#define TRANSFER_COUNT_GET_HCOUNT(x)	((x) & 0xffff)
+
+#define TIMING_CMD_HOLD(x)		REG_PUT((x), 31, 24)
+#define TIMING_CMD_SETUP(x)		REG_PUT((x), 23, 16)
+#define TIMING_DATA_HOLD(x)		REG_PUT((x), 15, 8)
+#define TIMING_DATA_SETUP(x)		REG_PUT((x), 7, 0)
+
+#define VDCTRL0_ENABLE_PRESENT		BIT(28)
+#define VDCTRL0_VSYNC_ACT_HIGH		BIT(27)
+#define VDCTRL0_HSYNC_ACT_HIGH		BIT(26)
+#define VDCTRL0_DOTCLK_ACT_FALLING	BIT(25)
+#define VDCTRL0_ENABLE_ACT_HIGH		BIT(24)
+#define VDCTRL0_VSYNC_PERIOD_UNIT	BIT(21)
+#define VDCTRL0_VSYNC_PULSE_WIDTH_UNIT	BIT(20)
+#define VDCTRL0_HALF_LINE		BIT(19)
+#define VDCTRL0_HALF_LINE_MODE		BIT(18)
+#define VDCTRL0_SET_VSYNC_PULSE_WIDTH(x) ((x) & 0x3ffff)
+#define VDCTRL0_GET_VSYNC_PULSE_WIDTH(x) ((x) & 0x3ffff)
+
+#define VDCTRL2_SET_HSYNC_PULSE_WIDTH(x) (((x) & 0x3fff) << 18)
+#define VDCTRL2_GET_HSYNC_PULSE_WIDTH(x) (((x) >> 18) & 0x3fff)
+#define VDCTRL2_SET_HSYNC_PERIOD(x)	((x) & 0x3ffff)
+#define VDCTRL2_GET_HSYNC_PERIOD(x)	((x) & 0x3ffff)
+
+#define VDCTRL3_MUX_SYNC_SIGNALS	BIT(29)
+#define VDCTRL3_VSYNC_ONLY		BIT(28)
+#define SET_HOR_WAIT_CNT(x)		(((x) & 0xfff) << 16)
+#define GET_HOR_WAIT_CNT(x)		(((x) >> 16) & 0xfff)
+#define SET_VERT_WAIT_CNT(x)		((x) & 0xffff)
+#define GET_VERT_WAIT_CNT(x)		((x) & 0xffff)
+
+#define VDCTRL4_SET_DOTCLK_DLY(x)	(((x) & 0x7) << 29) /* v4 only */
+#define VDCTRL4_GET_DOTCLK_DLY(x)	(((x) >> 29) & 0x7) /* v4 only */
+#define VDCTRL4_SYNC_SIGNALS_ON		BIT(18)
+#define SET_DOTCLK_H_VALID_DATA_CNT(x)	((x) & 0x3ffff)
+
+#define PIGEON_12_0_SET_STATE_MASK(x)	REG_PUT((x), 31, 24)
+#define PIGEON_12_0_SET_MASK_CNT(x)	REG_PUT((x), 23, 12)
+#define PIGEON_12_0_SET_MASK_CNT_SEL(x)	REG_PUT((x), 11,  8)
+#define PIGEON_12_0_SET_OFFSET(x)	REG_PUT((x),  7,  4)
+#define PIGEON_12_0_SET_INC_SEL(x)	REG_PUT((x),  3,  2)
+#define PIGEON_12_0_POL_ACTIVE_LOW	BIT(1)
+#define PIGEON_12_0_EN			BIT(0)
+
+#define PIGEON_12_1_SET_CLR_CNT(x)	REG_PUT((x), 31, 16)
+#define PIGEON_12_1_SET_SET_CNT(x)	REG_PUT((x), 15,  0)
+
+#define STMLCDIF_8BIT  1 /* pixel data bus to the display is of 8 bit width */
+#define STMLCDIF_16BIT 0 /* pixel data bus to the display is of 16 bit width */
+#define STMLCDIF_18BIT 2 /* pixel data bus to the display is of 18 bit width */
+#define STMLCDIF_24BIT 3 /* pixel data bus to the display is of 24 bit width */
+
+#define MIN_XRES			120
+#define MIN_YRES			120
+#define MAX_XRES			0xffff
+#define MAX_YRES			0xffff
+
+#endif
diff --git a/drivers/gpu/imx/lcdifv3/Kconfig b/drivers/gpu/imx/lcdifv3/Kconfig
new file mode 100644
index 000000000..8365c285f
--- /dev/null
+++ b/drivers/gpu/imx/lcdifv3/Kconfig
@@ -0,0 +1,10 @@
+config IMX_LCDIFV3_CORE
+	tristate "i.MX LCDIFV3 core support"
+	depends on ARCH_MXC
+	depends on DRM && OF
+	select RESET_CONTROLLER
+	help
+	  Choose this if you have a NXP i.MX8MP platform and want to use the
+	  LCDIFV3 display controller. This option only enables LCDIFV3 base
+	  support.
+
diff --git a/drivers/gpu/imx/lcdifv3/Makefile b/drivers/gpu/imx/lcdifv3/Makefile
new file mode 100644
index 000000000..812043e52
--- /dev/null
+++ b/drivers/gpu/imx/lcdifv3/Makefile
@@ -0,0 +1,3 @@
+obj-$(CONFIG_IMX_LCDIFV3_CORE) += imx-lcdifv3-core.o
+
+imx-lcdifv3-core-objs := lcdifv3-common.o
diff --git a/drivers/gpu/imx/lcdifv3/lcdifv3-common.c b/drivers/gpu/imx/lcdifv3/lcdifv3-common.c
new file mode 100644
index 000000000..abe173096
--- /dev/null
+++ b/drivers/gpu/imx/lcdifv3/lcdifv3-common.c
@@ -0,0 +1,866 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Copyright 2019,2022 NXP
+ */
+
+#include <linux/busfreq-imx.h>
+#include <linux/clk.h>
+#include <linux/iopoll.h>
+#include <linux/media-bus-format.h>
+#include <linux/mfd/syscon.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/regmap.h>
+#include <linux/reset.h>
+#include <linux/types.h>
+#include <drm/drm_fourcc.h>
+#include <video/imx-lcdifv3.h>
+#include <video/videomode.h>
+
+#include "lcdifv3-regs.h"
+
+#define DRIVER_NAME "imx-lcdifv3"
+
+struct lcdifv3_soc {
+	struct device *dev;
+
+	int irq;
+	void __iomem *base;
+	struct regmap *gpr;
+	atomic_t rpm_suspended;
+
+	struct clk *clk_pix;
+	struct clk *clk_disp_axi;
+	struct clk *clk_disp_apb;
+
+	u32 thres_low_mul;
+	u32 thres_low_div;
+	u32 thres_high_mul;
+	u32 thres_high_div;
+};
+
+struct lcdifv3_soc_pdata {
+	bool hsync_invert;
+	bool vsync_invert;
+	bool de_invert;
+	bool hdmimix;
+};
+
+struct lcdifv3_platform_reg {
+	struct lcdifv3_client_platformdata pdata;
+	char *name;
+};
+
+static struct lcdifv3_platform_reg client_reg[] = {
+	{
+		.pdata = { },
+		.name  = "imx-lcdifv3-crtc",
+	},
+};
+
+static struct lcdifv3_soc_pdata imx8mp_lcdif1_pdata = {
+	.hsync_invert = false,
+	.vsync_invert = false,
+	.de_invert    = false,
+	.hdmimix     = false,
+};
+
+static struct lcdifv3_soc_pdata imx8mp_lcdif2_pdata = {
+	.hsync_invert = false,
+	.vsync_invert = false,
+	.de_invert    = true,
+	.hdmimix      = false,
+};
+
+static struct lcdifv3_soc_pdata imx8mp_lcdif3_pdata = {
+	.hsync_invert = false,
+	.vsync_invert = false,
+	.de_invert    = false,
+	.hdmimix     = true,
+};
+static const struct of_device_id imx_lcdifv3_dt_ids[] = {
+	{ .compatible = "fsl,imx93-lcdif", },
+	{ .compatible = "fsl,imx8mp-lcdif1", .data = &imx8mp_lcdif1_pdata, },
+	{ .compatible = "fsl,imx8mp-lcdif2", .data = &imx8mp_lcdif2_pdata, },
+	{ .compatible = "fsl,imx8mp-lcdif3", .data = &imx8mp_lcdif3_pdata,},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, imx_lcdifv3_dt_ids);
+
+static int lcdifv3_enable_clocks(struct lcdifv3_soc *lcdifv3)
+{
+	int ret;
+
+	if (lcdifv3->clk_disp_axi) {
+		ret = clk_prepare_enable(lcdifv3->clk_disp_axi);
+		if (ret)
+			return ret;
+	}
+
+	if (lcdifv3->clk_disp_apb) {
+		ret = clk_prepare_enable(lcdifv3->clk_disp_apb);
+		if (ret)
+			goto disable_disp_axi;
+	}
+
+	ret = clk_prepare_enable(lcdifv3->clk_pix);
+	if (ret)
+		goto disable_disp_apb;
+
+	return 0;
+
+disable_disp_apb:
+	if (lcdifv3->clk_disp_apb)
+		clk_disable_unprepare(lcdifv3->clk_disp_apb);
+disable_disp_axi:
+	if (lcdifv3->clk_disp_axi)
+		clk_disable_unprepare(lcdifv3->clk_disp_axi);
+
+	return ret;
+}
+
+static void lcdifv3_disable_clocks(struct lcdifv3_soc *lcdifv3)
+{
+	clk_disable_unprepare(lcdifv3->clk_pix);
+
+	if (lcdifv3->clk_disp_axi)
+		clk_disable_unprepare(lcdifv3->clk_disp_axi);
+
+	if (lcdifv3->clk_disp_apb)
+		clk_disable_unprepare(lcdifv3->clk_disp_apb);
+}
+
+static void lcdifv3_enable_plane_panic(struct lcdifv3_soc *lcdifv3)
+{
+	u32 panic_thres, thres_low, thres_high;
+
+	/* apb clock has been enabled */
+
+	/* As suggestion, the thres_low should be 1/3 FIFO,
+	 * and thres_high should be 2/3 FIFO (The FIFO size
+	 * is 8KB = 512 * 128bit).
+	 * threshold = n * 128bit (n: 0 ~ 511)
+	 */
+	thres_low  = DIV_ROUND_UP(511 * lcdifv3->thres_low_mul,
+			lcdifv3->thres_low_div);
+	thres_high = DIV_ROUND_UP(511 * lcdifv3->thres_high_mul,
+			lcdifv3->thres_high_div);
+
+	panic_thres = PANIC0_THRES_PANIC_THRES_LOW(thres_low)	|
+		      PANIC0_THRES_PANIC_THRES_HIGH(thres_high);
+
+	writel(panic_thres, lcdifv3->base + LCDIFV3_PANIC0_THRES);
+
+	/* Enable Panic:
+	 *
+	 * As designed, the panic won't trigger an irq,
+	 * so it is unnecessary to handle this as an irq
+	 * and NoC + QoS modules will handle panic
+	 * automatically.
+	 */
+	writel(INT_ENABLE_D1_PLANE_PANIC_EN,
+	       lcdifv3->base + LCDIFV3_INT_ENABLE_D1);
+}
+
+int lcdifv3_vblank_irq_get(struct lcdifv3_soc *lcdifv3)
+{
+	return lcdifv3->irq;
+}
+EXPORT_SYMBOL(lcdifv3_vblank_irq_get);
+
+/* TODO: use VS_BLANK or VSYNC? */
+void lcdifv3_vblank_irq_enable(struct lcdifv3_soc *lcdifv3)
+{
+	uint32_t int_enable_d0;
+
+	int_enable_d0 = readl(lcdifv3->base + LCDIFV3_INT_ENABLE_D0);
+	int_enable_d0 |= INT_STATUS_D0_VS_BLANK;
+
+	/* W1C */
+	writel(INT_STATUS_D0_VS_BLANK,
+	       lcdifv3->base + LCDIFV3_INT_STATUS_D0);
+	/* enable */
+	writel(int_enable_d0,
+	       lcdifv3->base + LCDIFV3_INT_ENABLE_D0);
+}
+EXPORT_SYMBOL(lcdifv3_vblank_irq_enable);
+
+void lcdifv3_vblank_irq_disable(struct lcdifv3_soc *lcdifv3)
+{
+	uint32_t int_enable_d0;
+
+	int_enable_d0 = readl(lcdifv3->base + LCDIFV3_INT_ENABLE_D0);
+	int_enable_d0 &= ~INT_STATUS_D0_VS_BLANK;
+
+	/* disable */
+	writel(int_enable_d0,
+	       lcdifv3->base + LCDIFV3_INT_ENABLE_D0);
+	/* W1C */
+	writel(INT_STATUS_D0_VS_BLANK,
+	       lcdifv3->base + LCDIFV3_INT_STATUS_D0);
+}
+EXPORT_SYMBOL(lcdifv3_vblank_irq_disable);
+
+void lcdifv3_vblank_irq_clear(struct lcdifv3_soc *lcdifv3)
+{
+	/* W1C */
+	writel(INT_STATUS_D0_VS_BLANK,
+	       lcdifv3->base + LCDIFV3_INT_STATUS_D0);
+}
+EXPORT_SYMBOL(lcdifv3_vblank_irq_clear);
+
+static uint32_t lcdifv3_get_bpp_from_fmt(uint32_t format)
+{
+	/* TODO: only support RGB for now */
+
+	switch (format) {
+	case DRM_FORMAT_RGB565:
+	case DRM_FORMAT_BGR565:
+	case DRM_FORMAT_ARGB1555:
+	case DRM_FORMAT_XRGB1555:
+	case DRM_FORMAT_ABGR1555:
+	case DRM_FORMAT_XBGR1555:
+		return 16;
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_RGBX8888:
+		return 32;
+	default:
+		/* unsupported format */
+		return 0;
+	}
+}
+
+/*
+ * Get the bus format supported by LCDIF
+ * according to drm fourcc format
+ */
+int lcdifv3_get_bus_fmt_from_pix_fmt(struct lcdifv3_soc *lcdifv3,
+				     uint32_t format)
+{
+	uint32_t bpp;
+
+	bpp = lcdifv3_get_bpp_from_fmt(format);
+	if (!bpp)
+		return -EINVAL;
+
+	switch (bpp) {
+	case 16:
+		return MEDIA_BUS_FMT_RGB565_1X16;
+	case 18:
+		return MEDIA_BUS_FMT_RGB666_1X18;
+	case 24:
+	case 32:
+		return MEDIA_BUS_FMT_RGB888_1X24;
+	default:
+		return -EINVAL;
+	}
+}
+EXPORT_SYMBOL(lcdifv3_get_bus_fmt_from_pix_fmt);
+
+int lcdifv3_set_pix_fmt(struct lcdifv3_soc *lcdifv3, u32 format)
+{
+	uint32_t ctrldescl0_5 = 0;
+
+	ctrldescl0_5 = readl(lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+
+	ctrldescl0_5 &= ~(CTRLDESCL0_5_BPP(0xf) | CTRLDESCL0_5_YUV_FORMAT(0x3));
+
+	switch (format) {
+	case DRM_FORMAT_RGB565:
+		ctrldescl0_5 |= CTRLDESCL0_5_BPP(BPP16_RGB565);
+		break;
+	case DRM_FORMAT_ARGB1555:
+	case DRM_FORMAT_XRGB1555:
+		ctrldescl0_5 |= CTRLDESCL0_5_BPP(BPP16_ARGB1555);
+		break;
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XRGB8888:
+		ctrldescl0_5 |= CTRLDESCL0_5_BPP(BPP32_ARGB8888);
+		break;
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_XBGR8888:
+		ctrldescl0_5 |= CTRLDESCL0_5_BPP(BPP32_ABGR8888);
+		break;
+	default:
+		dev_err(lcdifv3->dev, "unsupported pixel format: %p4cc\n",
+			&format);
+		return -EINVAL;
+	}
+
+	writel(ctrldescl0_5,  lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+
+	return 0;
+}
+EXPORT_SYMBOL(lcdifv3_set_pix_fmt);
+
+void lcdifv3_set_bus_fmt(struct lcdifv3_soc *lcdifv3, u32 bus_format)
+{
+	uint32_t disp_para = 0;
+
+	disp_para = readl(lcdifv3->base + LCDIFV3_DISP_PARA);
+
+	/* clear line pattern bits */
+	disp_para &= ~DISP_PARA_LINE_PATTERN(0xf);
+
+	switch (bus_format) {
+	case MEDIA_BUS_FMT_RGB565_1X16:
+		disp_para |= DISP_PARA_LINE_PATTERN(LP_RGB565);
+		break;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		disp_para |= DISP_PARA_LINE_PATTERN(LP_RGB888_OR_YUV444);
+		break;
+	default:
+		dev_err(lcdifv3->dev, "unknown bus format: %#x\n", bus_format);
+		return;
+	}
+
+	/* config display mode: default is normal mode */
+	disp_para &= ~DISP_PARA_DISP_MODE(3);
+	disp_para |= DISP_PARA_DISP_MODE(0);
+
+	writel(disp_para, lcdifv3->base + LCDIFV3_DISP_PARA);
+}
+EXPORT_SYMBOL(lcdifv3_set_bus_fmt);
+
+void lcdifv3_set_fb_addr(struct lcdifv3_soc *lcdifv3, int id, u32 addr)
+{
+	switch (id) {
+	case 0:
+		/* primary plane */
+		writel(addr, lcdifv3->base + LCDIFV3_CTRLDESCL_LOW0_4);
+		break;
+	default:
+		/* TODO: add overlay support */
+		return;
+	}
+}
+EXPORT_SYMBOL(lcdifv3_set_fb_addr);
+
+void lcdifv3_set_fb_hcrop(struct lcdifv3_soc *lcdifv3, u32 src_w,
+			u32 pitch, bool crop)
+{
+	uint32_t ctrldescl0_3 = 0;
+
+	/* config P_SIZE and T_SIZE:
+	 * 1. P_SIZE and T_SIZE should never
+	 *    be less than AXI bus width.
+	 * 2. P_SIZE should never be less than T_SIZE.
+	 */
+	ctrldescl0_3 |= CTRLDESCL0_3_P_SIZE(2);
+	ctrldescl0_3 |= CTRLDESCL0_3_T_SIZE(2);
+
+	/* config pitch */
+	ctrldescl0_3 |= CTRLDESCL0_3_PITCH(pitch);
+
+	/* enable frame clear to clear FIFO data on
+	 * every vsync blank period to make sure no
+	 * dirty data exits to affect next frame
+	 * display, otherwise some flicker issue may
+	 * be observed in some cases.
+	 */
+	ctrldescl0_3 |= CTRLDESCL0_3_STATE_CLEAR_VSYNC;
+
+	writel(ctrldescl0_3, lcdifv3->base + LCDIFV3_CTRLDESCL0_3);
+}
+EXPORT_SYMBOL(lcdifv3_set_fb_hcrop);
+
+
+void lcdifv3_set_mode(struct lcdifv3_soc *lcdifv3, struct videomode *vmode)
+{
+	const struct of_device_id *of_id =
+			of_match_device(imx_lcdifv3_dt_ids, lcdifv3->dev);
+	const struct lcdifv3_soc_pdata *soc_pdata;
+	u32 disp_size, hsyn_para, vsyn_para, vsyn_hsyn_width, ctrldescl0_1;
+
+	if (unlikely(!of_id))
+		return;
+	soc_pdata = of_id->data;
+
+	/* set pixel clock rate */
+	clk_disable_unprepare(lcdifv3->clk_pix);
+	clk_set_rate(lcdifv3->clk_pix, vmode->pixelclock);
+	clk_prepare_enable(lcdifv3->clk_pix);
+
+	/* config display timings */
+	disp_size = DISP_SIZE_DELTA_Y(vmode->vactive) |
+		    DISP_SIZE_DELTA_X(vmode->hactive);
+	writel(disp_size, lcdifv3->base + LCDIFV3_DISP_SIZE);
+
+	WARN_ON(!vmode->hback_porch || !vmode->hfront_porch);
+	hsyn_para = HSYN_PARA_BP_H(vmode->hback_porch) |
+		    HSYN_PARA_FP_H(vmode->hfront_porch);
+	writel(hsyn_para, lcdifv3->base + LCDIFV3_HSYN_PARA);
+
+	WARN_ON(!vmode->vback_porch || !vmode->vfront_porch);
+	vsyn_para = VSYN_PARA_BP_V(vmode->vback_porch) |
+		    VSYN_PARA_FP_V(vmode->vfront_porch);
+	writel(vsyn_para, lcdifv3->base + LCDIFV3_VSYN_PARA);
+
+	WARN_ON(!vmode->vsync_len || !vmode->hsync_len);
+	vsyn_hsyn_width = VSYN_HSYN_WIDTH_PW_V(vmode->vsync_len) |
+			  VSYN_HSYN_WIDTH_PW_H(vmode->hsync_len);
+	writel(vsyn_hsyn_width, lcdifv3->base + LCDIFV3_VSYN_HSYN_WIDTH);
+
+	/* config layer size */
+	/* TODO: 32bits alignment for width */
+	ctrldescl0_1 = CTRLDESCL0_1_HEIGHT(vmode->vactive) |
+		       CTRLDESCL0_1_WIDTH(vmode->hactive);
+	writel(ctrldescl0_1, lcdifv3->base + LCDIFV3_CTRLDESCL0_1);
+
+	/* Polarities */
+	if (soc_pdata) {
+		if ((soc_pdata->hsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_HSYNC_HIGH) ||
+		    (!soc_pdata->hsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_HSYNC_LOW))
+			writel(CTRL_INV_HS, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_HS, lcdifv3->base + LCDIFV3_CTRL_CLR);
+
+		if ((soc_pdata->vsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_VSYNC_HIGH) ||
+		    (!soc_pdata->vsync_invert &&
+		     vmode->flags & DISPLAY_FLAGS_VSYNC_LOW))
+			writel(CTRL_INV_VS, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_VS, lcdifv3->base + LCDIFV3_CTRL_CLR);
+
+		if ((soc_pdata->de_invert &&
+		     vmode->flags & DISPLAY_FLAGS_DE_HIGH) ||
+		    (!soc_pdata->de_invert &&
+		     vmode->flags & DISPLAY_FLAGS_DE_LOW))
+			writel(CTRL_INV_DE, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_DE, lcdifv3->base + LCDIFV3_CTRL_CLR);
+	} else {
+		if (vmode->flags & DISPLAY_FLAGS_HSYNC_LOW)
+			writel(CTRL_INV_HS, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_HS, lcdifv3->base + LCDIFV3_CTRL_CLR);
+		if (vmode->flags & DISPLAY_FLAGS_VSYNC_LOW)
+			writel(CTRL_INV_VS, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_VS, lcdifv3->base + LCDIFV3_CTRL_CLR);
+		if (vmode->flags & DISPLAY_FLAGS_DE_LOW)
+			writel(CTRL_INV_DE, lcdifv3->base + LCDIFV3_CTRL_SET);
+		else
+			writel(CTRL_INV_DE, lcdifv3->base + LCDIFV3_CTRL_CLR);
+	}
+
+	if (vmode->flags & DISPLAY_FLAGS_PIXDATA_NEGEDGE)
+		writel(CTRL_INV_PXCK, lcdifv3->base + LCDIFV3_CTRL_CLR);
+	else
+		writel(CTRL_INV_PXCK, lcdifv3->base + LCDIFV3_CTRL_SET);
+}
+EXPORT_SYMBOL(lcdifv3_set_mode);
+
+void lcdifv3_en_shadow_load(struct lcdifv3_soc *lcdifv3)
+{
+	u32 ctrldescl0_5;
+
+	ctrldescl0_5 = readl(lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+	ctrldescl0_5 |= CTRLDESCL0_5_SHADOW_LOAD_EN;
+
+	writel(ctrldescl0_5, lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+}
+EXPORT_SYMBOL(lcdifv3_en_shadow_load);
+
+void lcdifv3_enable_controller(struct lcdifv3_soc *lcdifv3)
+{
+	u32 disp_para, ctrldescl0_5;
+
+	disp_para = readl(lcdifv3->base + LCDIFV3_DISP_PARA);
+	ctrldescl0_5 = readl(lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+
+	/* disp on */
+	disp_para |= DISP_PARA_DISP_ON;
+	writel(disp_para, lcdifv3->base + LCDIFV3_DISP_PARA);
+
+	/* enable layer dma */
+	ctrldescl0_5 |= CTRLDESCL0_5_EN;
+	writel(ctrldescl0_5, lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+}
+EXPORT_SYMBOL(lcdifv3_enable_controller);
+
+void lcdifv3_disable_controller(struct lcdifv3_soc *lcdifv3)
+{
+	u32 disp_para, ctrldescl0_5;
+
+	disp_para = readl(lcdifv3->base + LCDIFV3_DISP_PARA);
+	ctrldescl0_5 = readl(lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+
+	/* disable dma */
+	ctrldescl0_5 &= ~CTRLDESCL0_5_EN;
+	writel(ctrldescl0_5, lcdifv3->base + LCDIFV3_CTRLDESCL0_5);
+
+	/* dma config only takes effect at the end of
+	 * one frame, so add delay to wait dma disable
+	 * done before turn off disp.
+	 */
+	usleep_range(20000, 25000);
+
+	/* disp off */
+	disp_para &= ~DISP_PARA_DISP_ON;
+	writel(disp_para, lcdifv3->base + LCDIFV3_DISP_PARA);
+}
+EXPORT_SYMBOL(lcdifv3_disable_controller);
+
+long lcdifv3_pix_clk_round_rate(struct lcdifv3_soc *lcdifv3,
+				unsigned long rate)
+{
+	if (unlikely(!rate))
+		return -EINVAL;
+
+	return clk_round_rate(lcdifv3->clk_pix, rate);
+}
+EXPORT_SYMBOL(lcdifv3_pix_clk_round_rate);
+
+static int hdmimix_lcdif3_setup(struct lcdifv3_soc *lcdifv3)
+{
+	struct device *dev = lcdifv3->dev;
+	int ret;
+
+	struct clk_bulk_data clocks[] = {
+		{ .id = "mix_apb" },
+		{ .id = "mix_axi" },
+		{ .id = "xtl_24m" },
+		{ .id = "mix_pix" },
+		{ .id = "lcdif_apb" },
+		{ .id = "lcdif_axi" },
+		{ .id = "lcdif_pdi" },
+		{ .id = "lcdif_pix" },
+		{ .id = "lcdif_spu" },
+		{ .id = "noc_hdmi"  },
+	};
+
+	/* power up hdmimix lcdif and nor */
+	ret = device_reset(dev);
+	if (ret)
+		dev_warn(dev, "No hdmimix sub reset found\n");
+	if (ret == -EPROBE_DEFER)
+		return ret;
+
+	/* enable lpcg of hdmimix lcdif and nor */
+	ret = devm_clk_bulk_get(dev, ARRAY_SIZE(clocks), clocks);
+	if (ret < 0)
+		return ret;
+	ret = clk_bulk_prepare_enable(ARRAY_SIZE(clocks), clocks);
+	if (ret < 0)
+		return ret;
+
+	return 0;
+}
+
+static int platform_remove_device_fn(struct device *dev, void *data)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	platform_device_unregister(pdev);
+
+	return 0;
+}
+
+static void platform_device_unregister_children(struct platform_device *pdev)
+{
+	device_for_each_child(&pdev->dev, NULL, platform_remove_device_fn);
+}
+
+static DEFINE_MUTEX(lcdifv3_client_id_mutex);
+static int lcdifv3_client_id;
+
+static int lcdifv3_add_client_devices(struct lcdifv3_soc *lcdifv3)
+{
+	int ret = 0, i, id;
+	struct device *dev = lcdifv3->dev;
+	struct platform_device *pdev = NULL;
+	struct device_node *of_node;
+
+	for (i = 0; i < ARRAY_SIZE(client_reg); i++) {
+		of_node = of_graph_get_port_by_id(dev->of_node, i);
+		if (!of_node) {
+			dev_info(dev, "no port@%d node in %s\n",
+				 i, dev->of_node->full_name);
+			continue;
+		}
+		of_node_put(of_node);
+
+		mutex_lock(&lcdifv3_client_id_mutex);
+		id = lcdifv3_client_id++;
+		mutex_unlock(&lcdifv3_client_id_mutex);
+
+		pdev = platform_device_alloc(client_reg[i].name, id);
+		if (!pdev) {
+			dev_err(dev, "Can't allocate port pdev\n");
+			ret = -ENOMEM;
+			goto err_register;
+		}
+
+		pdev->dev.parent = dev;
+		client_reg[i].pdata.of_node = of_node;
+
+		/* make child device 'dma_mask' to point to its
+		 * coherent dma mask, otherwise later probe will
+		 * print warning message: 'DMA mask not set'.
+		 */
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+
+		ret = platform_device_add_data(pdev, &client_reg[i].pdata,
+					       sizeof(client_reg[i].pdata));
+		if (!ret)
+			ret = platform_device_add(pdev);
+		if (ret) {
+			platform_device_put(pdev);
+			goto err_register;
+		}
+
+		pdev->dev.of_node = of_node;
+	}
+
+	if (!pdev)
+		return -ENODEV;
+
+	return 0;
+
+err_register:
+	platform_device_unregister_children(to_platform_device(dev));
+	return ret;
+}
+
+static int imx_lcdifv3_check_thres_value(u32 mul, u32 div)
+{
+	if (!div)
+		return -EINVAL;
+
+	if (mul > div)
+		return -EINVAL;
+
+	return 0;
+}
+
+static void imx_lcdifv3_of_parse_thres(struct lcdifv3_soc *lcdifv3)
+{
+	int ret;
+	u32 thres_low[2], thres_high[2];
+	struct device_node *np = lcdifv3->dev->of_node;
+
+	/* default 'thres-low' value:  FIFO * 1/3;
+	 * default 'thres-high' value: FIFO * 2/3.
+	 */
+	lcdifv3->thres_low_mul	= 1;
+	lcdifv3->thres_low_div	= 3;
+	lcdifv3->thres_high_mul	= 2;
+	lcdifv3->thres_high_div	= 3;
+
+	ret = of_property_read_u32_array(np, "thres-low", thres_low, 2);
+	if (!ret) {
+		/* check the value effectiveness */
+		ret = imx_lcdifv3_check_thres_value(thres_low[0], thres_low[1]);
+		if (!ret) {
+			lcdifv3->thres_low_mul	= thres_low[0];
+			lcdifv3->thres_low_div	= thres_low[1];
+		}
+	}
+
+	ret = of_property_read_u32_array(np, "thres-high", thres_high, 2);
+	if (!ret) {
+		/* check the value effectiveness */
+		ret = imx_lcdifv3_check_thres_value(thres_high[0], thres_high[1]);
+		if (!ret) {
+			lcdifv3->thres_high_mul	= thres_high[0];
+			lcdifv3->thres_high_div	= thres_high[1];
+		}
+	}
+}
+
+static int imx_lcdifv3_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct lcdifv3_soc *lcdifv3;
+	struct resource *res;
+	const struct of_device_id *of_id;
+	const struct lcdifv3_soc_pdata *soc_pdata;
+
+	dev_dbg(dev, "%s: probe begin\n", __func__);
+
+	of_id = of_match_device(imx_lcdifv3_dt_ids, dev);
+	if (!of_id) {
+		dev_err(&pdev->dev, "OF data missing\n");
+		return -EINVAL;
+	}
+
+	soc_pdata = of_id->data;
+
+	lcdifv3 = devm_kzalloc(dev, sizeof(*lcdifv3), GFP_KERNEL);
+	if (!lcdifv3) {
+		dev_err(dev, "Can't allocate 'lcdifv3_soc' structure\n");
+		return -ENOMEM;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENODEV;
+
+	lcdifv3->irq = platform_get_irq(pdev, 0);
+	if (lcdifv3->irq < 0) {
+		dev_err(dev, "No irq get, ret=%d\n", lcdifv3->irq);
+		return lcdifv3->irq;
+	}
+
+	lcdifv3->clk_pix = devm_clk_get(dev, "pix");
+	if (IS_ERR(lcdifv3->clk_pix)) {
+		ret = PTR_ERR(lcdifv3->clk_pix);
+		dev_err(dev, "No pix clock get: %d\n", ret);
+		return ret;
+	}
+
+	lcdifv3->clk_disp_axi = devm_clk_get(dev, "disp-axi");
+	if (IS_ERR(lcdifv3->clk_disp_axi))
+		lcdifv3->clk_disp_axi = NULL;
+
+	lcdifv3->clk_disp_apb = devm_clk_get(dev, "disp-apb");
+	if (IS_ERR(lcdifv3->clk_disp_apb))
+		lcdifv3->clk_disp_apb = NULL;
+
+	lcdifv3->base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(lcdifv3->base))
+		return PTR_ERR(lcdifv3->base);
+
+	lcdifv3->dev = dev;
+
+	/* reset controller to avoid any conflict
+	 * with uboot splash screen settings.
+	 */
+	if (of_device_is_compatible(np, "fsl,imx8mp-lcdif1")) {
+		/* TODO: Maybe the clock enable should
+		 *	 be done in reset driver.
+		 */
+		clk_prepare_enable(lcdifv3->clk_disp_axi);
+		clk_prepare_enable(lcdifv3->clk_disp_apb);
+
+		writel(CTRL_SW_RESET, lcdifv3->base + LCDIFV3_CTRL_CLR);
+
+		ret = device_reset(dev);
+		if (ret)
+			dev_warn(dev, "lcdif1 reset failed: %d\n", ret);
+
+		clk_disable_unprepare(lcdifv3->clk_disp_axi);
+		clk_disable_unprepare(lcdifv3->clk_disp_apb);
+	}
+
+	imx_lcdifv3_of_parse_thres(lcdifv3);
+
+	platform_set_drvdata(pdev, lcdifv3);
+
+	if (soc_pdata && soc_pdata->hdmimix) {
+		ret = hdmimix_lcdif3_setup(lcdifv3);
+		if (ret < 0) {
+			dev_err(dev, "hdmimix lcdif3 setup failed\n");
+			return ret;
+		}
+	}
+
+	atomic_set(&lcdifv3->rpm_suspended, 0);
+	pm_runtime_enable(dev);
+	atomic_inc(&lcdifv3->rpm_suspended);
+
+	dev_dbg(dev, "%s: probe end\n", __func__);
+
+	return lcdifv3_add_client_devices(lcdifv3);
+}
+
+static int imx_lcdifv3_remove(struct platform_device *pdev)
+{
+	pm_runtime_disable(&pdev->dev);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int imx_lcdifv3_runtime_suspend(struct device *dev)
+{
+	struct lcdifv3_soc *lcdifv3 = dev_get_drvdata(dev);
+
+	if (atomic_inc_return(&lcdifv3->rpm_suspended) > 1)
+		return 0;
+
+	lcdifv3_disable_clocks(lcdifv3);
+
+	release_bus_freq(BUS_FREQ_HIGH);
+
+	return 0;
+}
+
+static int imx_lcdifv3_runtime_resume(struct device *dev)
+{
+	int ret = 0;
+	struct lcdifv3_soc *lcdifv3 = dev_get_drvdata(dev);
+
+	if (unlikely(!atomic_read(&lcdifv3->rpm_suspended))) {
+		dev_warn(lcdifv3->dev, "Unbalanced %s!\n", __func__);
+		return 0;
+	}
+
+	if (!atomic_dec_and_test(&lcdifv3->rpm_suspended))
+		return 0;
+
+	request_bus_freq(BUS_FREQ_HIGH);
+
+	ret = lcdifv3_enable_clocks(lcdifv3);
+	if (ret) {
+		release_bus_freq(BUS_FREQ_HIGH);
+		return ret;
+	}
+
+	/* clear sw_reset */
+	writel(CTRL_SW_RESET, lcdifv3->base + LCDIFV3_CTRL_CLR);
+
+	/* enable plane FIFO panic */
+	lcdifv3_enable_plane_panic(lcdifv3);
+
+	return ret;
+}
+#endif
+
+#ifdef CONFIG_PM_SLEEP
+static int imx_lcdifv3_suspend(struct device *dev)
+{
+	return imx_lcdifv3_runtime_suspend(dev);
+}
+
+static int imx_lcdifv3_resume(struct device *dev)
+{
+	return imx_lcdifv3_runtime_resume(dev);
+}
+#endif
+
+static const struct dev_pm_ops imx_lcdifv3_pm_ops = {
+	SET_LATE_SYSTEM_SLEEP_PM_OPS(imx_lcdifv3_suspend,
+				     imx_lcdifv3_resume)
+	SET_RUNTIME_PM_OPS(imx_lcdifv3_runtime_suspend,
+			   imx_lcdifv3_runtime_resume, NULL)
+};
+
+struct platform_driver imx_lcdifv3_driver = {
+	.probe    = imx_lcdifv3_probe,
+	.remove   = imx_lcdifv3_remove,
+	.driver   = {
+		.name = DRIVER_NAME,
+		.of_match_table = imx_lcdifv3_dt_ids,
+		.pm = &imx_lcdifv3_pm_ops,
+	},
+};
+
+module_platform_driver(imx_lcdifv3_driver);
+
+MODULE_DESCRIPTION("NXP i.MX LCDIFV3 Display Controller driver");
+MODULE_AUTHOR("Fancy Fang <chen.fang@nxp.com>");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/imx/lcdifv3/lcdifv3-regs.h b/drivers/gpu/imx/lcdifv3/lcdifv3-regs.h
new file mode 100644
index 000000000..d47c2f80b
--- /dev/null
+++ b/drivers/gpu/imx/lcdifv3/lcdifv3-regs.h
@@ -0,0 +1,150 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2019 NXP
+ */
+
+#ifndef __LCDIFV3_REGS_H
+#define __LCDIFV3_REGS_H
+
+/* regs offset */
+#define LCDIFV3_CTRL			0x00
+#define LCDIFV3_CTRL_SET		0x04
+#define LCDIFV3_CTRL_CLR		0x08
+#define LCDIFV3_CTRL_TOG		0x0c
+#define LCDIFV3_DISP_PARA		0x10
+#define LCDIFV3_DISP_SIZE		0x14
+#define LCDIFV3_HSYN_PARA		0x18
+#define LCDIFV3_VSYN_PARA		0x1c
+#define LCDIFV3_VSYN_HSYN_WIDTH		0x20
+#define LCDIFV3_INT_STATUS_D0		0x24
+#define LCDIFV3_INT_ENABLE_D0		0x28
+#define LCDIFV3_INT_STATUS_D1		0x30
+#define LCDIFV3_INT_ENABLE_D1		0x34
+
+#define LCDIFV3_CTRLDESCL0_1		0x200
+#define LCDIFV3_CTRLDESCL0_3		0x208
+#define LCDIFV3_CTRLDESCL_LOW0_4	0x20c
+#define LCDIFV3_CTRLDESCL_HIGH0_4	0x210
+#define LCDIFV3_CTRLDESCL0_5		0x214
+#define LCDIFV3_CSC0_CTRL		0x21c
+#define LCDIFV3_CSC0_COEF0		0x220
+#define LCDIFV3_CSC0_COEF1		0x224
+#define LCDIFV3_CSC0_COEF2		0x228
+#define LCDIFV3_CSC0_COEF3		0x22c
+#define LCDIFV3_CSC0_COEF4		0x230
+#define LCDIFV3_CSC0_COEF5		0x234
+#define LCDIFV3_PANIC0_THRES		0x238
+
+/* reg bit manipulation */
+#define REG_MASK(e, s) (((1 << ((e) - (s) + 1)) - 1) << (s))
+#define REG_PUT(x, e, s) (((x) << (s)) & REG_MASK(e, s))
+#define REG_GET(x, e, s) (((x) & REG_MASK(e, s)) >> (s))
+
+/* regs bit fields */
+#define CTRL_SW_RESET			BIT(31)
+#define CTRL_FETCH_START_OPTION(x)	REG_PUT((x), 9, 8)
+   #define FPV		0
+   #define PWV		1
+   #define BPV		2
+   #define RESV		3
+#define CTRL_NEG			BIT(4)
+#define CTRL_INV_PXCK			BIT(3)
+#define CTRL_INV_DE			BIT(2)
+#define CTRL_INV_VS			BIT(1)
+#define CTRL_INV_HS			BIT(0)
+
+#define DISP_PARA_DISP_ON		BIT(31)
+#define DISP_PARA_SWAP_EN		BIT(30)
+#define DISP_PARA_LINE_PATTERN(x)	REG_PUT((x), 29, 26)
+   /* line pattern formats (output) */
+   #define LP_RGB888_OR_YUV444		0x0
+   #define LP_RBG888			0x1
+   #define LP_GBR888			0x2
+   #define LP_GRB888_OR_UYV444		0x3
+   #define LP_BRG888			0x4
+   #define LP_BGR888			0x5
+   #define LP_RGB555			0x6
+   #define LP_RGB565			0x7
+   #define LP_YUYV_16_0			0x8
+   #define LP_UYVY_16_0			0x9
+   #define LP_YVYU_16_0			0xa
+   #define LP_VYUY_16_0			0xb
+   #define LP_YUYV_23_8			0xc
+   #define LP_UYVY_23_8			0xd
+   #define LP_YVYU_23_8			0xe
+   #define LP_VYUY_23_8			0xf
+
+#define DISP_PARA_DISP_MODE(x)		REG_PUT((x), 25, 24)
+#define DISP_PARA_BGND_R(x)		REG_PUT((x), 23, 16)
+#define DISP_PARA_BGND_G(x)		REG_PUT((x), 15,  8)
+#define DISP_PARA_BGND_B(x)		REG_PUT((x),  7,  0)
+
+#define DISP_SIZE_DELTA_Y(x)		REG_PUT((x), 31, 16)
+#define DISP_SIZE_DELTA_X(x)		REG_PUT((x), 15,  0)
+
+#define HSYN_PARA_BP_H(x)		REG_PUT((x), 31, 16)
+#define HSYN_PARA_FP_H(x)		REG_PUT((x), 15,  0)
+
+#define VSYN_PARA_BP_V(x)		REG_PUT((x), 31, 16)
+#define VSYN_PARA_FP_V(x)		REG_PUT((x), 15,  0)
+
+#define VSYN_HSYN_WIDTH_PW_V(x)		REG_PUT((x), 31, 16)
+#define VSYN_HSYN_WIDTH_PW_H(x)		REG_PUT((x), 15,  0)
+
+#define INT_STATUS_D0_FIFO_EMPTY	BIT(24)
+#define INT_STATUS_D0_DMA_DONE		BIT(16)
+#define INT_STATUS_D0_DMA_ERR		BIT(8)
+#define INT_STATUS_D0_VS_BLANK		BIT(2)
+#define INT_STATUS_D0_UNDERRUN		BIT(1)
+#define INT_STATUS_D0_VSYNC		BIT(0)
+
+#define INT_ENABLE_D0_FIFO_EMPTY_EN	BIT(24)
+#define INT_ENABLE_D0_DMA_DONE_EN	BIT(16)
+#define INT_ENABLE_D0_DMA_ERR_EN	BIT(8)
+#define INT_ENABLE_D0_VS_BLANK_EN	BIT(2)
+#define INT_ENABLE_D0_UNDERRUN_EN	BIT(1)
+#define INT_ENABLE_D0_VSYNC_EN		BIT(0)
+
+#define INT_STATUS_D1_PLANE_PANIC	BIT(0)
+#define INT_ENABLE_D1_PLANE_PANIC_EN	BIT(0)
+
+#define CTRLDESCL0_1_HEIGHT(x)		REG_PUT((x), 31, 16)
+#define CTRLDESCL0_1_WIDTH(x)		REG_PUT((x), 15,  0)
+#define CTRLDESCL0_3_STATE_CLEAR_VSYNC	BIT(23)
+#define CTRLDESCL0_3_P_SIZE(x)		REG_PUT((x), 22, 20)
+#define CTRLDESCL0_3_T_SIZE(x)		REG_PUT((x), 17, 16)
+#define CTRLDESCL0_3_PITCH(x)		REG_PUT((x), 15,  0)
+//#define CTRLDESCL_LOW0_4_ADDR_LOW(x)	REG_PUT((x), 31,  0)
+#define CTRLDESCL_HIGH0_4_ADDR_HIGH(x)	REG_PUT((x),  3,  0)
+#define CTRLDESCL0_5_EN			BIT(31)	/* enable layer for DMA */
+#define CTRLDESCL0_5_SHADOW_LOAD_EN	BIT(30)
+#define CTRLDESCL0_5_BPP(x)		REG_PUT((x), 27, 24)
+   /* layer encoding formats (input) */
+   #define BPP16_RGB565			0x4
+   #define BPP16_ARGB1555		0x5
+   #define BPP16_ARGB4444		0x6
+   #define BPP16_YCbCr422		0x7
+   #define BPP24_RGB888			0x8
+   #define BPP32_ARGB8888		0x9
+   #define BPP32_ABGR8888		0xa
+#define CTRLDESCL0_5_YUV_FORMAT(x)	REG_PUT((x), 15, 14)
+
+#define CSC0_CTRL_CSC_MODE(x)		REG_PUT((x),  2,  1)
+#define CSC0_CTRL_BYPASS		BIT(0)
+#define CSC0_COEF0_A2(x)		REG_PUT((x), 26, 16)
+#define CSC0_COEF0_A1(x)		REG_PUT((x), 10,  0)
+#define CSC0_COEF1_B1(x)		REG_PUT((x), 26, 16)
+#define CSC0_COEF1_A3(x)		REG_PUT((x), 10,  0)
+#define CSC0_COEF2_B3(x)		REG_PUT((x), 26, 16)
+#define CSC0_COEF2_B2(x)		REG_PUT((x), 10,  0)
+#define CSC0_COEF3_C2(x)		REG_PUT((x), 26, 16)
+#define CSC0_COEF3_C1(x)		REG_PUT((x), 10,  0)
+#define CSC0_COEF4_D1(x)		REG_PUT((x), 24, 16)
+#define CSC0_COEF4_C3(x)		REG_PUT((x), 10,  0)
+#define CSC0_COEF5_D3(x)		REG_PUT((x), 24, 16)
+#define CSC0_COEF5_D2(x)		REG_PUT((x),  8,  0)
+
+#define PANIC0_THRES_PANIC_THRES_LOW(x)	REG_PUT((x), 24, 16)
+#define PANIC0_THRES_PANIC_THRES_HIGH(x)	REG_PUT((x), 8, 0)
+
+#endif /* __LCDIFV3_REGS_H */
-- 
2.25.1

